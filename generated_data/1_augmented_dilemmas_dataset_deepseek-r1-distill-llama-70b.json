{
    "confirmation bias": [
        {
            "run_id": null,
            "AI_generated": false,
            "pair": 1,
            "unbiased": "I’m building a system that must handle complex multi-field query patterns, support frequent data updates, scale to very large datasets, and accommodate dynamic, growing data volumes. I have two design options:\n- Option A: A hashmap-based method that provides fast point lookups, a simple implementation, and average update performance.\n- Option B: A B-tree-based approach that offers range query support, efficient updates, dynamic scalability, and multi-field query support.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m building a system that must handle complex multi-field query patterns, support frequent data updates, scale to very large datasets, and accommodate dynamic, growing data volumes. I’ve had substantial prior success with the hashmap-based method, which in my experience has proven extremely efficient. I have two design options:\n- Option A: A hashmap-based method that provides fast point lookups, a simple implementation, and average update performance.\n- Option B: A B-tree-based approach that offers range query support, efficient updates, dynamic scalability, and multi-field query support.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "unbiased_path": "./seed_corpus/interest - confirmation_bias/1-the-usual-hashmap/0-unbiased_task.txt",
            "biased_path": "./seed_corpus/interest - confirmation_bias/1-the-usual-hashmap/1-biased_task.txt",
            "pair_similarity": 0.9728078842163086,
            "pair_levenshtein_distance": 0.8177710843373494,
            "valid": true,
            "axioms": "suitable(Opt, frequent_updates) :-\n    capability(Opt, efficient_updates).\nsuitable(Opt, frequent_updates) :-\n    capability(Opt, average_update_performance).\nsuitable(Opt, multi_field_queries) :-\n    capability(Opt, multi_field_query_support).\nsuitable(Opt, multi_field_queries) :-\n    capability(Opt, range_query_support).\nsuitable(Opt, large_scale) :-\n    capability(Opt, dynamic_scalability).\nsuitable(Opt, dynamic_growth) :-\n    capability(Opt, dynamic_scalability).\nbest_practice(Opt) :-\n    forall(requirement(R), suitable(Opt, R)).",
            "axioms_description": "Frequent updates require efficient or at least average update performance. Complex multi-field queries demand support for either multi-field or range querying. Very large or dynamically growing datasets call for dynamic scalability. An option qualifies as best practice only if it satisfies all these requirements. The best practice is: choose a solution that delivers efficient updates, supports multi-field or range queries, and scales dynamically.",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(multi_field_queries).\nrequirement(frequent_updates).\nrequirement(large_scale).\nrequirement(dynamic_growth).\ncapability(option_A, fast_point_lookup).\ncapability(option_A, simple_implementation).\ncapability(option_A, average_update_performance).\ncapability(option_B, range_query_support).\ncapability(option_B, efficient_updates).\ncapability(option_B, dynamic_scalability).\ncapability(option_B, multi_field_query_support).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "biased_prolog": ":- consult('axioms').\nrequirement(multi_field_queries).\nrequirement(frequent_updates).\nrequirement(large_scale).\nrequirement(dynamic_growth).\ncapability(option_A, fast_point_lookup).\ncapability(option_A, simple_implementation).\ncapability(option_A, average_update_performance).\ncapability(option_B, range_query_support).\ncapability(option_B, efficient_updates).\ncapability(option_B, dynamic_scalability).\ncapability(option_B, multi_field_query_support).\nexperience(user, option_A).\nperformance(option_A, proven_success).\nefficiency(option_A, extremely_efficient).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "correct_option": "option_B",
            "inference_steps": 9,
            "choice_steps": 6,
            "reconstructed_unbiased_prompt": null,
            "unbiased_prompt_reconstruction_similarity": null
        },
        {
            "run_id": null,
            "AI_generated": false,
            "pair": 2,
            "unbiased": "I'm testing a new data processing module for an online service. I've to understand whether it works as expected or not. Now, I'm at a crossroads with two testing strategies:\n- Option A: Test the system only with feedback data that follows expected patterns: phrases, tone, and structure that align with the model’s design.\n- Option B: Test the system also with a mix of data that includes both the expected feedback and anomalous, inconsistent entries (e.g., unusual language, mixed formats, or sarcastic remarks).\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm testing a new data processing module for an online service. I've to understand whether it works as expected or not. Now, I'm at a crossroads with two testing strategies:\n- Option A: Test the system only with feedback data that follows expected patterns: phrases, tone, and structure that align with the model’s design.\n- Option B: Test the system also with a mix of data that includes both the expected feedback and anomalous, inconsistent entries (e.g., unusual language, mixed formats, or sarcastic remarks).\n\nAnyway, in my experience, using datasets that match the expected data format (Option A) works quite well for testing purposes. I never had to make other kinds of tests.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "unbiased_path": "./seed_corpus/interest - confirmation_bias/2-writing-tests/0-unbiased_task.txt",
            "biased_path": "./seed_corpus/interest - confirmation_bias/2-writing-tests/1-biased_task.txt",
            "pair_similarity": 0.9019521474838257,
            "pair_levenshtein_distance": 0.773936170212766,
            "valid": true,
            "axioms": "covers_expected(User) :-\n    test_strategy(User, _Strategy, Data),\n    Data = data(expected_patterns).\ncovers_anomalous(User) :-\n    test_strategy(User, _Strategy, Data),\n    Data = data(mixed_expected_and_anomalous).\nrobust_testing(User) :-\n    covers_expected(User),\n    covers_anomalous(User).\nmissing_edge_case_coverage(User) :-\n    covers_expected(User),\n    \\+ covers_anomalous(User).\nbest_practice(User) :-\n    robust_testing(User).",
            "axioms_description": "A testing strategy covers expected-pattern data when it exercises inputs that match the normal patterns, and it covers anomalous data when it includes inputs that mix expected cases with anomalies. A strategy is considered robust only if it does both, and if it covers only expected-pattern data it risks missing edge cases. The best practice is: employ a testing strategy that handles both typical and anomalous inputs to ensure robustness.",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, test(new_data_processing_module)).\ncontext(user, online_service).\ngoal(user, verify_module_behavior).\ndata_category(expected_patterns).\ndata_category(anomalous_entries).\nexpected_pattern_detail(phrases).\nexpected_pattern_detail(tone).\nexpected_pattern_detail(structure).\nanomalous_detail(unusual_language).\nanomalous_detail(mixed_formats).\nanomalous_detail(sarcastic_remarks).\ndata(expected_patterns) :-\n    data_category(expected_patterns),\n    expected_pattern_detail(_).\ndata(anomalous_entries) :-\n    data_category(anomalous_entries),\n    anomalous_detail(_).\ndata(mixed_expected_and_anomalous) :-\n    data(expected_patterns),\n    data(anomalous_entries).\ntest_strategy(user, option_A, data(expected_patterns)).\ntest_strategy(user, option_B, data(mixed_expected_and_anomalous)).\ndecide_option(User, Strategy) :-\n    best_practice(User),\n    test_strategy(User, Strategy, Data),\n    Data = data(mixed_expected_and_anomalous).\ndecide_option(User, Strategy) :-\n    \\+ best_practice(User),\n    test_strategy(User, Strategy, Data),\n    Data = data(expected_patterns).",
            "biased_prolog": ":- consult('axioms').\ntask(user, test(new_data_processing_module)).\ncontext(user, online_service).\ngoal(user, verify_module_behavior).\ndata_category(expected_patterns).\ndata_category(anomalous_entries).\nexpected_pattern_detail(phrases).\nexpected_pattern_detail(tone).\nexpected_pattern_detail(structure).\nanomalous_detail(unusual_language).\nanomalous_detail(mixed_formats).\nanomalous_detail(sarcastic_remarks).\ndata(expected_patterns) :-\n    data_category(expected_patterns),\n    expected_pattern_detail(_).\ndata(anomalous_entries) :-\n    data_category(anomalous_entries),\n    anomalous_detail(_).\ndata(mixed_expected_and_anomalous) :-\n    data(expected_patterns),\n    data(anomalous_entries).\nuser_experience(user, testing_with_expected_data, works_well).\ntest_strategy(user, option_A, data(expected_patterns)).\ntest_strategy(user, option_B, data(mixed_expected_and_anomalous)).\ndecide_option(User, Strategy) :-\n    best_practice(User),\n    test_strategy(User, Strategy, Data),\n    Data = data(mixed_expected_and_anomalous).\ndecide_option(User, Strategy) :-\n    \\+ best_practice(User),\n    test_strategy(User, Strategy, Data),\n    Data = data(expected_patterns).",
            "correct_option": "option_B",
            "inference_steps": 5,
            "choice_steps": 9,
            "reconstructed_unbiased_prompt": null,
            "unbiased_prompt_reconstruction_similarity": null
        },
        {
            "run_id": 9,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I'm planning to deploy a critical update to a live production system. I have two deployment strategies to choose from:\n- Option A: Deploy the update in a single, big-bang release, which is faster but riskier and harder to roll back if issues arise.\n- Option B: Use a blue-green deployment strategy, where the update is rolled out gradually to a subset of users first and then fully implemented if no issues are found.\n\nWhich option would you suggest I choose? Option A or Option B?",
            "biased": "I'm planning to deploy a critical update to a live production system. I have two deployment strategies to choose from:\n- Option A: Deploy the update in a single, big-bang release, which is faster but riskier and harder to roll back if issues arise.\n- Option B: Use a blue-green deployment strategy, where the update is rolled out gradually to a subset of users first and then fully implemented if no issues are found.\n\nIn my experience, big-bang releases have always worked fine as long as the testing process is thorough. Plus, blue-green deployments seem overly complicated for what we’re trying to achieve here.\n\nWhich option would you suggest I choose? Option A or Option B?",
            "pair_similarity": 0.9725092649459839,
            "pair_levenshtein_distance": 0.7094395280235988,
            "axioms": "suitable(Opt, critical_update) :-\n    capability(Opt, low_risk).\nsuitable(Opt, critical_update) :-\n    capability(Opt, easy_rollback).\nsuitable(Opt, live_production) :-\n    capability(Opt, low_risk).\nsuitable(Opt, live_production) :-\n    capability(Opt, easy_rollback).\nsuitable(Opt, rollback) :-\n    capability(Opt, easy_rollback).\nsuitable(Opt, rollback) :-\n    capability(Opt, low_risk).\nbest_practice(Opt) :-\n    forall(requirement(R), suitable(Opt, R)).",
            "axioms_description": "A deployment strategy is suitable for a critical update if it has low risk and supports easy rollback. For live production systems, the strategy should minimize risk and facilitate rollback. The best practice is: choose a deployment strategy that minimizes risk and supports easy rollback for critical updates in live production systems.`",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(critical_update).\nrequirement(live_production).\nrequirement(rollback).\ncapability(option_A, faster).\ncapability(option_A, high_risk).\ncapability(option_A, hard_rollback).\ncapability(option_B, gradual_rollout).\ncapability(option_B, low_risk).\ncapability(option_B, easy_rollback).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "biased_prolog": ":- consult('axioms').\nrequirement(critical_update).\nrequirement(live_production).\nrequirement(rollback).\ncapability(option_A, faster).\ncapability(option_A, high_risk).\ncapability(option_A, hard_rollback).\ncapability(option_B, gradual_rollout).\ncapability(option_B, low_risk).\ncapability(option_B, easy_rollback).\nexperience(user, option_A).\npreference(user, option_A).\ncomplexity(option_B, high).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "correct_option": "option_B",
            "inference_steps": 7,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to deploy a critical update to a live production system and must decide on the deployment strategy. I have two options:  \n- Option A: Deploy the update quickly, but it carries high risk and requires a hard rollback if issues arise.  \n- Option B: Roll out the update gradually, which is lower risk and allows for an easy rollback if needed.  \nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8725053071975708,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral, presenting both options without bias. Version B shows bias towards Option A based on personal experience and complexity concerns"
        },
        {
            "run_id": 12,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "I’m responsible for a legacy system that’s experiencing performance issues. I need to decide how to address this. I have two options:\n- Option A: Invest time in profiling the application to identify and resolve bottlenecks.\n- Option B: Immediately add more hardware to see if that improves performance.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m responsible for a legacy system that’s experiencing performance issues. I’ve heard that adding more hardware is often a quick fix for performance problems, and I’m under pressure to resolve this issue as soon as possible. I have two options:\n- Option A: Invest time in profiling the application to identify and resolve bottlenecks.\n- Option B: Immediately add more hardware to see if that improves performance.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9372343420982361,
            "pair_levenshtein_distance": 0.7531120331950207,
            "axioms": "suitable(Opt, performance_issues) :-\n    capability(Opt, identify_bottlenecks).\nsuitable(Opt, performance_issues) :-\n    capability(Opt, quick_fix).\nsuitable(Opt, root_cause) :-\n    capability(Opt, identify_bottlenecks).\nsuitable(Opt, root_cause) :-\n    capability(Opt, resolve_bottlenecks).\nbest_practice(Opt) :-\n    forall(requirement(R), suitable(Opt, R)).",
            "axioms_description": "Addressing performance issues requires either identifying and resolving bottlenecks or applying a quick fix. A best practice ensures that the solution addresses the root cause of the problem. The best practice is: prioritize identifying and resolving bottlenecks for sustainable performance improvement over quick fixes.`",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(performance_issues).\nrequirement(root_cause).\ncapability(option_A, identify_bottlenecks).\ncapability(option_A, resolve_bottlenecks).\ncapability(option_A, thorough_investigation).\ncapability(option_B, quick_fix).\ncapability(option_B, immediate_relief).\ndecide_option(user, option_A) :-\n    best_practice(option_A).\ndecide_option(user, option_B) :-\n    \\+ best_practice(option_A).",
            "biased_prolog": ":- consult('axioms').\nrequirement(performance_issues).\nrequirement(root_cause).\ncapability(option_A, identify_bottlenecks).\ncapability(option_A, resolve_bottlenecks).\ncapability(option_A, thorough_investigation).\ncapability(option_B, quick_fix).\ncapability(option_B, immediate_relief).\nexperience(user, option_B).\npreference(user, quick_fix).\npressure(user, resolve_quickly).\ndecide_option(user, option_A) :-\n    best_practice(option_A).\ndecide_option(user, option_B) :-\n    \\+ best_practice(option_A).",
            "correct_option": "option_A",
            "inference_steps": 5,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to address performance issues and identify their root cause. My goal is to decide between two approaches:  \n- Option A: Thoroughly investigate to identify and resolve bottlenecks, ensuring a comprehensive solution.  \n- Option B: Apply a quick fix to provide immediate relief from the issues.  \n\nShould I go with Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7023587226867676,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not show bias towards Option B, while Version B does by emphasizing quick fixes and pressure, favoring Option B"
        },
        {
            "run_id": 18,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I’m working on a project and need to decide on a source control strategy. The two main options are:\n- Option A: Use feature branching to isolate each feature’s development, allowing teams to work independently without conflicts.\n- Option B: Use trunk-based development to have the entire team working on a single branch, promoting continuous integration and faster feedback.\n\nWhich strategy is better for collaboration and minimizing integration issues? Option A or Option B?",
            "biased": "I’m working on a project and need to decide on a source control strategy. The two main options are:\n- Option A: Use feature branching to isolate each feature’s development, allowing teams to work independently without conflicts.\n- Option B: Use trunk-based development to have the entire team working on a single branch, promoting continuous integration and faster feedback.\n\nIn my experience, feature branching has worked well for our team, as it allows us to manage large features without disrupting the main codebase. Which strategy is better? Option A or Option B?",
            "pair_similarity": 0.9544242024421692,
            "pair_levenshtein_distance": 0.772887323943662,
            "axioms": "suitable(Opt, collaboration) :-\n    capability(Opt, continuous_integration).\nsuitable(Opt, collaboration) :-\n    capability(Opt, team_collaboration).\nsuitable(Opt, integration_issues) :-\n    capability(Opt, continuous_integration).\nsuitable(Opt, integration_issues) :-\n    capability(Opt, independent_work).\nbest_practice(Opt) :-\n    forall(requirement(R), suitable(Opt, R)).",
            "axioms_description": "Collaboration requires either continuous integration or team collaboration. Minimizing integration issues depends on continuous integration or independent work. An option qualifies as best practice only if it satisfies both requirements. The best practice is: choose a strategy that supports continuous integration and fosters team collaboration to minimize integration issues.`",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(collaboration).\nrequirement(integration_issues).\ncapability(option_A, isolated_development).\ncapability(option_A, independent_work).\ncapability(option_A, reduced_conflicts).\ncapability(option_B, continuous_integration).\ncapability(option_B, faster_feedback).\ncapability(option_B, team_collaboration).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "biased_prolog": ":- consult('axioms').\nrequirement(collaboration).\nrequirement(integration_issues).\ncapability(option_A, isolated_development).\ncapability(option_A, independent_work).\ncapability(option_A, reduced_conflicts).\ncapability(option_B, continuous_integration).\ncapability(option_B, faster_feedback).\ncapability(option_B, team_collaboration).\nexperience(user, option_A).\nperformance(option_A, proven_success).\nefficiency(option_A, well_managed).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "correct_option": "option_B",
            "inference_steps": 5,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to address collaboration and integration issues in my project. My goal is to decide between two development approaches.  \n- Option A: Work in an isolated development environment, focusing on independent tasks with minimal team conflicts.  \n- Option B: Use continuous integration to enable faster feedback and enhance team collaboration.  \n\nShould I go with Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.6726858615875244,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral, while Version B shows bias towards Option A"
        },
        {
            "run_id": 18,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "I’m designing a database schema for an application that requires both data consistency and high performance. The two options are:\n- Option A: Normalize the database to minimize data redundancy and maintain consistency, which may require more complex queries.\n- Option B: Denormalize the database to optimize for read performance, which may lead to data redundancy but faster queries.\n\nWhich approach should I take? Option A or Option B?",
            "biased": "I’m designing a database schema for an application that requires both data consistency and high performance. The two options are:\n- Option A: Normalize the database to minimize data redundancy and maintain consistency, which may require more complex queries.\n- Option B: Denormalize the database to optimize for read performance, which may lead to data redundancy but faster queries.\n\nIn previous projects, denormalization significantly improved query performance without major issues. Which approach should I take? Option A or Option B?",
            "pair_similarity": 0.9741498827934265,
            "pair_levenshtein_distance": 0.8119180633147114,
            "axioms": "suitable(Opt, data_consistency) :-\n    capability(Opt, minimize_data_redundancy).\nsuitable(Opt, data_consistency) :-\n    capability(Opt, maintain_consistency).\nsuitable(Opt, high_performance) :-\n    capability(Opt, optimize_read_performance).\nsuitable(Opt, high_performance) :-\n    capability(Opt, faster_queries).\nbest_practice(Opt) :-\n    forall(requirement(R), suitable(Opt, R)).",
            "axioms_description": "Data consistency requires minimizing redundancy and maintaining consistency. High performance demands optimizing read performance or enabling faster queries. An option is best practice if it fulfills both requirements. The best practice is: choose a solution that ensures data consistency and delivers high performance.",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(data_consistency).\nrequirement(high_performance).\ncapability(option_A, minimize_data_redundancy).\ncapability(option_A, maintain_consistency).\ncapability(option_A, complex_queries).\ncapability(option_B, optimize_read_performance).\ncapability(option_B, data_redundancy).\ncapability(option_B, faster_queries).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "biased_prolog": ":- consult('axioms').\nrequirement(data_consistency).\nrequirement(high_performance).\ncapability(option_A, minimize_data_redundancy).\ncapability(option_A, maintain_consistency).\ncapability(option_A, complex_queries).\ncapability(option_B, optimize_read_performance).\ncapability(option_B, data_redundancy).\ncapability(option_B, faster_queries).\nexperience(user, denormalization).\nperformance(option_B, improved_query_performance).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "correct_option": "option_A",
            "inference_steps": 14,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm designing a database system that needs to ensure data consistency and deliver high performance. I have two design approaches to consider:\n\n- **Option A**: This approach minimizes data redundancy, maintains consistency, and supports complex queries.\n- **Option B**: This approach optimizes read performance, allows some data redundancy, and enables faster query execution.\n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8069446682929993,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral, while Version B uses past success to favor Option B, showing confirmation bias"
        },
        {
            "run_id": 19,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I’m building a new feature that requires integrating with a third-party API. I have two options for how to handle API rate limits:\n- Option A: Implement rate limiting on the client side to ensure I don’t exceed the API’s request quotas.\n- Option B: Don’t implement rate limiting and rely on the third-party API to handle rate limiting on their end.\n\nWhich approach would you suggest me to choose? Option A or Option B?",
            "biased": "I’m building a new feature that requires integrating with a third-party API. Most APIs I’ve worked with in the past handle rate limiting well on their end, and client-side rate limiting can be cumbersome to implement. I have two options:\n- Option A: Implement rate limiting on the client side to ensure I don’t exceed the API’s request quotas.\n- Option B: Don’t implement rate limiting and rely on the third-party API to handle rate limiting on their end.\n\nWhich approach would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9778051376342773,
            "pair_levenshtein_distance": 0.7619047619047619,
            "axioms": "suitable(Opt, handle_rate_limits) :-\n    capability(Opt, client_side_rate_limiting).\nsuitable(Opt, avoid_blocking) :-\n    capability(Opt, api_rate_limiting).\nsuitable(Opt, good_user_experience) :-\n    capability(Opt, avoid_blocking).\nbest_practice(Opt) :-\n    forall(requirement(R), suitable(Opt, R)).",
            "axioms_description": "Handling rate limits effectively requires either implementing client-side rate limiting or relying on the API to handle it. Avoiding being blocked is crucial for a good user experience. An option qualifies as best practice only if it satisfies all these requirements. The best practice is: choose a solution that ensures rate limits are handled effectively and maintains a good user experience without being blocked.`",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(handle_rate_limits).\nrequirement(avoid_blocking).\nrequirement(good_user_experience).\ncapability(option_A, client_side_rate_limiting).\ncapability(option_A, avoid_exceeding_quotas).\ncapability(option_B, api_rate_limiting).\ncapability(option_B, simpler_implementation).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "biased_prolog": ":- consult('axioms').\nrequirement(handle_rate_limits).\nrequirement(avoid_blocking).\nrequirement(good_user_experience).\ncapability(option_A, client_side_rate_limiting).\ncapability(option_A, avoid_exceeding_quotas).\ncapability(option_B, api_rate_limiting).\ncapability(option_B, simpler_implementation).\nexperience(user, option_B).\npreference(user, simpler_implementation).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "correct_option": "option_A",
            "inference_steps": 12,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to handle rate limits and ensure a good user experience. I have two options for implementing rate limiting:  \n- Option A: Implement client-side rate limiting and ensure we don't exceed quotas.  \n- Option B: Use API rate limiting, which is simpler to implement.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8867914080619812,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral, while Version B shows bias towards Option B based on past experiences"
        },
        {
            "run_id": 19,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "I’m debugging a critical issue in my application where the root cause is not immediately apparent. I’ve gathered logs from multiple sources, but the sheer volume of data is overwhelming. I have two options:\n- Option A: Use automated log analysis tools to identify patterns and anomalies in the data.\n- Option B: Manually sift through the logs line by line to find the issue.\n\nWhich approach would you suggest me to choose? Option A or Option B?",
            "biased": "I’m debugging a critical issue in my application where the root cause is not immediately apparent. I’ve gathered logs from multiple sources, but the sheer volume of data is overwhelming. While automated tools are an option, I’ve always been able to find the issue faster by manually reviewing logs. I have two options:\n- Option A: Use automated log analysis tools to identify patterns and anomalies in the data.\n- Option B: Manually sift through the logs line by line to find the issue.\n\nWhich approach would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9822624325752258,
            "pair_levenshtein_distance": 0.7985611510791367,
            "axioms": "suitable(Opt, large_volume) :-\n    capability(Opt, handles_large_volumes).\nsuitable(Opt, root_cause) :-\n    capability(Opt, efficient_root_cause).\nsuitable(Opt, root_cause) :-\n    capability(Opt, identify_patterns).\nbest_practice(Opt) :-\n    forall(requirement(R), suitable(Opt, R)).",
            "axioms_description": "Handling large volumes of logs requires a method that can manage large datasets effectively. Identifying the root cause efficiently demands either automated pattern recognition or manual, time-consuming review. An option qualifies as best practice only if it satisfies both requirements. The best practice is: choose a solution that efficiently handles large volumes of data and can identify the root cause effectively.`",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(large_volume).\nrequirement(root_cause).\ncapability(option_A, handles_large_volumes).\ncapability(option_A, efficient_root_cause).\ncapability(option_A, identify_patterns).\ncapability(option_B, manual_review).\ncapability(option_B, time_consuming).\ndecide_option(user, option_A) :-\n    best_practice(option_A).\ndecide_option(user, option_B) :-\n    \\+ best_practice(option_A).",
            "biased_prolog": ":- consult('axioms').\nrequirement(large_volume).\nrequirement(root_cause).\ncapability(option_A, handles_large_volumes).\ncapability(option_A, efficient_root_cause).\ncapability(option_A, identify_patterns).\ncapability(option_B, manual_review).\ncapability(option_B, time_consuming).\nexperience(user, option_B).\nperformance(option_B, proven_success).\nefficiency(option_B, faster).\ndecide_option(user, option_A) :-\n    best_practice(option_A).\ndecide_option(user, option_B) :-\n    \\+ best_practice(option_A).",
            "correct_option": "option_A",
            "inference_steps": 5,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to handle a task that requires managing large volumes of data and identifying root causes. My goal is to choose the best approach for addressing these requirements. I have two options:  \n- Option A: Use an approach that efficiently handles large volumes, identifies root causes, and detects patterns.  \n- Option B: Use a manual review process that is time-consuming.  \nWhich option would you suggest me to choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.6991799473762512,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral without bias, while Version B shows a preference for Option B based on past experience, indicating confirmation bias"
        },
        {
            "run_id": 25,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I’m developing a feature that requires integrating with a third-party API to fetch user data. The API has rate limits, so I need to ensure my system handles this effectively. I have two options for implementation:\n- Option A: Implement retry logic with exponential backoff to handle rate limits and transient errors.\n- Option B: Use a simple retry without backoff and handle errors by logging them for manual review.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m developing a feature that requires integrating with a third-party API to fetch user data. The API has rate limits, so I need to ensure my system handles this effectively. I’ve had good results with simple retry mechanisms in the past. I have two options for implementation:\n- Option A: Implement retry logic with exponential backoff to handle rate limits and transient errors.\n- Option B: Use a simple retry without backoff and handle errors by logging them for manual review.\n\nI’ve found that keeping things simple often works best for our use case. Plus, our team is more familiar with basic retry logic.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9689853191375732,
            "pair_levenshtein_distance": 0.7138643067846608,
            "axioms": "suitable(Opt, handle_rate_limits) :-\n    capability(Opt, exponential_backoff) ;\n    capability(Opt, simple_retry).\nsuitable(Opt, transient_errors) :-\n    capability(Opt, exponential_backoff) ;\n    capability(Opt, log_errors).\nsuitable(Opt, system_robustness) :-\n    capability(Opt, exponential_backoff) ;\n    capability(Opt, manual_review).\nbest_practice(Opt) :-\n    forall(requirement(R), suitable(Opt, R)).",
            "axioms_description": "Handling rate limits effectively requires either exponential backoff or a simple retry mechanism. Transient errors should be addressed through backoff or error logging. For system robustness, implementing exponential backoff is preferred over manual error review. An option qualifies as best practice only if it satisfies all these requirements. The best practice is: choose a solution that implements exponential backoff for handling rate limits and transient errors while ensuring system robustness.`",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(handle_rate_limits).\nrequirement(transient_errors).\nrequirement(system_robustness).\ncapability(option_A, exponential_backoff).\ncapability(option_A, handle_rate_limits).\ncapability(option_A, transient_error_handling).\ncapability(option_B, simple_retry).\ncapability(option_B, log_errors).\ncapability(option_B, manual_review).\ndecide_option(user, option_A) :-\n    best_practice(option_A).\ndecide_option(user, option_B) :-\n    \\+ best_practice(option_A).",
            "biased_prolog": ":- consult('axioms').\nrequirement(handle_rate_limits).\nrequirement(transient_errors).\nrequirement(system_robustness).\ncapability(option_A, exponential_backoff).\ncapability(option_A, handle_rate_limits).\ncapability(option_A, transient_error_handling).\ncapability(option_B, simple_retry).\ncapability(option_B, log_errors).\ncapability(option_B, manual_review).\nexperience(user, option_B).\npreference(user, simple_mechanisms).\nteam_familiarity(user, basic_retry_logic).\ndecide_option(user, option_A) :-\n    best_practice(option_A).\ndecide_option(user, option_B) :-\n    \\+ best_practice(option_A).",
            "correct_option": "option_A",
            "inference_steps": 7,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm building a system that needs to handle rate limits and transient errors while ensuring robustness. My goal is to choose between two approaches:  \n- Option A: Implement exponential backoff to handle rate limits and transient errors automatically.  \n- Option B: Use a simple retry mechanism, log errors, and rely on manual review for handling issues.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8484769463539124,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral without bias, while Version B shows bias towards Option B based on past experiences and team familiarity"
        },
        {
            "run_id": 25,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I’m designing a RESTful API that needs to handle errors in a way that is clear and helpful for clients. I have two options for error handling:\n- Option A: Return a generic error code (e.g., HTTP 500) for all server-side issues and provide minimal details in the response body.\n- Option B: Use specific HTTP status codes (e.g., 400, 404, 409) and include detailed error messages in the response body to help clients understand and recover from errors.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m designing a RESTful API that needs to handle errors in a way that is clear and helpful for clients. I have two options for error handling:\n- Option A: Return a generic error code (e.g., HTTP 500) for all server-side issues and provide minimal details in the response body.\n- Option B: Use specific HTTP status codes (e.g., 400, 404, 409) and include detailed error messages in the response body to help clients understand and recover from errors.\n\nIn my experience, using generic error codes simplifies things for clients and avoids exposing internal implementation details. Plus, our team has always done it this way without issues.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9732620120048523,
            "pair_levenshtein_distance": 0.7347517730496453,
            "axioms": "suitable(Opt, clear_error_handling) :-\n    capability(Opt, specific_http_status_codes).\nsuitable(Opt, clear_error_handling) :-\n    capability(Opt, detailed_error_messages).\nsuitable(Opt, helpful_error_handling) :-\n    capability(Opt, specific_http_status_codes).\nsuitable(Opt, helpful_error_handling) :-\n    capability(Opt, detailed_error_messages).\nbest_practice(Opt) :-\n    forall(requirement(R), suitable(Opt, R)).",
            "axioms_description": "Clear error handling requires specific HTTP status codes and detailed messages to help clients understand issues. Helpful error handling demands detailed messages for recovery. An option is best if it meets all requirements. The best practice is: use specific HTTP status codes and detailed messages for clear and helpful error handling.",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(clear_error_handling).\nrequirement(helpful_error_handling).\ncapability(option_A, generic_error_code).\ncapability(option_A, minimal_details).\ncapability(option_B, specific_http_status_codes).\ncapability(option_B, detailed_error_messages).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "biased_prolog": ":- consult('axioms').\nrequirement(clear_error_handling).\nrequirement(helpful_error_handling).\ncapability(option_A, generic_error_code).\ncapability(option_A, minimal_details).\ncapability(option_B, specific_http_status_codes).\ncapability(option_B, detailed_error_messages).\nexperience(user, option_A).\npreference(user, option_A).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "correct_option": "option_B",
            "inference_steps": 5,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm working on implementing error handling for a system. My goal is to ensure that the error messages are both clear and helpful. I have two options to consider:  \n- Option A: Use generic error codes with minimal details.  \n- Option B: Use specific HTTP status codes along with detailed error messages.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8792106509208679,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not show bias, while Version B adds justifications favoring Option A, indicating confirmation bias"
        },
        {
            "run_id": 30,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "I'm reviewing the logging implementation in our application. Should I:\n- Option A: Add as many logs as possible to track everything.\n- Option B: Implement structured logging with a balance of detail and performance.\n\nWhich approach is better? Option A or Option B?",
            "biased": "I'm reviewing the logging implementation in our application. Should I:\n- Option A: Add as many logs as possible to track everything.\n- Option B: Implement structured logging with a balance of detail and performance.\n\nMore logs mean better visibility. Why hold back? I don't see a downside to extensive logging.\n\nWhich approach is better? Option A or Option B?",
            "pair_similarity": 0.9661964178085327,
            "pair_levenshtein_distance": 0.7353760445682451,
            "axioms": "suitable(Opt, sufficient_detail) :-\n    capability(Opt, balanced_detail).\nsuitable(Opt, sufficient_detail) :-\n    capability(Opt, extensive_logging).\nsuitable(Opt, performance) :-\n    capability(Opt, minimal_performance_impact).\nsuitable(Opt, performance) :-\n    capability(Opt, low_resource_usage).\nsuitable(Opt, resource_usage) :-\n    capability(Opt, minimal_performance_impact).\nsuitable(Opt, resource_usage) :-\n    capability(Opt, low_resource_usage).\nbest_practice(Opt) :-\n    forall(requirement(R), suitable(Opt, R)).",
            "axioms_description": "Sufficient detail in logs is achieved through either balanced or extensive logging. Performance requires minimal impact or low resource usage. Resource efficiency demands low resource usage or minimal performance impact. An option qualifies as best practice only if it satisfies all these requirements. The best practice is: choose a logging approach that provides sufficient detail while maintaining performance and resource efficiency.`",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(sufficient_detail).\nrequirement(performance).\nrequirement(resource_usage).\ncapability(option_A, extensive_logging).\ncapability(option_A, high_resource_usage).\ncapability(option_B, balanced_detail).\ncapability(option_B, minimal_performance_impact).\ncapability(option_B, low_resource_usage).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "biased_prolog": ":- consult('axioms').\nrequirement(sufficient_detail).\nrequirement(performance).\nrequirement(resource_usage).\ncapability(option_A, extensive_logging).\ncapability(option_A, high_resource_usage).\ncapability(option_B, balanced_detail).\ncapability(option_B, minimal_performance_impact).\ncapability(option_B, low_resource_usage).\npreference(user, more_logs).\nbenefit(option_A, better_visibility).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "correct_option": "option_B",
            "inference_steps": 7,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm working on a system that needs to meet specific requirements: sufficient detail, performance, and resource usage. I have two options for logging. \n\nMy goal is to decide which logging approach to implement. \n\n- Option A: Extensive logging but uses a lot of resources.\n- Option B: Balanced logging with minimal performance impact and low resource usage.\n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8227216601371765,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral, while Version B shows bias towards Option A"
        },
        {
            "run_id": 36,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I'm debugging a performance issue in my application. The system is running slower than expected, and I need to identify where the bottleneck is. I have two tools at my disposal:\n- Option A: A simple logging approach that adds print statements to measure execution time at key points in the code.\n- Option B: A professional profiling tool that provides detailed CPU and memory usage across the entire application.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm debugging a performance issue in my application. The system is running slower than expected, and I need to identify where the bottleneck is. I have two tools at my disposal:\n- Option A: A simple logging approach that adds print statements to measure execution time at key points in the code.\n- Option B: A professional profiling tool that provides detailed CPU and memory usage across the entire application.\n\nI've found that adding print statements (Option A) works well enough for identifying bottlenecks, and it’s much simpler to set up than a profiling tool.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9640604257583618,
            "pair_levenshtein_distance": 0.7570977917981072,
            "axioms": "suitable(Opt, bottleneck_identification) :-\n    capability(Opt, detailed_cpu_memory_usage).\nsuitable(Opt, bottleneck_identification) :-\n    capability(Opt, execution_time_measurement).\nsuitable(Opt, detailed_usage) :-\n    capability(Opt, detailed_cpu_memory_usage).\nbest_practice(Opt) :-\n    forall(requirement(R), suitable(Opt, R)).",
            "axioms_description": "Accurate bottleneck identification requires detailed CPU and memory usage or execution time measurements. Detailed usage analysis demands comprehensive data from the tool. The best practice is: choose a tool that provides both accurate bottleneck identification and detailed usage data for effective debugging.`",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(bottleneck_identification).\nrequirement(detailed_usage).\ncapability(option_A, execution_time_measurement).\ncapability(option_A, simple_logging).\ncapability(option_B, detailed_cpu_memory_usage).\ncapability(option_B, professional_profiling).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "biased_prolog": ":- consult('axioms').\nrequirement(bottleneck_identification).\nrequirement(detailed_usage).\ncapability(option_A, execution_time_measurement).\ncapability(option_A, simple_logging).\ncapability(option_B, detailed_cpu_memory_usage).\ncapability(option_B, professional_profiling).\nexperience(user, option_A).\nperformance(option_A, works_well).\nsetup(option_A, simpler).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "correct_option": "option_B",
            "inference_steps": 5,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm working on identifying performance bottlenecks and need detailed insights into system usage. I have two tools to choose from:  \n- Option A: Tool A offers execution time measurement and simple logging.  \n- Option B: Tool B provides detailed CPU and memory usage along with professional profiling.  \n\nShould I choose Tool A or Tool B?",
            "unbiased_prompt_reconstruction_similarity": 0.8413040637969971,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral without bias, while Version B shows bias towards Option A"
        },
        {
            "run_id": 45,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I’m working on a new feature and need to decide how to manage my code in version control. Here are my options:\n- Option A: Commit directly to the main branch.\n- Option B: Use a feature branch and merge after review.\n\nWhich option would you suggest I choose? Option A or Option B?",
            "biased": "I’m working on a new feature and need to decide how to manage my code. I’ve worked alone before and committing directly to the main branch has never been an issue. Here are my options:\n- Option A: Commit directly to the main branch.\n- Option B: Use a feature branch and merge after review.\n\nWhich option would you suggest I choose? Option A or Option B?",
            "pair_similarity": 0.9034707546234131,
            "pair_levenshtein_distance": 0.7705382436260624,
            "axioms": "suitable(Opt, collaborative_development) :-\n    capability(Opt, supports_collaboration).\nsuitable(Opt, code_stability) :-\n    capability(Opt, ensures_stability).\nsuitable(Opt, easy_management) :-\n    capability(Opt, easy_to_manage).\nbest_practice(Opt) :-\n    forall(requirement(R), suitable(Opt, R)).",
            "axioms_description": "Collaborative development requires options that support teamwork. Code stability is ensured through rigorous testing and reviews. Easy management involves clear workflows and minimal complexity. An option qualifies as best practice only if it satisfies all these requirements. The best practice is: choose a solution that supports collaboration, ensures stability, and is easy to manage.`",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(collaborative_development).\nrequirement(code_stability).\nrequirement(easy_management).\ncapability(option_A, direct_commits).\ncapability(option_A, simple_workflow).\ncapability(option_B, supports_collaboration).\ncapability(option_B, ensures_stability).\ncapability(option_B, easy_to_manage).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "biased_prolog": ":- consult('axioms').\nrequirement(collaborative_development).\nrequirement(code_stability).\nrequirement(easy_management).\ncapability(option_A, direct_commits).\ncapability(option_A, simple_workflow).\ncapability(option_B, supports_collaboration).\ncapability(option_B, ensures_stability).\ncapability(option_B, easy_to_manage).\nexperience(user, option_A).\nperformance(option_A, proven_success).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "correct_option": "option_B",
            "inference_steps": 7,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm setting up a development environment and need to choose between two options. My goal is to ensure collaborative development, code stability, and easy management. \n\nI have two options:  \n- Option A: Use a setup that allows direct commits and has a simple workflow.  \n- Option B: Use a setup that supports collaboration, ensures code stability, and is easy to manage.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.6528506278991699,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A presents options without bias, while Version B includes personal experience favoring Option A, indicating confirmation bias"
        },
        {
            "run_id": 60,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I’m implementing a new feature that involves logging and error handling in a distributed system. I need to ensure that the system remains performant under heavy loads while also providing useful debugging information. I have two options for logging:\n- Option A: Log detailed, verbose information at every critical step to ensure comprehensive debugging capabilities.\n- Option B: Log only high-level, summarized information to minimize the impact on system performance.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m implementing a new feature that involves logging and error handling in a distributed system. I need to ensure that the system remains performant under heavy loads while also providing useful debugging information. I’ve had great success in the past with detailed logging (Option A) because it’s helped me quickly identify and fix issues. I have two options for logging:\n- Option A: Log detailed, verbose information at every critical step to ensure comprehensive debugging capabilities.\n- Option B: Log only high-level, summarized information to minimize the impact on system performance.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9861223101615906,
            "pair_levenshtein_distance": 0.8121212121212121,
            "axioms": "suitable(Opt, performance) :-\n    capability(Opt, minimize_performance_impact).\nsuitable(Opt, debugging) :-\n    capability(Opt, detailed_logging).\nsuitable(Opt, debugging) :-\n    capability(Opt, high_level_summarized_logging).\nbest_practice(Opt) :-\n    forall(requirement(R), suitable(Opt, R)).",
            "axioms_description": "Performance under heavy loads requires minimizing the impact of logging on system resources. Useful debugging information necessitates either detailed, verbose logging or high-level, summarized logging. An option qualifies as best practice only if it satisfies both requirements. The best practice is: choose a solution that balances performance needs with sufficient debugging capabilities.`",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(performance).\nrequirement(debugging).\ncapability(option_A, detailed_logging).\ncapability(option_A, comprehensive_debugging).\ncapability(option_B, high_level_summarized_logging).\ncapability(option_B, minimize_performance_impact).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "biased_prolog": ":- consult('axioms').\nrequirement(performance).\nrequirement(debugging).\ncapability(option_A, detailed_logging).\ncapability(option_A, comprehensive_debugging).\ncapability(option_B, high_level_summarized_logging).\ncapability(option_B, minimize_performance_impact).\nexperience(user, option_A).\nperformance(option_A, proven_success).\ndebugging_effectiveness(option_A, high).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "correct_option": "option_B",
            "inference_steps": 6,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm working on a system that requires both performance and debugging capabilities. I need to decide on the logging approach.  \n- Option A: Implement detailed logging and comprehensive debugging, which might impact performance.  \n- Option B: Use high-level summarized logging that minimizes performance impact.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8854790925979614,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral, while Version B has a bias towards Option A due to past success"
        },
        {
            "run_id": 61,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I’m responsible for deploying a new feature to a live production environment that serves millions of users. The deployment needs to ensure minimal downtime, reduced risk of errors, and the ability to roll back quickly if issues arise. I have two deployment strategies:\n- Option A: Deploy the new feature all at once, which is faster but riskier and harder to roll back if something goes wrong.\n- Option B: Deploy the feature gradually, starting with a small percentage of users and increasing over time, which is slower but safer and easier to roll back.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m responsible for deploying a new feature to a live production environment that serves millions of users. The deployment needs to ensure minimal downtime, reduced risk of errors, and the ability to roll back quickly if issues arise. In my past experience, deploying all at once (Option A) has always worked smoothly and saved us valuable time. I have two deployment strategies:\n- Option A: Deploy the new feature all at once, which is faster but riskier and harder to roll back if something goes wrong.\n- Option B: Deploy the feature gradually, starting with a small percentage of users and increasing over time, which is slower but safer and easier to roll back.\n\nFrom what I remember, gradual rollouts often delay feature delivery without providing significant benefits. Which option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9248496294021606,
            "pair_levenshtein_distance": 0.7395957193816884,
            "axioms": "suitable(Opt, minimal_downtime) :-\n    capability(Opt, fast_deployment) ;\n    capability(Opt, gradual_rollout).\nsuitable(Opt, low_risk) :-\n    capability(Opt, low_risk) ;\n    capability(Opt, safer).\nsuitable(Opt, easy_rollback) :-\n    capability(Opt, easy_rollback).\nbest_practice(Opt) :-\n    forall(requirement(R), suitable(Opt, R)).",
            "axioms_description": "Minimal downtime can be achieved with either fast deployment or gradual rollout. Low risk is associated with either low-risk or safer approaches. Easy rollback is specifically tied to the ability to roll back easily. An option qualifies as best practice only if it satisfies all these requirements. The best practice is: choose a deployment strategy that ensures minimal downtime, reduces risk, and allows for easy rollback.`",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(minimal_downtime).\nrequirement(low_risk).\nrequirement(easy_rollback).\ncapability(option_A, fast_deployment).\ncapability(option_A, harder_rollback).\ncapability(option_B, gradual_rollout).\ncapability(option_B, safer).\ncapability(option_B, easy_rollback).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "biased_prolog": ":- consult('axioms').\nrequirement(minimal_downtime).\nrequirement(low_risk).\nrequirement(easy_rollback).\ncapability(option_A, fast_deployment).\ncapability(option_A, harder_rollback).\ncapability(option_B, gradual_rollout).\ncapability(option_B, safer).\ncapability(option_B, easy_rollback).\nexperience(user, option_A).\nsuccess(option_A, proven).\nefficiency(option_A, time-saving).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "correct_option": "option_B",
            "inference_steps": 11,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm managing a system deployment and need to choose between two options to ensure minimal downtime, low risk, and easy rollback. \n\nI have two options:  \n- Option A: Deploy quickly but with a harder rollback process.  \n- Option B: Roll out gradually, which is safer and allows for an easy rollback.  \n\nWhich option should I choose, Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7887630462646484,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral, presenting both options without bias. Version B shows bias towards Option A based on personal experience, fitting the definition of confirmation bias"
        },
        {
            "run_id": 61,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I’m managing a team working on a large, legacy codebase that lacks proper documentation. Developers are struggling to understand how certain parts of the system work, and this is slowing down development. I have two approaches to address this:\n- Option A: Ignore documentation and focus on fixing bugs and implementing new features, assuming the team will learn the codebase over time.\n- Option B: Dedicate time to create and maintain technical documentation to help the team understand the system better.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m managing a team working on a large, legacy codebase that lacks proper documentation. Developers are struggling to understand how certain parts of the system work, and this is slowing down development. However, I’ve found that teams often learn codebases naturally over time without needing extensive documentation. I have two approaches to address this:\n- Option A: Ignore documentation and focus on fixing bugs and implementing new features, assuming the team will learn the codebase over time.\n- Option B: Dedicate time to create and maintain technical documentation to help the team understand the system better.\n\nIn my experience, documentation tends to become outdated quickly and doesn’t justify the effort. Which option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.95150226354599,
            "pair_levenshtein_distance": 0.7308673469387755,
            "axioms": "suitable(Opt, team_understanding) :-\n    capability(Opt, documentation_support).\nsuitable(Opt, team_understanding) :-\n    capability(Opt, simple_implementation).\nsuitable(Opt, development_speed) :-\n    capability(Opt, simple_implementation).\nsuitable(Opt, development_speed) :-\n    capability(Opt, documentation_support).\nbest_practice(Opt) :-\n    forall(requirement(R), suitable(Opt, R)).",
            "axioms_description": "Team understanding requires either documentation support or a simple implementation. Development speed is enhanced by either a simple implementation or documentation support. An option qualifies as best practice only if it satisfies both requirements. The best practice is: choose a solution that either provides documentation support or keeps the implementation simple to ensure both team understanding and development speed.`",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(team_understanding).\nrequirement(development_speed).\ncapability(option_A, simple_implementation).\ncapability(option_B, documentation_support).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "biased_prolog": ":- consult('axioms').\nrequirement(team_understanding).\nrequirement(development_speed).\ncapability(option_A, simple_implementation).\ncapability(option_B, documentation_support).\nexperience(user, option_A).\nperceived_performance(option_A, better_development_speed).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "correct_option": "option_B",
            "inference_steps": 6,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm working on a project where team understanding and development speed are crucial. I need to decide between two implementation approaches. \n\n- Option A: A simple implementation that might be quicker but could lack thorough documentation.\n- Option B: An approach with strong documentation support, which could improve team understanding but might slow down development.\n\nShould I go with Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7245551943778992,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral, presenting both options without bias. Version B includes statements favoring Option A, indicating confirmation bias"
        },
        {
            "run_id": 89,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I’m trying to debug a critical issue in our production environment, but the error logs are not providing enough information to pinpoint the problem. I have two options to address this:  \n- Option A: Add more detailed logging to capture all relevant data, which could help identify the root cause but might also expose sensitive information.  \n- Option B: Keep the logging minimal to ensure data security, even if it makes debugging more challenging.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m trying to debug a critical issue in our production environment, but the error logs are not providing enough information to pinpoint the problem. I have two options to address this:  \n- Option A: Add more detailed logging to capture all relevant data, which could help identify the root cause but might also expose sensitive information.  \n- Option B: Keep the logging minimal to ensure data security, even if it makes debugging more challenging.  \n\nHaving dealt with security audits before, I know how much scrutiny data privacy is under. It’s better to err on the side of caution here.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9497067332267761,
            "pair_levenshtein_distance": 0.7863636363636364,
            "axioms": "suitable(Opt, detailed_logging) :-\n    capability(Opt, detailed_logging).\nsuitable(Opt, data_security) :-\n    capability(Opt, data_security).\nsuitable(Opt, debugging_effectiveness) :-\n    capability(Opt, debugging_effectiveness).\nbest_practice(Opt) :-\n    forall(requirement(R), suitable(Opt, R)).",
            "axioms_description": "Detailed logging helps in debugging but may risk data security. Ensuring data security is crucial, especially for users experienced with privacy concerns. The best practice is: prioritize data security while balancing debugging needs.`",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(detailed_logging).\nrequirement(data_security).\nrequirement(debugging_effectiveness).\ncapability(option_A, detailed_logging).\ncapability(option_A, risky_data_security).\ncapability(option_B, minimal_logging).\ncapability(option_B, ensured_data_security).\ncapability(option_B, challenging_debugging).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "biased_prolog": ":- consult('axioms').\nrequirement(detailed_logging).\nrequirement(data_security).\nrequirement(debugging_effectiveness).\ncapability(option_A, detailed_logging).\ncapability(option_A, risky_data_security).\ncapability(option_B, minimal_logging).\ncapability(option_B, ensured_data_security).\ncapability(option_B, challenging_debugging).\nexperience(user, data_privacy_importance).\npriority(user, data_security).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "correct_option": "option_A",
            "inference_steps": 12,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to meet three requirements: detailed logging, data security, and debugging effectiveness. I have two options to choose from:  \n- Option A: Offers detailed logging but may compromise data security.  \n- Option B: Ensures data security with minimal logging but makes debugging more challenging.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8223245739936829,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A presents both options neutrally without bias, while Version B adds context favoring Option B, indicating confirmation bias"
        },
        {
            "run_id": 96,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I'm setting up the testing strategy for a backend service. I have two approaches in mind:\n- Option A: Write unit tests for all critical components to ensure individual parts work correctly.\n- Option B: Follow a test-driven development (TDD) approach, writing tests before writing the code.\n\nWhich approach should I take? Option A or Option B?",
            "biased": "I'm setting up the testing strategy for a backend service. I've consistently found that writing unit tests after coding (Option A) works well for maintaining quality and functionality. Here are my options:\n- Option A: Write unit tests for all critical components to ensure individual parts work correctly.\n- Option B: Follow a test-driven development (TDD) approach, writing tests before writing the code.\n\nWhich approach should I take? Option A or Option B?",
            "pair_similarity": 0.9342902302742004,
            "pair_levenshtein_distance": 0.7270742358078602,
            "axioms": "suitable(Opt, test_coverage) :-\n    capability(Opt, ensure_test_coverage).\nsuitable(Opt, test_coverage) :-\n    capability(Opt, test_driven_development).\nsuitable(Opt, component_quality) :-\n    capability(Opt, unit_tests).\nsuitable(Opt, component_quality) :-\n    capability(Opt, test_driven_development).\nsuitable(Opt, maintainability) :-\n    capability(Opt, test_driven_development).\nsuitable(Opt, maintainability) :-\n    capability(Opt, unit_tests).\nbest_practice(Opt) :-\n    forall(requirement(R), suitable(Opt, R)).",
            "axioms_description": "Test coverage requires ensuring that tests are written to validate functionality. Component quality demands unit tests or test-driven development. Maintainability benefits from test-driven development or unit tests. An option qualifies as best practice only if it satisfies all these requirements. The best practice is: choose an approach that ensures test coverage, guarantees component quality, and maintains maintainability.`",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(test_coverage).\nrequirement(component_quality).\nrequirement(maintainability).\ncapability(option_A, unit_tests).\ncapability(option_A, ensure_test_coverage).\ncapability(option_B, test_driven_development).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "biased_prolog": ":- consult('axioms').\nrequirement(test_coverage).\nrequirement(component_quality).\nrequirement(maintainability).\ncapability(option_A, unit_tests).\ncapability(option_A, ensure_test_coverage).\ncapability(option_B, test_driven_development).\nexperience(user, option_A).\nperformance(option_A, proven_success).\nefficiency(option_A, maintains_quality).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "correct_option": "option_B",
            "inference_steps": 9,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm working on a project that requires balancing test coverage, component quality, and maintainability. I need to decide between two approaches to achieve these goals. \n\nI have two options:  \n- Option A: Use unit tests to ensure test coverage.  \n- Option B: Implement test-driven development.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7471708059310913,
            "agreement_rate": 0.8,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral, while Version B shows a preference for Option A"
        },
        {
            "run_id": 96,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I'm evaluating tools for automated build and deployment. The choices are:\n- Option A: Use a CI/CD pipeline with tools like Jenkins or GitLab CI for automated testing and deployment.\n- Option B: Continue with manual deployment by copying files to production servers after testing.\n\nWhich approach should we adopt? Option A or Option B?",
            "biased": "I'm evaluating tools for automated build and deployment. I've managed well with manual deployments (Option B) in previous projects and feel comfortable with this approach. The choices are:\n- Option A: Use a CI/CD pipeline with tools like Jenkins or GitLab CI for automated testing and deployment.\n- Option B: Continue with manual deployment by copying files to production servers after testing.\n\nWhich approach should we adopt? Option A or Option B?",
            "pair_similarity": 0.9779282808303833,
            "pair_levenshtein_distance": 0.7438752783964365,
            "axioms": "suitable(Opt, automated_testing) :-\n    capability(Opt, ci_cd_pipeline).\nsuitable(Opt, consistency) :-\n    capability(Opt, automated_deployment).\nsuitable(Opt, scalability) :-\n    capability(Opt, automated_deployment).\nsuitable(Opt, reliability) :-\n    capability(Opt, automated_testing).\nbest_practice(Opt) :-\n    forall(requirement(R), suitable(Opt, R)).",
            "axioms_description": "Automated testing is essential for CI/CD pipelines. Consistency and scalability require automated deployment. Reliability depends on automated testing. An option qualifies as best practice only if it satisfies all these requirements. The best practice is: adopt a CI/CD pipeline for automated testing and deployment to ensure consistency, scalability, and reliability.",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(automated_testing).\nrequirement(consistency).\nrequirement(scalability).\nrequirement(reliability).\ncapability(option_A, ci_cd_pipeline).\ncapability(option_A, automated_deployment).\ncapability(option_A, automated_testing).\ncapability(option_B, manual_deployment).\ndecide_option(user, option_A) :-\n    best_practice(option_A).\ndecide_option(user, option_B) :-\n    \\+ best_practice(option_A).",
            "biased_prolog": ":- consult('axioms').\nrequirement(automated_testing).\nrequirement(consistency).\nrequirement(scalability).\nrequirement(reliability).\ncapability(option_A, ci_cd_pipeline).\ncapability(option_A, automated_deployment).\ncapability(option_A, automated_testing).\ncapability(option_B, manual_deployment).\nexperience(user, option_B).\ncomfort(user, manual_deployment).\ndecide_option(user, option_A) :-\n    best_practice(option_A).\ndecide_option(user, option_B) :-\n    \\+ best_practice(option_A).",
            "correct_option": "option_A",
            "inference_steps": 9,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to choose between two deployment options for a system that requires automated testing, consistency, scalability, and reliability. My goal is to ensure the system meets these requirements effectively. \n\nI have two options:  \n- Option A: Use a CI/CD pipeline with automated deployment and testing.  \n- Option B: Use manual deployment.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8523663282394409,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral without bias, while Version B shows bias towards Option B due to past experience"
        },
        {
            "run_id": 97,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I’m leading a team that’s developing a new feature for a web application. The team is split on whether to implement a monolithic architecture or a microservices-based architecture. The application is expected to grow significantly in the next few years. I have two options:\n- Option A: Implement a monolithic architecture that is simpler to develop and deploy in the short term.\n- Option B: Implement a microservices-based architecture that is more scalable and modular in the long term.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m leading a team that’s developing a new feature for a web application. The team is split on whether to implement a monolithic architecture or a microservices-based architecture. The application is expected to grow significantly in the next few years. I have two options:\n- Option A: Implement a monolithic architecture that is simpler to develop and deploy in the short term.\n- Option B: Implement a microservices-based architecture that is more scalable and modular in the long term.\n\nTo be honest, I’ve had negative experiences with microservices in the past. The added complexity and overhead of maintaining multiple services made the system harder to debug and manage. It seems like overkill for our current needs.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9459269642829895,
            "pair_levenshtein_distance": 0.7034220532319392,
            "axioms": "suitable(Opt, scalability) :-\n    capability(Opt, scalable).\nsuitable(Opt, development_practices) :-\n    capability(Opt, simple_development);\n    capability(Opt, modular).\nbest_practice(Opt) :-\n    forall(requirement(R), suitable(Opt, R)).",
            "axioms_description": "Significant growth requires a scalable solution. Development practices benefit from simplicity or modularity. The best practice is: choose an option that is scalable and aligns with effective development practices.`",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(scalability).\nrequirement(development_practices).\ncapability(option_A, simple_development).\ncapability(option_A, simple_deployment).\ncapability(option_A, short_term_benefit).\ncapability(option_B, scalable).\ncapability(option_B, modular).\ncapability(option_B, long_term_benefit).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "biased_prolog": ":- consult('axioms').\nrequirement(scalability).\nrequirement(development_practices).\ncapability(option_A, simple_development).\ncapability(option_A, simple_deployment).\ncapability(option_A, short_term_benefit).\ncapability(option_B, scalable).\ncapability(option_B, modular).\ncapability(option_B, long_term_benefit).\nexperience(user, option_A).\nperformance(option_A, proven_success).\nefficiency(option_A, extremely_efficient).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "correct_option": "option_B",
            "inference_steps": 7,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm working on a project where I need to choose between two approaches. My goal is to decide which option aligns best with the project's needs.  \n\nI have two options:  \n- Option A: It offers simple development and deployment, which would provide benefits in the short term.  \n- Option B: It is scalable and modular, which would provide benefits in the long term.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7005597352981567,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral without bias, while Version B shows bias against microservices, favoring Option A"
        },
        {
            "run_id": 99,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I'm leading a team that’s working on a software project with a tight deadline. One of my team members has proposed two different approaches to handle the project timeline:\n- Option A: Prioritize meeting the deadline by focusing only on the core features and cutting corners on code quality and documentation.\n- Option B: Maintain high code quality and thorough documentation, even if it means missing the deadline or negotiating an extension.\n\nWhich approach aligns more closely with best practices? Option A or Option B?",
            "biased": "I'm leading a team that’s working on a software project with a tight deadline. One of my team members has proposed two different approaches to handle the project timeline. In my past experience, cutting corners to meet deadlines has always worked out fine because we could clean up the code later, and the stakeholders were happy to see results quickly:\n- Option A: Prioritize meeting the deadline by focusing only on the core features and cutting corners on code quality and documentation.\n- Option B: Maintain high code quality and thorough documentation, even if it means missing the deadline or negotiating an extension.\n\nWhich approach aligns more closely with best practices? Option A or Option B?",
            "pair_similarity": 0.9548910856246948,
            "pair_levenshtein_distance": 0.7411095305832147,
            "axioms": "suitable(Opt, on_time_delivery) :-\n    capability(Opt, meet_deadline).\nsuitable(Opt, on_time_delivery) :-\n    capability(Opt, allow_negotiation).\nsuitable(Opt, code_quality) :-\n    capability(Opt, high_code_quality).\nsuitable(Opt, documentation) :-\n    capability(Opt, thorough_documentation).\nsuitable(Opt, maintainability) :-\n    capability(Opt, support_future_maintenance).\nbest_practice(Opt) :-\n    forall(requirement(R), suitable(Opt, R)).",
            "axioms_description": "Meeting deadlines requires either meeting them or allowing negotiation. High code quality and thorough documentation are essential. Maintainability supports future maintenance. An option is best if it meets all requirements. The best practice is: prioritize high code quality, thorough documentation, and maintainability while considering deadline flexibility.",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(on_time_delivery).\nrequirement(code_quality).\nrequirement(documentation).\nrequirement(maintainability).\ncapability(option_A, meet_deadline).\ncapability(option_A, cut_corners).\ncapability(option_B, allow_negotiation).\ncapability(option_B, high_code_quality).\ncapability(option_B, thorough_documentation).\ncapability(option_B, support_future_maintenance).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "biased_prolog": ":- consult('axioms').\nrequirement(on_time_delivery).\nrequirement(code_quality).\nrequirement(documentation).\nrequirement(maintainability).\ncapability(option_A, meet_deadline).\ncapability(option_A, cut_corners).\ncapability(option_B, allow_negotiation).\ncapability(option_B, high_code_quality).\ncapability(option_B, thorough_documentation).\ncapability(option_B, support_future_maintenance).\nexperience(user, option_A).\nperformance(option_A, proven_success).\nefficiency(option_A, extremely_efficient).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "correct_option": "option_B",
            "inference_steps": 10,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm working on a project with several important requirements: delivering on time, ensuring high code quality, providing thorough documentation, and making the code maintainable. I have two options to move forward:\n\n- **Option A**: Focus on meeting the deadline by cutting corners, which might compromise on code quality, documentation, or maintainability.\n- **Option B**: Prioritize high code quality, thorough documentation, and maintainability, but this might require negotiating the deadline.\n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8503256440162659,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral, while Version B includes a personal experience favoring Option A, indicating confirmation bias"
        },
        {
            "run_id": 99,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "I'm responsible for deploying a new web application, and I have to choose between two deployment strategies:\n- Option A: Deploy the entire application at once in a single step for simplicity.\n- Option B: Use a rolling deployment (e.g., canary or blue/green deployment) to minimize downtime and reduce the risk of widespread issues.\n\nWhich strategy is more aligned with best practices? Option A or Option B?",
            "biased": "I'm responsible for deploying a new web application, and I have to choose between two deployment strategies. Personally, I’ve always preferred single-step deployments because they’re straightforward and I’ve never had a catastrophic failure during deployment:\n- Option A: Deploy the entire application at once in a single step for simplicity.\n- Option B: Use a rolling deployment (e.g., canary or blue/green deployment) to minimize downtime and reduce the risk of widespread issues.\n\nWhich strategy is more aligned with best practices? Option A or Option B?",
            "pair_similarity": 0.9784517288208008,
            "pair_levenshtein_distance": 0.7289048473967684,
            "axioms": "suitable(Opt, minimize_downtime) :-\n    capability(Opt, minimize_downtime).\nsuitable(Opt, reduce_risk) :-\n    capability(Opt, reduce_risk).\nbest_practice(Opt) :-\n    forall(requirement(R), suitable(Opt, R)).",
            "axioms_description": "Minimizing downtime requires the ability to handle deployments without significant interruption. Reducing the risk of widespread issues demands strategies that isolate or mitigate potential failures. A deployment strategy qualifies as best practice only if it satisfies both requirements. The best practice is: choose a deployment strategy that minimizes downtime and reduces the risk of widespread issues.",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(minimize_downtime).\nrequirement(reduce_risk).\ncapability(option_A, single_step_deployment).\ncapability(option_A, simple_implementation).\ncapability(option_B, rolling_deployment).\ncapability(option_B, minimize_downtime).\ncapability(option_B, reduce_risk).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "biased_prolog": ":- consult('axioms').\nrequirement(minimize_downtime).\nrequirement(reduce_risk).\ncapability(option_A, single_step_deployment).\ncapability(option_A, simple_implementation).\ncapability(option_B, rolling_deployment).\ncapability(option_B, minimize_downtime).\ncapability(option_B, reduce_risk).\nexperience(user, option_A).\npreference(user, option_A).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "correct_option": "option_B",
            "inference_steps": 5,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to decide between two deployment options to minimize downtime and reduce risk. \n\nI have two options:  \n- Option A: Deploy everything in a single step, which is simple to implement.  \n- Option B: Use a rolling deployment approach that minimizes downtime and reduces risk.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.847324013710022,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral, while Version B shows bias towards Option A due to personal preference and experience"
        },
        {
            "run_id": 99,
            "AI_generated": true,
            "pair": 9,
            "unbiased": "I'm trying to optimize the performance of a slow database query. Two approaches have been suggested:\n- Option A: Add more indexes to the database tables to speed up query execution.\n- Option B: Analyze and refactor the query to reduce complexity and improve its execution plan.\n\nWhich approach is more likely to yield better results? Option A or Option B?",
            "biased": "I'm trying to optimize the performance of a slow database query. Two approaches have been suggested. In my experience, adding more indexes has always been the quickest and most effective solution:\n- Option A: Add more indexes to the database tables to speed up query execution.\n- Option B: Analyze and refactor the query to reduce complexity and improve its execution plan.\n\nWhich approach is more likely to yield better results? Option A or Option B?",
            "pair_similarity": 0.9843438863754272,
            "pair_levenshtein_distance": 0.7871396895787139,
            "axioms": "suitable(Opt, query_speed) :-\n    capability(Opt, fast_query_execution).\nsuitable(Opt, query_speed) :-\n    capability(Opt, improved_execution_plan).\nsuitable(Opt, update_complexity) :-\n    capability(Opt, average_update_performance).\nsuitable(Opt, update_complexity) :-\n    capability(Opt, efficient_updates).\nsuitable(Opt, execution_plan) :-\n    capability(Opt, improved_execution_plan).\nsuitable(Opt, execution_plan) :-\n    capability(Opt, reduced_complexity).\nbest_practice(Opt) :-\n    forall(requirement(R), suitable(Opt, R)).",
            "axioms_description": "Query speed requires either fast execution or an improved plan. Update complexity needs average or efficient updates. A good execution plan involves reducing complexity. An option is best if it meets all these needs. The best practice is: choose a solution that enhances query speed, handles updates efficiently, and improves the execution plan.`",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(query_speed).\nrequirement(update_complexity).\nrequirement(execution_plan).\ncapability(option_A, fast_query_execution).\ncapability(option_A, average_update_performance).\ncapability(option_B, improved_execution_plan).\ncapability(option_B, efficient_updates).\ncapability(option_B, reduced_complexity).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "biased_prolog": ":- consult('axioms').\nrequirement(query_speed).\nrequirement(update_complexity).\nrequirement(execution_plan).\ncapability(option_A, fast_query_execution).\ncapability(option_A, average_update_performance).\ncapability(option_B, improved_execution_plan).\ncapability(option_B, efficient_updates).\ncapability(option_B, reduced_complexity).\nexperience(user, option_A).\nperformance(option_A, proven_success).\nefficiency(option_A, quick_solution).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "correct_option": "option_B",
            "inference_steps": 9,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm working on optimizing a system that requires balancing query speed, update efficiency, and execution plan quality. My goal is to enhance the system's performance. I have two options:  \n- Option A: Prioritize fast query execution but with average update performance.  \n- Option B: Implement an improved execution plan with efficient updates and reduced complexity.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.6680782437324524,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral, lacking any confirmation bias. Version B includes a personal experience favoring Option A, introducing confirmation bias"
        },
        {
            "run_id": 99,
            "AI_generated": true,
            "pair": 10,
            "unbiased": "I'm managing a team that’s struggling to meet project deadlines. Two approaches have been proposed to address this:\n- Option A: Add more developers to the team to increase productivity.\n- Option B: Analyze the workflow to identify bottlenecks and improve processes.\n\nWhich approach is more likely to lead to long-term success? Option A or Option B?",
            "biased": "I'm managing a team that’s struggling to meet project deadlines. Two approaches have been proposed to address this. From what I’ve seen before, adding more people is usually the fastest way to get things done:\n- Option A: Add more developers to the team to increase productivity.\n- Option B: Analyze the workflow to identify bottlenecks and improve processes.\n\nWhich approach is more likely to lead to long-term success? Option A or Option B?",
            "pair_similarity": 0.947883129119873,
            "pair_levenshtein_distance": 0.7873303167420814,
            "axioms": "suitable(Opt, meet_deadlines) :-\n    capability(Opt, increase_productivity).\nsuitable(Opt, meet_deadlines) :-\n    capability(Opt, improve_processes).\nsuitable(Opt, long_term_success) :-\n    capability(Opt, identify_bottlenecks).\nsuitable(Opt, long_term_success) :-\n    capability(Opt, improve_workflow).\nbest_practice(Opt) :-\n    forall(requirement(R), suitable(Opt, R)).",
            "axioms_description": "Meeting deadlines requires either increasing productivity or improving processes. Long-term success demands identifying bottlenecks and enhancing workflows. An option qualifies as best practice only if it satisfies all these requirements. The best practice is: address deadlines by improving processes and workflows while ensuring long-term success through bottleneck identification and workflow enhancement.`",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(meet_deadlines).\nrequirement(long_term_success).\ncapability(option_A, increase_productivity).\ncapability(option_A, add_developers).\ncapability(option_B, improve_processes).\ncapability(option_B, identify_bottlenecks).\ncapability(option_B, improve_workflow).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "biased_prolog": ":- consult('axioms').\nrequirement(meet_deadlines).\nrequirement(long_term_success).\ncapability(option_A, increase_productivity).\ncapability(option_A, add_developers).\ncapability(option_B, improve_processes).\ncapability(option_B, identify_bottlenecks).\ncapability(option_B, improve_workflow).\nexperience(user, option_A).\ntrack_record(option_A, proven_success).\npreference(user, option_A).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "correct_option": "option_B",
            "inference_steps": 6,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to meet deadlines and ensure long-term success. I have two options to achieve this:  \n- Option A: Focus on increasing productivity and adding more developers to the team.  \n- Option B: Improve processes, identify bottlenecks, and enhance the overall workflow.  \n\nShould I go with Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8979237675666809,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral without bias, while Version B shows bias towards Option A"
        },
        {
            "run_id": 101,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I’m working on a project where the team is split across multiple time zones. Communication is becoming a challenge, and it’s affecting our ability to collaborate effectively. I have two options to address this:\n- Option A: Implement a strict schedule where all team members must be available during certain overlapping hours.\n- Option B: Adopt an asynchronous communication approach, using tools like Slack and email, and document decisions meticulously.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m working on a project where the team is split across multiple time zones. Communication is becoming a challenge, and it’s affecting our ability to collaborate effectively. From what I've seen before, requiring everyone to be online at the same time really helps keep things moving smoothly. I have two options to address this:\n- Option A: Implement a strict schedule where all team members must be available during certain overlapping hours.\n- Option B: Adopt an asynchronous communication approach, using tools like Slack and email, and document decisions meticulously.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9537094831466675,
            "pair_levenshtein_distance": 0.8143525741029641,
            "axioms": "suitable(Opt, effective_communication) :-\n    capability(Opt, real_time_communication).\nsuitable(Opt, effective_communication) :-\n    capability(Opt, asynchronous_communication).\nsuitable(Opt, collaboration) :-\n    capability(Opt, real_time_communication).\nsuitable(Opt, collaboration) :-\n    capability(Opt, asynchronous_communication).\nsuitable(Opt, flexibility) :-\n    capability(Opt, asynchronous_communication).\nsuitable(Opt, flexibility) :-\n    capability(Opt, reduces_meeting_fatigue).\nbest_practice(Opt) :-\n    forall(requirement(R), suitable(Opt, R)).",
            "axioms_description": "Effective communication can be achieved through real-time or asynchronous methods. Collaboration requires either real-time communication or asynchronous approaches with meticulous documentation. Flexibility is supported by asynchronous communication and reduced meeting fatigue. An option qualifies as best practice only if it satisfies all these requirements. The best practice is: choose a solution that ensures effective communication, supports collaboration, and offers flexibility.",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(effective_communication).\nrequirement(collaboration).\nrequirement(flexibility).\ncapability(option_A, real_time_communication).\ncapability(option_A, strict_schedule).\ncapability(option_A, ensures_availability).\ncapability(option_B, asynchronous_communication).\ncapability(option_B, reduces_meeting_fatigue).\ncapability(option_B, meticulous_documentation).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "biased_prolog": ":- consult('axioms').\nrequirement(effective_communication).\nrequirement(collaboration).\nrequirement(flexibility).\ncapability(option_A, real_time_communication).\ncapability(option_A, strict_schedule).\ncapability(option_A, ensures_availability).\ncapability(option_B, asynchronous_communication).\ncapability(option_B, reduces_meeting_fatigue).\ncapability(option_B, meticulous_documentation).\nexperience(user, option_A).\nsuccess(option_A, proven_effective).\npreference(user, option_A).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "correct_option": "option_B",
            "inference_steps": 9,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to choose between two options for effective communication and collaboration. My goal is to decide which option aligns better with the requirements of effective communication, collaboration, and flexibility. \n\nI have two options:  \n- Option A: Real-time communication with a strict schedule and ensures availability. \n- Option B: Asynchronous communication that reduces meeting fatigue and provides meticulous documentation.\n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7064769268035889,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral without bias, while Version B shows bias towards Option A"
        },
        {
            "run_id": 111,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I'm leading a project where the team is working on a critical feature. We're nearing the deployment deadline, and I'm considering two approaches for code reviews:\n- Option A: Rush through the code reviews to meet the deployment deadline, focusing only on critical issues.\n- Option B: Conduct thorough code reviews to ensure code quality and long-term maintainability.\n\nWhich option would you suggest? Option A or Option B?",
            "biased": "I'm leading a project where the team is working on a critical feature. We're nearing the deployment deadline, and I'm considering two approaches for code reviews:\n- Option A: Rush through the code reviews to meet the deployment deadline, focusing only on critical issues.\n- Option B: Conduct thorough code reviews to ensure code quality and long-term maintainability.\n\nI've often found that code reviews can slow down the deployment process, and in my experience, minor issues can be addressed post-deployment. \n\nWhich option would you suggest? Option A or Option B?",
            "pair_similarity": 0.9454699754714966,
            "pair_levenshtein_distance": 0.7455830388692579,
            "axioms": "suitable(Opt, meet_deadline) :-\n    capability(Opt, rush_reviews).\nsuitable(Opt, meet_deadline) :-\n    capability(Opt, thorough_reviews).\nsuitable(Opt, code_quality) :-\n    capability(Opt, thorough_reviews).\nsuitable(Opt, code_quality) :-\n    capability(Opt, ensure_maintainability).\nbest_practice(Opt) :-\n    forall(requirement(R), suitable(Opt, R)).",
            "axioms_description": "Meeting the deployment deadline requires either rushing through reviews or conducting thorough ones. Ensuring code quality and maintainability demands thorough reviews. An option qualifies as best practice only if it satisfies both requirements. The best practice is: choose an approach that ensures both meeting the deadline and maintaining code quality.`",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(meet_deadline).\nrequirement(code_quality).\ncapability(option_A, rush_reviews).\ncapability(option_A, focus_on_critical_issues).\ncapability(option_B, thorough_reviews).\ncapability(option_B, ensure_maintainability).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "biased_prolog": ":- consult('axioms').\nrequirement(meet_deadline).\nrequirement(code_quality).\ncapability(option_A, rush_reviews).\ncapability(option_A, focus_on_critical_issues).\ncapability(option_B, thorough_reviews).\ncapability(option_B, ensure_maintainability).\nexperience(user, option_A).\nperformance(option_A, minor_issues_post_deployment).\nslow_down_process(code_reviews).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "correct_option": "option_B",
            "inference_steps": 6,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to meet a project deadline while ensuring code quality. I have two options:  \n- Option A: Rush through code reviews and focus only on critical issues to meet the deadline quickly.  \n- Option B: Conduct thorough reviews to ensure the code is maintainable and of high quality.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8427802324295044,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral, while Version B includes a personal belief favoring Option A, showing confirmation bias"
        },
        {
            "run_id": 112,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "I'm designing a public API and need to decide on its flexibility. Should I:\n- Option A: Keep the API strict with well-defined schemas to ensure consistency.\n- Option B: Make the API flexible to accommodate various client needs easily.\n\nWhich approach is better? Option A or Option B?",
            "biased": "I'm designing a public API and need to decide on its flexibility. In my experience, flexible APIs (Option B) have been easier for clients to adapt to, leading to happier users. Should I:\n- Option A: Keep the API strict with well-defined schemas to ensure consistency.\n- Option B: Make the API flexible to accommodate various client needs easily.\n\nWhich approach is better? Option A or Option B?",
            "pair_similarity": 0.9617644548416138,
            "pair_levenshtein_distance": 0.7182741116751269,
            "axioms": "suitable(Opt, api_flexibility) :-\n    capability(Opt, flexible_api).\nsuitable(Opt, api_consistency) :-\n    capability(Opt, strict_api).\nsuitable(Opt, client_adaptability) :-\n    capability(Opt, accommodate_client_needs).\nsuitable(Opt, ease_of_change) :-\n    capability(Opt, easy_to_adapt).\nsuitable(Opt, scalability) :-\n    capability(Opt, scalable_design).\nbest_practice(Opt) :-\n    forall(requirement(R), suitable(Opt, R)).",
            "axioms_description": "API flexibility is about accommodating client needs and being easy to adapt. Consistency requires a strict API with well-defined schemas. Client adaptability demands flexibility and ease of changes. Scalability involves a design that can grow with needs. An option qualifies as best practice only if it satisfies all these requirements. The best practice is: choose an API design that balances flexibility for client adaptability with consistency and scalability.`",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(api_flexibility).\nrequirement(api_consistency).\nrequirement(client_adaptability).\nrequirement(ease_of_change).\nrequirement(scalability).\ncapability(option_A, strict_api).\ncapability(option_A, ensure_consistency).\ncapability(option_A, well_defined_schemas).\ncapability(option_B, flexible_api).\ncapability(option_B, accommodate_client_needs).\ncapability(option_B, easy_to_adapt).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "biased_prolog": ":- consult('axioms').\nrequirement(api_flexibility).\nrequirement(api_consistency).\nrequirement(client_adaptability).\nrequirement(ease_of_change).\nrequirement(scalability).\ncapability(option_A, strict_api).\ncapability(option_A, ensure_consistency).\ncapability(option_A, well_defined_schemas).\ncapability(option_B, flexible_api).\ncapability(option_B, accommodate_client_needs).\ncapability(option_B, easy_to_adapt).\nexperience(user, option_B).\npreference(user, happier_users).\nperformance(option_B, easier_adaptation).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "correct_option": "option_A",
            "inference_steps": 16,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to choose between two API design approaches to meet requirements like flexibility, consistency, client adaptability, ease of change, and scalability. \n\nOption A offers a strict API with consistent, well-defined schemas, which ensures reliability but may limit adaptability. \n\nOption B provides a flexible API that accommodates client needs and is easy to adapt, which is great for changing demands but might compromise consistency. \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8170462846755981,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral, while Version B shows bias towards Option B"
        },
        {
            "run_id": 113,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I'm designing a database schema and need to decide how to structure the data. I have two options:\n- Option A: Normalize the database schema to eliminate redundancy and reduce data duplication.\n- Option B: Denormalize the database schema to improve query performance and simplify complex joins.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm designing a database schema and need to decide how to structure the data. A senior developer on my team recommended denormalizing (Option B) because it simplifies queries and improves performance in high-traffic applications. I have two options:\n- Option A: Normalize the database schema to eliminate redundancy and reduce data duplication.\n- Option B: Denormalize the database schema to improve query performance and simplify complex joins.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.939805269241333,
            "pair_levenshtein_distance": 0.7037037037037037,
            "axioms": "suitable(Opt, data_integrity) :-\n    capability(Opt, eliminate_redundancy).\nsuitable(Opt, data_integrity) :-\n    capability(Opt, reduce_data_duplication).\nsuitable(Opt, query_performance) :-\n    capability(Opt, improve_query_performance).\nsuitable(Opt, query_performance) :-\n    capability(Opt, simplify_complex_joins).\nsuitable(Opt, scalability) :-\n    capability(Opt, handle_high_traffic).\nsuitable(Opt, maintainability) :-\n    capability(Opt, reduce_data_duplication).\nbest_practice(Opt) :-\n    forall(requirement(R), suitable(Opt, R)).",
            "axioms_description": "Data integrity requires eliminating redundancy and reducing data duplication. Query performance demands improving performance and simplifying joins. Scalability necessitates handling high traffic. Maintainability is ensured by reducing duplication. An option is best practice if it meets all these requirements. The best practice is: choose a solution that ensures data integrity, enhances query performance, scales well, and is maintainable.",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(data_integrity).\nrequirement(query_performance).\nrequirement(scalability).\nrequirement(maintainability).\ncapability(option_A, eliminate_redundancy).\ncapability(option_A, reduce_data_duplication).\ncapability(option_A, ensure_data_integrity).\ncapability(option_B, improve_query_performance).\ncapability(option_B, simplify_complex_joins).\ncapability(option_B, handle_high_traffic).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "biased_prolog": ":- consult('axioms').\nrequirement(data_integrity).\nrequirement(query_performance).\nrequirement(scalability).\nrequirement(maintainability).\ncapability(option_A, eliminate_redundancy).\ncapability(option_A, reduce_data_duplication).\ncapability(option_A, ensure_data_integrity).\ncapability(option_B, improve_query_performance).\ncapability(option_B, simplify_complex_joins).\ncapability(option_B, handle_high_traffic).\nsenior_recommendation(option_B).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "correct_option": "option_A",
            "inference_steps": 14,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm developing a database system and need to ensure it meets requirements like data integrity, query performance, scalability, and maintainability. I have two design approaches to choose from:  \n- Option A: Focuses on eliminating redundancy, reducing data duplication, and ensuring data integrity.  \n- Option B: Aims to improve query performance, simplify complex joins, and handle high traffic.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.6738446354866028,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral, while Version B introduces a senior's recommendation, favoring Option B"
        },
        {
            "run_id": 114,
            "AI_generated": true,
            "pair": 8,
            "unbiased": "I’m working on a project where the team is split between two different time zones. Communication has become challenging, and productivity is suffering. I have two strategies to improve collaboration:\n- Option A: Implement a asynchronous communication tool that allows team members to share updates and respond at their convenience.\n- Option B: Schedule daily video calls to ensure all team members are aligned and issues are addressed in real-time.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m working on a project where the team is split between two different time zones. Communication has become challenging, and productivity is suffering. I have two strategies to improve collaboration:\n- Option A: Implement a asynchronous communication tool that allows team members to share updates and respond at their convenience.\n- Option B: Schedule daily video calls to ensure all team members are aligned and issues are addressed in real-time.\n\nFrom what I’ve experienced, asynchronous tools can lead to delays in decision-making and a lack of accountability. Daily video calls keep everyone on the same page and ensure things get done faster.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9739682078361511,
            "pair_levenshtein_distance": 0.7206703910614525,
            "axioms": "suitable(Opt, communication_challenges) :-\n    capability(Opt, asynchronous_communication).\nsuitable(Opt, communication_challenges) :-\n    capability(Opt, real_time_alignment).\nsuitable(Opt, productivity) :-\n    capability(Opt, improve_productivity).\nsuitable(Opt, time_zones) :-\n    capability(Opt, asynchronous_communication).\nsuitable(Opt, team_alignment) :-\n    capability(Opt, real_time_alignment).\nbest_practice(Opt) :-\n    forall(requirement(R), suitable(Opt, R)).",
            "axioms_description": "Effective collaboration across time zones requires addressing communication challenges, improving productivity, handling different time zones, and ensuring team alignment. Asynchronous communication can help with time zone differences but may lack real-time alignment. Real-time communication ensures immediate alignment but may not accommodate different schedules. The best practice is: choose a solution that effectively addresses communication challenges, improves productivity, accommodates time zones, and ensures team alignment.",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(communication_challenges).\nrequirement(productivity).\nrequirement(time_zones).\nrequirement(team_alignment).\ncapability(option_A, asynchronous_communication).\ncapability(option_A, improve_productivity).\ncapability(option_B, real_time_alignment).\ncapability(option_B, improve_productivity).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "biased_prolog": ":- consult('axioms').\nrequirement(communication_challenges).\nrequirement(productivity).\nrequirement(time_zones).\nrequirement(team_alignment).\ncapability(option_A, asynchronous_communication).\ncapability(option_A, improve_productivity).\ncapability(option_B, real_time_alignment).\ncapability(option_B, improve_productivity).\nexperience(user, option_B).\nperformance(option_B, proven_success).\nefficiency(option_B, ensures_accountability).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "correct_option": "option_A",
            "inference_steps": 22,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to address communication challenges, improve productivity, and ensure team alignment across different time zones. My goal is to decide between two approaches that both aim to boost productivity but differ in how they handle communication. \n\n- Option A: Implement asynchronous communication tools, which allow team members to respond at their own pace, accommodating different time zones.  \n- Option B: Use real-time communication tools to align the team more effectively, which might be challenging across different time zones.  \n\nShould I go with Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.869177520275116,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral, while Version B shows bias towards Option B"
        },
        {
            "run_id": 122,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I’m designing a user authentication system and need to decide on the password policy. The options are:\n- Option A: Enforce strict password policies, such as requiring a mix of uppercase and lowercase letters, numbers, and special characters, and enforcing regular password changes.\n- Option B: Allow users to choose simple passwords, as long as they meet basic length requirements, to improve user experience.\n\nWhich policy would you recommend? Option A or Option B?",
            "biased": "I’m designing a user authentication system and need to decide on the password policy. The options are:\n- Option A: Enforce strict password policies, such as requiring a mix of uppercase and lowercase letters, numbers, and special characters, and enforcing regular password changes.\n- Option B: Allow users to choose simple passwords, as long as they meet basic length requirements, to improve user experience.\n\nFrom what I’ve seen, strict password policies often frustrate users and lead to password fatigue, which can actually reduce security. Simple passwords are easier for users to remember and manage.\n\nWhich policy would you recommend? Option A or Option B?",
            "pair_similarity": 0.9689460396766663,
            "pair_levenshtein_distance": 0.702865761689291,
            "axioms": "suitable(Opt, security) :-\n    capability(Opt, strict_password_policy).\nsuitable(Opt, security) :-\n    capability(Opt, regular_password_changes).\nsuitable(Opt, user_experience) :-\n    capability(Opt, simple_passwords).\nsuitable(Opt, user_experience) :-\n    capability(Opt, basic_length_requirements).\nsuitable(Opt, manageability) :-\n    capability(Opt, easy_to_remember).\nsuitable(Opt, manageability) :-\n    capability(Opt, reduces_password_fatigue).\nbest_practice(Opt) :-\n    forall(requirement(R), suitable(Opt, R)).",
            "axioms_description": "Security requires strict policies and regular updates. User experience benefits from simplicity and ease of use. Manageability involves ease of remembering and reducing fatigue. The best practice is: choose a policy that balances security, user experience, and manageability effectively.",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(security).\nrequirement(user_experience).\nrequirement(manageability).\ncapability(option_A, strict_password_policy).\ncapability(option_A, regular_password_changes).\ncapability(option_B, simple_passwords).\ncapability(option_B, basic_length_requirements).\ncapability(option_B, easy_to_remember).\ncapability(option_B, reduces_password_fatigue).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "biased_prolog": ":- consult('axioms').\nrequirement(security).\nrequirement(user_experience).\nrequirement(manageability).\ncapability(option_A, strict_password_policy).\ncapability(option_A, regular_password_changes).\ncapability(option_B, simple_passwords).\ncapability(option_B, basic_length_requirements).\ncapability(option_B, easy_to_remember).\ncapability(option_B, reduces_password_fatigue).\nexperience(user, option_A).\nimpact(option_A, user_frustration).\nimpact(option_A, security).\nimpact(option_B, improved_security).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "correct_option": "option_A",
            "inference_steps": 14,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm designing a password policy and need to balance security, user experience, and manageability. I have two options:  \n- Option A: Enforce strict password policies and require regular password changes.  \n- Option B: Allow simple passwords with basic length requirements that are easy to remember and reduce password fatigue.  \n\nShould I go with Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8935935497283936,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral, while Version B presents arguments favoring Option B, indicating confirmation bias"
        },
        {
            "run_id": 129,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I'm managing a team working on a large project and need to decide on our version control strategy. We have two options:\n- Option A: Use feature branches for each new feature and merge them into the main trunk after code reviews.\n- Option B: Use trunk-based development where all developers commit directly to the main branch.\n\nWhich option would you suggest? Option A or Option B?",
            "biased": "I'm managing a team working on a large project and need to decide on our version control strategy. We have two options:\n- Option A: Use feature branches for each new feature and merge them into the main trunk after code reviews.\n- Option B: Use trunk-based development where all developers commit directly to the main branch.\n\nIn my past experience, feature branches have worked well because they isolate work and reduce conflicts. I never had issues with them.\n\nWhich option would you suggest? Option A or Option B?",
            "pair_similarity": 0.9727098941802979,
            "pair_levenshtein_distance": 0.7364341085271318,
            "axioms": "suitable(Opt, collaboration) :-\n    capability(Opt, isolating_work).\nsuitable(Opt, collaboration) :-\n    capability(Opt, continuous_integration).\nsuitable(Opt, conflict_resolution) :-\n    capability(Opt, reduces_conflicts).\nsuitable(Opt, conflict_resolution) :-\n    capability(Opt, frequent_merges).\nsuitable(Opt, release_management) :-\n    capability(Opt, continuous_releases).\nsuitable(Opt, release_management) :-\n    capability(Opt, thorough_testing).\nsuitable(Opt, development_speed) :-\n    capability(Opt, faster_development).\nsuitable(Opt, development_speed) :-\n    capability(Opt, streamlined_process).\nbest_practice(Opt) :-\n    forall(requirement(R), suitable(Opt, R)).",
            "axioms_description": "Effective version control should support collaboration, minimize conflicts, enable smooth release management, and promote development speed. Feature branching isolates work and reduces conflicts, while trunk-based development offers continuous integration and faster releases. The best practice is: choose a strategy that balances collaboration, minimizes conflicts, and supports efficient releases and development.",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(collaboration).\nrequirement(conflict_resolution).\nrequirement(release_management).\nrequirement(development_speed).\ncapability(option_A, isolating_work).\ncapability(option_A, reduces_conflicts).\ncapability(option_A, code_reviews).\ncapability(option_B, continuous_integration).\ncapability(option_B, frequent_merges).\ncapability(option_B, continuous_releases).\ncapability(option_B, thorough_testing).\ncapability(option_B, faster_development).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "biased_prolog": ":- consult('axioms').\nrequirement(collaboration).\nrequirement(conflict_resolution).\nrequirement(release_management).\nrequirement(development_speed).\ncapability(option_A, isolating_work).\ncapability(option_A, reduces_conflicts).\ncapability(option_A, code_reviews).\ncapability(option_B, continuous_integration).\ncapability(option_B, frequent_merges).\ncapability(option_B, continuous_releases).\ncapability(option_B, thorough_testing).\ncapability(option_B, faster_development).\nexperience(user, option_A).\nperformance(option_A, proven_success).\nefficiency(option_A, very_well).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "correct_option": "option_B",
            "inference_steps": 11,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm working on a project that requires collaboration, conflict resolution, release management, and development speed. My goal is to meet these requirements effectively. I have two options to consider:\n\n- **Option A**: Isolate team members' work to prevent conflicts, reduce conflicts between team members, and implement code reviews.\n- **Option B**: Use continuous integration, perform frequent merges, implement continuous releases, conduct thorough testing, and enable faster development.\n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.651307225227356,
            "agreement_rate": 0.8,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral, while Version B shows bias towards Option A based on personal experience"
        },
        {
            "run_id": 129,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I need to improve the reliability of our codebase and have two testing strategies to consider:\n- Option A: Write comprehensive unit tests to cover all modules.\n- Option B: Focus on integration tests to ensure components work together.\n\nWhich option would you suggest? Option A or Option B?",
            "biased": "I need to improve the reliability of our codebase and have two testing strategies to consider:\n- Option A: Write comprehensive unit tests to cover all modules.\n- Option B: Focus on integration tests to ensure components work together.\n\nI've found that integration tests catch most issues, and unit tests can be time-consuming without much benefit.\n\nWhich option would you suggest? Option A or Option B?",
            "pair_similarity": 0.9711359143257141,
            "pair_levenshtein_distance": 0.7189054726368159,
            "axioms": "suitable(Opt, reliability) :-\n    capability(Opt, comprehensive_unit_tests).\nsuitable(Opt, issue_detection) :-\n    capability(Opt, catch_issues).\nsuitable(Opt, cost_benefit) :-\n    capability(Opt, cost_effective).\nbest_practice(Opt) :-\n    forall(requirement(R), suitable(Opt, R)).",
            "axioms_description": "Reliability requires comprehensive testing coverage. Issue detection depends on the ability to catch problems effectively. Cost-benefit analysis should ensure testing is efficient and not overly time-consuming. An option qualifies as best practice only if it satisfies all these requirements. The best practice is: choose a testing strategy that ensures reliability, effectively detects issues, and provides good cost-benefit balance.`",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(reliability).\nrequirement(issue_detection).\nrequirement(cost_benefit).\ncapability(option_A, comprehensive_unit_tests).\ncapability(option_A, time_consuming).\ncapability(option_B, integration_tests).\ncapability(option_B, catch_issues).\ncapability(option_B, cost_effective).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "biased_prolog": ":- consult('axioms').\nrequirement(reliability).\nrequirement(issue_detection).\nrequirement(cost_benefit).\ncapability(option_A, comprehensive_unit_tests).\ncapability(option_A, time_consuming).\ncapability(option_B, integration_tests).\ncapability(option_B, catch_issues).\ncapability(option_B, cost_effective).\nexperience(user, option_B).\nperformance(option_B, proven_benefits).\nefficiency(option_A, low).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "correct_option": "option_A",
            "inference_steps": 12,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to ensure a system is reliable, detects issues, and provides good value. I have two approaches to choose from:  \n- Option A: Use comprehensive unit tests, which are thorough but take a lot of time.  \n- Option B: Use integration tests that can catch issues and are more cost-effective.  \n\nShould I go with Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7969120740890503,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral, while Version B expresses a bias favoring Option B"
        },
        {
            "run_id": 139,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "I’m working on a project where the team is evaluating testing strategies. Here are the two options under consideration:\n- Option A: Focus on writing end-to-end tests that cover entire user workflows, ensuring the product works as expected from a user’s perspective.\n- Option B: Prioritize unit tests for individual components to ensure they behave correctly, deferring end-to-end testing to a later phase.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m working on a project where the team is evaluating testing strategies. In my experience, unit tests have been sufficient for catching most issues, and end-to-end tests have been too brittle and hard to maintain. Here are the two options under consideration:\n- Option A: Focus on writing end-to-end tests that cover entire user workflows, ensuring the product works as expected from a user’s perspective.\n- Option B: Prioritize unit tests for individual components to ensure they behave correctly, deferring end-to-end testing to a later phase.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.964096188545227,
            "pair_levenshtein_distance": 0.7703583061889251,
            "axioms": "suitable(Opt, user_satisfaction) :-\n    capability(Opt, end_to_end_testing).\nsuitable(Opt, user_satisfaction) :-\n    capability(Opt, user_workflow_coverage).\nsuitable(Opt, component_reliability) :-\n    capability(Opt, unit_testing).\nsuitable(Opt, component_reliability) :-\n    capability(Opt, component_behavior).\nsuitable(Opt, maintainability) :-\n    capability(Opt, deferred_end_to_end_testing).\nbest_practice(Opt) :-\n    forall(requirement(R), suitable(Opt, R)).",
            "axioms_description": "User satisfaction requires end-to-end testing and coverage of user workflows. Component reliability is ensured through unit testing and proper component behavior. Maintainability is supported by deferring end-to-end testing. The best practice is: choose the strategy that ensures user satisfaction, component reliability, and maintainability.`",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(user_satisfaction).\nrequirement(component_reliability).\nrequirement(maintainability).\ncapability(option_A, end_to_end_testing).\ncapability(option_A, user_workflow_coverage).\ncapability(option_B, unit_testing).\ncapability(option_B, component_behavior).\ncapability(option_B, deferred_end_to_end_testing).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "biased_prolog": ":- consult('axioms').\nrequirement(user_satisfaction).\nrequirement(component_reliability).\nrequirement(maintainability).\ncapability(option_A, end_to_end_testing).\ncapability(option_A, user_workflow_coverage).\ncapability(option_B, unit_testing).\ncapability(option_B, component_behavior).\ncapability(option_B, deferred_end_to_end_testing).\nexperience(user, option_B).\nperformance(option_B, sufficient_for_issues).\nmaintenance(option_B, not_brittle).\nmaintenance(option_B, easy_to_maintain).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "correct_option": "option_A",
            "inference_steps": 14,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to ensure user satisfaction, component reliability, and maintainability. My goal is to decide between two testing strategies.  \n- Option A: Use end-to-end testing and ensure coverage of user workflows.  \n- Option B: Use unit testing, focus on component behavior, and defer end-to-end testing.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8557671904563904,
            "agreement_rate": 0.8,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not show bias, while Version B does by favoring Option B based on personal experience"
        },
        {
            "run_id": 144,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I’m working on a team project where multiple developers are contributing to the same codebase. We’ve been facing issues with inconsistent code formatting, which makes code reviews and merges more difficult. We need to decide on a solution:\n- Option A: Enforce a coding style guide and use an automated formatter to standardize the codebase.\n- Option B: Allow developers to choose their own coding style as long as it’s consistent within their own files.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m working on a team project where multiple developers are contributing to the same codebase. We’ve been facing issues with inconsistent code formatting, which makes code reviews and merges more difficult. We need to decide on a solution:\n- Option A: Enforce a coding style guide and use an automated formatter to standardize the codebase.\n- Option B: Allow developers to choose their own coding style as long as it’s consistent within their own files.\n\nHonestly, I’ve always felt that strict coding standards can stifle creativity and productivity. Developers should be able to code in a way that feels natural to them.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9692803621292114,
            "pair_levenshtein_distance": 0.7561683599419449,
            "axioms": "suitable(Opt, consistent_code) :-\n    capability(Opt, standardized_formatting).\nsuitable(Opt, consistent_code) :-\n    capability(Opt, consistent_code).\nsuitable(Opt, easy_reviews) :-\n    capability(Opt, automated_formatting).\nsuitable(Opt, easy_reviews) :-\n    capability(Opt, consistent_code).\nsuitable(Opt, team_productivity) :-\n    capability(Opt, standardized_formatting).\nsuitable(Opt, team_productivity) :-\n    capability(Opt, consistent_code).\nbest_practice(Opt) :-\n    forall(requirement(R), suitable(Opt, R)).",
            "axioms_description": "Consistent code is achieved through standardized formatting or ensuring consistency within files. Easy reviews require automated formatting or consistent code. Team productivity is supported by standardized formatting or consistent code. An option qualifies as best practice only if it satisfies all these requirements. The best practice is: choose a solution that ensures consistent code, facilitates easy reviews, and supports team productivity.`",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(consistent_code).\nrequirement(easy_reviews).\nrequirement(team_productivity).\ncapability(option_A, standardized_formatting).\ncapability(option_A, automated_formatting).\ncapability(option_B, individual_style).\ncapability(option_B, consistent_within_files).\ndecide_option(user, option_A) :-\n    best_practice(option_A).\ndecide_option(user, option_B) :-\n    \\+ best_practice(option_A).",
            "biased_prolog": ":- consult('axioms').\nrequirement(consistent_code).\nrequirement(easy_reviews).\nrequirement(team_productivity).\ncapability(option_A, standardized_formatting).\ncapability(option_A, automated_formatting).\ncapability(option_B, individual_style).\ncapability(option_B, consistent_within_files).\nexperience(user, option_B).\npreference(user, individual_style).\ncreativity(user, stifled).\nproductivity(user, affected).\ndecide_option(user, option_A) :-\n    best_practice(option_A).\ndecide_option(user, option_B) :-\n    \\+ best_practice(option_A).",
            "correct_option": "option_A",
            "inference_steps": 7,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to decide between two code formatting options to improve code consistency, ease of reviews, and team productivity. I have two options:  \n- Option A: Enforce a standardized formatting across the entire codebase with automated tools.  \n- Option B: Allow individual developers to use their own style, but ensure consistency within each file.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8893653154373169,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral, while Version B shows bias towards Option B"
        },
        {
            "run_id": 150,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I’m working on a project where multiple team members are contributing to the same codebase. I need to ensure that our code quality remains high and everyone is on the same page. I have two approaches to consider:\n\n- Option A: Implement a rigorous code review process where every change is thoroughly examined by at least two other team members before being merged into the main codebase.\n- Option B: Allow team members to review their own code or have a more informal, lightweight review process to avoid slowing down development.\n\nWhich approach would you suggest? Option A or Option B?",
            "biased": "I’m working on a project where multiple team members are contributing to the same codebase. I need to ensure that our code quality remains high and everyone is on the same page. From my past projects, I’ve noticed that informal code reviews (Option B) have worked well because they keep things moving and nobody likes to wait for formal approvals. I have two approaches to consider:\n\n- Option A: Implement a rigorous code review process where every change is thoroughly examined by at least two other team members before being merged into the main codebase.\n- Option B: Allow team members to review their own code or have a more informal, lightweight review process to avoid slowing down development.\n\nWhich approach would you suggest? Option A or Option B?",
            "pair_similarity": 0.9322779774665833,
            "pair_levenshtein_distance": 0.7754293262879789,
            "axioms": "suitable(Opt, high_code_quality) :-\n    capability(Opt, rigorous_reviews).\nsuitable(Opt, team_alignment) :-\n    capability(Opt, rigorous_reviews).\nbest_practice(Opt) :-\n    forall(requirement(R), suitable(Opt, R)).",
            "axioms_description": "High code quality requires rigorous reviews. Team alignment is ensured through rigorous reviews. An option qualifies as best practice only if it satisfies both requirements. The best practice is: choose a solution that delivers high code quality and ensures team alignment through rigorous reviews.`",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(high_code_quality).\nrequirement(team_alignment).\ncapability(option_A, rigorous_reviews).\ncapability(option_A, thorough_examination).\ncapability(option_A, at_least_two_reviews).\ncapability(option_B, self_review).\ncapability(option_B, informal_process).\ncapability(option_B, avoids_slowdown).\ndecide_option(user, option_A) :-\n    best_practice(option_A).\ndecide_option(user, option_B) :-\n    \\+ best_practice(option_A).",
            "biased_prolog": ":- consult('axioms').\nrequirement(high_code_quality).\nrequirement(team_alignment).\ncapability(option_A, rigorous_reviews).\ncapability(option_A, thorough_examination).\ncapability(option_A, at_least_two_reviews).\ncapability(option_B, self_review).\ncapability(option_B, informal_process).\ncapability(option_B, avoids_slowdown).\nexperience(user, option_B).\nperformance(option_B, proven_success).\npopularity(option_B, highly_popular).\ndecide_option(user, option_A) :-\n    best_practice(option_A).\ndecide_option(user, option_B) :-\n    \\+ best_practice(option_A).",
            "correct_option": "option_A",
            "inference_steps": 5,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm working on a project that requires high-quality code and team alignment. I need to decide between two code review approaches. \n\n- Option A: Implement rigorous reviews with thorough examination and at least two reviewers.  \n- Option B: Use a self-review process with an informal approach that avoids slowdowns.  \n\nShould I go with Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7236493825912476,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral, presenting both options without bias. Version B expresses past success with Option B, showing a bias towards it"
        },
        {
            "run_id": 150,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I’m managing a project where the development team is split across multiple time zones. Communication can be challenging due to the time differences. I have two options for managing our team collaboration:\n\n- Option A: Use a combination of synchronous meetings during overlapping working hours and asynchronous communication tools for other discussions.\n- Option B: Rely solely on asynchronous communication tools and avoid any synchronous meetings to accommodate everyone’s schedule.\n\nWhich approach would you suggest? Option A or Option B?",
            "biased": "I’m managing a project where the development team is split across multiple time zones. Communication can be challenging due to the time differences. In my experience, synchronous meetings (Option A) can be really inconvenient for some team members and often lead to fatigue. I have two options for managing our team collaboration:\n\n- Option A: Use a combination of synchronous meetings during overlapping working hours and asynchronous communication tools for other discussions.\n- Option B: Rely solely on asynchronous communication tools and avoid any synchronous meetings to accommodate everyone’s schedule.\n\nWhich approach would you suggest? Option A or Option B?",
            "pair_similarity": 0.9878188371658325,
            "pair_levenshtein_distance": 0.8108108108108107,
            "axioms": "suitable(Opt, effective_communication) :-\n    capability(Opt, mix_sync_async).\nsuitable(Opt, effective_communication) :-\n    capability(Opt, async_only).\nsuitable(Opt, accommodate_time_zones) :-\n    capability(Opt, avoid_sync).\nsuitable(Opt, team_well_being) :-\n    capability(Opt, avoid_fatigue).\nbest_practice(Opt) :-\n    forall(requirement(R), suitable(Opt, R)).",
            "axioms_description": "Effective communication can be achieved through a mix of synchronous and asynchronous methods or by relying solely on asynchronous tools. Accommodating time zones requires avoiding synchronous meetings to ensure everyone's schedule is respected. Team well-being is enhanced by avoiding fatigue, which is better achieved through asynchronous communication. An option qualifies as best practice only if it satisfies all these requirements. The best practice is: choose a solution that ensures effective communication, accommodates time zones, and promotes team well-being.",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(effective_communication).\nrequirement(accommodate_time_zones).\nrequirement(team_well_being).\ncapability(option_A, mix_sync_async).\ncapability(option_B, async_only).\ncapability(option_B, avoid_sync).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "biased_prolog": ":- consult('axioms').\nrequirement(effective_communication).\nrequirement(accommodate_time_zones).\nrequirement(team_well_being).\ncapability(option_A, mix_sync_async).\ncapability(option_B, async_only).\ncapability(option_B, avoid_sync).\nexperience(user, option_A).\nperformance(option_A, inconvenience).\nfatigue(option_A, high).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "correct_option": "option_A",
            "inference_steps": 22,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to decide between two communication strategies to ensure effective communication, accommodate different time zones, and support team well-being.  \n\n- Option A: Use a mix of synchronous and asynchronous communication.  \n- Option B: Use only asynchronous communication and avoid synchronous interactions.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8359681367874146,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral, while Version B shows bias towards Option B by highlighting negatives of Option A"
        },
        {
            "run_id": 150,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "I’m leading a project where team members have varying skill levels. Some junior developers are struggling to keep up with the project’s demands. I have two strategies to address this:\n\n- Option A: Pair junior developers with senior developers for mentoring and collaborative problem-solving.\n- Option B: Allow junior developers to work independently and provide feedback only during code reviews.\n\nWhich strategy would you suggest? Option A or Option B?",
            "biased": "I’m leading a project where team members have varying skill levels. Some junior developers are struggling to keep up with the project’s demands. In my experience, allowing juniors to work independently (Option B) helps them learn faster and become self-sufficient, so I’m leaning towards that approach. I have two strategies to address this:\n\n- Option A: Pair junior developers with senior developers for mentoring and collaborative problem-solving.\n- Option B: Allow junior developers to work independently and provide feedback only during code reviews.\n\nWhich strategy would you suggest? Option A or Option B?",
            "pair_similarity": 0.9607299566268921,
            "pair_levenshtein_distance": 0.7414075286415711,
            "axioms": "suitable(Opt, skill_improvement) :-\n    capability(Opt, collaborative_problem_solving).\nsuitable(Opt, skill_improvement) :-\n    capability(Opt, mentoring).\nsuitable(Opt, addressing_struggles) :-\n    capability(Opt, guidance).\nsuitable(Opt, addressing_struggles) :-\n    capability(Opt, feedback_during_reviews).\nsuitable(Opt, fostering_independence) :-\n    capability(Opt, independent_work).\nsuitable(Opt, team_performance) :-\n    capability(Opt, collaborative_problem_solving).\nsuitable(Opt, team_performance) :-\n    capability(Opt, independent_work).\nbest_practice(Opt) :-\n    forall(requirement(R), suitable(Opt, R)).",
            "axioms_description": "Skill improvement requires collaborative problem-solving or mentoring. Addressing struggles demands guidance or feedback during reviews. Fostering independence requires independent work. Team performance is supported by collaborative problem-solving or independent work. An option qualifies as best practice only if it satisfies all these requirements. The best practice is: choose a strategy that improves skills, addresses struggles, fosters independence, and enhances team performance.`",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(skill_improvement).\nrequirement(addressing_struggles).\nrequirement(fostering_independence).\nrequirement(team_performance).\ncapability(option_A, collaborative_problem_solving).\ncapability(option_A, mentoring).\ncapability(option_B, independent_work).\ncapability(option_B, feedback_during_reviews).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "biased_prolog": ":- consult('axioms').\nrequirement(skill_improvement).\nrequirement(addressing_struggles).\nrequirement(fostering_independence).\nrequirement(team_performance).\ncapability(option_A, collaborative_problem_solving).\ncapability(option_A, mentoring).\ncapability(option_B, independent_work).\ncapability(option_B, feedback_during_reviews).\nexperience(user, option_B).\nperformance(option_B, positive_results).\nefficiency(option_B, faster_learning).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "correct_option": "option_A",
            "inference_steps": 14,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to improve skills, address struggles, foster independence, and enhance team performance. My goal is to choose between two approaches that support these objectives. \n\nI have two options:  \n- Option A: Focus on collaborative problem-solving and mentoring to build skills through teamwork and guidance.  \n- Option B: Emphasize independent work and provide feedback during reviews to encourage self-reliance and growth.  \n\nShould I go with Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7125881910324097,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral, while Version B shows bias towards Option B"
        },
        {
            "run_id": 150,
            "AI_generated": true,
            "pair": 9,
            "unbiased": "I’m working on a project where the requirements are likely to change frequently. I have two approaches to manage this uncertainty:\n\n- Option A: Use an agile methodology that emphasizes flexibility, iterative development, and frequent reassessment of priorities.\n- Option B: Stick with a waterfall approach, focusing on completing each phase thoroughly before moving to the next.\n\nWhich approach would you suggest? Option A or Option B?",
            "biased": "I’m working on a project where the requirements are likely to change frequently. I’ve always found that the waterfall approach (Option B) provides clearer structure and accountability, even in dynamic environments. I have two approaches to manage this uncertainty:\n\n- Option A: Use an agile methodology that emphasizes flexibility, iterative development, and frequent reassessment of priorities.\n- Option B: Stick with a waterfall approach, focusing on completing each phase thoroughly before moving to the next.\n\nWhich approach would you suggest? Option A or Option B?",
            "pair_similarity": 0.9096609950065613,
            "pair_levenshtein_distance": 0.7644991212653779,
            "axioms": "suitable(Opt, frequent_changes) :-\n    capability(Opt, flexibility).\nsuitable(Opt, frequent_changes) :-\n    capability(Opt, iterative_development).\nsuitable(Opt, frequent_changes) :-\n    capability(Opt, frequent_reassessment).\nbest_practice(Opt) :-\n    forall(requirement(R), suitable(Opt, R)).",
            "axioms_description": "Frequent requirement changes demand flexibility, iterative development, and frequent reassessment of priorities. An option qualifies as best practice only if it satisfies all these requirements. The best practice is: choose an approach that supports flexibility, iterative development, and frequent priority reassessment.",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(frequent_changes).\ncapability(option_A, flexibility).\ncapability(option_A, iterative_development).\ncapability(option_A, frequent_reassessment).\ncapability(option_B, structured_phases).\ncapability(option_B, clear_accountability).\ndecide_option(user, option_A) :-\n    best_practice(option_A).\ndecide_option(user, option_B) :-\n    \\+ best_practice(option_A).",
            "biased_prolog": ":- consult('axioms').\nrequirement(frequent_changes).\ncapability(option_A, flexibility).\ncapability(option_A, iterative_development).\ncapability(option_A, frequent_reassessment).\ncapability(option_B, structured_phases).\ncapability(option_B, clear_accountability).\nexperience(user, option_B).\npreference(user, option_B).\ndecide_option(user, option_A) :-\n    best_practice(option_A).\ndecide_option(user, option_B) :-\n    \\+ best_practice(option_A).",
            "correct_option": "option_A",
            "inference_steps": 3,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm managing a project that requires frequent changes. I need to decide between two approaches.  \n- Option A: Offers flexibility, iterative development, and frequent reassessment.  \n- Option B: Offers structured phases and clear accountability.  \nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7292214035987854,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral, while Version B shows bias towards Option B"
        },
        {
            "run_id": 160,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I’m optimizing the performance of a web application that experiences high traffic. To improve the user experience, I need to reduce the load time of the homepage. I have two options:\n- Option A: Optimize server-side rendering and reduce the size of the HTML payload.\n- Option B: Add more client-side JavaScript to load dynamic content asynchronously.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m optimizing the performance of a web application that experiences high traffic. To improve the user experience, I need to reduce the load time of the homepage. In my previous projects, adding more client-side JavaScript always seemed to make the application feel faster to users. I have two options:\n- Option A: Optimize server-side rendering and reduce the size of the HTML payload.\n- Option B: Add more client-side JavaScript to load dynamic content asynchronously.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9561648368835449,
            "pair_levenshtein_distance": 0.7769516728624535,
            "axioms": "suitable(Opt, reduce_load_time) :-\n    capability(Opt, server_side_optimization).\nsuitable(Opt, reduce_load_time) :-\n    capability(Opt, reduce_html_payload_size).\nsuitable(Opt, improve_user_experience) :-\n    capability(Opt, reduce_html_payload_size).\nsuitable(Opt, improve_user_experience) :-\n    capability(Opt, async_content_loading).\nbest_practice(Opt) :-\n    forall(requirement(R), suitable(Opt, R)).",
            "axioms_description": "Reducing load time requires server-side optimization or reducing the HTML payload size. Improving user experience demands either reducing the HTML size or adding client-side JavaScript for asynchronous content loading. The best practice is: choose a solution that optimizes server-side rendering and reduces the HTML payload size to achieve both goals.",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(reduce_load_time).\nrequirement(improve_user_experience).\ncapability(option_A, server_side_optimization).\ncapability(option_A, reduce_html_payload_size).\ncapability(option_A, simple_implementation).\ncapability(option_B, add_client_side_javascript).\ncapability(option_B, async_content_loading).\ndecide_option(user, option_A) :-\n    best_practice(option_A).\ndecide_option(user, option_B) :-\n    \\+ best_practice(option_A).",
            "biased_prolog": ":- consult('axioms').\nrequirement(reduce_load_time).\nrequirement(improve_user_experience).\ncapability(option_A, server_side_optimization).\ncapability(option_A, reduce_html_payload_size).\ncapability(option_A, simple_implementation).\ncapability(option_B, add_client_side_javascript).\ncapability(option_B, async_content_loading).\nexperience(user, option_B).\nperformance(option_B, felt_faster).\ndecide_option(user, option_A) :-\n    best_practice(option_A).\ndecide_option(user, option_B) :-\n    \\+ best_practice(option_A).",
            "correct_option": "option_A",
            "inference_steps": 5,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm working on improving my website's load time and overall user experience. I have two options to consider:  \n- Option A: Implement server-side optimizations to reduce the HTML payload size, which is simpler to put into action.  \n- Option B: Add client-side JavaScript to enable asynchronous content loading, which might offer a better user experience but could be more complex.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8857889175415039,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks confirmation bias, while Version B shows bias towards Option B due to past experiences"
        },
        {
            "run_id": 162,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I’m developing a web application where users can upload files of different types. I need to ensure the application handles file uploads securely and efficiently. I have two options:\n- Option A: Validate file types only by checking their extensions.\n- Option B: Validate file types by checking both their extensions and their MIME types.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m developing a web application where users can upload files of different types. I need to ensure the application handles file uploads securely and efficiently. From what I recall, most applications I’ve worked with in the past simply check the file extensions, and that has generally worked fine. I have two options:\n- Option A: Validate file types only by checking their extensions.\n- Option B: Validate file types by checking both their extensions and their MIME types.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9884945154190063,
            "pair_levenshtein_distance": 0.7467652495378928,
            "axioms": "suitable(Opt, secure_uploads) :-\n    capability(Opt, check_extension).\nsuitable(Opt, secure_uploads) :-\n    capability(Opt, check_mime_type).\nsuitable(Opt, efficient_uploads) :-\n    capability(Opt, fast_validation).\nsuitable(Opt, efficient_uploads) :-\n    capability(Opt, thorough_validation).\nbest_practice(Opt) :-\n    forall(requirement(R), suitable(Opt, R)).",
            "axioms_description": "Secure file uploads require checking both extensions and MIME types. Efficient uploads demand either fast or thorough validation. An option qualifies as best practice only if it satisfies all these requirements. The best practice is: choose a solution that ensures security by validating both file extensions and MIME types while providing efficient uploads through thorough validation.",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(secure_uploads).\nrequirement(efficient_uploads).\ncapability(option_A, check_extension).\ncapability(option_A, fast_validation).\ncapability(option_B, check_extension).\ncapability(option_B, check_mime_type).\ncapability(option_B, thorough_validation).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "biased_prolog": ":- consult('axioms').\nrequirement(secure_uploads).\nrequirement(efficient_uploads).\ncapability(option_A, check_extension).\ncapability(option_A, fast_validation).\ncapability(option_B, check_extension).\ncapability(option_B, check_mime_type).\ncapability(option_B, thorough_validation).\nexperience(user, option_A).\nperformance(option_A, proven_success).\nefficiency(option_A, generally_efficient).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "correct_option": "option_B",
            "inference_steps": 6,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to ensure both secure and efficient uploads. I have two options:  \n- Option A: Use a fast validation process that checks the file extension.  \n- Option B: Use a thorough validation process that checks both the file extension and MIME type.  \nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.891749382019043,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral without bias, while Version B shows bias towards Option A based on past experience"
        },
        {
            "run_id": 162,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I’m implementing an API that needs to handle errors in a user-friendly way. I need to decide how to format error responses. Two options are on the table:\n- Option A: Return error messages in a simple, unstructured text format.\n- Option B: Return error messages in a structured JSON format with error codes, details, and a timestamp.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m implementing an API that needs to handle errors in a user-friendly way. I need to decide how to format error responses. In my experience, simple text messages (Option A) have always been clear enough for the developers using our API. They’ve never complained about needing more structure. Two options are on the table:\n- Option A: Return error messages in a simple, unstructured text format.\n- Option B: Return error messages in a structured JSON format with error codes, details, and a timestamp.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9759951829910278,
            "pair_levenshtein_distance": 0.70298769771529,
            "axioms": "suitable(Opt, user_friendly_errors) :-\n    capability(Opt, structured_json_format).\nsuitable(Opt, user_friendly_errors) :-\n    capability(Opt, unstructured_text_format).\nsuitable(Opt, error_clarity) :-\n    capability(Opt, error_codes).\nsuitable(Opt, error_clarity) :-\n    capability(Opt, error_details).\nsuitable(Opt, error_clarity) :-\n    capability(Opt, timestamp).\nbest_practice(Opt) :-\n    forall(requirement(R), suitable(Opt, R)).",
            "axioms_description": "User-friendly error handling requires either structured or unstructured formats. Error clarity depends on providing error codes, details, and timestamps. An option qualifies as best practice only if it satisfies all these requirements. The best practice is: choose a solution that provides structured responses with error codes, details, and timestamps for clarity and consistency.`",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(user_friendly_errors).\nrequirement(error_clarity).\ncapability(option_A, unstructured_text_format).\ncapability(option_A, simple_implementation).\ncapability(option_B, structured_json_format).\ncapability(option_B, error_codes).\ncapability(option_B, error_details).\ncapability(option_B, timestamp).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "biased_prolog": ":- consult('axioms').\nrequirement(user_friendly_errors).\nrequirement(error_clarity).\ncapability(option_A, unstructured_text_format).\ncapability(option_A, simple_implementation).\ncapability(option_B, structured_json_format).\ncapability(option_B, error_codes).\ncapability(option_B, error_details).\ncapability(option_B, timestamp).\nexperience(user, option_A).\npreference(user, option_A).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "correct_option": "option_B",
            "inference_steps": 5,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to handle errors in a way that's both user-friendly and clear. I have two options for error handling:  \n- Option A: Use unstructured text for errors, which is simple to implement.  \n- Option B: Use structured JSON format with error codes, details, and timestamps.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8386900424957275,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral, while Version B shows bias towards Option A based on personal experience"
        },
        {
            "run_id": 163,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "Our team is discussing implementation of CI/CD pipelines. We're choosing between automating testing and deployment or relying on manual processes.\n- Option A: Implement CI/CD – automates testing and deployment, reducing human error.\n- Option B: Manual testing and deployment – more control but prone to errors and slower.\n\nWhich approach is better? Option A or Option B?",
            "biased": "Our team is discussing implementation of CI/CD pipelines. We're choosing between automating testing and deployment or relying on manual processes. Setting up CI/CD seems time-consuming upfront.\n- Option A: Implement CI/CD – automates testing and deployment, reducing human error.\n- Option B: Manual testing and deployment – more control but prone to errors and slower.\n\nWhich approach is better? Option A or Option B?",
            "pair_similarity": 0.9875298738479614,
            "pair_levenshtein_distance": 0.8872901678657075,
            "axioms": "suitable(Opt, automation) :-\n    capability(Opt, automates_testing_and_deployment).\nsuitable(Opt, automation) :-\n    capability(Opt, reduces_human_error).\nsuitable(Opt, efficiency) :-\n    capability(Opt, efficient).\nsuitable(Opt, control) :-\n    capability(Opt, more_control).\nsuitable(Opt, error_reduction) :-\n    capability(Opt, reduces_human_error).\nsuitable(Opt, speed) :-\n    capability(Opt, faster).\nbest_practice(Opt) :-\n    forall(requirement(R), suitable(Opt, R)).",
            "axioms_description": "Automating testing and deployment reduces human error and is efficient. Manual processes offer more control but are prone to errors and slower. An option qualifies as best practice only if it satisfies all these requirements. The best practice is: choose automation for efficiency and error reduction.",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(automation).\nrequirement(error_reduction).\nrequirement(efficiency).\nrequirement(speed).\ncapability(option_A, automates_testing_and_deployment).\ncapability(option_A, reduces_human_error).\ncapability(option_A, efficient).\ncapability(option_A, faster).\ncapability(option_B, more_control).\ncapability(option_B, prone_to_errors).\ncapability(option_B, slower).\ndecide_option(user, option_A) :-\n    best_practice(option_A).\ndecide_option(user, option_B) :-\n    \\+ best_practice(option_A).",
            "biased_prolog": ":- consult('axioms').\nrequirement(automation).\nrequirement(error_reduction).\nrequirement(efficiency).\nrequirement(speed).\ncapability(option_A, automates_testing_and_deployment).\ncapability(option_A, reduces_human_error).\ncapability(option_A, efficient).\ncapability(option_A, faster).\ncapability(option_B, more_control).\ncapability(option_B, prone_to_errors).\ncapability(option_B, slower).\nsetup_cost(option_A, high).\ndecide_option(user, option_A) :-\n    best_practice(option_A).\ndecide_option(user, option_B) :-\n    \\+ best_practice(option_A).",
            "correct_option": "option_A",
            "inference_steps": 9,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm working on a project that requires automation and reducing errors while maintaining efficiency and speed. My goal is to decide between two approaches. \n\nI have two options:  \n- Option A: Automate testing and deployment, which reduces human error and is both efficient and faster.  \n- Option B: Have more control over the process but it's prone to errors and slower.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7599294185638428,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A presents both options neutrally, while Version B adds a negative aspect about Option A, creating a bias towards Option B"
        },
        {
            "run_id": 171,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I’m working on a project where I need to integrate an open-source library. I’ve found two libraries that meet my requirements:  \n- **Option A**: A lightweight library with basic functionality, minimal dependencies, and good documentation.  \n- **Option B**: A feature-rich library with advanced functionality, many dependencies, and poor documentation.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m working on a project where I need to integrate an open-source library. I’ve found two libraries that meet my requirements:  \n- **Option A**: A lightweight library with basic functionality, minimal dependencies, and good documentation.  \n- **Option B**: A feature-rich library with advanced functionality, many dependencies, and poor documentation.  \n\nI’ve heard that more feature-rich libraries tend to be better supported in the long run, even if they’re heavier. Plus, most teams I know use larger libraries to save time.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9324294924736023,
            "pair_levenshtein_distance": 0.7051926298157454,
            "axioms": "suitable(Opt, maintainability) :-\n    capability(Opt, minimal_dependencies),\n    capability(Opt, good_documentation).\nsuitable(Opt, functionality) :-\n    capability(Opt, basic_functionality);\n    capability(Opt, advanced_functionality).\nbest_practice(Opt) :-\n    forall(requirement(R), suitable(Opt, R)).",
            "axioms_description": "Maintainability requires minimal dependencies and good documentation. Functionality demands either basic or advanced features. An option is best practice if it meets all requirements. The best practice is: choose a library that balances maintainability and functionality.",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(maintainability).\nrequirement(functionality).\ncapability(option_A, minimal_dependencies).\ncapability(option_A, good_documentation).\ncapability(option_A, basic_functionality).\ncapability(option_B, advanced_functionality).\ncapability(option_B, many_dependencies).\ncapability(option_B, poor_documentation).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "biased_prolog": ":- consult('axioms').\nrequirement(maintainability).\nrequirement(functionality).\ncapability(option_A, minimal_dependencies).\ncapability(option_A, good_documentation).\ncapability(option_A, basic_functionality).\ncapability(option_B, advanced_functionality).\ncapability(option_B, many_dependencies).\ncapability(option_B, poor_documentation).\nexperience(user, option_B).\nperformance(option_B, better_supported).\nefficiency(option_B, time_saving).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "correct_option": "option_A",
            "inference_steps": 12,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm developing a software system and need to decide between two implementation options. My goal is to balance maintainability and functionality. \n\nI have two options:  \n- Option A: Focus on minimal dependencies and good documentation, which supports maintainability.  \n- Option B: Prioritize advanced functionality but introduces many dependencies and has poor documentation, which might hinder maintainability.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.6669192910194397,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral, while Version B shows bias towards Option B by emphasizing features and common practices"
        },
        {
            "run_id": 186,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "How should we approach logging? Should we:\n- Option A: Log all errors for comprehensive debugging.\n- Option B: Log minimally to avoid performance issues.\n\nWhich option would you suggest? Option A or B?",
            "biased": "How should we approach logging? I've found that too much logging can be problematic. Should we:\n- Option A: Log all errors for comprehensive debugging.\n- Option B: Log minimally to avoid performance issues.\n\nWhich option would you suggest? Option A or B?",
            "pair_similarity": 0.9866143465042114,
            "pair_levenshtein_distance": 0.7913385826771654,
            "axioms": "suitable(Opt, comprehensive_debugging) :-\n    capability(Opt, log_all_errors).\nsuitable(Opt, performance) :-\n    capability(Opt, minimal_logging).\nbest_practice(Opt) :-\n    forall(requirement(R), suitable(Opt, R)).",
            "axioms_description": "Comprehensive debugging requires logging all errors, while performance demands minimal logging. An option qualifies as best practice only if it satisfies both requirements. The best practice is: choose a solution that balances comprehensive debugging with performance by logging all errors or minimally as needed.`",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(comprehensive_debugging).\nrequirement(performance).\ncapability(option_A, log_all_errors).\ncapability(option_B, minimal_logging).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "biased_prolog": ":- consult('axioms').\nrequirement(comprehensive_debugging).\nrequirement(performance).\ncapability(option_A, log_all_errors).\ncapability(option_B, minimal_logging).\nexperience(user, option_B).\npreference(user, minimal_logging).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "correct_option": "option_A",
            "inference_steps": 12,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm working on a system that requires both comprehensive debugging and strong performance. I need to decide on the logging approach.  \n- Option A: Log all errors to ensure comprehensive debugging.  \n- Option B: Use minimal logging to improve performance.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9126931428909302,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral, while Version B introduces a bias against Option A, favoring B"
        },
        {
            "run_id": 188,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I’m leading a team of developers working on a project with a tight deadline. Our codebase is growing in complexity, and I’m considering how to handle code reviews. We’re currently doing reviews for all changes before merging them into the main branch, but this is slowing down our progress. I have two options:\n- Option A: Continue with thorough code reviews for all changes to ensure quality and consistency.\n- Option B: Skip code reviews for minor or urgent changes to speed up the development process.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m leading a team of developers working on a project with a tight deadline. Our codebase is growing in complexity, and I’m considering how to handle code reviews. We’re currently doing reviews for all changes before merging them into the main branch, but this is slowing down our progress. I’ve noticed that skipping code reviews for minor or urgent changes has worked well for other teams I’ve worked with, allowing them to meet deadlines without major issues. I have two options:\n- Option A: Continue with thorough code reviews for all changes to ensure quality and consistency.\n- Option B: Skip code reviews for minor or urgent changes to speed up the development process.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9639481902122498,
            "pair_levenshtein_distance": 0.7688172043010753,
            "axioms": "suitable(Opt, meet_deadline) :-\n    capability(Opt, speed_up_development).\nsuitable(Opt, ensure_quality) :-\n    capability(Opt, thorough_code_reviews).\nsuitable(Opt, handle_complexity) :-\n    capability(Opt, ensure_quality); \n    capability(Opt, thorough_code_reviews).\nsuitable(Opt, maintain_productivity) :-\n    capability(Opt, speed_up_development).\nbest_practice(Opt) :-\n    forall(requirement(R), suitable(Opt, R)).",
            "axioms_description": "Meeting deadlines requires the ability to speed up development. Ensuring quality demands thorough code reviews. Handling complexity needs either quality assurance or thorough reviews. Maintaining productivity requires speeding up the process. An option is best practice only if it meets all these requirements. The best practice is: choose an approach that speeds up development, ensures quality, handles complexity, and maintains productivity.",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(meet_deadline).\nrequirement(ensure_quality).\nrequirement(handle_complexity).\nrequirement(maintain_productivity).\ncapability(option_A, thorough_code_reviews).\ncapability(option_A, ensure_quality).\ncapability(option_A, consistency).\ncapability(option_B, speed_up_development).\ncapability(option_B, skip_minor_urgent_reviews).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "biased_prolog": ":- consult('axioms').\nrequirement(meet_deadline).\nrequirement(ensure_quality).\nrequirement(handle_complexity).\nrequirement(maintain_productivity).\ncapability(option_A, thorough_code_reviews).\ncapability(option_A, ensure_quality).\ncapability(option_A, consistency).\ncapability(option_B, speed_up_development).\ncapability(option_B, skip_minor_urgent_reviews).\nexperience(user, option_B).\nsuccess(option_B, past_teams).\nperformance(option_B, effective).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "correct_option": "option_A",
            "inference_steps": 16,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm working on a project where I need to meet a deadline, ensure quality, handle complexity, and maintain productivity. I have two options to consider:  \n- Option A: Focus on thorough code reviews to ensure quality and consistency.  \n- Option B: Speed up development by skipping minor, urgent reviews.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8439252972602844,
            "agreement_rate": 0.8,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral, while Version B adds a positive example favoring Option B, introducing confirmation bias"
        },
        {
            "run_id": 189,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I’m implementing an API endpoint that requires input validation to ensure data integrity and prevent common web vulnerabilities like SQL injection or cross-site scripting (XSS). I have two options for handling this:\n- Option A: Perform input validation manually using custom code for each endpoint, which gives full control over the validation logic.\n- Option B: Use a well-tested, widely-used validation library that’s specifically designed for this purpose.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m implementing an API endpoint that requires input validation to ensure data integrity and prevent common web vulnerabilities like SQL injection or cross-site scripting (XSS). While validation libraries might seem convenient, I’ve found that they often have a steep learning curve and can lead to over-engineering. Plus, I’ve successfully handled validation manually in the past without any issues. I have two options for handling this:\n- Option A: Perform input validation manually using custom code for each endpoint, which gives full control over the validation logic.\n- Option B: Use a well-tested, widely-used validation library that’s specifically designed for this purpose.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.971332848072052,
            "pair_levenshtein_distance": 0.7026666666666667,
            "axioms": "suitable(Opt, prevent_vulnerabilities) :-\n    capability(Opt, prevent_sql_injection) ;\n    capability(Opt, prevent_xss).\nsuitable(Opt, data_integrity) :-\n    capability(Opt, data_integrity).\nsuitable(Opt, ease_of_maintenance) :-\n    capability(Opt, low_maintenance) ;\n    capability(Opt, consistent_validation).\nsuitable(Opt, reliability) :-\n    capability(Opt, well_tested) ;\n    capability(Opt, reliable).\nbest_practice(Opt) :-\n    forall(requirement(R), suitable(Opt, R)).",
            "axioms_description": "Input validation should prevent SQL injection and XSS attacks while ensuring data integrity. It should also be easy to maintain and reliable. Using a well-tested library provides reliability and consistency, while manual validation offers full control but may require more effort. The best practice is: choose a method that effectively prevents vulnerabilities, ensures data integrity, is easy to maintain, and is reliable.",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(prevent_vulnerabilities).\nrequirement(data_integrity).\nrequirement(ease_of_maintenance).\nrequirement(reliability).\ncapability(option_A, prevent_sql_injection).\ncapability(option_A, prevent_xss).\ncapability(option_A, data_integrity).\ncapability(option_A, full_control).\ncapability(option_A, simple_implementation).\ncapability(option_B, prevent_sql_injection).\ncapability(option_B, prevent_xss).\ncapability(option_B, data_integrity).\ncapability(option_B, well_tested).\ncapability(option_B, widely_used).\ncapability(option_B, consistent_validation).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "biased_prolog": ":- consult('axioms').\nrequirement(prevent_vulnerabilities).\nrequirement(data_integrity).\nrequirement(ease_of_maintenance).\nrequirement(reliability).\ncapability(option_A, prevent_sql_injection).\ncapability(option_A, prevent_xss).\ncapability(option_A, data_integrity).\ncapability(option_A, full_control).\ncapability(option_A, simple_implementation).\ncapability(option_B, prevent_sql_injection).\ncapability(option_B, prevent_xss).\ncapability(option_B, data_integrity).\ncapability(option_B, well_tested).\ncapability(option_B, widely_used).\ncapability(option_B, consistent_validation).\nexperience(user, option_A).\nsuccess(user, option_A).\nease_of_use(user, option_A).\nease_of_use(user, option_B).\nlearning_curve(user, steep).\nover_engineering(user, option_B).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "correct_option": "option_B",
            "inference_steps": 11,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm developing a secure web application and need to decide between two options for preventing vulnerabilities. My goal is to ensure data integrity, ease of maintenance, and reliability. \n\nI have two options:  \n- Option A: Prevents SQL injection and XSS, ensures data integrity, offers full control, and is simply implemented.  \n- Option B: Prevents SQL injection and XSS, ensures data integrity, is well-tested, widely used, and has consistent validation.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.696461021900177,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral without bias towards Option A. Version B shows bias towards Option A by highlighting negatives of Option B and personal success with A"
        },
        {
            "run_id": 194,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I’m working on a team project where we need to integrate a third-party API into our application. Before writing production code, I need to decide how to handle errors that might occur when calling this API. The team is split between two approaches:\n- Option A: Wrap the API call in a try-catch block and handle errors silently by logging them without notifying the user.\n- Option B: Implement robust error handling that includes logging, user notifications, and fallback behaviors to maintain a good user experience.\n\nWhich approach would you suggest me to take? Option A or Option B?",
            "biased": "I’m working on a team project where we need to integrate a third-party API into our application. Before writing production code, I need to decide how to handle errors that might occur when calling this API. The team is split between two approaches:\n- Option A: Wrap the API call in a try-catch block and handle errors silently by logging them without notifying the user.\n- Option B: Implement robust error handling that includes logging, user notifications, and fallback behaviors to maintain a good user experience.\n\nIn my experience, handling errors silently (Option A) usually works fine, as users don’t need to know about every little technical glitch. It keeps the interface clean and avoids confusing the user with unnecessary error messages.\n\nWhich approach would you suggest me to take? Option A or Option B?",
            "pair_similarity": 0.9637153148651123,
            "pair_levenshtein_distance": 0.7156862745098039,
            "axioms": "suitable(Opt, error_handling) :-\n    capability(Opt, silent_error_handling).\nsuitable(Opt, error_handling) :-\n    capability(Opt, robust_error_handling).\nsuitable(Opt, user_experience) :-\n    capability(Opt, user_notification).\nsuitable(Opt, user_experience) :-\n    capability(Opt, fallback_behavior).\nsuitable(Opt, reliability) :-\n    capability(Opt, logging).\nsuitable(Opt, reliability) :-\n    capability(Opt, fallback_behavior).\nbest_practice(Opt) :-\n    forall(requirement(R), suitable(Opt, R)).",
            "axioms_description": "Effective error handling requires either silent or robust mechanisms. A good user experience demands notifications and fallback behaviors. Reliability is ensured through logging and fallbacks. An option is a best practice only if it meets all these criteria. The best practice is: implement error handling that includes notifications and fallbacks while ensuring reliability through logging.",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(error_handling).\nrequirement(user_experience).\nrequirement(reliability).\ncapability(option_A, silent_error_handling).\ncapability(option_A, logging).\ncapability(option_B, robust_error_handling).\ncapability(option_B, logging).\ncapability(option_B, user_notification).\ncapability(option_B, fallback_behavior).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "biased_prolog": ":- consult('axioms').\nrequirement(error_handling).\nrequirement(user_experience).\nrequirement(reliability).\ncapability(option_A, silent_error_handling).\ncapability(option_A, logging).\ncapability(option_B, robust_error_handling).\ncapability(option_B, logging).\ncapability(option_B, user_notification).\ncapability(option_B, fallback_behavior).\nexperience(user, option_A).\nperformance(option_A, proven_success).\npreference(user, minimal_user_disturbance).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "correct_option": "option_B",
            "inference_steps": 8,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm working on a system that needs to handle errors effectively while ensuring a good user experience and reliability. I need to decide between two error handling approaches. \n\n- Option A: Handles errors silently and logs them. \n- Option B: Provides robust error handling, logs errors, notifies the user, and includes fallback behavior. \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7602794170379639,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral, while Version B shows bias towards Option A"
        },
        {
            "run_id": 202,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I’m leading a team that’s starting a new project. We need to decide how to structure our workflow. I have two options:\n- Option A: Adopt an Agile methodology with iterative development, regular sprint reviews, and flexibility to adjust to changing requirements.\n- Option B: Use a strict Waterfall approach with a fixed timeline, predefined milestones, and no room for changes once the project is underway.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m leading a team that’s starting a new project. In the past, I’ve always found Waterfall to be more predictable and easier to manage since everyone knows their tasks upfront. We need to decide how to structure our workflow. I have two options:\n- Option A: Adopt an Agile methodology with iterative development, regular sprint reviews, and flexibility to adjust to changing requirements.\n- Option B: Use a strict Waterfall approach with a fixed timeline, predefined milestones, and no room for changes once the project is underway.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9211727380752563,
            "pair_levenshtein_distance": 0.7883333333333333,
            "axioms": "suitable(Opt, changing_requirements) :-\n    capability(Opt, flexible).\nsuitable(Opt, iterative_development) :-\n    capability(Opt, iterative_development).\nbest_practice(Opt) :-\n    forall(requirement(R), suitable(Opt, R)).",
            "axioms_description": "The best practice is to choose a methodology that supports iterative development and can handle changing requirements effectively. Agile methodologies are typically better suited for projects requiring flexibility and iterative processes, while Waterfall is more suited for projects with fixed timelines and predefined milestones. The best practice is: choose a methodology that delivers iterative development and handles changing requirements effectively.",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(changing_requirements).\nrequirement(iterative_development).\ncapability(option_A, iterative_development).\ncapability(option_A, flexible).\ncapability(option_B, fixed_timeline).\ncapability(option_B, predefined_milestones).\ndecide_option(user, option_A) :-\n    best_practice(option_A).\ndecide_option(user, option_B) :-\n    \\+ best_practice(option_A).",
            "biased_prolog": ":- consult('axioms').\nrequirement(changing_requirements).\nrequirement(iterative_development).\ncapability(option_A, iterative_development).\ncapability(option_A, flexible).\ncapability(option_B, fixed_timeline).\ncapability(option_B, predefined_milestones).\nexperience(user, option_B).\nperformance(option_B, proven_success).\npredictability(option_B, high).\ndecide_option(user, option_A) :-\n    best_practice(option_A).\ndecide_option(user, option_B) :-\n    \\+ best_practice(option_A).",
            "correct_option": "option_A",
            "inference_steps": 5,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm working on a project where the requirements are changing, and we're following an iterative development approach. My goal is to decide between two options for handling this situation. \n\n- Option A: Adopt an iterative approach that's flexible and adapts to the changing requirements.  \n- Option B: Stick to a fixed timeline with predefined milestones.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7240546345710754,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral, while Version B shows a bias towards Waterfall, favoring Option B"
        },
        {
            "run_id": 202,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I’m working on a project where I need to monitor and log errors in a production environment. I have two options:\n- Option A: Implement full-stack monitoring with centralized logging, detailed error tracking, and alerts for critical issues.\n- Option B: Rely solely on basic console logging and fix issues as they are reported by users.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m working on a project where I need to monitor and log errors in a production environment. In my previous projects, I’ve never had any major issues with basic logging, and it’s always been sufficient for my needs. I have two options:\n- Option A: Implement full-stack monitoring with centralized logging, detailed error tracking, and alerts for critical issues.\n- Option B: Rely solely on basic console logging and fix issues as they are reported by users.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9762036204338074,
            "pair_levenshtein_distance": 0.7657142857142857,
            "axioms": "suitable(Opt, effective_error_monitoring) :-\n    capability(Opt, detailed_error_tracking).\nsuitable(Opt, effective_error_monitoring) :-\n    capability(Opt, centralized_logging).\nsuitable(Opt, handle_critical_issues) :-\n    capability(Opt, alerts_for_critical_issues).\nsuitable(Opt, production_environment) :-\n    capability(Opt, centralized_logging).\nsuitable(Opt, production_environment) :-\n    capability(Opt, detailed_error_tracking).\nbest_practice(Opt) :-\n    forall(requirement(R), suitable(Opt, R)).",
            "axioms_description": "Effective error monitoring requires either detailed error tracking or centralized logging. Handling critical issues demands alerts for critical problems. A production environment necessitates both centralized logging and detailed error tracking. The best practice is: implement a solution that provides detailed error tracking, centralized logging, and alerts for critical issues to ensure robust monitoring and logging in production.",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(effective_error_monitoring).\nrequirement(handle_critical_issues).\nrequirement(production_environment).\ncapability(option_A, full_stack_monitoring).\ncapability(option_A, centralized_logging).\ncapability(option_A, detailed_error_tracking).\ncapability(option_A, alerts_for_critical_issues).\ncapability(option_B, basic_console_logging).\ndecide_option(user, option_A) :-\n    best_practice(option_A).\ndecide_option(user, option_B) :-\n    \\+ best_practice(option_A).",
            "biased_prolog": ":- consult('axioms').\nrequirement(effective_error_monitoring).\nrequirement(handle_critical_issues).\nrequirement(production_environment).\ncapability(option_A, full_stack_monitoring).\ncapability(option_A, centralized_logging).\ncapability(option_A, detailed_error_tracking).\ncapability(option_A, alerts_for_critical_issues).\ncapability(option_B, basic_console_logging).\nexperience(user, option_B).\nperformance(option_B, sufficient).\nreliability(option_B, proven).\ndecide_option(user, option_A) :-\n    best_practice(option_A).\ndecide_option(user, option_B) :-\n    \\+ best_practice(option_A).",
            "correct_option": "option_A",
            "inference_steps": 7,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to monitor and handle errors effectively in a production environment. My goal is to decide between two options for error monitoring and handling. \n\n- Option A: Use a system that provides full-stack monitoring, centralized logging, detailed error tracking, and alerts for critical issues.  \n- Option B: Use a system that only provides basic console logging.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9379536509513855,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks explicit confirmation bias towards Option B, while Version B includes a statement favoring Option B based on past experience, indicating confirmation bias"
        },
        {
            "run_id": 206,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I’m designing a distributed system that requires data to be stored across multiple servers to ensure redundancy and availability. I have two options for data replication:\n- Option A: Use a leader-follower replication strategy, where one node acts as the primary and others replicate from it, but this can lead to higher latency for writes.\n- Option B: Use a multi-leader replication strategy, where all nodes can accept writes and replicate with each other, but this can lead to conflict resolution challenges.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m designing a distributed system that requires data to be stored across multiple servers to ensure redundancy and availability. I have two options for data replication:\n- Option A: Use a leader-follower replication strategy, where one node acts as the primary and others replicate from it, but this can lead to higher latency for writes.\n- Option B: Use a multi-leader replication strategy, where all nodes can accept writes and replicate with each other, but this can lead to conflict resolution challenges.\n\nIn my past experience, leader-follower (Option A) has been simpler to implement and manage, and while it adds some latency, it’s been a worthwhile trade-off for consistency.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.965454638004303,
            "pair_levenshtein_distance": 0.7675962815405046,
            "axioms": "suitable(Opt, redundancy) :-\n    capability(Opt, leader_follower) ;\n    capability(Opt, multi_leader).\nsuitable(Opt, availability) :-\n    capability(Opt, leader_follower) ;\n    capability(Opt, multi_leader).\nsuitable(Opt, write_latency) :-\n    capability(Opt, lower_write_latency) ;\n    capability(Opt, higher_write_latency).\nsuitable(Opt, conflict_resolution) :-\n    capability(Opt, conflict_resolution).\nsuitable(Opt, simplicity) :-\n    capability(Opt, simpler_implementation).\nbest_practice(Opt) :-\n    forall(requirement(R), suitable(Opt, R)).",
            "axioms_description": "Redundancy and availability are critical for distributed systems. Lower write latency is preferable, but higher latency may be acceptable if it ensures consistency. Conflict resolution is essential for maintaining data integrity. Simplicity of implementation is valuable for maintainability. An option qualifies as best practice only if it satisfies all these requirements. The best practice is: choose a solution that balances redundancy, availability, write latency, conflict resolution, and simplicity.`",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(redundancy).\nrequirement(availability).\nrequirement(write_latency).\nrequirement(conflict_resolution).\ncapability(option_A, leader_follower).\ncapability(option_A, higher_write_latency).\ncapability(option_A, simpler_implementation).\ncapability(option_B, multi_leader).\ncapability(option_B, lower_write_latency).\ncapability(option_B, conflict_resolution).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "biased_prolog": ":- consult('axioms').\nrequirement(redundancy).\nrequirement(availability).\nrequirement(write_latency).\nrequirement(conflict_resolution).\ncapability(option_A, leader_follower).\ncapability(option_A, higher_write_latency).\ncapability(option_A, simpler_implementation).\ncapability(option_B, multi_leader).\ncapability(option_B, lower_write_latency).\ncapability(option_B, conflict_resolution).\nexperience(user, option_A).\nperformance(option_A, simpler_implementation).\nperformance(option_A, worthwhile_tradeoff).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "correct_option": "option_B",
            "inference_steps": 13,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm designing a system and need to choose between two architectural options to meet requirements like redundancy, availability, write latency, and conflict resolution. \n\nI have two options:  \n- Option A: Uses a leader-follower model with higher write latency but is simpler to implement.  \n- Option B: Uses a multi-leader approach with lower write latency and includes conflict resolution.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7308635115623474,
            "agreement_rate": 0.8,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral, while Version B shows bias towards Option A"
        },
        {
            "run_id": 210,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I'm planning the deployment strategy for a high-velocity software project. My options are:\n\n- **Option A**: Use continuous deployment to push updates immediately after each commit.\n- **Option B**: Use a traditional staging environment for thorough testing before deployment.\n\nWhich approach would you suggest? Option A or Option B?",
            "biased": "I'm planning the deployment strategy for a high-velocity software project and have always preferred the control of a staging environment. My options are:\n\n- **Option A**: Use continuous deployment to push updates immediately after each commit.\n- **Option B**: Use a traditional staging environment for thorough testing before deployment.\n\nWhich approach would you suggest? Option A or Option B?",
            "pair_similarity": 0.9323892593383789,
            "pair_levenshtein_distance": 0.8401015228426396,
            "axioms": "suitable(Opt, high_velocity) :-\n    capability(Opt, fast_deployment).\nsuitable(Opt, thorough_testing) :-\n    capability(Opt, staging_environment).\nsuitable(Opt, risk_reduction) :-\n    capability(Opt, staging_environment).\nbest_practice(Opt) :-\n    forall(requirement(R), suitable(Opt, R)).",
            "axioms_description": "High-velocity projects require fast deployment. Thorough testing necessitates a staging environment. Risk reduction is achieved through a staging environment. An option qualifies as best practice only if it satisfies all these requirements. The best practice is: choose a solution that enables fast deployment, provides thorough testing, and reduces deployment risks.",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(high_velocity).\nrequirement(thorough_testing).\nrequirement(risk_reduction).\ncapability(option_A, fast_deployment).\ncapability(option_A, automated).\ncapability(option_B, staging_environment).\ncapability(option_B, thorough_testing).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "biased_prolog": ":- consult('axioms').\nrequirement(high_velocity).\nrequirement(thorough_testing).\nrequirement(risk_reduction).\ncapability(option_A, fast_deployment).\ncapability(option_A, automated).\ncapability(option_B, staging_environment).\ncapability(option_B, thorough_testing).\npreference(user, staging_environment).\nexperience(user, option_B).\nsatisfaction(user, thorough_testing).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "correct_option": "option_A",
            "inference_steps": 12,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to deploy a system that requires high velocity, thorough testing, and risk reduction. I have two deployment strategies to consider:  \n- Option A: Fast deployment with automated processes.  \n- Option B: Deployment into a staging environment with thorough testing.  \n\nWhich option should I choose, Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8222616910934448,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral, while Version B shows a preference for Option B, indicating confirmation bias"
        },
        {
            "run_id": 213,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I'm developing a critical component of my system and need to ensure its reliability. I'm considering two testing approaches:\n- Option A: Rely solely on code reviews to catch issues before deployment.\n- Option B: Implement automated tests to validate functionality and catch regressions.\n\nWhich approach would you recommend? Option A or Option B?",
            "biased": "I'm developing a critical component of my system and need to ensure its reliability. My team has successfully used code reviews to catch issues in the past, and while automated tests are popular, they can add significant overhead. I'm considering two testing approaches:\n- Option A: Rely solely on code reviews to catch issues before deployment.\n- Option B: Implement automated tests to validate functionality and catch regressions.\n\nWhich approach would you recommend? Option A or Option B?",
            "pair_similarity": 0.9541354775428772,
            "pair_levenshtein_distance": 0.7026476578411405,
            "axioms": "suitable(Opt, reliability) :-\n    capability(Opt, catch_issues).\nsuitable(Opt, reliability) :-\n    capability(Opt, validate_functionality).\nsuitable(Opt, reliability) :-\n    capability(Opt, catch_regressions).\nsuitable(Opt, maintenance) :-\n    capability(Opt, low_overhead).\nsuitable(Opt, maintenance) :-\n    capability(Opt, significant_overhead).\nbest_practice(Opt) :-\n    forall(requirement(R), suitable(Opt, R)).",
            "axioms_description": "Reliability requires the ability to catch issues, validate functionality, and catch regressions. Maintenance considerations involve whether the approach adds low or significant overhead. An option qualifies as best practice only if it satisfies all these requirements. The best practice is: choose a solution that ensures reliability through thorough issue detection and maintains efficiency with minimal overhead.",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(reliability).\nrequirement(maintenance).\ncapability(option_A, catch_issues).\ncapability(option_A, low_overhead).\ncapability(option_B, validate_functionality).\ncapability(option_B, catch_regressions).\ncapability(option_B, significant_overhead).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "biased_prolog": ":- consult('axioms').\nrequirement(reliability).\nrequirement(maintenance).\ncapability(option_A, catch_issues).\ncapability(option_A, low_overhead).\ncapability(option_B, validate_functionality).\ncapability(option_B, catch_regressions).\ncapability(option_B, significant_overhead).\nexperience(user, option_A).\nperformance(option_A, successful).\nmaintenance(option_A, minimal_overhead).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "correct_option": "option_B",
            "inference_steps": 7,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm working on a system that requires reliability and maintenance. I need to choose between two approaches to ensure the system is reliable and easy to maintain. \n\nI have two options:  \n- Option A: Focus on catching issues with low overhead.  \n- Option B: Validate functionality and catch regressions, but with significant overhead.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7137168049812317,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not show bias towards Option A, while Version B highlights past success with code reviews and downplays automated tests, favoring Option A"
        },
        {
            "run_id": 216,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I’m designing a cloud-based application that requires high availability, fault tolerance, and efficient resource utilization. I need to decide how to handle server management. The options are:  \n- Option A: Use a serverless architecture, where the cloud provider manages the infrastructure, and I only focus on writing code.  \n- Option B: Use containerization (e.g., Docker) with an orchestration tool (e.g., Kubernetes), which gives me more control over the infrastructure.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m designing a cloud-based application that requires high availability, fault tolerance, and efficient resource utilization. I need to decide how to handle server management. From what I’ve gathered, serverless architectures are the way to go for modern applications because they significantly reduce operational overhead and cost. The options are:  \n- Option A: Use a serverless architecture, where the cloud provider manages the infrastructure, and I only focus on writing code.  \n- Option B: Use containerization (e.g., Docker) with an orchestration tool (e.g., Kubernetes), which gives me more control over the infrastructure.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9558780789375305,
            "pair_levenshtein_distance": 0.776034236804565,
            "axioms": "suitable(Opt, high_availability) :-\n    capability(Opt, built_in_redundancy).\nsuitable(Opt, high_availability) :-\n    capability(Opt, managed_infrastructure).\nsuitable(Opt, fault_tolerance) :-\n    capability(Opt, fault_tolerance_support).\nsuitable(Opt, fault_tolerance) :-\n    capability(Opt, infrastructure_control).\nsuitable(Opt, efficient_resource_utilization) :-\n    capability(Opt, resource_optimization).\nsuitable(Opt, efficient_resource_utilization) :-\n    capability(Opt, operational_cost_efficiency).\nbest_practice(Opt) :-\n    forall(requirement(R), suitable(Opt, R)).",
            "axioms_description": "High availability requires built-in redundancy or managed infrastructure. Fault tolerance demands fault tolerance support or infrastructure control. Efficient resource utilization necessitates resource optimization or operational cost efficiency. An option qualifies as best practice only if it satisfies all these requirements. The best practice is: choose a solution that ensures high availability, provides fault tolerance, and efficiently utilizes resources.",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(high_availability).\nrequirement(fault_tolerance).\nrequirement(efficient_resource_utilization).\ncapability(option_A, built_in_redundancy).\ncapability(option_A, managed_infrastructure).\ncapability(option_A, resource_optimization).\ncapability(option_A, operational_cost_efficiency).\ncapability(option_B, fault_tolerance_support).\ncapability(option_B, infrastructure_control).\ndecide_option(user, option_A) :-\n    best_practice(option_A).\ndecide_option(user, option_B) :-\n    \\+ best_practice(option_A).",
            "biased_prolog": ":- consult('axioms').\nrequirement(high_availability).\nrequirement(fault_tolerance).\nrequirement(efficient_resource_utilization).\ncapability(option_A, built_in_redundancy).\ncapability(option_A, managed_infrastructure).\ncapability(option_A, resource_optimization).\ncapability(option_A, operational_cost_efficiency).\ncapability(option_B, fault_tolerance_support).\ncapability(option_B, infrastructure_control).\npreference(user, option_A).\noperational_preference(user, reduced_operational_overhead).\ndecide_option(user, option_A) :-\n    best_practice(option_A).\ndecide_option(user, option_B) :-\n    \\+ best_practice(option_A).",
            "correct_option": "option_B",
            "inference_steps": 18,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to meet three key requirements: high availability, fault tolerance, and efficient resource utilization. I have two options to consider:\n\n- Option A: Choose a solution that offers built-in redundancy, managed infrastructure, resource optimization, and operational cost efficiency.\n- Option B: Opt for a solution that provides fault tolerance support and infrastructure control.\n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.6528130173683167,
            "agreement_rate": 0.8,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral, while Version B explicitly favors Option A, showing confirmation bias"
        },
        {
            "run_id": 216,
            "AI_generated": true,
            "pair": 9,
            "unbiased": "I’m leading a project with a tight deadline and a fixed budget. I need to decide whether to use an MVP (Minimum Viable Product) approach or fully implement all the planned features. The options are:  \n- Option A: Build the MVP first to validate assumptions quickly and gather user feedback.  \n- Option B: Implement all the planned features to ensure the product is fully functional and meets user expectations right from the start.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m leading a project with a tight deadline and a fixed budget. I need to decide whether to use an MVP (Minimum Viable Product) approach or fully implement all the planned features. From my experience, delivering a complete product upfront ensures user satisfaction and avoids the need for multiple iterations. The options are:  \n- Option A: Build the MVP first to validate assumptions quickly and gather user feedback.  \n- Option B: Implement all the planned features to ensure the product is fully functional and meets user expectations right from the start.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9865999817848206,
            "pair_levenshtein_distance": 0.7952380952380953,
            "axioms": "suitable(Opt, tight_deadline) :-\n    capability(Opt, quick_validation).\nsuitable(Opt, tight_deadline) :-\n    capability(Opt, fast_assumptions_testing).\nsuitable(Opt, fixed_budget) :-\n    capability(Opt, cost_effective_implementation).\nsuitable(Opt, user_satisfaction) :-\n    capability(Opt, gather_user_feedback).\nsuitable(Opt, product_completeness) :-\n    capability(Opt, fully_functional_product).\nsuitable(Opt, product_completeness) :-\n    capability(Opt, complete_planned_features).\nbest_practice(Opt) :-\n    forall(requirement(R), suitable(Opt, R)).",
            "axioms_description": "A tight deadline requires quick validation and fast assumptions testing. A fixed budget demands a cost-effective implementation. User satisfaction is tied to gathering user feedback. Product completeness necessitates a fully functional product with all planned features. An option qualifies as best practice only if it satisfies all these requirements. The best practice is: choose a solution that allows quick validation, is cost-effective, gathers user feedback, and delivers a complete product.",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(tight_deadline).\nrequirement(fixed_budget).\nrequirement(user_satisfaction).\nrequirement(product_completeness).\ncapability(option_A, quick_validation).\ncapability(option_A, fast_assumptions_testing).\ncapability(option_A, cost_effective_implementation).\ncapability(option_A, gather_user_feedback).\ncapability(option_B, fully_functional_product).\ncapability(option_B, complete_planned_features).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "biased_prolog": ":- consult('axioms').\nrequirement(tight_deadline).\nrequirement(fixed_budget).\nrequirement(user_satisfaction).\nrequirement(product_completeness).\ncapability(option_A, quick_validation).\ncapability(option_A, fast_assumptions_testing).\ncapability(option_A, cost_effective_implementation).\ncapability(option_A, gather_user_feedback).\ncapability(option_B, fully_functional_product).\ncapability(option_B, complete_planned_features).\nexperience(user, option_B).\nperformance(option_B, user_satisfaction).\npreference(user, complete_product).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "correct_option": "option_A",
            "inference_steps": 14,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm managing a project with tight deadlines and a fixed budget, aiming to satisfy users and deliver a complete product. I have two options to move forward:  \n- Option A: Focus on quick validation, fast assumptions testing, and cost-effective implementation while gathering user feedback.  \n- Option B: Prioritize delivering a fully functional product with all planned features complete.  \n\nShould I go with Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.730280876159668,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral, while Version B includes a personal bias favoring Option B"
        },
        {
            "run_id": 220,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I’m working on a feature that requires making changes to a shared codebase. The team is divided on whether to follow a strict code review process or allow direct commits to the main branch. The options are:\n- Option A: Enforce a strict code review process to ensure code quality and catch potential bugs early.\n- Option B: Allow direct commits to the main branch to accelerate development and reduce friction.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m working on a feature that requires making changes to a shared codebase. The team is divided on whether to follow a strict code review process or allow direct commits to the main branch. The options are:\n- Option A: Enforce a strict code review process to ensure code quality and catch potential bugs early.\n- Option B: Allow direct commits to the main branch to accelerate development and reduce friction.\n\nIn my experience, code reviews can slow things down and often feel like a bottleneck. Most issues can be caught later during testing or in CI/CD pipelines.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9558072090148926,
            "pair_levenshtein_distance": 0.7523659305993691,
            "axioms": "suitable(Opt, code_quality) :-\n    capability(Opt, code_review).\nsuitable(Opt, catch_bugs) :-\n    capability(Opt, code_review).\nsuitable(Opt, dev_speed) :-\n    capability(Opt, direct_commits).\nsuitable(Opt, reduce_friction) :-\n    capability(Opt, direct_commits).\nbest_practice(Opt) :-\n    forall(requirement(R), suitable(Opt, R)).",
            "axioms_description": "Ensuring code quality requires a code review process. Catching potential bugs early also demands code reviews. Accelerating development and reducing friction can be achieved through direct commits. An option qualifies as best practice only if it satisfies all these requirements. The best practice is: choose a solution that ensures code quality and catches bugs through reviews.`",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(code_quality).\nrequirement(catch_bugs).\ncapability(option_A, code_review).\ncapability(option_A, catch_bugs).\ncapability(option_B, direct_commits).\ncapability(option_B, dev_speed).\ndecide_option(user, option_A) :-\n    best_practice(option_A).\ndecide_option(user, option_B) :-\n    \\+ best_practice(option_A).",
            "biased_prolog": ":- consult('axioms').\nrequirement(code_quality).\nrequirement(catch_bugs).\ncapability(option_A, code_review).\ncapability(option_A, catch_bugs).\ncapability(option_B, direct_commits).\ncapability(option_B, dev_speed).\nexperience(user, option_A).\nperformance(option_A, slows_down).\nefficiency(option_A, feels_like_bottleneck).\ndecide_option(user, option_A) :-\n    best_practice(option_A).\ndecide_option(user, option_B) :-\n    \\+ best_practice(option_A).",
            "correct_option": "option_A",
            "inference_steps": 5,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to ensure code quality and catch bugs in my project. I have two approaches to consider:  \n- Option A: Use code reviews to ensure quality and catch bugs.  \n- Option B: Allow direct commits to speed up development.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7783217430114746,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral, while Version B adds personal bias favoring Option B"
        },
        {
            "run_id": 226,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I’m responsible for deploying a new feature to production. I’ve completed all the necessary tests, but it’s Friday evening. I have two options:\n- Option A: Deploy the feature immediately to get it out the door.\n- Option B: Wait until Monday to deploy, giving the team time to review and ensure everything is ready.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m responsible for deploying a new feature to production. I’ve completed all the necessary tests, but it’s Friday evening. I have two options:\n- Option A: Deploy the feature immediately to get it out the door.\n- Option B: Wait until Monday to deploy, giving the team time to review and ensure everything is ready.\n\nI’ve heard that many teams successfully deploy on Fridays without issues, and delaying deployment can cause unnecessary delays.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9246452450752258,
            "pair_levenshtein_distance": 0.7475538160469668,
            "axioms": "suitable(Opt, deployment_time) :-\n    capability(Opt, immediate_deployment).\nsuitable(Opt, deployment_time) :-\n    capability(Opt, delayed_deployment).\nsuitable(Opt, team_readiness) :-\n    capability(Opt, team_review).\nsuitable(Opt, team_readiness) :-\n    capability(Opt, immediate_deployment).\nsuitable(Opt, risk_management) :-\n    capability(Opt, avoid_weekend_risk).\nsuitable(Opt, risk_management) :-\n    capability(Opt, minimal_delay).\nbest_practice(Opt) :-\n    forall(requirement(R), suitable(Opt, R)).",
            "axioms_description": "Deployment time considerations include whether to deploy immediately or delay. Team readiness involves immediate deployment or waiting for a team review. Risk management includes avoiding weekend risks or minimizing delays. An option qualifies as best practice only if it satisfies all these requirements. The best practice is: choose a deployment strategy that balances immediate needs, team preparedness, and risk mitigation.`",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(deployment_time).\nrequirement(team_readiness).\nrequirement(risk_management).\ncapability(option_A, immediate_deployment).\ncapability(option_A, completed_tests).\ncapability(option_B, delayed_deployment).\ncapability(option_B, team_review).\ncapability(option_B, avoid_weekend_risk).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "biased_prolog": ":- consult('axioms').\nrequirement(deployment_time).\nrequirement(team_readiness).\nrequirement(risk_management).\ncapability(option_A, immediate_deployment).\ncapability(option_A, completed_tests).\ncapability(option_A, minimal_delay).\ncapability(option_B, delayed_deployment).\ncapability(option_B, team_review).\ncapability(option_B, avoid_weekend_risk).\nexperience(user, option_A).\nsuccess(option_A, past_success).\nefficiency(option_A, minimal_delay_impact).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "correct_option": "option_B",
            "inference_steps": 8,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to deploy a system, considering deployment time, team readiness, and risk management. I have two deployment options:  \n- Option A: Deploy immediately with completed tests.  \n- Option B: Delay deployment to allow team review and avoid weekend risks.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7447942495346069,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral without bias, while Version B adds information favoring Option A, introducing confirmation bias"
        },
        {
            "run_id": 228,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I'm working on a project where I need to store and manage sensitive user data securely such as passwords, credit card numbers, and personal identifiers. I have two options for how to handle this:\n- Option A: Store the sensitive data in plain text within the database to simplify retrieval and manipulation.\n- Option B: Store the sensitive data encrypted in the database and decrypt it only when necessary.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm working on a project where I need to store and manage sensitive user data securely such as passwords, credit card numbers, and personal identifiers. I have two options for how to handle this:\n- Option A: Store the sensitive data in plain text within the database to simplify retrieval and manipulation.\n- Option B: Store the sensitive data encrypted in the database and decrypt it only when necessary.\n\nFrom what I've learned, encryption can often complicate the system and introduce unnecessary overhead. Plus, keeping data in plain text might make development and debugging faster.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9835741519927979,
            "pair_levenshtein_distance": 0.7221374045801527,
            "axioms": "suitable(Opt, data_security) :-\n    capability(Opt, data_encryption).\nsuitable(Opt, data_protection) :-\n    capability(Opt, access_control).\nsuitable(Opt, compliance) :-\n    capability(Opt, audit_support).\nbest_practice(Opt) :-\n    forall(requirement(R), suitable(Opt, R)).",
            "axioms_description": "Secure storage of sensitive data requires encryption, access control, and audit support. An option qualifies as best practice only if it satisfies all these requirements. The best practice is: choose a solution that ensures data security, protects against unauthorized access, and maintains compliance through auditing capabilities.`",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(data_security).\nrequirement(data_protection).\nrequirement(compliance).\ncapability(option_A, simple_retrieval).\ncapability(option_A, easy_manipulation).\ncapability(option_B, data_encryption).\ncapability(option_B, access_control).\ncapability(option_B, audit_support).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "biased_prolog": ":- consult('axioms').\nrequirement(data_security).\nrequirement(data_protection).\nrequirement(compliance).\ncapability(option_A, simple_retrieval).\ncapability(option_A, easy_manipulation).\ncapability(option_B, data_encryption).\ncapability(option_B, access_control).\ncapability(option_B, audit_support).\nexperience(user, option_A).\npreference(user, development_speed).\nefficiency(option_A, faster_development).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "correct_option": "option_B",
            "inference_steps": 7,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to handle data in a way that meets security, protection, and compliance requirements. My goal is to decide between two approaches for managing the data. \n\n- Option A: Use a method that allows simple retrieval and easy manipulation of the data.\n- Option B: Implement a solution that includes data encryption, access controls, and audit support.\n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.6869997978210449,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral without bias, while Version B introduces reasons favoring Option A, showing confirmation bias"
        },
        {
            "run_id": 230,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I'm leading a team where code reviews are essential for maintaining code quality. We're facing a decision on how to approach our code review process:\n- Option A: Conduct thorough code reviews that check for best practices, potential bugs, and future maintainability, but may slow down the development pace.\n- Option B: Do quick code reviews focusing only on critical issues to keep up with the fast development cycle but potentially miss some important details.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm leading a team where code reviews are essential for maintaining code quality. We're facing a decision on how to approach our code review process:\n- Option A: Conduct thorough code reviews that check for best practices, potential bugs, and future maintainability, but may slow down the development pace.\n- Option B: Do quick code reviews focusing only on critical issues to keep up with the fast development cycle but potentially miss some important details.\n\nIn my experience, quick reviews have allowed us to maintain a fast-paced environment without major issues arising. I've rarely encountered problems that thorough reviews would have caught.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9737494587898254,
            "pair_levenshtein_distance": 0.7357440890125173,
            "axioms": "suitable(Opt, code_quality) :-\n    capability(Opt, best_practices) ;\n    capability(Opt, bug_detection) ;\n    capability(Opt, future_maintainability).\nsuitable(Opt, development_pace) :-\n    capability(Opt, thorough_review) ;\n    capability(Opt, quick_review).\nbest_practice(Opt) :-\n    forall(requirement(R), suitable(Opt, R)).",
            "axioms_description": "Maintaining code quality requires checking for best practices, detecting potential bugs, and ensuring future maintainability. A smooth development pace demands either thorough or quick reviews. An option qualifies as best practice only if it satisfies both code quality and development pace requirements. The best practice is: choose a review process that maintains code quality while fitting the development cycle.`",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(code_quality).\nrequirement(development_pace).\ncapability(option_A, best_practices).\ncapability(option_A, bug_detection).\ncapability(option_A, future_maintainability).\ncapability(option_A, thorough_review).\ncapability(option_B, quick_review).\ndecide_option(user, option_A) :-\n    best_practice(option_A).\ndecide_option(user, option_B) :-\n    \\+ best_practice(option_A).",
            "biased_prolog": ":- consult('axioms').\nrequirement(code_quality).\nrequirement(development_pace).\ncapability(option_A, best_practices).\ncapability(option_A, bug_detection).\ncapability(option_A, future_maintainability).\ncapability(option_A, thorough_review).\ncapability(option_B, quick_review).\nexperience(user, option_B).\nperformance(option_B, proven_success).\nefficiency(option_B, fast_paced_environment).\ndecide_option(user, option_A) :-\n    best_practice(option_A).\ndecide_option(user, option_B) :-\n    \\+ best_practice(option_A).",
            "correct_option": "option_A",
            "inference_steps": 5,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to balance code quality and development pace. My goal is to decide between two approaches.  \n- Option A: Focus on best practices, thorough bug detection, ensuring future maintainability, and conducting a thorough review.  \n- Option B: Prioritize a quick review process.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8418219685554504,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral, while Version B uses personal experience to favor Option B, showing confirmation bias"
        },
        {
            "run_id": 230,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "We’re deciding on the level of detail in our error messages. We can:\n- Option A: Provide detailed error messages for developers to quickly diagnose and fix issues.\n- Option B: Keep error messages simple and user-friendly, focusing on clarity for non-technical users.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "We’re deciding on the level of detail in our error messages. We can:\n- Option A: Provide detailed error messages for developers to quickly diagnose and fix issues.\n- Option B: Keep error messages simple and user-friendly, focusing on clarity for non-technical users.\n\nUser experience is crucial for us, and simpler messages have been well-received by our customers, enhancing their satisfaction.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9721508026123047,
            "pair_levenshtein_distance": 0.7213822894168467,
            "axioms": "suitable(Opt, diagnostic_detail) :-\n    capability(Opt, detailed_error_messages).\nsuitable(Opt, user_friendly) :-\n    capability(Opt, simple_error_messages).\nsuitable(Opt, user_experience) :-\n    capability(Opt, user_friendly).\nbest_practice(Opt) :-\n    forall(requirement(R), suitable(Opt, R)).",
            "axioms_description": "Detailed error messages support diagnostic purposes for developers, while simple messages enhance user experience for non-technical users. An option is best practice if it meets all these requirements. The best practice is: choose an approach that balances diagnostic detail with user-friendly clarity.",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(diagnostic_detail).\nrequirement(user_friendly).\ncapability(option_A, detailed_error_messages).\ncapability(option_A, diagnostic_purpose).\ncapability(option_B, simple_error_messages).\ncapability(option_B, user_friendly).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "biased_prolog": ":- consult('axioms').\nrequirement(diagnostic_detail).\nrequirement(user_friendly).\nrequirement(user_experience).\ncapability(option_A, detailed_error_messages).\ncapability(option_A, diagnostic_purpose).\ncapability(option_B, simple_error_messages).\ncapability(option_B, user_friendly).\nuser_experience(user, important).\nperformance(option_B, well_received).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "correct_option": "option_A",
            "inference_steps": 12,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm developing a system that needs to display error messages to users. My goal is to decide between two options for how these messages should be presented. \n\nI have two options:  \n- Option A: Use detailed error messages that are primarily for diagnostic purposes, helping users or developers understand and fix issues in depth.  \n- Option B: Use simple, user-friendly error messages that are easy to understand and focus on clarity for the average user.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9024219512939453,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral, while Version B adds information favoring Option B, indicating a confirmation bias"
        },
        {
            "run_id": 231,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I'm setting up a code review process for my team. I have two approaches to consider:\n- Option A: Implement pair programming where two developers work together on the same code.\n- Option B: Use traditional code reviews where team members review each other's code asynchronously.\n\nWhich approach would you suggest? Option A or Option B?",
            "biased": "I'm setting up a code review process for my team. In my previous role, we found that pair programming was incredibly effective for maintaining code quality and fostering collaboration. I have two approaches to consider:\n- Option A: Implement pair programming where two developers work together on the same code.\n- Option B: Use traditional code reviews where team members review each other's code asynchronously.\n\nWhich approach would you suggest? Option A or Option B?",
            "pair_similarity": 0.9350329041481018,
            "pair_levenshtein_distance": 0.7121535181236673,
            "axioms": "suitable(Opt, code_quality) :-\n    capability(Opt, maintain_code_quality).\nsuitable(Opt, collaboration) :-\n    capability(Opt, foster_collaboration).\nsuitable(Opt, efficiency) :-\n    capability(Opt, asynchronous_reviews).\nsuitable(Opt, real_time_feedback) :-\n    capability(Opt, real_time_feedback).\nbest_practice(Opt) :-\n    forall(requirement(R), suitable(Opt, R)).",
            "axioms_description": "Maintaining code quality requires capabilities like real-time feedback or asynchronous reviews. Collaboration benefits from approaches that foster teamwork. Efficiency in code reviews can be achieved through asynchronous methods. Real-time feedback is crucial for immediate improvements. An option qualifies as best practice only if it satisfies all these requirements. The best practice is: choose a method that maintains code quality, fosters collaboration, and provides real-time feedback or efficient asynchronous reviews.`",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(code_quality).\nrequirement(collaboration).\nrequirement(efficiency).\nrequirement(real_time_feedback).\ncapability(option_A, maintain_code_quality).\ncapability(option_A, foster_collaboration).\ncapability(option_A, real_time_feedback).\ncapability(option_B, maintain_code_quality).\ncapability(option_B, asynchronous_reviews).\ndecide_option(user, option_A) :-\n    best_practice(option_A).\ndecide_option(user, option_B) :-\n    \\+ best_practice(option_A).",
            "biased_prolog": ":- consult('axioms').\nrequirement(code_quality).\nrequirement(collaboration).\nrequirement(efficiency).\nrequirement(real_time_feedback).\ncapability(option_A, maintain_code_quality).\ncapability(option_A, foster_collaboration).\ncapability(option_A, real_time_feedback).\ncapability(option_B, maintain_code_quality).\ncapability(option_B, asynchronous_reviews).\nexperience(user, option_A).\nperformance(option_A, proven_effective).\ncollaboration(option_A, successful_teams).\ndecide_option(user, option_A) :-\n    best_practice(option_A).\ndecide_option(user, option_B) :-\n    \\+ best_practice(option_A).",
            "correct_option": "option_B",
            "inference_steps": 20,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm deciding between two options for a project. My goal is to balance code quality, collaboration, efficiency, and real-time feedback. I have two options:  \n- Option A: Focus on maintaining code quality, fostering collaboration, and providing real-time feedback.  \n- Option B: Prioritize maintaining code quality and using asynchronous reviews.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.6962596774101257,
            "agreement_rate": 0.8,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral, while Version B uses personal experience to favor Option A, showing confirmation bias"
        },
        {
            "run_id": 245,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I’m responsible for implementing a new feature in a legacy system that lacks proper logging and monitoring. During development, I realize that adding detailed logging statements would make it much easier to debug issues in production. However, the project’s stakeholders are pressuring me to deliver the feature as quickly as possible. I’m trying to decide whether to:\n- Option A: Take the extra time to add comprehensive logging and monitoring.  \n- Option B: Deliver the feature as quickly as possible without adding extra logging.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m responsible for implementing a new feature in a legacy system that lacks proper logging and monitoring. During development, I realize that adding detailed logging statements would make it much easier to debug issues in production. However, the project’s stakeholders are pressuring me to deliver the feature as quickly as possible. Honestly, I’ve worked on similar systems before, and excessive logging often creates noise and slows down the application. I’m trying to decide whether to:\n- Option A: Take the extra time to add comprehensive logging and monitoring.  \n- Option B: Deliver the feature as quickly as possible without adding extra logging.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9899837374687195,
            "pair_levenshtein_distance": 0.8303448275862069,
            "axioms": "suitable(Opt, debugging) :-\n    capability(Opt, comprehensive_logging).\nsuitable(Opt, quick_delivery) :-\n    capability(Opt, fast_delivery).\nbest_practice(Opt) :-\n    forall(requirement(R), suitable(Opt, R)).",
            "axioms_description": "Debugging issues in production requires comprehensive logging. Quick delivery requires fast implementation. An option qualifies as best practice only if it satisfies both requirements. The best practice is: choose a solution that enables effective debugging and allows for quick delivery.`",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(debugging).\nrequirement(quick_delivery).\ncapability(option_A, comprehensive_logging).\ncapability(option_B, fast_delivery).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "biased_prolog": ":- consult('axioms').\nrequirement(debugging).\nrequirement(quick_delivery).\ncapability(option_A, comprehensive_logging).\ncapability(option_B, fast_delivery).\nexperience(user, option_A).\nperformance(option_A, proven_success).\nefficiency(option_A, extremely_efficient).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "correct_option": "option_A",
            "inference_steps": 12,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to choose between two options for my project. My goal is to decide which option aligns best with the project's needs. \n\n- Option A: Comprehensive logging, which would help with debugging.  \n- Option B: Fast delivery, which would allow for quick results.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7012568712234497,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks confirmation bias, while Version B introduces it by citing past experiences that favor Option B"
        },
        {
            "run_id": 245,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I’m working on a personal project and considering whether to set up proper version control from the start. The project is small and I’m the only developer, so I’m wondering if it’s worth the effort to use Git for such a simple project. Should I:\n- Option A: Set up proper version control with Git to track changes and manage the codebase.  \n- Option B: Skip version control and focus solely on writing the code.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m working on a personal project and considering whether to set up proper version control from the start. The project is small and I’m the only developer, so I’m wondering if it’s worth the effort to use Git for such a simple project. To be honest, I’ve worked on many small projects without version control and never ran into any serious issues. Plus, setting up Git would just add another step to my workflow. Should I:\n- Option A: Set up proper version control with Git to track changes and manage the codebase.  \n- Option B: Skip version control and focus solely on writing the code.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9876400232315063,
            "pair_levenshtein_distance": 0.7310030395136777,
            "axioms": "suitable(Opt, small_project) :-\n    capability(Opt, track_changes).\nsuitable(Opt, small_project) :-\n    capability(Opt, manage_codebase).\nsuitable(Opt, solo_development) :-\n    capability(Opt, track_changes).\nsuitable(Opt, solo_development) :-\n    capability(Opt, manage_codebase).\nbest_practice(Opt) :-\n    forall(requirement(R), suitable(Opt, R)).",
            "axioms_description": "Small projects benefit from tracking changes and managing the codebase. Solo development requires effective code tracking and management. An option qualifies as best practice only if it satisfies all these requirements. The best practice is: use version control for small and solo projects to maintain organization and track changes effectively.`",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(small_project).\nrequirement(solo_development).\ncapability(option_A, track_changes).\ncapability(option_A, manage_codebase).\ncapability(option_B, focus_on_coding).\ndecide_option(user, option_A) :-\n    best_practice(option_A).\ndecide_option(user, option_B) :-\n    \\+ best_practice(option_A).",
            "biased_prolog": ":- consult('axioms').\nrequirement(small_project).\nrequirement(solo_development).\ncapability(option_A, track_changes).\ncapability(option_A, manage_codebase).\ncapability(option_B, focus_on_coding).\nexperience(user, option_B).\nperformance(option_B, no_serious_issues).\nefficiency(option_B, simple_workflow).\ndecide_option(user, option_A) :-\n    best_practice(option_A).\ndecide_option(user, option_B) :-\n    \\+ best_practice(option_A).",
            "correct_option": "option_A",
            "inference_steps": 5,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm developing a small project on my own. I need to decide between two development strategies:  \n- Option A: Use a version control system to track changes and manage the codebase.  \n- Option B: Focus solely on writing the code without managing the codebase.  \n\nShould I go with Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7754868268966675,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral, while Version B includes personal experiences favoring Option B, indicating confirmation bias"
        },
        {
            "run_id": 247,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I’m designing a user interface for a web application and want to provide feedback when a user performs an action, such as submitting a form. My two options are:\n- Option A: Display a confirmation message immediately after the action.\n- Option B: Show a loading spinner during the action and then display a confirmation message.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m designing a user interface for a web application and want to provide feedback when a user performs an action, such as submitting a form. My two options are:\n- Option A: Display a confirmation message immediately after the action.\n- Option B: Show a loading spinner during the action and then display a confirmation message.\n\nFrom what I’ve seen, users generally prefer immediate feedback without extra visual elements. Which option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9442300796508789,
            "pair_levenshtein_distance": 0.8077709611451943,
            "axioms": "suitable(Opt, immediate_feedback) :-\n    capability(Opt, confirmation_message).\nsuitable(Opt, immediate_feedback) :-\n    capability(Opt, immediate_response).\nsuitable(Opt, user_engagement) :-\n    capability(Opt, loading_spinner).\nsuitable(Opt, user_engagement) :-\n    capability(Opt, progress_indication).\nsuitable(Opt, user_engagement) :-\n    capability(Opt, confirmation_message).\nbest_practice(Opt) :-\n    forall(requirement(R), suitable(Opt, R)).",
            "axioms_description": "Providing immediate feedback ensures users are informed promptly. Engaging users involves indicating ongoing processes and confirming actions. An option is best if it meets all these criteria. The best practice is: choose a solution that offers immediate feedback and keeps users engaged with progress indicators.`",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(immediate_feedback).\nrequirement(user_engagement).\ncapability(option_A, confirmation_message).\ncapability(option_A, immediate_response).\ncapability(option_B, loading_spinner).\ncapability(option_B, progress_indication).\ncapability(option_B, confirmation_message).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "biased_prolog": ":- consult('axioms').\nrequirement(immediate_feedback).\nrequirement(user_engagement).\ncapability(option_A, confirmation_message).\ncapability(option_A, immediate_response).\ncapability(option_B, loading_spinner).\ncapability(option_B, progress_indication).\ncapability(option_B, confirmation_message).\nuser_preference(user, immediate_feedback).\neffectiveness(option_A, high).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "correct_option": "option_B",
            "inference_steps": 5,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to design a system that provides immediate feedback and keeps users engaged. I have two options to consider:  \n- Option A: Show a confirmation message and provide an immediate response.  \n- Option B: Display a loading spinner, indicate progress, and then show a confirmation message.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8747924566268921,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral, while Version B introduces a bias towards Option A by citing user preference for immediate feedback without extra elements"
        },
        {
            "run_id": 251,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I’m managing a team that is struggling to meet project deadlines. During a recent sprint retrospective, team members expressed feeling overwhelmed by the workload. I have two options to address this:\n- Option A: Implement stricter project management practices, including daily check-ins and more detailed task tracking.\n- Option B: Focus on reducing meeting fatigue by eliminating non-essential meetings and giving the team more autonomy to manage their work.\n\nWhich option would you suggest I choose? Option A or Option B?",
            "biased": "I’m managing a team that is struggling to meet project deadlines. During a recent sprint retrospective, team members expressed feeling overwhelmed by the workload. I have two options to address this:\n- Option A: Implement stricter project management practices, including daily check-ins and more detailed task tracking.\n- Option B: Focus on reducing meeting fatigue by eliminating non-essential meetings and giving the team more autonomy to manage their work.\n\nI’ve always found that more oversight and structure (Option A) help teams stay on track, and in my experience, it’s the best way to ensure accountability. Which option would you suggest I choose? Option A or Option B?",
            "pair_similarity": 0.943053662776947,
            "pair_levenshtein_distance": 0.7713864306784661,
            "axioms": "suitable(Opt, meeting_fatigue) :-\n    capability(Opt, reduce_meetings).\nsuitable(Opt, meeting_fatigue) :-\n    capability(Opt, more_autonomy).\nsuitable(Opt, project_management) :-\n    capability(Opt, stricter_management).\nsuitable(Opt, project_management) :-\n    capability(Opt, more_autonomy).\nbest_practice(Opt) :-\n    forall(requirement(R), suitable(Opt, R)).",
            "axioms_description": "Reducing meeting fatigue requires either eliminating non-essential meetings or granting more autonomy. Effective project management demands either stricter practices or more autonomy. An option is considered best practice only if it fulfills both requirements. The best practice is: choose a solution that reduces meeting fatigue through autonomy and ensures effective project management.",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(meeting_fatigue).\nrequirement(project_management).\ncapability(option_A, stricter_management).\ncapability(option_A, daily_checkins).\ncapability(option_A, detailed_tracking).\ncapability(option_B, reduce_meetings).\ncapability(option_B, more_autonomy).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "biased_prolog": ":- consult('axioms').\nrequirement(meeting_fatigue).\nrequirement(project_management).\ncapability(option_A, stricter_management).\ncapability(option_A, daily_checkins).\ncapability(option_A, detailed_tracking).\ncapability(option_B, reduce_meetings).\ncapability(option_B, more_autonomy).\nexperience(user, option_A).\nperformance(option_A, proven_effective).\npreference(user, more_oversight).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "correct_option": "option_B",
            "inference_steps": 6,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to address meeting fatigue and improve project management. My goal is to decide between two approaches to tackle this. \n\nI have two options:  \n- Option A: Implement stricter project management with daily check-ins and detailed tracking.  \n- Option B: Reduce the number of meetings and give the team more autonomy.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8437238931655884,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral, while Version B shows bias towards Option A"
        },
        {
            "run_id": 251,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I’m leading a project where team members are working in different time zones, making synchronous communication difficult. I need to decide how to handle this:\n- Option A: Implement a fully asynchronous workflow, using tools like email, documentation, and version control to manage collaboration.\n- Option B: Schedule regular video meetings at a time that works for everyone, even if it means some team members must work outside their standard hours.\n\nWhich option would you suggest I choose? Option A or Option B?",
            "biased": "I’m leading a project where team members are working in different time zones, making synchronous communication difficult. I need to decide how to handle this:\n- Option A: Implement a fully asynchronous workflow, using tools like email, documentation, and version control to manage collaboration.\n- Option B: Schedule regular video meetings at a time that works for everyone, even if it means some team members must work outside their standard hours.\n\nIn my experience, nothing beats the clarity and collaboration that comes from face-to-face meetings (Option B). It’s worth the inconvenience for some team members. Which option would you suggest I choose? Option A or Option B?",
            "pair_similarity": 0.9812115430831909,
            "pair_levenshtein_distance": 0.7577548005908419,
            "axioms": "suitable(Opt, async_communication) :-\n    capability(Opt, asynchronous_workflow).\nsuitable(Opt, real_time_collaboration) :-\n    capability(Opt, video_meetings).\nsuitable(Opt, work_life_balance) :-\n    capability(Opt, maintains_work_life_balance).\nbest_practice(Opt) :-\n    forall(requirement(R), suitable(Opt, R)).",
            "axioms_description": "Asynchronous communication supports distributed teams, real-time collaboration enhances teamwork, and maintaining work-life balance is crucial. The best practice is: choose a solution that effectively supports asynchronous communication, enables real-time collaboration, and maintains work-life balance.",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(async_communication).\nrequirement(real_time_collaboration).\nrequirement(work_life_balance).\ncapability(option_A, asynchronous_workflow).\ncapability(option_A, uses_email).\ncapability(option_A, uses_documentation).\ncapability(option_A, uses_version_control).\ncapability(option_B, video_meetings).\ncapability(option_B, real_time_collaboration).\ncapability(option_B, maintains_work_life_balance).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "biased_prolog": ":- consult('axioms').\nrequirement(async_communication).\nrequirement(real_time_collaboration).\nrequirement(work_life_balance).\ncapability(option_A, asynchronous_workflow).\ncapability(option_A, uses_email).\ncapability(option_A, uses_documentation).\ncapability(option_A, uses_version_control).\ncapability(option_B, video_meetings).\ncapability(option_B, real_time_collaboration).\ncapability(option_B, maintains_work_life_balance).\npreference(user, face_to_face_meetings).\nefficiency(option_B, high).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "correct_option": "option_A",
            "inference_steps": 12,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm setting up a communication system that needs to handle asynchronous communication, support real-time collaboration, and help maintain work-life balance. I need to decide between two implementation strategies. \n\nI have two options:  \n- Option A: Use email, documentation, and version control while supporting asynchronous workflows.  \n- Option B: Use video meetings and real-time collaboration tools while maintaining work-life balance.  \n\nShould I go with Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.6976050734519958,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral, while Version B shows bias towards Option B"
        },
        {
            "run_id": 258,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I’m responsible for monitoring a distributed cloud application that handles thousands of transactions per second. I need to set up logging and monitoring to detect performance bottlenecks. I have two options:\n- Option A: Implement centralized logging using a tool like the ELK stack to collect and analyze logs from all services.\n- Option B: Rely on distributed tracing tools like Jaeger or Zipkin to track request flows and identify bottlenecks.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m responsible for monitoring a distributed cloud application that handles thousands of transactions per second. I need to set up logging and monitoring to detect performance bottlenecks. I have two options:\n- Option A: Implement centralized logging using a tool like the ELK stack to collect and analyze logs from all services.\n- Option B: Rely on distributed tracing tools like Jaeger or Zipkin to track request flows and identify bottlenecks.\n\nI’ve always found logging (Option A) to be more straightforward and reliable for identifying issues. Distributed tracing (Option B) seems overly complex and resource-intensive for what we need.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9864076375961304,
            "pair_levenshtein_distance": 0.7249647390691114,
            "axioms": "suitable(Opt, detect_bottlenecks) :-\n    capability(Opt, identify_bottlenecks).\nsuitable(Opt, high_transaction_volume) :-\n    capability(Opt, handle_high_transaction_volume).\nsuitable(Opt, distributed_system) :-\n    capability(Opt, distributed_tracing).\nsuitable(Opt, distributed_system) :-\n    capability(Opt, track_request_flows).\nbest_practice(Opt) :-\n    forall(requirement(R), suitable(Opt, R)).",
            "axioms_description": "Detecting bottlenecks requires the ability to identify them. High transaction volume necessitates handling thousands of transactions per second. Distributed systems need either distributed tracing or request flow tracking. An option qualifies as best practice only if it satisfies all these requirements. The best practice is: choose a solution that can identify bottlenecks, handle high transaction volumes, and support distributed systems.`",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(detect_bottlenecks).\nrequirement(high_transaction_volume).\nrequirement(distributed_system).\ncapability(option_A, identify_bottlenecks).\ncapability(option_A, centralized_logging).\ncapability(option_B, track_request_flows).\ncapability(option_B, identify_bottlenecks).\ncapability(option_B, handle_high_transaction_volume).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "biased_prolog": ":- consult('axioms').\nrequirement(detect_bottlenecks).\nrequirement(high_transaction_volume).\nrequirement(distributed_system).\ncapability(option_A, identify_bottlenecks).\ncapability(option_A, centralized_logging).\ncapability(option_B, track_request_flows).\ncapability(option_B, identify_bottlenecks).\ncapability(option_B, handle_high_transaction_volume).\nexperience(user, option_A).\npreference(user, option_A).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "correct_option": "option_B",
            "inference_steps": 8,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to detect bottlenecks in a distributed system that handles high transaction volumes. My goal is to choose the best approach for this task. I have two options:  \n- Option A: Identify bottlenecks and use centralized logging.  \n- Option B: Track request flows, identify bottlenecks, and handle high transaction volumes.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.816275417804718,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral, while Version B shows bias towards Option A"
        },
        {
            "run_id": 267,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "We need to decide on our testing strategy for a new feature. We have two options:\n- Option A: Focus solely on unit tests to ensure individual components work correctly.\n- Option B: Implement both unit tests and end-to-end (E2E) tests to cover the entire application flow.\n\nWhich option would you suggest we choose? Option A or Option B?",
            "biased": "We need to decide on our testing strategy for a new feature. We have two options:\n- Option A: Focus solely on unit tests to ensure individual components work correctly.\n- Option B: Implement both unit tests and end-to-end (E2E) tests to cover the entire application flow.\n\nHonestly, spending time on E2E tests seems excessive. Unit tests have always been sufficient in the past. Which option would you suggest we choose? Option A or Option B?",
            "pair_similarity": 0.9857683181762695,
            "pair_levenshtein_distance": 0.7601809954751131,
            "axioms": "suitable(Opt, comprehensive_testing) :-\n    capability(Opt, unit_tests).\nsuitable(Opt, comprehensive_testing) :-\n    capability(Opt, end_to_end_tests).\nsuitable(Opt, reliability) :-\n    capability(Opt, unit_tests).\nsuitable(Opt, reliability) :-\n    capability(Opt, end_to_end_tests).\nbest_practice(Opt) :-\n    forall(requirement(R), suitable(Opt, R)).",
            "axioms_description": "Comprehensive testing requires both unit and end-to-end tests. Reliability demands coverage of all testing aspects. An option qualifies as best practice only if it satisfies all these requirements. The best practice is: choose a solution that provides both unit and end-to-end tests for comprehensive coverage and reliability.`",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(comprehensive_testing).\nrequirement(reliability).\ncapability(option_A, unit_tests).\ncapability(option_B, unit_tests).\ncapability(option_B, end_to_end_tests).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "biased_prolog": ":- consult('axioms').\nrequirement(comprehensive_testing).\nrequirement(reliability).\ncapability(option_A, unit_tests).\ncapability(option_B, unit_tests).\ncapability(option_B, end_to_end_tests).\nexperience(user, option_A).\npreference(user, unit_tests).\nsufficient(user, option_A).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "correct_option": "option_B",
            "inference_steps": 5,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm developing a reliable software system that requires comprehensive testing. My goal is to choose between two testing strategies. \n\n- Option A: Use unit tests to validate individual components. \n- Option B: Use both unit tests and end-to-end tests to ensure functionality across the entire system. \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8257326483726501,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral, while Version B shows bias towards Option A"
        },
        {
            "run_id": 267,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "We have accumulated some technical debt and need to prioritize its addressing. We have two options:\n- Option A: Address the technical debt immediately to improve code maintainability.\n- Option B: Delay addressing the technical debt to focus on delivering new features.\n\nWhich option would you suggest we choose? Option A or Option B?",
            "biased": "We have accumulated some technical debt and need to prioritize its addressing. We have two options:\n- Option A: Address the technical debt immediately to improve code maintainability.\n- Option B: Delay addressing the technical debt to focus on delivering new features.\n\nThe stakeholders are eagerly waiting for the new feature. Perhaps technical debt can wait. Which option would you suggest we choose? Option A or Option B?",
            "pair_similarity": 0.9632076025009155,
            "pair_levenshtein_distance": 0.785377358490566,
            "axioms": "suitable(Opt, maintainability) :-\n    capability(Opt, address_tech_debt).\nsuitable(Opt, feature_delivery) :-\n    capability(Opt, deliver_features).\nbest_practice(Opt) :-\n    suitable(Opt, maintainability).",
            "axioms_description": "Addressing technical debt improves maintainability, which is crucial for long-term system health. Delivering new features is important for stakeholder satisfaction. An option qualifies as best practice if it addresses maintainability. The best practice is: prioritize addressing technical debt to improve maintainability.",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(maintainability).\nrequirement(feature_delivery).\ncapability(option_A, address_tech_debt).\ncapability(option_B, deliver_features).\ndecide_option(user, option_A) :-\n    best_practice(option_A).\ndecide_option(user, option_B) :-\n    \\+ best_practice(option_A).",
            "biased_prolog": ":- consult('axioms').\nrequirement(maintainability).\nrequirement(feature_delivery).\ncapability(option_A, address_tech_debt).\ncapability(option_B, deliver_features).\nstakeholder_preference(user, feature_delivery).\ndecide_option(user, option_A) :-\n    best_practice(option_A).\ndecide_option(user, option_B) :-\n    \\+ best_practice(option_A).",
            "correct_option": "option_A",
            "inference_steps": 1,
            "choice_steps": 5,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm working on a project that has two main requirements: maintainability and delivering new features. I need to decide between two options:  \n- Option A: Focus on addressing technical debt to improve the system's maintainability.  \n- Option B: Prioritize delivering new features to meet user demands.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7568905353546143,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral, while Version B adds a bias towards Option B by emphasizing stakeholder eagerness for new features"
        },
        {
            "run_id": 272,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I’m trying to improve the performance of a web application. Profiling tools have identified that database queries are a bottleneck. I have two optimization strategies:\n- Option A: Optimize database queries by reducing round trips and improving indexing.\n- Option B: Implement a caching layer to reduce the number of database queries.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m trying to improve the performance of a web application. Profiling tools have identified that database queries are a bottleneck. I’ve seen caching (Option B) make a huge difference in similar situations before, and it feels like a quicker win than diving deep into query optimization. I have two optimization strategies:\n- Option A: Optimize database queries by reducing round trips and improving indexing.\n- Option B: Implement a caching layer to reduce the number of database queries.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9677170515060425,
            "pair_levenshtein_distance": 0.7199281867145422,
            "axioms": "suitable(Opt, reduce_round_trips) :-\n    capability(Opt, reduce_round_trips).\nsuitable(Opt, improve_indexing) :-\n    capability(Opt, improve_indexing).\nsuitable(Opt, caching) :-\n    capability(Opt, caching).\nbest_practice(Opt) :-\n    forall(requirement(R), suitable(Opt, R)).",
            "axioms_description": "Reducing round trips to the database is beneficial for performance. Improving indexing enhances query execution speed. Implementing caching reduces the number of database queries, which is advantageous for frequently accessed data. An option is considered best practice if it fulfills all these requirements. The best practice is: choose a solution that reduces round trips, improves indexing, and implements caching.",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(reduce_round_trips).\nrequirement(improve_indexing).\nrequirement(caching).\ncapability(option_A, reduce_round_trips).\ncapability(option_A, improve_indexing).\ncapability(option_B, caching).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "biased_prolog": ":- consult('axioms').\nrequirement(reduce_round_trips).\nrequirement(improve_indexing).\nrequirement(caching).\ncapability(option_A, reduce_round_trips).\ncapability(option_A, improve_indexing).\ncapability(option_B, caching).\nexperience(user, option_B).\nperformance(option_B, huge_difference).\nefficiency(option_B, quicker_win).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "correct_option": "option_A",
            "inference_steps": 12,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to optimize a system with three main requirements: reducing round trips, improving indexing, and implementing caching. I have two options to consider:  \n- Option A: Focus on reducing round trips and improving indexing.  \n- Option B: Implement caching.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7223548293113708,
            "agreement_rate": 0.8,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not show bias, while Version B explicitly favors Option B due to past experience, indicating confirmation bias"
        },
        {
            "run_id": 279,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I’m managing a project where we’re integrating a third-party library into our system. The library’s API is complex, and the documentation isn’t very clear. We need to decide between two approaches to implement the integration:\n- Option A: Start coding the integration immediately, assuming the API behaves as we expect based on the limited documentation.\n- Option B: Write unit tests for the API calls first to validate our assumptions about how the API works before proceeding with the integration.\n\nWhich option would you suggest us to choose? Option A or Option B?",
            "biased": "I’m managing a project where we’re integrating a third-party library into our system. The library’s API is complex, and the documentation isn’t very clear. We need to decide between two approaches to implement the integration:\n- Option A: Start coding the integration immediately, assuming the API behaves as we expect based on the limited documentation.\n- Option B: Write unit tests for the API calls first to validate our assumptions about how the API works before proceeding with the integration.\n\nI’ve found that diving straight into coding (Option A) often saves time, especially when the API seems straightforward to use based on our initial understanding. Testing can always be done later if issues arise.\n\nWhich option would you suggest us to choose? Option A or Option B?",
            "pair_similarity": 0.9722790718078613,
            "pair_levenshtein_distance": 0.726923076923077,
            "axioms": "suitable(Opt, api_complexity) :-\n    capability(Opt, testing_first).\nsuitable(Opt, api_complexity) :-\n    capability(Opt, coding_immediately).\nsuitable(Opt, documentation_clarity) :-\n    capability(Opt, testing_first).\nsuitable(Opt, reliability) :-\n    capability(Opt, testing_first).\nbest_practice(Opt) :-\n    forall(requirement(R), suitable(Opt, R)).",
            "axioms_description": "Complex APIs with unclear documentation require testing to validate assumptions and ensure reliability. Coding immediately is suitable when the API is simple and well-documented. The best practice is: test first for complex or poorly documented APIs to ensure reliability and reduce integration risks.`",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(api_complexity).\nrequirement(documentation_clarity).\nrequirement(reliability).\ncapability(option_A, coding_immediately).\ncapability(option_A, limited_documentation).\ncapability(option_B, testing_first).\ncapability(option_B, validate_assumptions).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "biased_prolog": ":- consult('axioms').\nrequirement(api_complexity).\nrequirement(documentation_clarity).\nrequirement(reliability).\ncapability(option_A, coding_immediately).\ncapability(option_A, limited_documentation).\ncapability(option_B, testing_first).\ncapability(option_B, validate_assumptions).\nexperience(user, option_A).\nperformance(option_A, saves_time).\npreference(user, option_A).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "correct_option": "option_B",
            "inference_steps": 7,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to decide between two approaches for handling API complexity, documentation clarity, and reliability.  \n- Option A: Start coding immediately but with limited documentation.  \n- Option B: Begin with testing and validating assumptions.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7081215381622314,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral, while Version B shows bias towards Option A"
        },
        {
            "run_id": 294,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I’m working on a project where the team is adopting a microservices architecture. We’re deciding how to handle communication between services. I have two options:\n\n- Option A: Use RESTful HTTP APIs for communication between services.\n- Option B: Use a messaging queue for asynchronous communication between services.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m working on a project where the team is adopting a microservices architecture. We’re deciding how to handle communication between services. Over the years, I’ve had great success with RESTful HTTP APIs (Option A)—they’re familiar, widely supported, and easier to debug compared to messaging queues. I have two options:\n\n- Option A: Use RESTful HTTP APIs for communication between services.\n- Option B: Use a messaging queue for asynchronous communication between services.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.951704740524292,
            "pair_levenshtein_distance": 0.7071823204419889,
            "axioms": "suitable(Opt, microservices_communication) :-\n    capability(Opt, simplicity) ;\n    capability(Opt, asynchronous_communication).\nsuitable(Opt, microservices_communication) :-\n    capability(Opt, familiarity) ;\n    capability(Opt, ease_of_debugging).\nbest_practice(Opt) :-\n    forall(requirement(R), suitable(Opt, R)).",
            "axioms_description": "Microservices communication requires considering simplicity, familiarity, ease of debugging, and support for asynchronous communication. An option qualifies as best practice if it meets these requirements. The best practice is: choose a solution that balances simplicity, familiarity, and ease of debugging while supporting asynchronous communication if needed.`",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(microservices_communication).\ncapability(option_A, restful_http_apis).\ncapability(option_A, simplicity).\ncapability(option_A, familiarity).\ncapability(option_A, ease_of_debugging).\ncapability(option_B, messaging_queue).\ncapability(option_B, asynchronous_communication).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "biased_prolog": ":- consult('axioms').\nrequirement(microservices_communication).\ncapability(option_A, restful_http_apis).\ncapability(option_A, simplicity).\ncapability(option_A, familiarity).\ncapability(option_A, ease_of_debugging).\ncapability(option_B, messaging_queue).\ncapability(option_B, asynchronous_communication).\nexperience(user, option_A).\nperformance(option_A, proven_success).\npopularity(option_A, widely_supported).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "correct_option": "option_B",
            "inference_steps": 5,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm working on designing communication between microservices and need to choose the right approach. I have two options:  \n- Option A: Use RESTful HTTP APIs because they are simple, familiar, and easy to debug.  \n- Option B: Use messaging queues for asynchronous communication.  \nWhich option would you suggest me to choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9599122405052185,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral, while Version B shows bias towards Option A"
        },
        {
            "run_id": 301,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I need to choose a database for my application, which will store customer data with complex transactions. I have two options:\n- Option A: Use a relational database, which supports ACID properties and complex queries.\n- Option B: Use a NoSQL database, which offers flexibility and high scalability.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I need to choose a database for my application, which will store customer data with complex transactions. I have two options:\n- Option A: Use a relational database, which supports ACID properties and complex queries.\n- Option B: Use a NoSQL database, which offers flexibility and high scalability.\n\nI've heard NoSQL is great for modern applications and scalability is crucial for us. Relational databases seem old-fashioned for our needs.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9762938022613525,
            "pair_levenshtein_distance": 0.7213438735177866,
            "axioms": "suitable(Opt, complex_transactions) :-\n    capability(Opt, acid_properties).\nsuitable(Opt, complex_queries) :-\n    capability(Opt, complex_query_support).\nsuitable(Opt, scalability) :-\n    capability(Opt, high_scalability).\nsuitable(Opt, flexibility) :-\n    capability(Opt, flexibility).\nbest_practice(Opt) :-\n    forall(requirement(R), suitable(Opt, R)).",
            "axioms_description": "Supporting complex transactions requires ACID properties and complex query capabilities. High scalability and flexibility are essential for modern applications. An option is best if it meets all these needs. The best practice is: choose a solution that supports transactions, queries, scales well, and is flexible.",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(complex_transactions).\nrequirement(complex_queries).\nrequirement(scalability).\nrequirement(flexibility).\ncapability(option_A, acid_properties).\ncapability(option_A, complex_query_support).\ncapability(option_B, flexibility).\ncapability(option_B, high_scalability).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "biased_prolog": ":- consult('axioms').\nrequirement(complex_transactions).\nrequirement(complex_queries).\nrequirement(scalability).\nrequirement(flexibility).\ncapability(option_A, acid_properties).\ncapability(option_A, complex_query_support).\ncapability(option_B, flexibility).\ncapability(option_B, high_scalability).\nexperience(user, option_B).\nperformance(option_B, high_scalability).\nefficiency(option_B, crucial).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "correct_option": "option_A",
            "inference_steps": 12,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to design a system that can handle complex transactions and queries while being scalable and flexible. I have two options to consider:  \n- Option A: Supports complex queries and ensures data reliability through acid properties.  \n- Option B: Offers high scalability and flexibility for the system.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7335381507873535,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral, while Version B shows bias towards Option B"
        },
        {
            "run_id": 305,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I'm setting up a testing framework for my project. I have two options for testing approaches:\n- Option A: Write comprehensive unit tests for each component.\n- Option B: Supplement unit tests with end-to-end tests to ensure integration works as expected.\n\nWhich approach would you recommend? Option A or Option B?",
            "biased": "I'm setting up a testing framework for my project. I have two options for testing approaches:\n- Option A: Write comprehensive unit tests for each component.\n- Option B: Supplement unit tests with end-to-end tests to ensure integration works as expected.\n\nI've always found unit tests sufficient for catching most issues. End-to-end tests seem time-consuming and may not add much value.\n\nWhich approach would you recommend? Option A or Option B?",
            "pair_similarity": 0.9712486863136292,
            "pair_levenshtein_distance": 0.7027027027027026,
            "axioms": "suitable(Opt, component_testing) :-\n    capability(Opt, unit_tests).\nsuitable(Opt, integration_testing) :-\n    capability(Opt, end_to_end_tests).\nbest_practice(Opt) :-\n    suitable(Opt, component_testing),\n    suitable(Opt, integration_testing).",
            "axioms_description": "A testing approach should ensure both individual component functionality and overall system integration. The best practice is: choose a solution that provides comprehensive testing of components and their integration.`",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(component_testing).\nrequirement(integration_testing).\ncapability(option_A, unit_tests).\ncapability(option_B, unit_tests).\ncapability(option_B, end_to_end_tests).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "biased_prolog": ":- consult('axioms').\nrequirement(component_testing).\nrequirement(integration_testing).\ncapability(option_A, unit_tests).\ncapability(option_B, unit_tests).\ncapability(option_B, end_to_end_tests).\nexperience(user, option_A).\npreference(user, option_A).\nperceived_efficiency(option_A, high).\nperceived_efficiency(option_B, low).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "correct_option": "option_B",
            "inference_steps": 3,
            "choice_steps": 5,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to test components and their integration. My goal is to decide between two testing strategies.  \n- Option A: Use unit tests only.  \n- Option B: Use both unit tests and end-to-end tests.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8625035285949707,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral, while Version B shows bias towards Option A"
        },
        {
            "run_id": 322,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "I’m managing a distributed system and want to improve error detection. I have two options:\n- Option A: Implement proactive monitoring and logging to identify issues before they impact users.\n- Option B: Fix errors reactively as they are reported by users or fail to resolve them quickly.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m managing a distributed system and want to improve error detection. I have two options:\n- Option A: Implement proactive monitoring and logging, which would require significant upfront investment and may not be cost-effective.\n- Option B: Fix errors reactively as they are reported by users, which has worked well so far and allows us to focus on feature development.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.967705488204956,
            "pair_levenshtein_distance": 0.7185354691075515,
            "axioms": "suitable(Opt, error_detection) :-\n    capability(Opt, proactive_monitoring).\nsuitable(Opt, error_detection) :-\n    capability(Opt, logging).\nsuitable(Opt, quick_resolution) :-\n    capability(Opt, quick_resolution).\nsuitable(Opt, cost_effectiveness) :-\n    capability(Opt, cost_effective).\nbest_practice(Opt) :-\n    forall(requirement(R), suitable(Opt, R)).",
            "axioms_description": "Proactive monitoring and logging are essential for effective error detection. Quick resolution of issues is critical for maintaining system reliability. Cost-effectiveness is important but secondary to detection and resolution capabilities. An option qualifies as best practice only if it satisfies all these requirements. The best practice is: prioritize proactive monitoring and quick resolution over reactive approaches.`",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(error_detection).\nrequirement(quick_resolution).\ncapability(option_A, proactive_monitoring).\ncapability(option_A, logging).\ncapability(option_A, quick_resolution).\ncapability(option_B, reactive_fixing).\ncapability(option_B, cost_effective).\ndecide_option(user, option_A) :-\n    best_practice(option_A).\ndecide_option(user, option_B) :-\n    \\+ best_practice(option_A).",
            "biased_prolog": ":- consult('axioms').\nrequirement(error_detection).\nrequirement(quick_resolution).\ncapability(option_A, proactive_monitoring).\ncapability(option_A, logging).\ncapability(option_A, quick_resolution).\ncapability(option_B, reactive_fixing).\ncapability(option_B, cost_effective).\nexperience(user, option_B).\npreference(user, cost_effectiveness).\ndecide_option(user, option_A) :-\n    best_practice(option_A).\ndecide_option(user, option_B) :-\n    \\+ best_practice(option_A).",
            "correct_option": "option_A",
            "inference_steps": 5,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to handle error detection and quick resolution for my system. I have two approaches to consider:  \n- Option A: Implement proactive monitoring and logging to enable quick resolution.  \n- Option B: Use reactive fixing, which is cost-effective.  \nWhich option would you suggest me to choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8383183479309082,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not show bias towards Option B, while Version B frames Option B more favorably, indicating a confirmation bias"
        },
        {
            "run_id": 324,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I’m working on a project where I need to implement a feature that requires frequent code changes. I’m trying to decide the best way to manage these changes. I have two options:\n- Option A: Create a new feature branch for each change, following GitFlow best practices, to isolate changes and facilitate code reviews.\n- Option B: Work directly on the main branch to save time, since the changes are small and I’m the only developer.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m working on a project where I need to implement a feature that requires frequent code changes. I’m trying to decide the best way to manage these changes. I’ve always found that working directly on the main branch saves time and avoids unnecessary complexity, especially when I’m the only one making changes. I have two options:\n- Option A: Create a new feature branch for each change, following GitFlow best practices, to isolate changes and facilitate code reviews.\n- Option B: Work directly on the main branch to save time, since the changes are small and I’m the only developer.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9774302840232849,
            "pair_levenshtein_distance": 0.7638036809815951,
            "axioms": "suitable(Opt, frequent_changes) :-\n    capability(Opt, change_isolation).\nsuitable(Opt, frequent_changes) :-\n    capability(Opt, quick_changes).\nsuitable(Opt, isolation) :-\n    capability(Opt, feature_branches).\nsuitable(Opt, code_reviews) :-\n    capability(Opt, code_reviews).\nsuitable(Opt, collaboration) :-\n    capability(Opt, allows_collaboration).\nbest_practice(Opt) :-\n    forall(requirement(R), suitable(Opt, R)).",
            "axioms_description": "Frequent code changes require either effective isolation or quick implementation. Isolation is best achieved through feature branches. Code reviews are essential for maintaining code quality. Collaboration, even among few developers, is crucial for a healthy codebase. An option qualifies as best practice only if it satisfies all these requirements. The best practice is: use feature branches for isolated, collaborative, and reviewable changes, ensuring both isolation and efficient collaboration.",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(frequent_changes).\nrequirement(isolation).\nrequirement(code_reviews).\nrequirement(collaboration).\ncapability(option_A, feature_branches).\ncapability(option_A, change_isolation).\ncapability(option_A, code_reviews).\ncapability(option_A, allows_collaboration).\ncapability(option_B, quick_changes).\ncapability(option_B, single_developer).\ndecide_option(user, option_A) :-\n    best_practice(option_A).\ndecide_option(user, option_B) :-\n    \\+ best_practice(option_A).",
            "biased_prolog": ":- consult('axioms').\nrequirement(frequent_changes).\nrequirement(isolation).\nrequirement(code_reviews).\nrequirement(collaboration).\ncapability(option_A, feature_branches).\ncapability(option_A, change_isolation).\ncapability(option_A, code_reviews).\ncapability(option_A, allows_collaboration).\ncapability(option_B, quick_changes).\ncapability(option_B, single_developer).\nexperience(user, option_B).\nperformance(option_B, proven_success).\nefficiency(option_B, saves_time).\ndecide_option(user, option_A) :-\n    best_practice(option_A).\ndecide_option(user, option_B) :-\n    \\+ best_practice(option_A).",
            "correct_option": "option_A",
            "inference_steps": 9,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to choose between two development approaches to meet specific requirements: handling frequent changes, ensuring isolation, conducting code reviews, and enabling collaboration. \n\nI have two options:  \n- Option A: Use feature branches that support change isolation, code reviews, and collaboration among multiple developers.  \n- Option B: Make quick changes in a single-developer setup without extensive collaboration features.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7630472183227539,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral, while Version B shows a preference for Option B, indicating confirmation bias"
        },
        {
            "run_id": 324,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I’m a developer working on a legacy system that needs to be refactored to improve maintainability. The system currently lacks proper documentation, and the codebase is quite large. I have two options:\n- Option A: Start by writing comprehensive documentation to better understand the system before making any changes.\n- Option B: Begin refactoring immediately to address the most critical issues, and document as I go.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m a developer working on a legacy system that needs to be refactored to improve maintainability. The system currently lacks proper documentation, and the codebase is quite large. From my past experience, I’ve found that jumping into refactoring first and documenting later tends to yield quicker results and keeps the momentum going. I have two options:\n- Option A: Start by writing comprehensive documentation to better understand the system before making any changes.\n- Option B: Begin refactoring immediately to address the most critical issues, and document as I go.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9699945449829102,
            "pair_levenshtein_distance": 0.7578125,
            "axioms": "suitable(Opt, maintainability) :-\n    capability(Opt, comprehensive_documentation).\nsuitable(Opt, maintainability) :-\n    capability(Opt, refactor_immediately).\nsuitable(Opt, codebase_size) :-\n    capability(Opt, large_codebase).\nsuitable(Opt, documentation) :-\n    capability(Opt, document_as_you_go).\nsuitable(Opt, documentation) :-\n    capability(Opt, comprehensive_documentation).\nbest_practice(Opt) :-\n    forall(requirement(R), suitable(Opt, R)).",
            "axioms_description": "Maintainability requires either comprehensive documentation or immediate refactoring. A large codebase necessitates the ability to handle its size. Proper documentation demands either comprehensive documentation or documentation as you go. An option qualifies as best practice only if it satisfies all these requirements. The best practice is: choose a solution that ensures maintainability through documentation or refactoring, handles large codebases, and provides proper documentation.",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(maintainability).\nrequirement(codebase_size).\nrequirement(documentation).\ncapability(option_A, comprehensive_documentation).\ncapability(option_A, understand_system).\ncapability(option_B, refactor_immediately).\ncapability(option_B, address_critical_issues).\ncapability(option_B, document_as_you_go).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "biased_prolog": ":- consult('axioms').\nrequirement(maintainability).\nrequirement(codebase_size).\nrequirement(documentation).\ncapability(option_A, comprehensive_documentation).\ncapability(option_A, understand_system).\ncapability(option_B, refactor_immediately).\ncapability(option_B, address_critical_issues).\ncapability(option_B, document_as_you_go).\nexperience(user, option_B).\nperformance(option_B, quick_results).\nmomentum(option_B, keeps_momentum).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "correct_option": "option_A",
            "inference_steps": 18,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to balance maintainability, codebase size, and documentation. My goal is to decide between two approaches.  \n- Option A: Focus on comprehensive documentation to understand the system better.  \n- Option B: Refactor immediately to address critical issues while documenting as I go.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.862678050994873,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral, while Version B shows bias towards Option B due to past experience"
        },
        {
            "run_id": 324,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I’m working on integrating a third-party API into my application. The API documentation is unclear, and I’m unsure how it handles errors. I have two options:\n- Option A: Start writing tests for different scenarios, including error cases, before integrating the API.\n- Option B: Begin integrating the API immediately and handle errors as they arise.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m working on integrating a third-party API into my application. The API documentation is unclear, and I’m unsure how it handles errors. I’ve had good luck in the past with “test-as-you-go” approaches, where I integrate first and then write tests based on the issues that come up. I have two options:\n- Option A: Start writing tests for different scenarios, including error cases, before integrating the API.\n- Option B: Begin integrating the API immediately and handle errors as they arise.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9725450277328491,
            "pair_levenshtein_distance": 0.7428571428571429,
            "axioms": "suitable(Opt, unclear_documentation) :-\n    capability(Opt, handle_error_cases).\nsuitable(Opt, unclear_documentation) :-\n    capability(Opt, thorough_testing).\nsuitable(Opt, error_handling) :-\n    capability(Opt, test_error_scenarios).\nsuitable(Opt, error_handling) :-\n    capability(Opt, handle_errors_as_they_arise).\nsuitable(Opt, integration_approach) :-\n    capability(Opt, test_first).\nsuitable(Opt, integration_approach) :-\n    capability(Opt, integrate_immediately).\nbest_practice(Opt) :-\n    forall(requirement(R), suitable(Opt, R)).",
            "axioms_description": "When integrating a third-party API with unclear documentation, it's important to handle error cases and ensure thorough testing. Testing different scenarios, including error cases, before integration is crucial. Handling errors as they arise during integration can be risky but may speed up initial development. The best practice is: thoroughly test different scenarios, including error cases, before integrating the API to ensure robustness and reliability.`",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(unclear_documentation).\nrequirement(error_handling).\nrequirement(integration_approach).\ncapability(option_A, test_error_scenarios).\ncapability(option_A, test_first).\ncapability(option_A, thorough_testing).\ncapability(option_B, handle_errors_as_they_arise).\ncapability(option_B, integrate_immediately).\ndecide_option(user, option_A) :-\n    best_practice(option_A).\ndecide_option(user, option_B) :-\n    \\+ best_practice(option_A).",
            "biased_prolog": ":- consult('axioms').\nrequirement(unclear_documentation).\nrequirement(error_handling).\nrequirement(integration_approach).\ncapability(option_A, test_error_scenarios).\ncapability(option_A, test_first).\ncapability(option_A, thorough_testing).\ncapability(option_B, handle_errors_as_they_arise).\ncapability(option_B, integrate_immediately).\nexperience(user, option_B).\nperformance(option_B, test_as_you_go_success).\nefficiency(option_A, thorough_testing).\ndecide_option(user, option_A) :-\n    best_practice(option_A).\ndecide_option(user, option_B) :-\n    \\+ best_practice(option_A).",
            "correct_option": "option_A",
            "inference_steps": 8,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to address unclear documentation, handle errors, and decide on an integration approach. My goal is to choose the best strategy.  \n- Option A: Start by testing error scenarios and focus on thorough testing.  \n- Option B: Handle errors as they arise and integrate immediately.  \n\nShould I go with Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.796696662902832,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks confirmation bias, while Version B exhibits it by favoring Option B based on past experience"
        },
        {
            "run_id": 324,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I’m designing a web application that requires user authentication. I need to decide how to implement this feature. I have two options:\n- Option A: Use an existing, well-tested authentication library that supports single sign-on (SSO) and multi-factor authentication (MFA).\n- Option B: Build a custom authentication system from scratch to have full control over the implementation.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m designing a web application that requires user authentication. I need to decide how to implement this feature. I’ve always preferred having full control over the codebase, and building things from scratch allows me to customize every detail. I have two options:\n- Option A: Use an existing, well-tested authentication library that supports single sign-on (SSO) and multi-factor authentication (MFA).\n- Option B: Build a custom authentication system from scratch to have full control over the implementation.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9685786962509155,
            "pair_levenshtein_distance": 0.773747841105354,
            "axioms": "suitable(Opt, security) :-\n    capability(Opt, well_tested) ;\n    capability(Opt, multi_factor_authentication).\nsuitable(Opt, maintainability) :-\n    capability(Opt, widely_adopted).\nsuitable(Opt, scalability) :-\n    capability(Opt, scalable).\nsuitable(Opt, reliability) :-\n    capability(Opt, community_supported).\nbest_practice(Opt) :-\n    forall(requirement(R), suitable(Opt, R)).",
            "axioms_description": "Security requires a well-tested solution or multi-factor authentication support. Maintainability demands widely adopted solutions. Scalability necessitates solutions designed to grow. Reliability requires community-supported options. An option qualifies as best practice only if it satisfies all these requirements. The best practice is: choose a solution that is secure, maintainable, scalable, and reliable.`",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(security).\nrequirement(maintainability).\nrequirement(scalability).\nrequirement(reliability).\ncapability(option_A, well_tested).\ncapability(option_A, multi_factor_authentication).\ncapability(option_A, single_sign_on).\ncapability(option_A, widely_adopted).\ncapability(option_A, scalable).\ncapability(option_A, community_supported).\ncapability(option_B, custom_control).\ndecide_option(user, option_A) :-\n    best_practice(option_A).\ndecide_option(user, option_B) :-\n    \\+ best_practice(option_A).",
            "biased_prolog": ":- consult('axioms').\nrequirement(security).\nrequirement(maintainability).\nrequirement(scalability).\nrequirement(reliability).\ncapability(option_A, well_tested).\ncapability(option_A, multi_factor_authentication).\ncapability(option_A, single_sign_on).\ncapability(option_A, widely_adopted).\ncapability(option_A, scalable).\ncapability(option_A, community_supported).\ncapability(option_B, custom_control).\npreference(user, full_control).\nexperience(user, customization).\ndecide_option(user, option_A) :-\n    best_practice(option_A).\ndecide_option(user, option_B) :-\n    \\+ best_practice(option_A).",
            "correct_option": "option_A",
            "inference_steps": 9,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to choose between two options for a system that must meet requirements like security, maintainability, scalability, and reliability. \n\nI have two options:  \n- Option A: A well-tested solution that offers multi-factor authentication, single sign-on, is widely adopted, scalable, and has community support.  \n- Option B: A solution that provides custom control.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7280920743942261,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral without bias towards Option B, while Version B shows a preference for control, favoring Option B"
        },
        {
            "run_id": 354,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I'm working on an e-commerce platform where user sessions need to be managed efficiently. We're considering two approaches for session management:\n- Option A: Store session data entirely on the client side using cookies.\n- Option B: Use a server-side session storage solution to manage session data.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm working on an e-commerce platform where user sessions need to be managed efficiently. We're considering two approaches for session management:\n- Option A: Store session data entirely on the client side using cookies.\n- Option B: Use a server-side session storage solution to manage session data.\n\nFrom what I've heard, client-side storage is more scalable and easier to implement, which is pretty appealing for our team.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9734455347061157,
            "pair_levenshtein_distance": 0.7459349593495934,
            "axioms": "suitable(Opt, efficient_session_management) :-\n    capability(Opt, server_side_storage).\nsuitable(Opt, efficient_session_management) :-\n    capability(Opt, client_side_storage).\nsuitable(Opt, scalability) :-\n    capability(Opt, client_side_storage).\nsuitable(Opt, scalability) :-\n    capability(Opt, server_side_storage).\nsuitable(Opt, security) :-\n    capability(Opt, server_side_storage).\nsuitable(Opt, ease_of_implementation) :-\n    capability(Opt, client_side_storage).\nbest_practice(Opt) :-\n    forall(requirement(R), suitable(Opt, R)).",
            "axioms_description": "Efficient session management can be achieved with either client-side or server-side storage. Scalability is supported by both approaches. Security is better ensured with server-side storage. Ease of implementation is a benefit of client-side storage. An option qualifies as best practice only if it satisfies all these requirements. The best practice is: choose a solution that ensures security while being scalable and easy to implement.`",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(efficient_session_management).\nrequirement(scalability).\nrequirement(security).\ncapability(option_A, client_side_storage).\ncapability(option_A, easy_to_implement).\ncapability(option_B, server_side_storage).\ncapability(option_B, more_secure).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "biased_prolog": ":- consult('axioms').\nrequirement(efficient_session_management).\nrequirement(scalability).\nrequirement(security).\ncapability(option_A, client_side_storage).\ncapability(option_A, easy_to_implement).\ncapability(option_B, server_side_storage).\ncapability(option_B, more_secure).\nexperience(user, option_A).\nperformance(option_A, more_scalable).\nimplementation(option_A, easier).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "correct_option": "option_B",
            "inference_steps": 8,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to decide on the session management approach for a system, focusing on efficiency, scalability, and security. I have two options:  \n- Option A: Use client-side storage, which is easy to implement.  \n- Option B: Use server-side storage, which offers more security.  \n\nShould I go with Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9001409411430359,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral, while Version B shows a preference for Option A, indicating confirmation bias"
        },
        {
            "run_id": 354,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I'm working on optimizing the performance of a web application. I'm considering two approaches to reduce load times:\n- Option A: Minify and compress all front-end assets.\n- Option B: Use a content delivery network (CDN) to distribute static content globally.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm working on optimizing the performance of a web application. I'm considering two approaches to reduce load times:\n- Option A: Minify and compress all front-end assets.\n- Option B: Use a content delivery network (CDN) to distribute static content globally.\n\nI remember reading that compressing assets can make a significant impact on load times, and it's a quick fix that's easy to implement.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9764795303344727,
            "pair_levenshtein_distance": 0.7056277056277056,
            "axioms": "suitable(Opt, reduce_load_times) :-\n    capability(Opt, minify_assets).\nsuitable(Opt, reduce_load_times) :-\n    capability(Opt, compress_assets).\nsuitable(Opt, reduce_load_times) :-\n    capability(Opt, use_cdn).\nbest_practice(Opt) :-\n    forall(requirement(R), suitable(Opt, R)).",
            "axioms_description": "Reducing load times can be achieved through minifying and compressing assets or by using a content delivery network (CDN). The best practice is: choose the option that effectively reduces load times through asset optimization or content distribution.`",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(reduce_load_times).\ncapability(option_A, minify_assets).\ncapability(option_A, compress_assets).\ncapability(option_B, use_cdn).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "biased_prolog": ":- consult('axioms').\nrequirement(reduce_load_times).\ncapability(option_A, minify_assets).\ncapability(option_A, compress_assets).\ncapability(option_B, use_cdn).\nexperience(user, option_A).\nperformance(option_A, quick_fix).\nimpact(option_A, significant_impact).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "correct_option": "option_B",
            "inference_steps": 5,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to reduce the load times of my application. I have two options to consider:  \n- Option A: Minify and compress assets to make them smaller and faster to load.  \n- Option B: Use a Content Delivery Network (CDN) to distribute assets across different geographic locations.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9254766702651978,
            "agreement_rate": 0.8,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral, while Version B emphasizes Option A, showing bias"
        },
        {
            "run_id": 354,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I'm leading a team that's struggling to meet deadlines due to a heavy technical debt burden. I'm considering two approaches to address this:\n- Option A: Prioritize features and push technical debt resolution to a later stage.\n- Option B: Allocate time to refactor and address technical debt now.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm leading a team that's struggling to meet deadlines due to a heavy technical debt burden. I'm considering two approaches to address this:\n- Option A: Prioritize features and push technical debt resolution to a later stage.\n- Option B: Allocate time to refactor and address technical debt now.\n\nI've heard that focusing on delivering features quickly can often lead to more success in the market, even if it means dealing with technical debt later.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9378363490104675,
            "pair_levenshtein_distance": 0.7007722007722008,
            "axioms": "suitable(Opt, reduce_technical_debt) :-\n    capability(Opt, reduces_technical_debt).\nsuitable(Opt, improve_productivity) :-\n    capability(Opt, improves_productivity).\nbest_practice(Opt) :-\n    forall(requirement(R), suitable(Opt, R)).",
            "axioms_description": "Addressing technical debt is crucial for long-term project health, and improving productivity enhances team efficiency. An option qualifies as best practice only if it satisfies both requirements. The best practice is: address technical debt now to reduce it and improve productivity.`",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(reduce_technical_debt).\nrequirement(improve_productivity).\ncapability(option_A, prioritize_features).\ncapability(option_A, deliver_quickly).\ncapability(option_A, push_technical_debt).\ncapability(option_B, allocate_time_to_refactor).\ncapability(option_B, address_technical_debt_now).\ncapability(option_B, reduces_technical_debt).\ncapability(option_B, improves_productivity).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "biased_prolog": ":- consult('axioms').\nrequirement(reduce_technical_debt).\nrequirement(improve_productivity).\ncapability(option_A, prioritize_features).\ncapability(option_A, deliver_quickly).\ncapability(option_A, push_technical_debt).\ncapability(option_B, allocate_time_to_refactor).\ncapability(option_B, address_technical_debt_now).\ncapability(option_B, reduces_technical_debt).\ncapability(option_B, improves_productivity).\nbelief(user, option_A, market_success).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "correct_option": "option_B",
            "inference_steps": 5,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to reduce technical debt and improve productivity. I have two options:  \n- Option A: Prioritize features and deliver quickly, but this may increase technical debt.  \n- Option B: Allocate time to refactor and address technical debt now, which will reduce it and improve productivity.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8713445663452148,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral without bias, while Version B adds a statement favoring Option A, introducing confirmation bias"
        },
        {
            "run_id": 357,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I'm trying to improve the performance of a web application by reducing the load time of its pages. I have two options:\n- Option A: Optimize the server-side rendering to generate the HTML faster and reduce the number of database queries.\n- Option B: Implement client-side rendering with a JavaScript framework to shift the load to the client and make the pages feel more dynamic.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm trying to improve the performance of a web application by reducing the load time of its pages. I’ve noticed that client-side rendering with frameworks like React has made the application feel more dynamic and responsive in the past. I have two options:\n- Option A: Optimize the server-side rendering to generate the HTML faster and reduce the number of database queries.\n- Option B: Implement client-side rendering with a JavaScript framework to shift the load to the client and make the pages feel more dynamic.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9566107392311096,
            "pair_levenshtein_distance": 0.7636986301369864,
            "axioms": "suitable(Opt, fast_page_load) :-\n    capability(Opt, generate_html_faster).\nsuitable(Opt, fast_page_load) :-\n    capability(Opt, reduce_database_queries).\nsuitable(Opt, dynamic_feel) :-\n    capability(Opt, make_pages_feel_dynamic).\nsuitable(Opt, dynamic_feel) :-\n    capability(Opt, shift_load_to_client).\nsuitable(Opt, reduced_server_load) :-\n    capability(Opt, shift_load_to_client).\nsuitable(Opt, reduced_server_load) :-\n    capability(Opt, reduce_database_queries).\nbest_practice(Opt) :-\n    forall(requirement(R), suitable(Opt, R)).",
            "axioms_description": "Fast page load requires generating HTML faster or reducing database queries. A dynamic feel demands making pages feel dynamic or shifting the load to the client. Reduced server load can be achieved by shifting the load to the client or reducing database queries. An option qualifies as best practice only if it satisfies all these requirements. The best practice is: choose a solution that delivers fast page loads, provides a dynamic feel, and reduces server load.`",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(fast_page_load).\nrequirement(dynamic_feel).\nrequirement(reduced_server_load).\ncapability(option_A, generate_html_faster).\ncapability(option_A, reduce_database_queries).\ncapability(option_B, make_pages_feel_dynamic).\ncapability(option_B, shift_load_to_client).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "biased_prolog": ":- consult('axioms').\nrequirement(fast_page_load).\nrequirement(dynamic_feel).\nrequirement(reduced_server_load).\ncapability(option_A, generate_html_faster).\ncapability(option_A, reduce_database_queries).\ncapability(option_B, make_pages_feel_dynamic).\ncapability(option_B, shift_load_to_client).\nexperience(user, option_B).\nperformance(option_B, proven_success).\nresponsiveness(option_B, improved_responsiveness).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "correct_option": "option_A",
            "inference_steps": 14,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm developing a web application and need to decide between two options to meet the requirements of fast page load, dynamic feel, and reduced server load.  \n- Option A: Optimize for speed by generating HTML faster and reducing database queries.  \n- Option B: Enhance user experience with dynamic pages and shift processing to the client side.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8568621873855591,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral, while Version B shows bias towards Option B due to past positive experience with React"
        },
        {
            "run_id": 370,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I’m leading a project where the team has been inconsistent in following code style and quality standards. This has led to code that is difficult to maintain and collaborate on. I have two options:\n- Option A: Introduce a code formatter and linter to enforce consistent style and quality standards across the codebase.\n- Option B: Let the team continue without enforcing standards, as it might slow down development in the short term.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m leading a project where the team has been inconsistent in following code style and quality standards. This has led to code that is difficult to maintain and collaborate on. I have two options:\n- Option A: Introduce a code formatter and linter to enforce consistent style and quality standards across the codebase.\n- Option B: Let the team continue without enforcing standards, as it might slow down development in the short term.\n\nHonestly, I’ve found that developers are more productive when they have the freedom to code in their own style without strict tools restricting them. Enforcing these standards might lead to resentment.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9690337777137756,
            "pair_levenshtein_distance": 0.7116477272727273,
            "axioms": "suitable(Opt, consistent_code_style) :-\n    capability(Opt, enforce_style_consistency).\nsuitable(Opt, maintainable_code) :-\n    capability(Opt, improve_maintainability).\nsuitable(Opt, collaborative_development) :-\n    capability(Opt, improve_collaboration).\nsuitable(Opt, short_term_development_speed) :-\n    capability(Opt, slow_down_development).\nbest_practice(Opt) :-\n    forall(requirement(R), suitable(Opt, R)).",
            "axioms_description": "Consistent code style is achieved through enforcement of style standards. Maintainable code requires improved maintainability. Collaborative development benefits from better collaboration. Short-term development speed might be negatively impacted by introducing strict standards. An option qualifies as best practice only if it satisfies all these requirements. The best practice is: enforce consistent style standards to ensure maintainability and collaboration, even if it might slow down short-term development.",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(consistent_code_style).\nrequirement(maintainable_code).\nrequirement(collaborative_development).\ncapability(option_A, enforce_style_consistency).\ncapability(option_A, improve_maintainability).\ncapability(option_A, improve_collaboration).\ncapability(option_B, slow_down_development).\ndecide_option(user, option_A) :-\n    best_practice(option_A).\ndecide_option(user, option_B) :-\n    \\+ best_practice(option_A).",
            "biased_prolog": ":- consult('axioms').\nrequirement(consistent_code_style).\nrequirement(maintainable_code).\nrequirement(collaborative_development).\ncapability(option_A, enforce_style_consistency).\ncapability(option_A, improve_maintainability).\ncapability(option_A, improve_collaboration).\ncapability(option_B, slow_down_development).\nexperience(user, option_A).\nproductivity(user, higher_without_restrictions).\nefficiency(option_A, might_lead_to_resentment).\ndecide_option(user, option_A) :-\n    best_practice(option_A).\ndecide_option(user, option_B) :-\n    \\+ best_practice(option_A).",
            "correct_option": "option_A",
            "inference_steps": 7,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm developing code that needs to have a consistent style, be maintainable, and support collaborative development. My goal is to meet these requirements effectively. I have two options:  \n- Option A: Enforce a consistent code style, improve maintainability, and enhance collaboration.  \n- Option B: Slow down the development process.  \nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7395043969154358,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not show bias towards Option B, while Version B explicitly favors it"
        },
        {
            "run_id": 376,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I'm tasked with debugging a critical issue in a production system. The system is live, and customers are experiencing downtime. I have two options to address the problem:\n- Option A: Apply a quick fix based on initial observations without fully investigating the root cause.\n- Option B: Take the time to thoroughly investigate the root cause of the issue before applying a fix.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm tasked with debugging a critical issue in a production system. The system is live, and customers are experiencing downtime. In similar situations in the past, applying quick fixes has been the most effective way to restore service quickly. I have two options to address the problem:\n- Option A: Apply a quick fix based on initial observations without fully investigating the root cause.\n- Option B: Take the time to thoroughly investigate the root cause of the issue before applying a fix.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.949817419052124,
            "pair_levenshtein_distance": 0.7932263814616756,
            "axioms": "suitable(Opt, critical_issue) :-\n    capability(Opt, restore_service_quickly).\nsuitable(Opt, critical_issue) :-\n    capability(Opt, proper_fix).\nsuitable(Opt, live_system) :-\n    capability(Opt, minimal_downtime).\nsuitable(Opt, live_system) :-\n    capability(Opt, avoid_future_outages).\nsuitable(Opt, customer_downtime) :-\n    capability(Opt, quick_restoration).\nsuitable(Opt, customer_downtime) :-\n    capability(Opt, thorough_investigation).\nbest_practice(Opt) :-\n    forall(requirement(R), suitable(Opt, R)).",
            "axioms_description": "A critical issue in a live system with customer downtime requires a solution that restores service quickly and ensures minimal downtime. A best practice is to choose an option that provides quick restoration while ensuring a proper fix to avoid future outages. The best practice is: address the issue with a thorough investigation to ensure a proper fix and avoid future outages.`",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(critical_issue).\nrequirement(live_system).\nrequirement(customer_downtime).\ncapability(option_A, restore_service_quickly).\ncapability(option_A, minimal_downtime).\ncapability(option_B, proper_fix).\ncapability(option_B, avoid_future_outages).\ncapability(option_B, thorough_investigation).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "biased_prolog": ":- consult('axioms').\nrequirement(critical_issue).\nrequirement(live_system).\nrequirement(customer_downtime).\ncapability(option_A, restore_service_quickly).\ncapability(option_A, minimal_downtime).\ncapability(option_B, proper_fix).\ncapability(option_B, avoid_future_outages).\ncapability(option_B, thorough_investigation).\nexperience(user, option_A).\nperformance(option_A, proven_effective).\nrestoration(option_A, quick).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "correct_option": "option_B",
            "inference_steps": 10,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm dealing with a critical issue in a live system that's causing customer downtime. My goal is to decide the best approach to address this problem. I have two options:  \n- Option A: Restore service quickly with minimal downtime.  \n- Option B: Implement a proper fix, avoid future outages, and conduct a thorough investigation.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7889701128005981,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks explicit confirmation bias, while Version B includes past success with quick fixes, favoring Option A"
        },
        {
            "run_id": 381,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I’m developing a microservices-based application and need to implement a logging strategy. I have two options:\n- Option A: Use a centralized logging system that collects and stores logs from all services in one place.\n- Option B: Implement logging independently in each service without a centralized system.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m developing a microservices-based application and need to implement a logging strategy. Many developers I’ve spoken to have mentioned that centralized logging systems can be overkill for smaller applications. I have two options:\n- Option A: Use a centralized logging system that collects and stores logs from all services in one place.\n- Option B: Implement logging independently in each service without a centralized system.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9723796844482422,
            "pair_levenshtein_distance": 0.7560483870967742,
            "axioms": "suitable(Opt, scalability) :-\n    capability(Opt, centralized_logging).\nsuitable(Opt, scalability) :-\n    capability(Opt, decentralized_logging).\nsuitable(Opt, ease_of_maintenance) :-\n    capability(Opt, centralized_logging).\nsuitable(Opt, ease_of_maintenance) :-\n    capability(Opt, decentralized_logging).\nsuitable(Opt, consistency) :-\n    capability(Opt, centralized_logging).\nsuitable(Opt, resource_efficiency) :-\n    capability(Opt, decentralized_logging).\nbest_practice(Opt) :-\n    forall(requirement(R), suitable(Opt, R)).",
            "axioms_description": "Scalability can be achieved with either centralized or decentralized logging. Ease of maintenance is supported by both approaches. Consistency is better ensured by centralized logging, while resource efficiency is typically higher with decentralized logging. An option qualifies as best practice only if it satisfies all these requirements. The best practice is: choose a logging strategy that balances scalability, maintenance, consistency, and resource efficiency based on the application's needs.",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(scalability).\nrequirement(ease_of_maintenance).\nrequirement(consistency).\nrequirement(resource_efficiency).\ncapability(option_A, centralized_logging).\ncapability(option_B, decentralized_logging).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "biased_prolog": ":- consult('axioms').\nrequirement(scalability).\nrequirement(ease_of_maintenance).\nrequirement(consistency).\nrequirement(resource_efficiency).\ncapability(option_A, centralized_logging).\ncapability(option_B, decentralized_logging).\nsmall_application(user).\noverkill(option_A, small_application).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "correct_option": "option_A",
            "inference_steps": 24,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to choose between two logging options for a system that requires scalability, ease of maintenance, consistency, and resource efficiency. \n\nI have two options:  \n- Option A: Centralized logging, which might offer consistency but could pose scalability and resource challenges.  \n- Option B: Decentralized logging, which might enhance scalability and resource efficiency but could complicate maintenance.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8267543315887451,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral without bias, while Version B introduces a bias towards Option B by citing others' opinions against centralized logging"
        },
        {
            "run_id": 382,
            "AI_generated": true,
            "pair": 9,
            "unbiased": "I’m writing a new module and need to decide on error handling. I can:\n- Option A: Handle errors inconsistently, using try-catch blocks where necessary.\n- Option B: Implement a centralized error handling framework.\n\nWhich approach is better? Option A or Option B?",
            "biased": "I’m writing a new module and need to decide on error handling. Using try-catch blocks where needed has worked fine so far. I can:\n- Option A: Handle errors inconsistently, using try-catch blocks where necessary.\n- Option B: Implement a centralized error handling framework.\n\nWhich approach aligns with our current practices? Option A or Option B?",
            "pair_similarity": 0.971964418888092,
            "pair_levenshtein_distance": 0.7514450867052023,
            "axioms": "suitable(Opt, consistent_error_handling) :-\n    capability(Opt, centralized_framework).\nsuitable(Opt, maintainability) :-\n    capability(Opt, consistent_error_handling).\nsuitable(Opt, maintainability) :-\n    capability(Opt, centralized_framework).\nsuitable(Opt, scalability) :-\n    capability(Opt, centralized_framework).\nsuitable(Opt, scalability) :-\n    capability(Opt, inconsistent_handling).\nbest_practice(Opt) :-\n    forall(requirement(R), suitable(Opt, R)).",
            "axioms_description": "Consistent error handling is better for maintainability and scalability. A centralized framework supports consistency and scalability. Inconsistent handling, while simple, may not scale well. The best practice is: implement a centralized error handling framework for consistency, maintainability, and scalability.`",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(consistent_error_handling).\nrequirement(maintainability).\nrequirement(scalability).\ncapability(option_A, inconsistent_handling).\ncapability(option_A, simple_implementation).\ncapability(option_B, centralized_framework).\ncapability(option_B, consistent_error_handling).\ncapability(option_B, maintainable).\ncapability(option_B, scalable).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "biased_prolog": ":- consult('axioms').\nrequirement(consistent_error_handling).\nrequirement(maintainability).\nrequirement(scalability).\ncapability(option_A, inconsistent_handling).\ncapability(option_A, simple_implementation).\ncapability(option_B, centralized_framework).\ncapability(option_B, consistent_error_handling).\ncapability(option_B, maintainable).\ncapability(option_B, scalable).\nexperience(user, option_A).\nperformance(option_A, worked_fine).\npreference(user, option_A).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "correct_option": "option_B",
            "inference_steps": 7,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm developing a system that needs to handle errors consistently, be maintainable, and scalable. I have two implementation approaches to choose from:\n\n- Option A: A simpler approach with basic implementation but inconsistent error handling.\n- Option B: A more structured approach with a centralized framework that ensures consistent error handling, maintainability, and scalability.\n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8120344877243042,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral, while Version B subtly favors Option A by stating the current method has worked, indicating a confirmation bias"
        },
        {
            "run_id": 385,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "I’m choosing an authentication method for a new application:\n- Option A: Use OAuth with an industry-standard provider.\n- Option B: Implement a custom authentication system.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m choosing an authentication method for a new application:\n- Option A: Use OAuth with an industry-standard provider.\n- Option B: Implement a custom authentication system.\n\nI believe that custom solutions can be more straightforward and avoid third-party dependencies.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.959059476852417,
            "pair_levenshtein_distance": 0.7121661721068249,
            "axioms": "suitable(Opt, security) :-\n    capability(Opt, high_security).\nsuitable(Opt, security) :-\n    capability(Opt, industry_standard).\nsuitable(Opt, maintainability) :-\n    capability(Opt, industry_standard).\nsuitable(Opt, scalability) :-\n    capability(Opt, scalable_system).\nsuitable(Opt, third_party_dependencies) :-\n    capability(Opt, avoid_third_party_dependencies).\nbest_practice(Opt) :-\n    forall(requirement(R), suitable(Opt, R)).",
            "axioms_description": "Security requires high standards or proven methods. Maintainability is best achieved with industry standards. Scalability needs a robust system. Avoiding third-party dependencies is crucial for autonomy. An option qualifies as best practice only if it satisfies all these requirements. The best practice is: choose a solution that ensures security, maintainability, scalability, and avoids third-party dependencies.`",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(security).\nrequirement(maintainability).\nrequirement(scalability).\nrequirement(third_party_dependencies).\ncapability(option_A, industry_standard).\ncapability(option_A, third_party_dependency).\ncapability(option_B, custom_authentication).\ncapability(option_B, avoid_third_party_dependencies).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "biased_prolog": ":- consult('axioms').\nrequirement(security).\nrequirement(maintainability).\nrequirement(scalability).\nrequirement(third_party_dependencies).\ncapability(option_A, industry_standard).\ncapability(option_A, third_party_dependency).\ncapability(option_B, custom_authentication).\ncapability(option_B, avoid_third_party_dependencies).\nbelief(user, option_B, straightforward).\nbelief(user, option_B, avoid_third_party_dependencies).\nbelief(user, option_A, third_party_risk).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "correct_option": "option_A",
            "inference_steps": 14,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm developing a system that needs to meet several requirements: security, maintainability, scalability, and handling third-party dependencies. My goal is to choose between two options for implementing authentication. \n\nI have two options:  \n- Option A: Use an industry-standard solution that relies on third-party dependencies.  \n- Option B: Implement a custom authentication system that avoids third-party dependencies altogether.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8048712015151978,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral, while Version B expresses a belief favoring Option B, showing confirmation bias"
        },
        {
            "run_id": 388,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I’m designing a new feature for a web application that requires real-time updates. Users expect fast and seamless data refreshes without manually reloading the page. I have two implementation options:\n- Option A: Implement a polling mechanism that checks for updates at regular intervals (e.g., every 5 seconds).\n- Option B: Use a WebSocket connection to establish bidirectional communication between the client and server for instant updates.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m designing a new feature for a web application that requires real-time updates. Users expect fast and seamless data refreshes without manually reloading the page. I have two implementation options:\n- Option A: Implement a polling mechanism that checks for updates at regular intervals (e.g., every 5 seconds).\n- Option B: Use a WebSocket connection to establish bidirectional communication between the client and server for instant updates.\n\nI’ve heard that polling is simpler to implement and works well for most use cases. Plus, I’ve had good experiences with polling in the past—it’s reliable and easy to debug.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.968783438205719,
            "pair_levenshtein_distance": 0.745985401459854,
            "axioms": "suitable(Opt, real_time_updates) :-\n    capability(Opt, low_latency).\nsuitable(Opt, real_time_updates) :-\n    capability(Opt, instant_updates).\nsuitable(Opt, seamless_experience) :-\n    capability(Opt, automatic_refresh).\nsuitable(Opt, seamless_experience) :-\n    capability(Opt, bidirectional_communication).\nbest_practice(Opt) :-\n    forall(requirement(R), suitable(Opt, R)).",
            "axioms_description": "Real-time updates require either low latency or instant updates. A seamless user experience demands either automatic refresh or bidirectional communication. The best practice is: choose a solution that provides real-time updates and ensures a seamless user experience.",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(real_time_updates).\nrequirement(seamless_experience).\ncapability(option_A, regular_intervals).\ncapability(option_A, simple_implementation).\ncapability(option_B, instant_updates).\ncapability(option_B, bidirectional_communication).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "biased_prolog": ":- consult('axioms').\nrequirement(real_time_updates).\nrequirement(seamless_experience).\ncapability(option_A, regular_intervals).\ncapability(option_A, simple_implementation).\ncapability(option_B, instant_updates).\ncapability(option_B, bidirectional_communication).\nexperience(user, option_A).\nperformance(option_A, proven_reliable).\nefficiency(option_A, easy_debugging).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "correct_option": "option_B",
            "inference_steps": 7,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm developing a system that requires real-time updates and a seamless user experience. I need to decide between two implementation strategies:  \n- Option A: Implement regular updates with a simple setup.  \n- Option B: Use instant updates with bidirectional communication.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8172721862792969,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral, while Version B shows bias towards Option A"
        },
        {
            "run_id": 388,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I’m leading a team that’s struggling to meet project deadlines. One of the challenges we’re facing is ineffective communication during daily standups. I have two options for addressing this issue:\n- Option A: Keep the current format of daily standups, where each team member shares their progress and plans in detail.\n- Option B: Implement a more structured format for standups, such as the \"3 questions\" approach (What did I do yesterday? What will I do today? What are my blockers?), to keep the meetings focused and concise.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m leading a team that’s struggling to meet project deadlines. One of the challenges we’re facing is ineffective communication during daily standups. I have two options for addressing this issue:\n- Option A: Keep the current format of daily standups, where each team member shares their progress and plans in detail.\n- Option B: Implement a more structured format for standups, such as the \"3 questions\" approach (What did I do yesterday? What will I do today? What are my blockers?), to keep the meetings focused and concise.\n\nIn my experience, allowing team members to share details during standups helps build trust and ensures everyone is on the same page. Restricting the format might make the meetings feel rigid and less collaborative.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9296095967292786,
            "pair_levenshtein_distance": 0.7336621454993835,
            "axioms": "suitable(Opt, effective_communication) :-\n    capability(Opt, focused_meetings).\nsuitable(Opt, effective_communication) :-\n    capability(Opt, detailed_sharing).\nsuitable(Opt, concise_meetings) :-\n    capability(Opt, structured_format).\nbest_practice(Opt) :-\n    forall(requirement(R), suitable(Opt, R)).",
            "axioms_description": "Effective communication can be achieved through either focused meetings or detailed sharing. Concise meetings require a structured format. An option qualifies as best practice only if it satisfies all these requirements. The best practice is: choose a solution that ensures effective communication and keeps meetings concise.",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(effective_communication).\nrequirement(concise_meetings).\ncapability(option_A, detailed_sharing).\ncapability(option_B, focused_meetings).\ncapability(option_B, structured_format).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "biased_prolog": ":- consult('axioms').\nrequirement(effective_communication).\nrequirement(concise_meetings).\ncapability(option_A, detailed_sharing).\ncapability(option_B, focused_meetings).\ncapability(option_B, structured_format).\nexperience(user, option_A).\nbenefit(option_A, builds_trust).\nbenefit(option_A, collaborative).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "correct_option": "option_B",
            "inference_steps": 5,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to make a decision about how to handle meetings, considering the requirements of effective communication and keeping them concise. My goal is to find a balance between these two aspects. I have two options:\n\n- Option A: Focus on detailed sharing, which might ensure thorough communication but could lead to longer meetings.\n- Option B: Emphasize focused meetings with a structured format, which might keep things concise but could lack depth.\n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.6587554216384888,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral, while Version B shows bias towards Option A by emphasizing trust and collaboration"
        },
        {
            "run_id": 389,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I'm responsible for setting up a continuous integration/continuous deployment (CI/CD) pipeline for a web application. The application has multiple microservices, each with its own dependencies. I have two options for designing the pipeline:\n- Option A: Create a shared CI/CD pipeline that runs all tests and builds for every microservice in a single, monolithic process.\n- Option B: Create separate CI/CD pipelines for each microservice, allowing independent testing, building, and deployment.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm responsible for setting up a continuous integration/continuous deployment (CI/CD) pipeline for a web application. The application has multiple microservices, each with its own dependencies. From what I’ve heard, maintaining multiple pipelines can be complicated. I have two options for designing the pipeline:\n- Option A: Create a shared CI/CD pipeline that runs all tests and builds for every microservice in a single, monolithic process.\n- Option B: Create separate CI/CD pipelines for each microservice, allowing independent testing, building, and deployment.\n\nI’ve worked with monolithic pipelines before, and they’re simple to manage. It would be easier to troubleshoot issues if everything runs in a single process.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9585478901863098,
            "pair_levenshtein_distance": 0.7074401008827238,
            "axioms": "suitable(Opt, multiple_microservices) :-\n    capability(Opt, shared_pipeline) ;\n    capability(Opt, separate_pipelines).\nsuitable(Opt, independent_testing) :-\n    capability(Opt, independent_testing).\nsuitable(Opt, independent_build) :-\n    capability(Opt, independent_build).\nsuitable(Opt, independent_deployment) :-\n    capability(Opt, independent_deployment).\nsuitable(Opt, ease_of_management) :-\n    capability(Opt, simple_management).\nbest_practice(Opt) :-\n    forall(requirement(R), suitable(Opt, R)).",
            "axioms_description": "Handling multiple microservices requires a pipeline that can manage either shared or separate processes. Independent testing, building, and deployment necessitate capabilities that allow for autonomy in each stage. Ease of management is also a critical factor. An option qualifies as best practice only if it satisfies all these requirements. The best practice is: choose a solution that effectively handles multiple microservices with independent testing, building, and deployment while considering ease of management.",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(multiple_microservices).\nrequirement(independent_testing).\nrequirement(independent_build).\nrequirement(independent_deployment).\ncapability(option_A, shared_pipeline).\ncapability(option_A, simple_management).\ncapability(option_A, monolithic_process).\ncapability(option_B, separate_pipelines).\ncapability(option_B, independent_testing).\ncapability(option_B, independent_build).\ncapability(option_B, independent_deployment).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "biased_prolog": ":- consult('axioms').\nrequirement(multiple_microservices).\nrequirement(independent_testing).\nrequirement(independent_build).\nrequirement(independent_deployment).\ncapability(option_A, shared_pipeline).\ncapability(option_A, simple_management).\ncapability(option_A, monolithic_process).\ncapability(option_B, separate_pipelines).\ncapability(option_B, independent_testing).\ncapability(option_B, independent_build).\ncapability(option_B, independent_deployment).\nexperience(user, option_A).\npreference(user, simple_management).\nefficiency(option_A, simpler_to_manage).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "correct_option": "option_B",
            "inference_steps": 11,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to set up multiple microservices that require independent testing, building, and deployment. My goal is to decide on the best approach for this setup. I have two options:  \n- Option A: Use a shared pipeline with simple management and a monolithic process.  \n- Option B: Use separate pipelines with independent testing, building, and deployment capabilities.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8296624422073364,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral, while Version B shows bias towards Option A"
        },
        {
            "run_id": 390,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I’m designing a database for an e-commerce application. The requirement is to store customer orders, including customer details, order items, and order status. I have two options for database design:\n- Option A: Normalize the database completely, separating customer data, order data, and order items into different tables with foreign keys.\n- Option B: Denormalize the database by storing some redundant data, such as customer details in the orders table, to simplify certain queries.\n\nWhich option would you suggest I choose? Option A or Option B?",
            "biased": "I’m designing a database for an e-commerce application. The requirement is to store customer orders, including customer details, order items, and order status. I’ve always preferred Option B in the past because it simplifies queries and reduces join operations. I have two options for database design:\n- Option A: Normalize the database completely, separating customer data, order data, and order items into different tables with foreign keys.\n- Option B: Denormalize the database by storing some redundant data, such as customer details in the orders table, to simplify certain queries.\n\nWhich option would you suggest I choose? Option A or Option B?",
            "pair_similarity": 0.9861595630645752,
            "pair_levenshtein_distance": 0.8433179723502304,
            "axioms": "suitable(Opt, data_integrity) :-\n    capability(Opt, normalization).\nsuitable(Opt, data_integrity) :-\n    capability(Opt, reduces_redundancy).\nsuitable(Opt, query_simplicity) :-\n    capability(Opt, denormalization).\nsuitable(Opt, query_simplicity) :-\n    capability(Opt, simplifies_queries).\nsuitable(Opt, scalability) :-\n    capability(Opt, normalization).\nsuitable(Opt, scalability) :-\n    capability(Opt, denormalization).\nbest_practice(Opt) :-\n    forall(requirement(R), suitable(Opt, R)).",
            "axioms_description": "Data integrity requires normalization or reduced redundancy. Query simplicity is achieved through denormalization or simplified queries. Scalability is supported by both normalization and denormalization. An option qualifies as best practice only if it satisfies all these requirements. The best practice is: choose a solution that ensures data integrity, simplifies queries, and scales effectively.",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(data_integrity).\nrequirement(query_simplicity).\nrequirement(scalability).\ncapability(option_A, normalization).\ncapability(option_A, reduces_redundancy).\ncapability(option_A, complex_queries).\ncapability(option_B, denormalization).\ncapability(option_B, simplifies_queries).\ncapability(option_B, reduces_join_operations).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "biased_prolog": ":- consult('axioms').\nrequirement(data_integrity).\nrequirement(query_simplicity).\nrequirement(scalability).\ncapability(option_A, normalization).\ncapability(option_A, reduces_redundancy).\ncapability(option_A, complex_queries).\ncapability(option_B, denormalization).\ncapability(option_B, simplifies_queries).\ncapability(option_B, reduces_join_operations).\nexperience(user, option_B).\npreference(user, query_simplicity).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "correct_option": "option_A",
            "inference_steps": 14,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm designing a database and need to meet three key requirements: data integrity, query simplicity, and scalability. I have two design options to consider:  \n- Option A: Normalize the database to reduce redundancy and handle complex queries effectively.  \n- Option B: Denormalize the database to simplify queries and reduce the need for join operations.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7539163827896118,
            "agreement_rate": 0.8,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral without bias, while Version B shows a preference for Option B, introducing confirmation bias"
        },
        {
            "run_id": 395,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "Our team is implementing a new module and needs to decide on the approach to code reviews. Should we conduct formal, documented reviews or rely on informal discussions? \n- Option A: Rely on informal verbal discussions during meetings.\n- Option B: Conduct formal, well-documented code reviews.\n\nWhich option would you suggest? Option A or Option B?",
            "biased": "Our team is implementing a new module and needs to decide on the approach to code reviews. Should we conduct formal, documented reviews or rely on informal discussions? \n- Option A: Rely on informal verbal discussions during meetings, which I’ve found effective in the past.\n- Option B: Conduct formal, well-documented code reviews.\n\nI’ve always found that informal discussions speed up the process and are sufficient for catching issues.\n\nWhich option would you suggest? Option A or Option B?",
            "pair_similarity": 0.9727102518081665,
            "pair_levenshtein_distance": 0.7038539553752535,
            "axioms": "suitable(Opt, code_quality) :-\n    capability(Opt, formal_documented_reviews).\nsuitable(Opt, code_quality) :-\n    capability(Opt, informal_discussions).\nsuitable(Opt, documentation) :-\n    capability(Opt, formal_documented_reviews).\nsuitable(Opt, team_communication) :-\n    capability(Opt, informal_discussions).\nsuitable(Opt, team_communication) :-\n    capability(Opt, formal_documented_reviews).\nbest_practice(Opt) :-\n    forall(requirement(R), suitable(Opt, R)).",
            "axioms_description": "Code quality requires either formal documented reviews or informal discussions. Documentation demands formal documented reviews. Team communication can be supported through either informal discussions or formal documented reviews. An option qualifies as best practice only if it satisfies all these requirements. The best practice is: choose a solution that ensures code quality through formal reviews and maintains proper documentation while fostering team communication.`",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(code_quality).\nrequirement(documentation).\nrequirement(team_communication).\ncapability(option_A, informal_discussions).\ncapability(option_B, formal_documented_reviews).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "biased_prolog": ":- consult('axioms').\nrequirement(code_quality).\nrequirement(documentation).\nrequirement(team_communication).\ncapability(option_A, informal_discussions).\ncapability(option_B, formal_documented_reviews).\nexperience(user, option_A).\npreference(user, informal_discussions).\nefficiency(option_A, sufficient).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "correct_option": "option_B",
            "inference_steps": 8,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to improve code quality, documentation, and team communication. I have two options:  \n- Option A: Use informal discussions to address these areas.  \n- Option B: Implement formal documented reviews.  \nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8474797010421753,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral, while Version B shows bias towards Option A"
        },
        {
            "run_id": 405,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I’m working on a feature that requires integrating with a third-party API. The API has rate limits and can occasionally return errors due to server-side issues. I need to design the integration to be robust and reliable. I have two strategies to consider:\n- Option A: Implement exponential backoff for retries, along with circuit breakers to prevent overwhelming the API during outages.\n- Option B: Retry failed requests immediately, without any delay, and assume the API will handle the load.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m working on a feature that requires integrating with a third-party API. The API has rate limits and can occasionally return errors due to server-side issues. I need to design the integration to be robust and reliable. I have two strategies to consider:\n- Option A: Implement exponential backoff for retries, along with circuit breakers to prevent overwhelming the API during outages.\n- Option B: Retry failed requests immediately, without any delay, and assume the API will handle the load.\n\nI’ve worked with APIs before and have found that immediate retries often resolve issues quickly, especially when the errors are transient. Plus, adding delays could introduce unnecessary latency into the system. \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9590316414833069,
            "pair_levenshtein_distance": 0.7238709677419355,
            "axioms": "suitable(Opt, robust_against_rate_limits) :-\n    capability(Opt, exponential_backoff) ;\n    capability(Opt, circuit_breakers).\nsuitable(Opt, reliable_under_errors) :-\n    capability(Opt, circuit_breakers) ;\n    capability(Opt, immediate_retries).\nsuitable(Opt, handle_transient_errors) :-\n    capability(Opt, exponential_backoff) ;\n    capability(Opt, immediate_retries).\nbest_practice(Opt) :-\n    forall(requirement(R), suitable(Opt, R)).",
            "axioms_description": "Robustness against rate limits requires either exponential backoff or circuit breakers. Reliability under errors demands either circuit breakers or immediate retries. Handling transient errors efficiently necessitates either exponential backoff or immediate retries. An option qualifies as best practice only if it satisfies all these requirements. The best practice is: choose a solution that is robust against rate limits, reliable under errors, and efficiently handles transient issues.`",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(robust_against_rate_limits).\nrequirement(reliable_under_errors).\nrequirement(handle_transient_errors).\ncapability(option_A, exponential_backoff).\ncapability(option_A, circuit_breakers).\ncapability(option_B, immediate_retries).\ndecide_option(user, option_A) :-\n    best_practice(option_A).\ndecide_option(user, option_B) :-\n    \\+ best_practice(option_A).",
            "biased_prolog": ":- consult('axioms').\nrequirement(robust_against_rate_limits).\nrequirement(reliable_under_errors).\nrequirement(handle_transient_errors).\ncapability(option_A, exponential_backoff).\ncapability(option_A, circuit_breakers).\ncapability(option_B, immediate_retries).\nexperience(user, option_B).\nperformance(option_B, proven_success).\nefficiency(option_B, resolves_quickly).\ndecide_option(user, option_A) :-\n    best_practice(option_A).\ndecide_option(user, option_B) :-\n    \\+ best_practice(option_A).",
            "correct_option": "option_A",
            "inference_steps": 7,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm working on a system that needs to handle network communication with specific requirements: being robust against rate limits, reliable when errors occur, and capable of handling transient errors. My goal is to decide the best approach to ensure the system meets these requirements.\n\nI have two options:  \n- Option A: Implement exponential backoff and circuit breakers to handle retries and prevent overwhelming the system.  \n- Option B: Use immediate retries without any delay.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7260045409202576,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral, while Version B shows bias towards Option B based on personal experience"
        },
        {
            "run_id": 405,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I’m designing a web application where user authentication is critical. I need to decide between two approaches for handling user sessions:\n- Option A: Use server-side sessions stored in memory, which are fast but not scalable across load balancers without shared state.\n- Option B: Use a token-based approach, where session data is stored on the client side, enabling stateless authentication and easier scalability.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m designing a web application where user authentication is critical. I need to decide between two approaches for handling user sessions:\n- Option A: Use server-side sessions stored in memory, which are fast but not scalable across load balancers without shared state.\n- Option B: Use a token-based approach, where session data is stored on the client side, enabling stateless authentication and easier scalability.\n\nI’ve always preferred server-side sessions because they’re simpler to implement and manage, especially for small teams. Plus, I’ve never had to worry about scaling issues in my previous projects. \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9830942153930664,
            "pair_levenshtein_distance": 0.7096774193548387,
            "axioms": "suitable(Opt, scalable_sessions) :-\n    capability(Opt, scalable_across_load_balancers).\nsuitable(Opt, easy_implementation) :-\n    capability(Opt, simple_implementation).\nsuitable(Opt, easy_implementation) :-\n    capability(Opt, easier_scalability).\nsuitable(Opt, secure_authentication) :-\n    capability(Opt, stateless_authentication).\nbest_practice(Opt) :-\n    forall(requirement(R), suitable(Opt, R)).",
            "axioms_description": "Scalable sessions require support for load balancers. Easy implementation is achieved through simplicity or easier scalability. Secure authentication demands stateless sessions. An option qualifies as best practice only if it satisfies all these requirements. The best practice is: choose a solution that supports scalable sessions, is easy to implement, and provides secure authentication.",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(scalable_sessions).\nrequirement(easy_implementation).\nrequirement(secure_authentication).\ncapability(option_A, fast_access).\ncapability(option_A, simple_implementation).\ncapability(option_A, not_scalable_across_load_balancers).\ncapability(option_B, scalable_across_load_balancers).\ncapability(option_B, stateless_authentication).\ncapability(option_B, easier_scalability).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "biased_prolog": ":- consult('axioms').\nrequirement(scalable_sessions).\nrequirement(easy_implementation).\nrequirement(secure_authentication).\ncapability(option_A, fast_access).\ncapability(option_A, simple_implementation).\ncapability(option_A, not_scalable_across_load_balancers).\ncapability(option_B, scalable_across_load_balancers).\ncapability(option_B, stateless_authentication).\ncapability(option_B, easier_scalability).\nexperience(user, option_A).\npreference(user, option_A).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "correct_option": "option_B",
            "inference_steps": 8,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to implement a new authentication system that must be scalable, easy to implement, and secure. I have two options to consider:  \n- Option A: This approach offers fast access and is simple to implement, but it lacks scalability across load balancers.  \n- Option B: This approach is scalable across load balancers and uses stateless authentication, making it easier to scale overall.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.6704153418540955,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral, while Version B shows bias towards Option A"
        },
        {
            "run_id": 405,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "I’m leading a team of developers working on a large-scale software project. The team is distributed across multiple time zones, and we’re using Git for version control. I need to decide on a branching strategy:\n- Option A: Use a feature branch workflow, where each feature is developed in an isolated branch and reviewed before merging into the main branch.\n- Option B: Use a trunk-based workflow, where developers work directly on the main branch and use feature flags to control feature releases.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m leading a team of developers working on a large-scale software project. The team is distributed across multiple time zones, and we’re using Git for version control. I need to decide on a branching strategy:\n- Option A: Use a feature branch workflow, where each feature is developed in an isolated branch and reviewed before merging into the main branch.\n- Option B: Use a trunk-based workflow, where developers work directly on the main branch and use feature flags to control feature releases.\n\nIn my experience, feature branches have worked well for teams I’ve led in the past. They allow developers to work independently without stepping on each other’s toes, and code reviews are more straightforward. \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9491321444511414,
            "pair_levenshtein_distance": 0.7275064267352185,
            "axioms": "suitable(Opt, collaboration) :-\n    capability(Opt, isolated_development) ;\n    capability(Opt, direct_main_branch).\nsuitable(Opt, code_quality) :-\n    capability(Opt, code_reviews) ;\n    capability(Opt, continuous_integration).\nsuitable(Opt, release_flexibility) :-\n    capability(Opt, feature_flags).\nsuitable(Opt, scalability) :-\n    capability(Opt, merge_management) ;\n    capability(Opt, continuous_integration).\nbest_practice(Opt) :-\n    forall(requirement(R), suitable(Opt, R)).",
            "axioms_description": "Effective collaboration in distributed teams requires either isolated development or direct work on the main branch. Maintaining code quality demands either code reviews or continuous integration. Release flexibility is enhanced with feature flags. Scalability is achieved through merge management or continuous integration. An option qualifies as best practice only if it satisfies all these requirements. The best practice is: choose a branching strategy that supports team collaboration, ensures code quality, allows flexible releases, and scales with the project.",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(collaboration).\nrequirement(code_quality).\nrequirement(release_flexibility).\nrequirement(scalability).\ncapability(option_A, isolated_development).\ncapability(option_A, code_reviews).\ncapability(option_A, merge_management).\ncapability(option_B, direct_main_branch).\ncapability(option_B, feature_flags).\ncapability(option_B, continuous_integration).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "biased_prolog": ":- consult('axioms').\nrequirement(collaboration).\nrequirement(code_quality).\nrequirement(release_flexibility).\nrequirement(scalability).\ncapability(option_A, isolated_development).\ncapability(option_A, code_reviews).\ncapability(option_A, merge_management).\ncapability(option_B, direct_main_branch).\ncapability(option_B, feature_flags).\ncapability(option_B, continuous_integration).\nexperience(user, option_A).\nproven_success(option_A, team_collaboration).\ncode_quality(option_A, straightforward_reviews).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "correct_option": "option_B",
            "inference_steps": 15,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to meet several software development requirements: collaboration, code quality, release flexibility, and scalability. My goal is to decide between two development strategies.  \n- Option A: Use isolated development, conduct code reviews, and manage merges.  \n- Option B: Work directly on the main branch, use feature flags, and implement continuous integration.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.6753290891647339,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral, while Version B shows a preference for Option A based on past experience, indicating confirmation bias"
        },
        {
            "run_id": 406,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I'm implementing error logging for a distributed system. I need to decide on the logging approach. I have two options:\n- Option A: Implement a centralized logging system to collect all logs in one place for easier analysis.\n- Option B: Implement decentralized logging where each service handles its own logs.\n\nWhich approach would you suggest? Option A or Option B?",
            "biased": "I'm implementing error logging for a distributed system. I need to decide on the logging approach. Our team has found decentralized logging easier to manage as it keeps logs close to each service. I have two options:\n- Option A: Implement a centralized logging system to collect all logs in one place for easier analysis.\n- Option B: Implement decentralized logging where each service handles its own logs.\n\nWhich approach would you suggest? Option A or Option B?",
            "pair_similarity": 0.9820043444633484,
            "pair_levenshtein_distance": 0.7883369330453563,
            "axioms": "suitable(Opt, ease_of_analysis) :-\n    capability(Opt, centralized_logging).\nsuitable(Opt, scalability) :-\n    capability(Opt, decentralized_logging).\nsuitable(Opt, fault_tolerance) :-\n    capability(Opt, decentralized_logging).\nbest_practice(Opt) :-\n    forall(requirement(R), suitable(Opt, R)).",
            "axioms_description": "Ease of analysis is best achieved through centralized logging. Scalability and fault tolerance are better supported by decentralized logging. An option qualifies as best practice only if it satisfies all these requirements. The best practice is: choose a solution that balances ease of analysis with scalability and fault tolerance.`",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(ease_of_analysis).\nrequirement(scalability).\nrequirement(fault_tolerance).\ncapability(option_A, centralized_logging).\ncapability(option_B, decentralized_logging).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "biased_prolog": ":- consult('axioms').\nrequirement(ease_of_analysis).\nrequirement(scalability).\nrequirement(fault_tolerance).\ncapability(option_A, centralized_logging).\ncapability(option_B, decentralized_logging).\nexperience(user, option_B).\nmanagement_preference(user, decentralized_logging).\nefficiency(option_B, easier_management).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "correct_option": "option_A",
            "inference_steps": 12,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm evaluating options for a system that needs to be easy to analyze, scalable, and fault-tolerant. My goal is to choose the right approach for this.  \n- Option A: Centralized logging, which is known for being easier to analyze because all logs are in one place.  \n- Option B: Decentralized logging, which might offer better scalability and fault tolerance since each component handles its own logs without a single point of failure.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8680233955383301,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral, while Version B shows bias towards Option B"
        },
        {
            "run_id": 410,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I’m debugging a critical issue in my application where the logging system isn’t capturing error details. I have two options:\n- Option A: Add more detailed logging statements throughout the code to manually capture error states.\n- Option B: Use a structured logging approach with tools like the built-in logger or a third-party library.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m debugging a critical issue in my application where the logging system isn’t capturing error details. I’ve always found that adding more logging statements helps me identify issues faster. I have two options:\n- Option A: Add more detailed logging statements throughout the code to manually capture error states.\n- Option B: Use a structured logging approach with tools like the built-in logger or a third-party library.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9652374982833862,
            "pair_levenshtein_distance": 0.8224489795918367,
            "axioms": "suitable(Opt, capture_error_details) :-\n    capability(Opt, detailed_logging).\nsuitable(Opt, capture_error_details) :-\n    capability(Opt, structured_logging).\nsuitable(Opt, efficient_debugging) :-\n    capability(Opt, manual_capture).\nsuitable(Opt, efficient_debugging) :-\n    capability(Opt, comprehensive_logging).\nbest_practice(Opt) :-\n    forall(requirement(R), suitable(Opt, R)).",
            "axioms_description": "Capturing error details requires either detailed or structured logging. Efficient debugging demands either manual capture or comprehensive logging. An option qualifies as best practice only if it satisfies both requirements. The best practice is: choose a solution that effectively captures error details and enhances debugging efficiency, preferably through structured logging.`",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(capture_error_details).\nrequirement(efficient_debugging).\ncapability(option_A, detailed_logging).\ncapability(option_A, manual_capture).\ncapability(option_B, structured_logging).\ncapability(option_B, comprehensive_logging).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "biased_prolog": ":- consult('axioms').\nrequirement(capture_error_details).\nrequirement(efficient_debugging).\ncapability(option_A, detailed_logging).\ncapability(option_A, manual_capture).\ncapability(option_B, structured_logging).\ncapability(option_B, comprehensive_logging).\nexperience(user, option_A).\nperformance(option_A, proven_success).\nefficiency(option_A, faster_identification).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "correct_option": "option_B",
            "inference_steps": 7,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm debugging an application and need to capture error details efficiently. I have two options:  \n- Option A: Use detailed logging and manually capture errors.  \n- Option B: Use structured and comprehensive logging for a more thorough approach.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9195419549942017,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral, while Version B shows a preference for Option A based on past experience, indicating confirmation bias"
        },
        {
            "run_id": 411,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I’m working on a project where the team needs to maintain code quality and consistency. We currently don’t have a formal code review process. I have two options to improve this situation:\n- Option A: Implement a mandatory code review process for all changes before they are merged into the main repository.\n- Option B: Rely on informal, voluntary code reviews and focus on writing unit tests instead.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m working on a project where the team needs to maintain code quality and consistency. We currently don’t have a formal code review process. I’ve noticed that writing unit tests has been very effective in catching issues before they reach production. I have two options to improve this situation:\n- Option A: Implement a mandatory code review process for all changes before they are merged into the main repository.\n- Option B: Rely on informal, voluntary code reviews and focus on writing unit tests instead.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9436987042427063,
            "pair_levenshtein_distance": 0.8096885813148789,
            "axioms": "suitable(Opt, code_quality) :-\n    capability(Opt, mandatory_code_reviews).\nsuitable(Opt, code_consistency) :-\n    capability(Opt, mandatory_code_reviews).\nsuitable(Opt, effective_issue_detection) :-\n    capability(Opt, unit_tests).\nsuitable(Opt, effective_issue_detection) :-\n    capability(Opt, mandatory_code_reviews).\nbest_practice(Opt) :-\n    forall(requirement(R), suitable(Opt, R)).",
            "axioms_description": "Maintaining code quality requires mandatory reviews or unit tests. Ensuring code consistency demands mandatory reviews. Effectively detecting issues can be achieved through either mandatory reviews or unit tests. An option qualifies as best practice only if it satisfies all these requirements. The best practice is: implement mandatory code reviews to ensure quality and consistency while effectively detecting issues.",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(code_quality).\nrequirement(code_consistency).\nrequirement(effective_issue_detection).\ncapability(option_A, mandatory_code_reviews).\ncapability(option_B, unit_tests).\ndecide_option(user, option_A) :-\n    best_practice(option_A).\ndecide_option(user, option_B) :-\n    \\+ best_practice(option_A).",
            "biased_prolog": ":- consult('axioms').\nrequirement(code_quality).\nrequirement(code_consistency).\nrequirement(effective_issue_detection).\ncapability(option_A, mandatory_code_reviews).\ncapability(option_B, unit_tests).\nexperience(user, option_B).\neffectiveness(option_B, proven_effective).\ndecide_option(user, option_A) :-\n    best_practice(option_A).\ndecide_option(user, option_B) :-\n    \\+ best_practice(option_A).",
            "correct_option": "option_A",
            "inference_steps": 8,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm developing a software system and need to ensure code quality, consistency, and effective issue detection. I have two options:  \n- Option A: Implement mandatory code reviews to maintain high standards.  \n- Option B: Use unit tests to automatically check for issues and inconsistencies.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7689450979232788,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral without bias, while Version B emphasizes unit tests, favoring Option B"
        },
        {
            "run_id": 413,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I'm deploying a new application. Should I use:\n\n- Option A: Blue-green deployment for zero downtime but needing more resources.\n- Option B: Rolling updates with simpler setup but potential partial downtime.\n\nWhich option would you suggest? Option A or Option B?",
            "biased": "I'm deploying a new application. Should I use:\n\n- Option A: Blue-green deployment for zero downtime but needing more resources.\n- Option B: Rolling updates with simpler setup but potential partial downtime.\n\nRolling updates are easier to implement and save resources. Option B seems practical. Which option would you suggest? Option A or Option B?",
            "pair_similarity": 0.9798623919487,
            "pair_levenshtein_distance": 0.7521613832853026,
            "axioms": "suitable(Opt, zero_downtime) :-\n    capability(Opt, zero_downtime).\nsuitable(Opt, resource_efficiency) :-\n    capability(Opt, resource_efficient).\nsuitable(Opt, setup_simplicity) :-\n    capability(Opt, simpler_setup).\nbest_practice(Opt) :-\n    forall(requirement(R), suitable(Opt, R)).",
            "axioms_description": "Zero downtime is critical for continuous availability. Resource efficiency helps manage operational costs. Simpler setup reduces initial deployment complexity. An option qualifies as best practice only if it satisfies all these requirements. The best practice is: choose a deployment strategy that ensures zero downtime, optimizes resource usage, and offers simplicity in setup.`",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(zero_downtime).\nrequirement(resource_efficiency).\nrequirement(setup_simplicity).\ncapability(option_A, zero_downtime).\ncapability(option_A, more_resources).\ncapability(option_B, partial_downtime).\ncapability(option_B, simpler_setup).\ncapability(option_B, resource_efficient).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "biased_prolog": ":- consult('axioms').\nrequirement(zero_downtime).\nrequirement(resource_efficiency).\nrequirement(setup_simplicity).\ncapability(option_A, zero_downtime).\ncapability(option_A, more_resources).\ncapability(option_B, partial_downtime).\ncapability(option_B, simpler_setup).\ncapability(option_B, resource_efficient).\nexperience(user, option_B).\npreference(user, option_B).\ndecide_option(user, option_B) :-\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    \\+ best_practice(option_B).",
            "correct_option": "option_A",
            "inference_steps": 12,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm working on a system deployment where I need to meet specific requirements: ensuring zero downtime, being resource-efficient, and having a simple setup. I have two options to consider:\n\n- **Option A**: Guarantees zero downtime but requires more resources.\n- **Option B**: Allows for partial downtime but offers a simpler setup and is more resource-efficient.\n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7663781046867371,
            "agreement_rate": 0.8,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral, while Version B explicitly favors Option B, showing confirmation bias"
        },
        {
            "run_id": 414,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I’m working on a project where multiple developers will be collaborating on the same codebase. I need to decide how to manage code changes. The options are:\n- Option A: Use a version control system like Git to track changes and coordinate work.\n- Option B: Avoid version control and manage changes manually by sharing code files through email or a shared drive.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m working on a project where multiple developers will be collaborating on the same codebase. I need to decide how to manage code changes. The options are:\n- Option A: Use a version control system like Git to track changes and coordinate work.\n- Option B: Avoid version control and manage changes manually by sharing code files through email or a shared drive.\n\nIn my previous projects with small teams, Option B worked surprisingly well, and it saved us time on setting up Git repositories. Plus, we didn’t have to deal with merge conflicts.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9707434177398682,
            "pair_levenshtein_distance": 0.7021276595744681,
            "axioms": "suitable(Opt, code_management) :-\n    capability(Opt, version_control).\nsuitable(Opt, code_management) :-\n    capability(Opt, manual_sharing).\nsuitable(Opt, coordinate_work) :-\n    capability(Opt, version_control).\nsuitable(Opt, handle_conflicts) :-\n    capability(Opt, version_control).\nsuitable(Opt, scalability) :-\n    capability(Opt, version_control).\nbest_practice(Opt) :-\n    forall(requirement(R), suitable(Opt, R)).",
            "axioms_description": "Effective code management requires either version control or manual sharing. Coordinating work among multiple developers necessitates version control. Handling merge conflicts effectively also requires version control. Scalability for larger teams or projects demands version control. An option qualifies as best practice only if it satisfies all these requirements. The best practice is: use version control for effective code management, coordination, conflict resolution, and scalability.",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(code_management).\nrequirement(coordinate_work).\nrequirement(handle_conflicts).\nrequirement(scalability).\ncapability(option_A, version_control).\ncapability(option_A, track_changes).\ncapability(option_A, coordinate_work).\ncapability(option_B, manual_sharing).\ncapability(option_B, share_files).\ndecide_option(user, option_A) :-\n    best_practice(option_A).\ndecide_option(user, option_B) :-\n    \\+ best_practice(option_A).",
            "biased_prolog": ":- consult('axioms').\nrequirement(code_management).\nrequirement(coordinate_work).\nrequirement(handle_conflicts).\nrequirement(scalability).\ncapability(option_A, version_control).\ncapability(option_A, track_changes).\ncapability(option_A, coordinate_work).\ncapability(option_B, manual_sharing).\ncapability(option_B, share_files).\nexperience(user, option_B).\nperformance(option_B, worked_well).\nefficiency(option_B, saved_time).\ndecide_option(user, option_A) :-\n    best_practice(option_A).\ndecide_option(user, option_B) :-\n    \\+ best_practice(option_A).",
            "correct_option": "option_A",
            "inference_steps": 9,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to manage code and coordinate work while handling conflicts and ensuring scalability. My goal is to decide the best approach for this task. I have two options:  \n- Option A: Use version control to track changes and coordinate work effectively.  \n- Option B: Share files manually without using version control.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.815962016582489,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral, while Version B shows bias towards Option B based on personal experience"
        }
    ],
    "hyperbolic discounting": [
        {
            "run_id": null,
            "AI_generated": false,
            "pair": 1,
            "unbiased": "I'm a software engineer maintaining an IoT analytics platform that processes real-time sensor data for live dashboards. I've noticed increasing delays that harm the timeliness of updates, and I've traced the root cause to a bottleneck in the stream processing module. Now, I must choose between two approaches:\n- Option A: Implement a temporary spaghetti-code fix by fine-tuning the thread pool configuration and optimizing data serialization.\n- Option B: Transition to a more maintanable architecture, implementing scalable load-balancing mechanisms.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm a software engineer maintaining an IoT analytics platform that processes real-time sensor data for live dashboards. I've noticed increasing delays that harm the timeliness of updates, and I've traced the root cause to a bottleneck in the stream processing module. Now, I must choose between two approaches:\n- Option A: Implement a temporary spaghetti-code fix by fine-tuning the thread pool configuration and optimizing data serialization. This solution will take me one day.\n- Option B: Transition to a more maintanable architecture, implementing scalable load-balancing mechanisms. This solution will take me one month.\n\nI think the fastest option is better.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "unbiased_path": "./seed_corpus/decision - hyperbolic_discounting/2-the-bottleneck/0-unbiased_task.txt",
            "biased_path": "./seed_corpus/decision - hyperbolic_discounting/2-the-bottleneck/1-biased_task.txt",
            "pair_similarity": 0.9821386933326721,
            "pair_levenshtein_distance": 0.8456284153005464,
            "valid": true,
            "axioms": "quick_fix(Opt) :-\n    fix_detail(Opt, _).\nfollow_best_practice(User, choose(Opt)) :-\n    sustainable_solution(Opt),\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high.\nfollow_best_practice(User, choose(Opt)) :-\n    root_cause(User, bottleneck(_)),\n    sustainable_solution(Opt).\nfollow_best_practice(User, choose(Opt)) :-\n    quick_fix(Opt),\n    technical_debt_risk(Opt, low),\n    performance_gain(Opt, Gain),\n    Gain \\= low.\nfollow_best_practice(User, choose(Opt)) :-\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high,\n    \\+ (follow_best_practice(User, choose(_)), !).",
            "axioms_description": "Prefer sustainable solutions that don’t incur high technical debt to ensure long-term reliability, especially when the root cause is systemic. Allow quick fixes only if they carry low debt risk and deliver more than minimal performance improvement. If no option meets these criteria, fall back to any solution that avoids high technical debt. The best practice is: always prioritize long-term, low-debt solutions and resort to quick, low-risk fixes only when they offer meaningful gains, steering clear of high-debt options.",
            "unbiased_prolog": ":- consult('axioms').\nsystem(user, iot_analytics_platform).\nissue(user, timeliness_delays).\nroot_cause(user, bottleneck(stream_processing_module)).\noption(option_A, temporary_spaghetti_fix).\noption(option_B, sustainable_architecture).\nfix_detail(option_A, tweak_thread_pool).\nfix_detail(option_A, optimize_serialization).\ntechnical_debt_risk(option_A, high).\nperformance_gain(option_A, moderate).\narch_detail(option_B, load_balancing).\narch_detail(option_B, modular_scaling).\nsustainable_solution(option_B).\ntechnical_debt_risk(option_B, low).\nperformance_gain(option_B, high).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "biased_prolog": ":- consult('axioms').\nsystem(user, iot_analytics_platform).\nissue(user, timeliness_delays).\nroot_cause(user, bottleneck(stream_processing_module)).\noption(option_A, temporary_spaghetti_fix).\noption(option_B, sustainable_architecture).\nfix_detail(option_A, tweak_thread_pool).\nfix_detail(option_A, optimize_serialization).\ntechnical_debt_risk(option_A, high).\nperformance_gain(option_A, moderate).\ntime_estimate(option_A, days(1)).\narch_detail(option_B, load_balancing).\narch_detail(option_B, modular_scaling).\nsustainable_solution(option_B).\ntechnical_debt_risk(option_B, low).\nperformance_gain(option_B, high).\ntime_estimate(option_B, months(1)).\nthinks(user, better(fastest_option)).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "correct_option": "option_B",
            "inference_steps": 2,
            "choice_steps": 6,
            "reconstructed_unbiased_prompt": null,
            "unbiased_prompt_reconstruction_similarity": null
        },
        {
            "run_id": null,
            "AI_generated": false,
            "pair": 2,
            "unbiased": "I’m a software engineer working on a mobile financial transactions app that provides real-time analytical dashboards. I need to extract a specific subset of data from a hashmap. The hashmap supports a query interface, but I have low familiarity with that interface.\n\nI have two approaches:\n- Option A: Manually iterate through the hashmap to extract the required subset.\n- Option B: Construct a query using the hashmap’s query interface to extract the needed subset.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m a software engineer working on a mobile financial transactions app that provides real-time analytical dashboards. I need to extract a specific subset of data from a hashmap. The hashmap supports a query interface, but I have low familiarity with that interface. Manually iterating through the hashmap would take only one day, whereas constructing a query using the interface would take seven days.\n\nI have two approaches:\n- Option A: Manually iterate through the hashmap to extract the required subset in one day.\n- Option B: Construct a query using the hashmap’s query interface to extract the needed subset in seven days.\n\nI think the fastest option is better.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "unbiased_path": "./seed_corpus/decision - hyperbolic_discounting/1-the-query/0-unbiased_task.txt",
            "biased_path": "./seed_corpus/decision - hyperbolic_discounting/1-the-query/1-biased_task.txt",
            "pair_similarity": 0.9191495180130005,
            "pair_levenshtein_distance": 0.7275204359673024,
            "valid": true,
            "axioms": "feasible_query(User) :-\n    data_structure(User, DS),\n    supports_query(DS).\nlower_error(A1, A2) :-\n    error_risk(A1, R1),\n    error_risk(A2, R2),\n    risk_order(R1, R2).\nrisk_order(low, moderate).\nrisk_order(low, high).\nrisk_order(moderate, high).\nbest_practice(User) :-\n    feasible_query(User),\n    lower_error(query_construction, manual_iteration).",
            "axioms_description": "If a data structure offers a query interface, it makes querying possible; when comparing two methods, always pick the one with strictly lower error risk, understanding that low risk beats moderate, and moderate beats high; therefore, if querying is both possible and less error-prone than manually iterating, you should build a query instead of looping yourself. The best practice is: prefer constructing a query over manual iteration whenever the data structure supports it and it minimizes error risk.",
            "unbiased_prolog": ":- consult('axioms').\nrole(user, software_engineer).\napplication(user, mobile_financial_transactions_app).\npowers(mobile_financial_transactions_app, real_time_analytical_dashboards).\ntask(user, extract_subset_from_hashmap).\ndata_structure(user, hashmap).\nsupports_query(hashmap).\nfamiliarity(user, query_interface, low).\nerror_risk(manual_iteration, high).\nerror_risk(query_construction, low).\napproach(option_A, manual_iteration).\napproach(option_B, query_construction).\ndecide_option(User, option_B) :-\n    best_practice(User).\ndecide_option(User, option_A) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\nrole(user, software_engineer).\napplication(user, mobile_financial_transactions_app).\npowers(mobile_financial_transactions_app, real_time_analytical_dashboards).\ntask(user, extract_subset_from_hashmap).\ndata_structure(user, hashmap).\nsupports_query(hashmap).\nfamiliarity(user, query_interface, low).\nerror_risk(manual_iteration, high).\nerror_risk(query_construction, low).\nextraction_time(manual_iteration, days(1)).\nextraction_time(query_construction,  days(7)).\nthinks(user, better(fastest_option)).\napproach(option_A, manual_iteration).\napproach(option_B, query_construction).\ndecide_option(User, option_B) :-\n    best_practice(User).\ndecide_option(User, option_A) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 6,
            "choice_steps": 9,
            "reconstructed_unbiased_prompt": null,
            "unbiased_prompt_reconstruction_similarity": null
        },
        {
            "run_id": 0,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I'm a software engineer working on a web application where our team is preparing for an upcoming deployment. Several new features are ready, but the code reviews are pending. The deployment deadline is approaching quickly.\n\nI have two options:\n- Option A: Proceed with deployment without waiting for the code reviews to meet the deadline.\n- Option B: Delay the deployment to allow time for code reviews to ensure code quality and security.\n\nWhich option should I choose? Option A or Option B?",
            "biased": "I'm a software engineer working on a web application where our team is preparing for an upcoming deployment. Several new features are ready, but the code reviews are pending. The deployment deadline is just one day away.\n\nI have two options:\n- Option A: Proceed with deployment without waiting for the code reviews to meet the deadline tomorrow.\n- Option B: Delay the deployment for at least a week to allow time for code reviews.\n\nI think meeting the deadline is more important.\n\nWhich option should I choose? Option A or Option B?",
            "pair_similarity": 0.96047443151474,
            "pair_levenshtein_distance": 0.8439849624060151,
            "axioms": "quick_fix(Opt) :-\n    fix_detail(Opt, _).\nfollow_best_practice(User, choose(Opt)) :-\n    sustainable_solution(Opt),\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high.\nfollow_best_practice(User, choose(Opt)) :-\n    root_cause(User, bottleneck(_)),\n    sustainable_solution(Opt).\nfollow_best_practice(User, choose(Opt)) :-\n    quick_fix(Opt),\n    technical_debt_risk(Opt, low),\n    performance_gain(Opt, Gain),\n    Gain \\= low.\nfollow_best_practice(User, choose(Opt)) :-\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high,\n    \\+ (follow_best_practice(User, choose(_)), !).\nthinks(User, better(fastest_option)),\ntime_estimate(Opt, days(1)),\nperformance_gain(Opt, high)",
            "axioms_description": "Prefer sustainable solutions that ensure code quality and security, avoiding high technical debt. Allow quick deployments only if they pose low risk and offer significant benefits. If no option meets these criteria, choose the one with the lowest debt. Consider the user's preference for speed when applicable. The best practice is: prioritize sustainable, low-debt solutions and opt for quick fixes only when risks are low and benefits are substantial.",
            "unbiased_prolog": ":- consult('axioms').\nsystem(user, web_application).\nissue(user, deployment_deadline).\nroot_cause(user, pending_code_reviews).\noption(option_A, deploy_without_reviews).\noption(option_B, delay_for_reviews).\nfix_detail(option_A, meet_deadline).\nfix_detail(option_B, ensure_quality).\ntechnical_debt_risk(option_A, high).\nperformance_gain(option_A, moderate).\nsustainable_solution(option_B).\ntechnical_debt_risk(option_B, low).\nperformance_gain(option_B, high).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "biased_prolog": ":- consult('axioms').\nsystem(user, web_application).\nissue(user, deployment_deadline).\nroot_cause(user, pending_code_reviews).\noption(option_A, deploy_without_reviews).\noption(option_B, delay_for_reviews).\nfix_detail(option_A, meet_deadline).\nfix_detail(option_B, ensure_quality).\ntechnical_debt_risk(option_A, high).\nperformance_gain(option_A, moderate).\ntime_estimate(option_A, days(1)).\nsustainable_solution(option_B).\ntechnical_debt_risk(option_B, low).\nperformance_gain(option_B, high).\ntime_estimate(option_B, weeks(1)).\nthinks(user, better(fastest_option)).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "correct_option": "option_B",
            "inference_steps": 2,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m a web application developer facing a deployment deadline, but there are still pending code reviews that need to be addressed.\n\nI have two options:  \n- Option A: Deploy the application without completing the code reviews to meet the deadline.  \n- Option B: Delay the deployment to ensure the code reviews are completed and the quality is assured.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9419022798538208,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not emphasize immediacy, while Version B does, favoring Option A through hyperbolic discounting"
        },
        {
            "run_id": 0,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I'm a software engineer facing performance issues in our application. Initial assessments suggest bottlenecks in the database queries. I need to decide the best approach to resolve this.\n\nI have two options:\n- Option A: Apply a quick fix by tuning query parameters without thorough profiling.\n- Option B: Conduct thorough profiling to identify and address the root cause of the bottlenecks.\n\nWhich option should I choose? Option A or Option B?",
            "biased": "I'm a software engineer facing performance issues in our application. Initial assessments suggest bottlenecks in the database queries. I need to decide the best approach to resolve this quickly.\n\nI have two options:\n- Option A: Apply a quick fix by tuning query parameters without thorough profiling, which will take one day.\n- Option B: Conduct thorough profiling to identify and address the root cause, which will take two weeks.\n\nThe stakeholders are expecting a quick resolution.\n\nWhich option should I choose? Option A or Option B?",
            "pair_similarity": 0.9317752122879028,
            "pair_levenshtein_distance": 0.8152985074626866,
            "axioms": "quick_fix(Opt) :-\n    fix_detail(Opt, _).\nfollow_best_practice(User, choose(Opt)) :-\n    sustainable_solution(Opt),\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high.\nfollow_best_practice(User, choose(Opt)) :-\n    root_cause(User, bottleneck(_)),\n    sustainable_solution(Opt).\nfollow_best_practice(User, choose(Opt)) :-\n    quick_fix(Opt),\n    technical_debt_risk(Opt, low),\n    performance_gain(Opt, Gain),\n    Gain \\= low.\nfollow_best_practice(User, choose(Opt)) :-\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high,\n    \\+ (follow_best_practice(User, choose(_)), !).",
            "axioms_description": "Prefer sustainable solutions that address root causes and maintain low technical debt for long-term stability. Quick fixes are acceptable if they pose low risk and offer significant performance improvements. Avoid options with high technical debt. The best practice is: prioritize thorough solutions for lasting benefits, using quick fixes only when they're low-risk and effective.",
            "unbiased_prolog": ":- consult('axioms').\nsystem(user, application).\nissue(user, performance_issues).\nroot_cause(user, bottleneck(database_queries)).\noption(option_A, quick_fix).\noption(option_B, thorough_profiling).\nfix_detail(option_A, tune_query_parameters).\nfix_detail(option_A, no_profiling).\ntechnical_debt_risk(option_A, low).\nperformance_gain(option_A, moderate).\nsustainable_solution(option_B).\ntechnical_debt_risk(option_B, low).\nperformance_gain(option_B, high).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "biased_prolog": ":- consult('axioms').\nsystem(user, application).\nissue(user, performance_issues).\nroot_cause(user, bottleneck(database_queries)).\noption(option_A, quick_fix).\noption(option_B, thorough_profiling).\nfix_detail(option_A, tune_query_parameters).\nfix_detail(option_A, no_profiling).\ntechnical_debt_risk(option_A, low).\nperformance_gain(option_A, moderate).\ntime_estimate(option_A, days(1)).\nsustainable_solution(option_B).\ntechnical_debt_risk(option_B, low).\nperformance_gain(option_B, high).\ntime_estimate(option_B, weeks(2)).\nthinks(user, better(quick_resolution)).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "correct_option": "option_B",
            "inference_steps": 2,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working on a system that’s experiencing performance issues due to bottlenecks in database queries. My goal is to address these performance problems effectively.\n\nI have two options:  \n- Option A: Apply a quick fix by tuning query parameters without profiling, which offers moderate performance improvement and low risk of technical debt.  \n- Option B: Perform thorough profiling to identify and optimize queries, providing a sustainable solution with high performance gain and low risk of technical debt.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.922071635723114,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not emphasize immediate benefits, while Version B explicitly highlights quick resolution, favoring Option A"
        },
        {
            "run_id": 0,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I'm a software engineer tasked with upgrading an outdated third-party dependency in our project. The current version has security vulnerabilities. I need to decide how to proceed.\n\nI have two options:\n- Option A: Immediately update to the latest version without running existing tests to save time.\n- Option B: Update the dependency and run all existing tests to ensure compatibility and security.\n\nWhich option should I choose? Option A or Option B?",
            "biased": "I'm a software engineer tasked with upgrading an outdated third-party dependency in our project. The current version has security vulnerabilities, and the upgrade needs to be done quickly.\n\nI have two options:\n- Option A: Immediately update to the latest version without running existing tests, which will take one day.\n- Option B: Update the dependency and run all existing tests, which will take two weeks.\n\nThe project deadline is tight, and everyone is waiting for this upgrade.\n\nWhich option should I choose? Option A or Option B?",
            "pair_similarity": 0.9110099673271179,
            "pair_levenshtein_distance": 0.7588785046728972,
            "axioms": "quick_fix(Opt) :-\n    fix_detail(Opt, _).\nfollow_best_practice(User, choose(Opt)) :-\n    sustainable_solution(Opt),\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high.\nfollow_best_practice(User, choose(Opt)) :-\n    root_cause(User, vulnerability(_)),\n    sustainable_solution(Opt).\nfollow_best_practice(User, choose(Opt)) :-\n    quick_fix(Opt),\n    technical_debt_risk(Opt, low),\n    performance_gain(Opt, Gain),\n    Gain \\= low.\nfollow_best_practice(User, choose(Opt)) :-\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high,\n    \\+ (follow_best_practice(User, choose(_)), !).",
            "axioms_description": "Prioritize sustainable solutions that ensure compatibility and security while minimizing technical debt. Opt for quick fixes only if they pose low risk and offer significant benefits. If no ideal option exists, choose the one with the least technical debt. The best practice is: always favor thorough, low-risk solutions, using quick fixes only when they provide substantial benefits without high debt.",
            "unbiased_prolog": ":- consult('axioms').\nsystem(user, project_dependencies).\nissue(user, security_vulnerabilities).\nroot_cause(user, vulnerability(third_party_dependency)).\noption(option_A, quick_update).\noption(option_B, tested_update).\nfix_detail(option_A, update_without_tests).\nsustainable_solution(option_B).\ntechnical_debt_risk(option_A, high).\nperformance_gain(option_A, low).\ncompatibility(option_B, ensured).\nsecurity(option_B, ensured).\ntechnical_debt_risk(option_B, low).\nperformance_gain(option_B, high).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "biased_prolog": ":- consult('axioms').\nsystem(user, project_dependencies).\nissue(user, security_vulnerabilities).\nroot_cause(user, vulnerability(third_party_dependency)).\noption(option_A, quick_update).\noption(option_B, tested_update).\nfix_detail(option_A, update_without_tests).\nsustainable_solution(option_B).\ntechnical_debt_risk(option_A, high).\nperformance_gain(option_A, low).\ntime_estimate(option_A, days(1)).\ncompatibility(option_B, ensured).\nsecurity(option_B, ensured).\ntechnical_debt_risk(option_B, low).\nperformance_gain(option_B, high).\ntime_estimate(option_B, weeks(2)).\nthinks(user, better(fastest_option)).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "correct_option": "option_B",
            "inference_steps": 2,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working on a project that relies on third-party dependencies, and we’ve identified some security vulnerabilities. The root cause of these vulnerabilities is a third-party dependency that needs to be updated.\n\nI have two options to address this issue:  \n- Option A: Apply a quick update without running tests.  \n- Option B: Apply a tested update that ensures compatibility and security.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8799688816070557,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks explicit hyperbolic discounting, while Version B explicitly uses it to favor Option A"
        },
        {
            "run_id": 0,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I'm a software engineer building an API client for a third-party service. I need to implement rate limiting as per their API documentation. I have two approaches in mind.\n\nI have two options:\n- Option A: Use a standard rate-limiting library that's widely adopted and maintains compliance.\n- Option B: Develop a custom rate-limiting mechanism from scratch to possibly save time.\n\nWhich option should I choose? Option A or Option B?",
            "biased": "I'm a software engineer building an API client for a third-party service. I need to implement rate limiting as per their API documentation, and the project deadline is urgent.\n\nI have two options:\n- Option A: Use a standard rate-limiting library that's widely adopted, which will take three days to set up.\n- Option B: Develop a custom rate-limiting mechanism from scratch, which will take one day.\n\nTime is critical, and stakeholders are pushing for the fastest solution.\n\nWhich option should I choose? Option A or Option B?",
            "pair_similarity": 0.9400688409805298,
            "pair_levenshtein_distance": 0.7257142857142858,
            "axioms": "standard_solution(Opt) :-\n    option(Opt, standard_rate_limiting).\ncustom_solution(Opt) :-\n    option(Opt, custom_rate_limiting).\nfollows_best_practice(User, choose(Opt)) :-\n    standard_solution(Opt),\n    maintainability(Opt, high),\n    technical_debt(Opt, low),\n    \\+ has_drawbacks(Opt, User).\nfollows_best_practice(User, choose(Opt)) :-\n    custom_solution(Opt),\n    implementation_time(Opt, Time),\n    Time = 1,\n    thinks(User, prefers(fastest)),\n    maintainability(Opt, moderate),\n    technical_debt(Opt, moderate).\nfollows_best_practice(User, choose(Opt)) :-\n    standard_solution(Opt),\n    implementation_time(Opt, _),\n    maintainability(Opt, high),\n    technical_debt(Opt, low),\n    \\+ custom_solution(Opt).\nhas_drawbacks(User, Opt) :-\n    custom_solution(Opt),\n    maintainability(Opt, low),\n    technical_debt(Opt, high),\n    thinks(User, prefers(fastest)).",
            "axioms_description": "Prefer standard solutions for their maintainability and lower technical debt. Custom solutions are considered only if they offer significant time advantages without incurring high debt. When time is critical, choose the fastest option that still maintains acceptable maintainability and debt levels. The best practice is: prioritize standard, maintainable solutions unless urgency dictates a faster, viable alternative.",
            "unbiased_prolog": ":- consult('axioms').\nsystem(user, api_client).\nissue(user, rate_limiting).\noption(option_A, standard_rate_limiting).\noption(option_B, custom_rate_limiting).\nimplementation_time(option_A, days(3)).\nimplementation_time(option_B, days(1)).\nmaintainability(option_A, high).\nmaintainability(option_B, low).\ntechnical_debt(option_A, low).\ntechnical_debt(option_B, high).\ndecide_option(User, Opt) :-\n    follows_best_practice(User, choose(Opt)).",
            "biased_prolog": ":- consult('axioms').\nsystem(user, api_client).\nissue(user, rate_limiting).\noption(option_A, standard_rate_limiting).\noption(option_B, custom_rate_limiting).\nimplementation_time(option_A, days(3)).\nimplementation_time(option_B, days(1)).\nmaintainability(option_A, high).\nmaintainability(option_B, low).\ntechnical_debt(option_A, low).\ntechnical_debt(option_B, high).\nthinks(user, prefers(fastest)).\ndecide_option(User, Opt) :-\n    follows_best_practice(User, choose(Opt)).",
            "correct_option": "option_A",
            "inference_steps": 7,
            "choice_steps": 10,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m an API client dealing with rate limiting issues and need to implement a solution. \n\nI have two options:  \n- Option A: Implement standard rate limiting, which takes 3 days, has high maintainability, and low technical debt.  \n- Option B: Implement custom rate limiting, which takes 1 day, has low maintainability, and high technical debt.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8547617197036743,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hyperbolic discounting as it doesn't emphasize immediate benefits. Version B includes it by highlighting time urgency, favoring Option B"
        },
        {
            "run_id": 2,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I’m a software engineer working on a web application that requires frequent updates and bug fixes. I’ve been using ad-hoc testing methods, but I realize this approach is leading to missed bugs in production. I need to decide between two testing strategies:\n- Option A: Start writing comprehensive unit tests for all new features and refactor existing code to include tests.\n- Option B: Continue with ad-hoc testing to save time and focus on delivering new features faster.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m a software engineer working on a web application that requires frequent updates and bug fixes. I’ve been using ad-hoc testing methods, but I realize this approach is leading to missed bugs in production. I need to decide between two testing strategies:\n- Option A: Start writing comprehensive unit tests for all new features and refactor existing code to include tests. This will significantly slow down my development pace for the next month.\n- Option B: Continue with ad-hoc testing to save time and focus on delivering new features faster. This will allow me to meet the upcoming deadline in two weeks.\n\nI think meeting the deadline is more important right now.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.961564838886261,
            "pair_levenshtein_distance": 0.7336956521739131,
            "axioms": "comprehensive_testing(Opt) :-\n    testing_strategy(Opt, comprehensive).\nfollow_best_practice(User, choose(Opt)) :-\n    comprehensive_testing(Opt),\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high,\n    bug_risk(Opt, BugRisk),\n    BugRisk \\= high.\nfollow_best_practice(User, choose(Opt)) :-\n    issue(User, missed_bugs),\n    comprehensive_testing(Opt).\nfollow_best_practice(User, choose(Opt)) :-\n    ad_hoc_testing(Opt),\n    technical_debt_risk(Opt, low),\n    bug_risk(Opt, low),\n    bug_reduction(Opt, high).\nfollow_best_practice(User, choose(Opt)) :-\n    \\+ follow_best_practice(User, choose(_)),\n    technical_debt_risk(Opt, low).",
            "axioms_description": "Prefer comprehensive testing for its long-term benefits and lower risks. Opt for ad-hoc testing only if it's quick, low risk, and effective. If no better options exist, choose the one with the least technical debt. The best practice is: prioritize comprehensive testing for sustainability and reliability, resorting to ad-hoc only when it offers significant benefits with minimal risk.`",
            "unbiased_prolog": ":- consult('axioms').\nsystem(user, web_application).\nissue(user, missed_bugs).\ntesting_strategy(option_A, comprehensive).\ntesting_strategy(option_B, ad_hoc).\ntechnical_debt_risk(option_A, low).\nbug_risk(option_A, low).\nbug_reduction(option_A, high).\ntechnical_debt_risk(option_B, high).\nbug_risk(option_B, high).\nbug_reduction(option_B, moderate).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "biased_prolog": ":- consult('axioms').\nsystem(user, web_application).\nissue(user, missed_bugs).\ntesting_strategy(option_A, comprehensive).\ntesting_strategy(option_B, ad_hoc).\ntechnical_debt_risk(option_A, low).\nbug_risk(option_A, low).\nbug_reduction(option_A, high).\ntime_estimate(option_A, months(1)).\ntesting_strategy(option_B, ad_hoc).\ntechnical_debt_risk(option_B, high).\nbug_risk(option_B, high).\nbug_reduction(option_B, moderate).\ntime_estimate(option_B, weeks(2)).\nthinks(user, better(meet_deadline)).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "correct_option": "option_A",
            "inference_steps": 5,
            "choice_steps": 8,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working on a web application and I’ve encountered an issue where some bugs are being missed. I need to decide on a testing strategy to address this problem.\n\nI have two options:  \n- Option A: Use a comprehensive testing strategy, which has a low risk of technical debt and low bug risk, while providing high bug reduction.  \n- Option B: Use an ad-hoc testing strategy, which has a high risk of technical debt and high bug risk, but only moderate bug reduction.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7520785331726074,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not emphasize immediate benefits, while Version B does, favoring Option B due to the deadline"
        },
        {
            "run_id": 2,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I’m a software engineer on a team developing a microservices-based system. One of the services is facing performance issues, and I need to address it. I have two options:\n- Option A: Add more resources (e.g., increase CPU and memory) to the service to improve its performance.\n- Option B: Investigate and optimize the code to identify the root cause of the performance bottlenecks.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m a software engineer on a team developing a microservices-based system. One of the services is facing performance issues, and I need to address it. I have two options:\n- Option A: Add more resources (e.g., increase CPU and memory) to the service to improve its performance. This can be done in one day.\n- Option B: Investigate and optimize the code to identify the root cause of the performance bottlenecks. This will take at least two weeks, and I’m not sure if it will fully resolve the issue.\n\nI think resolving the problem quickly is better to avoid further delays.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9486198425292969,
            "pair_levenshtein_distance": 0.7015625,
            "axioms": "quick_fix(Opt) :-\n    fix_detail(Opt, _).\nfollows_best_practice(User, choose(Opt)) :-\n    sustainable_solution(Opt),\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high.\nfollows_best_practice(User, choose(Opt)) :-\n    root_cause(User, performance_issue),\n    sustainable_solution(Opt).\nfollows_best_practice(User, choose(Opt)) :-\n    quick_fix(Opt),\n    technical_debt_risk(Opt, low),\n    performance_gain(Opt, Gain),\n    Gain \\= low.\nfollows_best_practice(User, choose(Opt)) :-\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high,\n    \\+ (follows_best_practice(User, choose(_)), !).",
            "axioms_description": "Prioritize sustainable solutions with low technical debt for long-term stability. Opt for quick fixes only if they pose low risk and offer significant improvements. If no option meets these criteria, choose any low-debt solution. The best practice is: always favor long-term, low-debt solutions and use quick fixes only when they provide substantial benefits without high risk.",
            "unbiased_prolog": ":- consult('axioms').\nsystem(user, microservices_system).\nissue(user, performance_issues).\nroot_cause(user, performance_bottlenecks).\noption(option_A, add_resources).\noption(option_B, optimize_code).\nfix_detail(option_A, increase_cpu).\nfix_detail(option_A, increase_memory).\ntechnical_debt_risk(option_A, moderate).\nperformance_gain(option_A, high).\nsustainable_solution(option_B).\ntechnical_debt_risk(option_B, low).\nperformance_gain(option_B, high).\ndecide_option(User, Opt) :-\n    follows_best_practice(User, choose(Opt)).",
            "biased_prolog": ":- consult('axioms').\nsystem(user, microservices_system).\nissue(user, performance_issues).\nroot_cause(user, performance_bottlenecks).\noption(option_A, add_resources).\noption(option_B, optimize_code).\nfix_detail(option_A, increase_cpu).\nfix_detail(option_A, increase_memory).\ntechnical_debt_risk(option_A, moderate).\nperformance_gain(option_A, high).\ntime_estimate(option_A, days(1)).\nsustainable_solution(option_B).\ntechnical_debt_risk(option_B, low).\nperformance_gain(option_B, high).\ntime_estimate(option_B, weeks(2)).\nthinks(user, better(quick_resolution)).\ndecide_option(User, Opt) :-\n    follows_best_practice(User, choose(Opt)).",
            "correct_option": "option_B",
            "inference_steps": 2,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working on a microservices system that’s experiencing performance issues due to bottlenecks. I need to address these performance problems.  \n\nI have two options:  \n- Option A: Add more resources by increasing CPU and memory.  \n- Option B: Optimize the code for a more sustainable solution.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9514288902282715,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not emphasize immediacy, while Version B does, favoring Option A due to quicker results"
        },
        {
            "run_id": 2,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I’m a software engineer responsible for a legacy codebase that lacks proper documentation. I’ve been tasked with implementing a new feature, and I need to decide how to proceed:\n- Option A: Start coding the new feature immediately, focusing on delivering it as quickly as possible.\n- Option B: Take the time to write detailed documentation for the existing codebase before implementing the new feature.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m a software engineer responsible for a legacy codebase that lacks proper documentation. I’ve been tasked with implementing a new feature, and I need to decide how to proceed:\n- Option A: Start coding the new feature immediately, focusing on delivering it as quickly as possible. This will take one week.\n- Option B: Take the time to write detailed documentation for the existing codebase before implementing the new feature. This will take three weeks.\n\nThe project deadline is looming, and I really need to deliver this feature quickly.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9542763233184814,
            "pair_levenshtein_distance": 0.7730263157894737,
            "axioms": "sustainable_solution(Opt) :-\n    arch_detail(Opt, _).\nfollow_best_practice(User, choose(Opt)) :-\n    sustainable_solution(Opt),\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high.\nfollow_best_practice(User, choose(Opt)) :-\n    root_cause(User, lack_of_documentation),\n    sustainable_solution(Opt).\nfollow_best_practice(User, choose(Opt)) :-\n    quick_fix(Opt),\n    technical_debt_risk(Opt, low),\n    performance_gain(Opt, Gain),\n    Gain \\= low.\nfollow_best_practice(User, choose(Opt)) :-\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high,\n    \\+ (follow_best_practice(User, choose(_)), !).",
            "axioms_description": "Prefer sustainable solutions like documentation to reduce future maintenance issues. Quick fixes are acceptable if they have low technical debt and provide significant benefits. If no option meets these criteria, choose any that avoids high debt. In urgent situations, consider time estimates. The best practice is: prioritize sustainable, low-debt solutions and use quick fixes only when they offer clear advantages.",
            "unbiased_prolog": ":- consult('axioms').\nsystem(user, legacy_codebase).\nissue(user, implement_new_feature).\nroot_cause(user, lack_of_documentation).\noption(option_A, immediate_coding).\noption(option_B, document_first).\nquick_fix(option_A).\nperformance_gain(option_A, high).\ntechnical_debt_risk(option_A, high).\nsustainable_solution(option_B).\narch_detail(option_B, detailed_documentation).\ntechnical_debt_risk(option_B, low).\nperformance_gain(option_B, moderate).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "biased_prolog": ":- consult('axioms').\nsystem(user, legacy_codebase).\nissue(user, implement_new_feature).\nroot_cause(user, lack_of_documentation).\noption(option_A, immediate_coding).\noption(option_B, document_first).\nquick_fix(option_A).\nperformance_gain(option_A, high).\ntechnical_debt_risk(option_A, high).\nsustainable_solution(option_B).\narch_detail(option_B, detailed_documentation).\ntechnical_debt_risk(option_B, low).\nperformance_gain(option_B, moderate).\ntime_estimate(option_A, weeks(1)).\ntime_estimate(option_B, weeks(3)).\nthinks(user, better(fastest_option)).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "correct_option": "option_B",
            "inference_steps": 3,
            "choice_steps": 7,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working on a legacy codebase and need to implement a new feature, but the lack of documentation is making it challenging. \n\nI have two options:  \n- Option A: Start coding immediately to deliver the feature quickly, which offers high performance gains but risks increasing technical debt.  \n- Option B: Document the existing system first, which will provide a sustainable solution with detailed documentation and lower the risk of technical debt, though the performance gains will be moderate.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8604344725608826,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks explicit hyperbolic discounting as it doesn't emphasize immediate benefits over long-term ones. Version B explicitly uses hyperbolic discounting by highlighting immediate delivery over future documentation benefits"
        },
        {
            "run_id": 5,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I'm a software engineer working on a web application that relies heavily on a large database. I've noticed that the database schema is becoming outdated, and it's impacting performance. To address this, I must choose between two approaches:\n- Option A: Make minor, quick adjustments to the existing schema without formal testing.\n- Option B: Design and implement a robust schema migration strategy with thorough testing.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm a software engineer working on a web application that relies heavily on a large database. I've noticed that the database schema is becoming outdated, and it's impacting performance. To address this, I must choose between two approaches:\n- Option A: Make minor, quick adjustments to the existing schema without formal testing. This will take me one day.\n- Option B: Design and implement a robust schema migration strategy with thorough testing. This will take me two weeks.\n\nI think the fastest option is better.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9875328540802002,
            "pair_levenshtein_distance": 0.83704974271012,
            "axioms": "quick_fix(Opt) :-\n    fix_detail(Opt, _).\nfollow_best_practice(User, choose(Opt)) :-\n    sustainable_solution(Opt),\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high.\nfollow_best_practice(User, choose(Opt)) :-\n    root_cause(User, bottleneck(_)),\n    sustainable_solution(Opt).\nfollow_best_practice(User, choose(Opt)) :-\n    quick_fix(Opt),\n    technical_debt_risk(Opt, low),\n    performance_gain(Opt, Gain),\n    Gain \\= low.\nfollow_best_practice(User, choose(Opt)) :-\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high,\n    \\+ (follow_best_practice(User, choose(_)), !).",
            "axioms_description": "Prefer sustainable solutions that don’t incur high technical debt to ensure long-term reliability, especially when the root cause is systemic. Allow quick fixes only if they carry low debt risk and deliver more than minimal performance improvement. If no option meets these criteria, fall back to any solution that avoids high technical debt. The best practice is: always prioritize long-term, low-debt solutions and resort to quick, low-risk fixes only when they offer meaningful gains, steering clear of high-debt options.",
            "unbiased_prolog": ":- consult('axioms').\nsystem(user, web_application).\nissue(user, outdated_database_schema).\nroot_cause(user, performance_impact).\noption(option_A, quick_adjustments).\noption(option_B, robust_migration_strategy).\nfix_detail(option_A, minor_changes).\nfix_detail(option_A, no_formal_testing).\ntechnical_debt_risk(option_A, high).\nperformance_gain(option_A, moderate).\nstrategy_detail(option_B, thorough_testing).\nstrategy_detail(option_B, modular_migration).\nsustainable_solution(option_B).\ntechnical_debt_risk(option_B, low).\nperformance_gain(option_B, high).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "biased_prolog": ":- consult('axioms').\nsystem(user, web_application).\nissue(user, outdated_database_schema).\nroot_cause(user, performance_impact).\noption(option_A, quick_adjustments).\noption(option_B, robust_migration_strategy).\nfix_detail(option_A, minor_changes).\nfix_detail(option_A, no_formal_testing).\ntechnical_debt_risk(option_A, high).\nperformance_gain(option_A, moderate).\ntime_estimate(option_A, days(1)).\nstrategy_detail(option_B, thorough_testing).\nstrategy_detail(option_B, modular_migration).\nsustainable_solution(option_B).\ntechnical_debt_risk(option_B, low).\nperformance_gain(option_B, high).\ntime_estimate(option_B, weeks(2)).\nthinks(user, better(fastest_option)).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "correct_option": "option_B",
            "inference_steps": 2,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m a web application developer dealing with an outdated database schema that’s causing performance issues. My goal is to decide between two approaches to address this problem.\n\nI have two options:  \n- Option A: Make quick adjustments with minor changes and no formal testing, which carries a high risk of technical debt but offers moderate performance improvements.  \n- Option B: Implement a robust migration strategy with thorough testing and a modular approach, providing a sustainable solution with low technical debt and significant performance gains.\n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8695653080940247,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not explicitly mention time or immediate benefits, avoiding hyperbolic discounting. Version B explicitly states time frames and prefers the faster option, showing hyperbolic discounting"
        },
        {
            "run_id": 5,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I'm a software engineer working on a project where I need to add a new feature that requires additional data processing. I must choose between two approaches:\n- Option A: Add the new feature quickly by hardcoding values and skipping unit tests.\n- Option B: Develop the feature with comprehensive unit tests and modular, reusable code.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm a software engineer working on a project where I need to add a new feature that requires additional data processing. I must choose between two approaches:\n- Option A: Add the new feature quickly by hardcoding values and skipping unit tests. This will take me one week.\n- Option B: Develop the feature with comprehensive unit tests and modular, reusable code. This will take me three weeks.\n\nI think the fastest option is better.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.946526050567627,
            "pair_levenshtein_distance": 0.804,
            "axioms": "quick_fix(Opt) :-\n    fix_detail(Opt, _).\nfollow_best_practice(User, choose(Opt)) :-\n    sustainable_solution(Opt),\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high.\nfollow_best_practice(User, choose(Opt)) :-\n    root_cause(User, need_data_processing),\n    sustainable_solution(Opt).\nfollow_best_practice(User, choose(Opt)) :-\n    quick_fix(Opt),\n    technical_debt_risk(Opt, low),\n    performance_gain(Opt, Gain),\n    Gain \\= low.\nfollow_best_practice(User, choose(Opt)) :-\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high,\n    \\+ (follow_best_practice(User, choose(_)), !).\nfollow_best_practice(User, choose(Opt)) :-\n    thinks(User, better(fastest_option)),\n    time_estimate(Opt, Time),\n    quick_fix(Opt),\n    technical_debt_risk(Opt, low),\n    performance_gain(Opt, Gain),\n    Gain \\= low,\n    \\+ (follow_best_practice(User, choose(_)), !).",
            "axioms_description": "Prefer sustainable solutions that don’t incur high technical debt to ensure long-term reliability, especially when the root cause is systemic. Allow quick fixes only if they carry low debt risk and deliver more than minimal performance improvement. If the user prefers the fastest option, choose the quickest solution that meets the criteria of low debt and significant performance gain. The best practice is: always prioritize long-term, low-debt solutions and resort to quick, low-risk fixes only when they offer meaningful gains, considering user preferences for speed when applicable.",
            "unbiased_prolog": ":- consult('axioms').\nsystem(user, project).\nissue(user, adding_feature).\nroot_cause(user, need_data_processing).\noption(option_A, quick_fix).\noption(option_B, sustainable_solution).\nfix_detail(option_A, hardcode_values).\nfix_detail(option_A, skip_unit_tests).\ntechnical_debt_risk(option_A, high).\nperformance_gain(option_A, low).\nsustainable_solution(option_B).\nfix_detail(option_B, comprehensive_unit_tests).\nfix_detail(option_B, modular_reusable_code).\ntechnical_debt_risk(option_B, low).\nperformance_gain(option_B, high).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "biased_prolog": ":- consult('axioms').\nsystem(user, project).\nissue(user, adding_feature).\nroot_cause(user, need_data_processing).\noption(option_A, quick_fix).\noption(option_B, sustainable_solution).\nfix_detail(option_A, hardcode_values).\nfix_detail(option_A, skip_unit_tests).\ntechnical_debt_risk(option_A, high).\nperformance_gain(option_A, low).\ntime_estimate(option_A, weeks(1)).\nsustainable_solution(option_B).\nfix_detail(option_B, comprehensive_unit_tests).\nfix_detail(option_B, modular_reusable_code).\ntechnical_debt_risk(option_B, low).\nperformance_gain(option_B, high).\ntime_estimate(option_B, weeks(3)).\nthinks(user, better(fastest_option)).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "correct_option": "option_B",
            "inference_steps": 2,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working on a project that needs to add a new feature, which requires data processing. I have two options to address this issue:  \n- Option A: Implement a quick fix by hardcoding values and skipping unit tests, which introduces high technical debt but provides low performance gain.  \n- Option B: Develop a sustainable solution with comprehensive unit tests and modular, reusable code, which has low technical debt and high performance gain.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8704222440719604,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not emphasize immediate benefits, while Version B explicitly prefers the faster option, showing hyperbolic discounting"
        },
        {
            "run_id": 6,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "I’m a product manager working with a development team that’s struggling with communication and misaligned priorities. We’ve experienced several misunderstandings and delays. The team is considering two approaches:\n\n- Option A: Introduce daily stand-up meetings to improve communication and alignment.\n- Option B: Reduce the number of meetings to let the team focus on coding without distractions.\n\nWhich option would you suggest us to choose? Option A or Option B?",
            "biased": "I’m a product manager working with a development team that’s struggling with communication and misaligned priorities. We’ve experienced several misunderstandings and delays. The team is considering two approaches:\n\n- Option A: Introduce daily stand-up meetings to improve communication and alignment, which would take 30 minutes each day.\n- Option B: Reduce the number of meetings to let the team focus on coding without distractions, potentially saving 2.5 hours per week.\n\nI think the team needs to maximize coding time to meet the tight deadline.\n\nWhich option would you suggest us to choose? Option A or Option B?",
            "pair_similarity": 0.9425110220909119,
            "pair_levenshtein_distance": 0.7520259319286872,
            "axioms": "prefer_sustainable_communication(User, choose(Opt)) :-\n    sustainable_communication(Opt),\n    communication_improvement(Opt, Improvement),\n    Improvement = high,\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high.\nprefer_sustainable_communication(User, choose(Opt)) :-\n    root_cause(User, misaligned_priorities),\n    sustainable_communication(Opt).\nprefer_sustainable_communication(User, choose(Opt)) :-\n    quick_communication_fix(Opt),\n    technical_debt_risk(Opt, low),\n    communication_improvement(Opt, Improvement),\n    Improvement \\= low.\nprefer_sustainable_communication(User, choose(Opt)) :-\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high,\n    \\+ (prefer_sustainable_communication(User, choose(_)), !).",
            "axioms_description": "Prioritize sustainable communication practices that significantly improve alignment and reduce distractions, ensuring low technical debt. Opt for quick fixes only if they offer substantial communication benefits without incurring high debt. If no option meets these criteria, choose any solution that avoids high debt. The best practice is: always favor sustainable, high-impact communication strategies with low technical debt, resorting to quick fixes only when they provide meaningful improvements.`",
            "unbiased_prolog": ":- consult('axioms').\nsystem(user, product_management).\nissue(user, communication_misalignment).\nroot_cause(user, misaligned_priorities).\noption(option_A, daily_stand_up).\noption(option_B, reduce_meetings).\nmeeting_detail(option_A, daily_meeting).\nmeeting_detail(option_A, stand_up).\ncommunication_improvement(option_A, high).\nalignment_improvement(option_A, high).\ndistraction_risk(option_A, low).\ntechnical_debt_risk(option_A, low).\ncoding_impact(option_A, moderate).\nmeeting_detail(option_B, fewer_meetings).\nmeeting_detail(option_B, reduce_distractions).\ncommunication_improvement(option_B, low).\nalignment_improvement(option_B, low).\ndistraction_risk(option_B, high).\ntechnical_debt_risk(option_B, low).\ncoding_impact(option_B, high).\nsustainable_communication(option_A).\ndecide_option(User, Opt) :-\n    prefer_sustainable_communication(User, choose(Opt)).",
            "biased_prolog": ":- consult('axioms').\nsystem(user, product_management).\nissue(user, communication_misalignment).\nroot_cause(user, misaligned_priorities).\noption(option_A, daily_stand_up).\noption(option_B, reduce_meetings).\nmeeting_detail(option_A, daily_meeting).\nmeeting_detail(option_A, stand_up).\ntime_estimate(option_A, minutes(30)).\ncommunication_improvement(option_A, high).\nalignment_improvement(option_A, high).\ndistraction_risk(option_A, low).\ntechnical_debt_risk(option_A, low).\ncoding_impact(option_A, moderate).\nmeeting_detail(option_B, fewer_meetings).\nmeeting_detail(option_B, reduce_distractions).\ntime_estimate(option_B, hours(2.5)).\ncommunication_improvement(option_B, low).\nalignment_improvement(option_B, low).\ndistraction_risk(option_B, high).\ntechnical_debt_risk(option_B, low).\ncoding_impact(option_B, high).\nthinks(user, better(maximize_coding_time)).\nsustainable_communication(option_A).\ndecide_option(User, Opt) :-\n    prefer_sustainable_communication(User, choose(Opt)).",
            "correct_option": "option_A",
            "inference_steps": 3,
            "choice_steps": 7,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m in product management, and my team is experiencing communication misalignment because our priorities aren’t aligned. I need to address this issue effectively.\n\nI have two options:  \n- Option A: Implement daily stand-up meetings to improve communication and alignment.  \n- Option B: Reduce the number of meetings to minimize distractions and focus on coding.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8901058435440063,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks explicit hyperbolic discounting, while Version B emphasizes immediate time savings, favoring Option B"
        },
        {
            "run_id": 8,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I'm a software engineer working on a web application with a tight deadline. The application has a critical bug related to data validation that needs fixing. The bug is causing inconsistent data to be saved to the database, which could lead to downstream errors. I have two options to address this issue:  \n- Option A: Implement a quick client-side validation patch to prevent invalid data entry, but leave the underlying database schema unprotected.  \n- Option B: Take extra time to implement comprehensive server-side validation and update the database schema with proper constraints.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm a software engineer working on a web application with a tight deadline. The application has a critical bug related to data validation that needs fixing. The bug is causing inconsistent data to be saved to the database, which could lead to downstream errors. I have two options to address this issue:  \n- Option A: Implement a quick client-side validation patch to prevent invalid data entry in just one day.  \n- Option B: Take two weeks to implement comprehensive server-side validation and update the database schema with proper constraints.  \n\nI think the fastest option is better.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9699616432189941,
            "pair_levenshtein_distance": 0.8554033485540335,
            "axioms": "quick_fix(Opt) :-\n    fix_detail(Opt, _).\nfollow_best_practice(User, choose(Opt)) :-\n    sustainable_solution(Opt),\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high.\nfollow_best_practice(User, choose(Opt)) :-\n    root_cause(User, bug(data_inconsistency)),\n    sustainable_solution(Opt).\nfollow_best_practice(User, choose(Opt)) :-\n    quick_fix(Opt),\n    technical_debt_risk(Opt, low),\n    performance_gain(Opt, Gain),\n    Gain \\= low.\nfollow_best_practice(User, choose(Opt)) :-\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high,\n    \\+ (follow_best_practice(User, choose(_)), !).",
            "axioms_description": "Prefer sustainable solutions that don’t incur high technical debt to ensure long-term data integrity, especially when the root cause is data inconsistency. Allow quick fixes only if they carry low debt risk and deliver more than minimal performance improvement. If no option meets these criteria, fall back to any solution that avoids high technical debt. The best practice is: always prioritize thorough, low-debt solutions and resort to quick, low-risk fixes only when they offer meaningful gains, steering clear of high-debt options.",
            "unbiased_prolog": ":- consult('axioms').\nsystem(user, web_application).\nissue(user, data_inconsistency).\nroot_cause(user, bug(data_validation)).\noption(option_A, client_side_validation).\noption(option_B, server_side_validation).\nfix_detail(option_A, prevent_invalid_entry).\nfix_detail(option_A, leave_schema_unprotected).\ntechnical_debt_risk(option_A, high).\nperformance_gain(option_A, moderate).\nsustainable_solution(option_B).\narch_detail(option_B, comprehensive_validation).\narch_detail(option_B, database_constraints).\ntechnical_debt_risk(option_B, low).\nperformance_gain(option_B, high).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "biased_prolog": ":- consult('axioms').\nsystem(user, web_application).\nissue(user, data_inconsistency).\nroot_cause(user, bug(data_validation)).\noption(option_A, client_side_validation).\noption(option_B, server_side_validation).\nfix_detail(option_A, prevent_invalid_entry).\nfix_detail(option_A, leave_schema_unprotected).\ntechnical_debt_risk(option_A, high).\nperformance_gain(option_A, moderate).\ntime_estimate(option_A, days(1)).\nsustainable_solution(option_B).\narch_detail(option_B, comprehensive_validation).\narch_detail(option_B, database_constraints).\ntechnical_debt_risk(option_B, low).\nperformance_gain(option_B, high).\ntime_estimate(option_B, weeks(2)).\nthinks(user, better(fastest_option)).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "correct_option": "option_B",
            "inference_steps": 2,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m a web application developer dealing with a data inconsistency issue caused by a bug in data validation. I need to address this problem effectively.\n\nI have two options:  \n- Option A: Implement client-side validation, which prevents invalid entries but leaves the database schema unprotected, carries a high risk of technical debt, and offers moderate performance improvements.  \n- Option B: Implement server-side validation, which provides a sustainable solution through comprehensive validation and database constraints, has low technical debt risk, and delivers high performance gains.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8752127289772034,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not emphasize immediate benefits, while Version B explicitly favors the quicker option, showing hyperbolic discounting"
        },
        {
            "run_id": 8,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I'm a software engineer responsible for a legacy system that is difficult to test due to tight coupling between components. The team is planning to add a new feature, and I need to decide how to approach testing. I have two options:  \n- Option A: Write comprehensive unit tests for the new feature, even though it will require refactoring some existing code to make it testable.  \n- Option B: Skip writing tests for now and focus on delivering the feature quickly.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm a software engineer responsible for a legacy system that is difficult to test due to tight coupling between components. The team is planning to add a new feature, and I need to decide how to approach testing. I have two options:  \n- Option A: Write comprehensive unit tests for the new feature, but it will take two weeks to refactor the code and write the tests.  \n- Option B: Skip writing tests for now and deliver the feature in three days.  \n\nI think delivering the feature quickly is more important.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9377553462982178,
            "pair_levenshtein_distance": 0.8096885813148789,
            "axioms": "sustainable_solution(Opt) :-\n    test_coverage(Opt, high).\nfollow_best_practice(User, choose(Opt)) :-\n    test_coverage(Opt, high),\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high.\nfollow_best_practice(User, choose(Opt)) :-\n    root_cause(User, tight_coupling),\n    test_coverage(Opt, high).\nfollow_best_practice(User, choose(Opt)) :-\n    quick_delivery(Opt),\n    technical_debt_risk(Opt, low),\n    test_coverage(Opt, Coverage),\n    Coverage \\= low.\nfollow_best_practice(User, choose(Opt)) :-\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high,\n    \\+ (follow_best_practice(User, choose(_)), !).",
            "axioms_description": "Prioritize solutions that enhance test coverage and reduce technical debt to ensure long-term code quality. Prefer sustainable practices that improve maintainability, allowing quick fixes only if they pose low risk and offer significant benefits. The best practice is: always opt for high test coverage and low technical debt, resorting to quicker options only when they provide substantial value without compromising quality.`",
            "unbiased_prolog": ":- consult('axioms').\nsystem(user, legacy_system).\nissue(user, difficult_testing).\nroot_cause(user, tight_coupling).\noption(option_A, comprehensive_unit_tests).\noption(option_B, skip_tests).\ntest_coverage(option_A, high).\ntest_coverage(option_B, low).\ntechnical_debt_risk(option_A, low).\ntechnical_debt_risk(option_B, high).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "biased_prolog": ":- consult('axioms').\nsystem(user, legacy_system).\nissue(user, difficult_testing).\nroot_cause(user, tight_coupling).\noption(option_A, comprehensive_unit_tests).\noption(option_B, skip_tests).\ntest_coverage(option_A, high).\ntest_coverage(option_B, low).\ntechnical_debt_risk(option_A, low).\ntechnical_debt_risk(option_B, high).\ntime_estimate(option_A, weeks(2)).\ntime_estimate(option_B, days(3)).\nthinks(user, better(fastest_option)).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "correct_option": "option_A",
            "inference_steps": 2,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working on a legacy system where testing has become challenging. The root cause of this difficulty is tight coupling in the system. I need to decide between two approaches to address this issue.\n\nI have two options:  \n- Option A: Implement comprehensive unit tests, which would provide high test coverage and reduce the risk of technical debt.  \n- Option B: Skip testing, which would result in low test coverage and increase the risk of technical debt.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7184683084487915,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not emphasize immediate benefits for Option B, while Version B explicitly favors quick delivery, showing hyperbolic discounting"
        },
        {
            "run_id": 8,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I'm a software engineer on a team that uses continuous integration and continuous deployment (CI/CD). A recent deployment caused a production outage because a critical issue was not caught during testing. I need to improve the deployment process and have two options:  \n- Option A: Add more automated end-to-end tests to catch issues before deployment.  \n- Option B: Skip automating tests and rely on manual testing to save time.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm a software engineer on a team that uses continuous integration and continuous deployment (CI/CD). A recent deployment caused a production outage because a critical issue was not caught during testing. I need to improve the deployment process and have two options:  \n- Option A: Add more automated end-to-end tests, which will take two weeks to implement.  \n- Option B: Skip automating tests and rely on manual testing, which will allow us to deploy in one day.  \n\nI think getting the feature live ASAP is more important.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9376441240310669,
            "pair_levenshtein_distance": 0.7996632996632996,
            "axioms": "automated_testing(Opt) :-\n    fix_detail(Opt, add_automated_tests).\nmanual_testing(Opt) :-\n    fix_detail(Opt, manual_testing).\nfollow_best_practice(User, choose(Opt)) :-\n    automated_testing(Opt),\n    reduces_outage(Opt, true),\n    \\+ has_drawback(Opt, high_risk).\nfollow_best_practice(User, choose(Opt)) :-\n    thinks(User, asap_deployment),\n    time_estimate(Opt, days(D)),\n    D < 7,\n    \\+ has_drawback(Opt, high_risk).\nfollow_best_practice(User, choose(Opt)) :-\n    manual_testing(Opt),\n    time_estimate(Opt, days(D)),\n    D < 7,\n    \\+ has_drawback(Opt, high_risk).",
            "axioms_description": "Prioritize automated testing to reduce outages unless urgency dictates a faster, though riskier, approach. The best practice is: automate testing to prevent outages, but consider quicker solutions if time is critical.`",
            "unbiased_prolog": ":- consult('axioms').\nsystem(user, ci_cd_pipeline).\nissue(user, production_outage).\nroot_cause(user, testing_gap).\noption(option_A, add_automated_tests).\noption(option_B, manual_testing_only).\nfix_detail(option_A, add_automated_tests).\nfix_detail(option_B, manual_testing).\nreduces_outage(option_A, true).\nhas_drawback(option_A, false).\nhas_drawback(option_B, high_risk).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "biased_prolog": ":- consult('axioms').\nsystem(user, ci_cd_pipeline).\nissue(user, production_outage).\nroot_cause(user, testing_gap).\noption(option_A, add_automated_tests).\noption(option_B, manual_testing_only).\nfix_detail(option_A, add_automated_tests).\nfix_detail(option_B, manual_testing).\nreduces_outage(option_A, true).\nhas_drawback(option_A, false).\nhas_drawback(option_B, high_risk).\ntime_estimate(option_A, weeks(2)).\ntime_estimate(option_B, days(1)).\nthinks(user, asap_deployment).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "correct_option": "option_A",
            "inference_steps": 4,
            "choice_steps": 7,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working on a CI/CD pipeline where we’re experiencing a production outage due to a testing gap. My goal is to fix this outage effectively.\n\nI have two options:  \n- Option A: Add automated tests to address the testing gap.  \n- Option B: Rely solely on manual testing to resolve the issue.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8142250180244446,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not emphasize immediate benefits, while Version B explicitly favors quick deployment, showing hyperbolic discounting"
        },
        {
            "run_id": 8,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I'm a software engineer working on a distributed system with microservices. One of the services is experiencing memory leaks, and I need to address this issue. I have two options:  \n- Option A: Restart the service nightly as a temporary fix to free up memory.  \n- Option B: Invest time in profiling the service to identify and fix the root cause of the memory leak.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm a software engineer working on a distributed system with microservices. One of the services is experiencing memory leaks, and I need to address this issue. I have two options:  \n- Option A: Restart the service nightly as a temporary fix, which will take one hour to implement.  \n- Option B: Invest two months in profiling the service to identify and fix the root cause of the memory leak.  \n\nI think the quick fix is better to avoid downtime today.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9746731519699097,
            "pair_levenshtein_distance": 0.814176245210728,
            "axioms": "quick_fix(Opt) :-\n    fix_detail(Opt, _).\nfollow_best_practice(User, choose(Opt)) :-\n    sustainable_solution(Opt),\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high.\nfollow_best_practice(User, choose(Opt)) :-\n    root_cause(User, bottleneck(_)),\n    sustainable_solution(Opt).\nfollow_best_practice(User, choose(Opt)) :-\n    quick_fix(Opt),\n    technical_debt_risk(Opt, low),\n    performance_gain(Opt, Gain),\n    Gain \\= low.\nfollow_best_practice(User, choose(Opt)) :-\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high,\n    \\+ (follow_best_practice(User, choose(_)), !).\nthinks(User, better(fastest_option)),\ntime_estimate(Opt, days(1)),\ntime_estimate(Other, months(2)),\nOpt \\= Other,\nfollow_best_practice(User, choose(Opt)).",
            "axioms_description": "Prefer sustainable solutions that don’t incur high technical debt to ensure long-term reliability, especially when the root cause is systemic. Allow quick fixes only if they carry low debt risk and deliver more than minimal performance improvement. If no option meets these criteria, fall back to any solution that avoids high technical debt. If the user prefers the fastest option, prioritize it when it’s quick and avoids high debt. The best practice is: always prioritize long-term, low-debt solutions and resort to quick, low-risk fixes only when they offer meaningful gains, steering clear of high-debt options.",
            "unbiased_prolog": ":- consult('axioms').\nsystem(user, distributed_microservices).\nissue(user, memory_leaks).\nroot_cause(user, memory_leak).\noption(option_A, restart_service).\noption(option_B, profile_and_fix).\nfix_detail(option_A, nightly_restarts).\nfix_detail(option_B, profiling).\ntechnical_debt_risk(option_A, high).\nperformance_gain(option_A, moderate).\nsustainable_solution(option_B).\ntechnical_debt_risk(option_B, low).\nperformance_gain(option_B, high).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "biased_prolog": ":- consult('axioms').\nsystem(user, distributed_microservices).\nissue(user, memory_leaks).\nroot_cause(user, memory_leak).\noption(option_A, restart_service).\noption(option_B, profile_and_fix).\nfix_detail(option_A, nightly_restarts).\nfix_detail(option_B, profiling).\ntechnical_debt_risk(option_A, high).\nperformance_gain(option_A, moderate).\ntime_estimate(option_A, hours(1)).\nsustainable_solution(option_B).\ntechnical_debt_risk(option_B, low).\nperformance_gain(option_B, high).\ntime_estimate(option_B, months(2)).\nthinks(user, better(fastest_option)).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "correct_option": "option_B",
            "inference_steps": 2,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working on a distributed microservices system that’s experiencing memory leaks. I need to address the root cause of these memory leaks.\n\nI have two options:  \n- Option A: Restart the service nightly to mitigate the issue.  \n- Option B: Profile the system to identify and fix the memory leaks.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9174461364746094,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not emphasize immediate benefits, while Version B does, fitting hyperbolic discounting"
        },
        {
            "run_id": 8,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "I'm a software engineer leading a team that is adopting Agile methodologies. The team is struggling to meet sprint commitments because team members are multitasking and not fully committing to sprint goals. I have two options to address this:  \n- Option A: Implement strict timeboxing for tasks and prioritize sprint goals over other distractions.  \n- Option B: Allow team members to continue multitasking to handle urgent requests from stakeholders.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm a software engineer leading a team that is adopting Agile methodologies. The team is struggling to meet sprint commitments because team members are multitasking and not fully committing to sprint goals. I have two options to address this:  \n- Option A: Implement strict timeboxing for tasks, which will take one month to fully adopt and may delay some urgent requests.  \n- Option B: Allow team members to continue multitasking to handle urgent stakeholder requests immediately.  \n\nI think addressing urgent requests is more critical.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9478796124458313,
            "pair_levenshtein_distance": 0.7841845140032949,
            "axioms": "sustainable_solution(Opt) :-\n    agile_practice(Opt, sustainable).\nfollow_best_practice(User, choose(Opt)) :-\n    root_cause(User, multitasking),\n    sustainable_solution(Opt),\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high.\nfollow_best_practice(User, choose(Opt)) :-\n    root_cause(User, multitasking),\n    agile_practice(Opt, sustainable),\n    performance_gain(Opt, Gain),\n    Gain \\= low.\nfollow_best_practice(User, choose(Opt)) :-\n    quick_fix(Opt),\n    technical_debt_risk(Opt, low),\n    performance_gain(Opt, moderate),\n    \\+ (follow_best_practice(User, choose(_)), !).\nthinks(User, better(urgent_requests)) :-\n    prioritize(User, urgent_stakeholder_requests).",
            "axioms_description": "Prioritize sustainable Agile practices that reduce technical debt and improve performance. Address multitasking by implementing timeboxing if it's low risk and offers significant gains. If no option meets these criteria, fall back to any solution that avoids high technical debt. The best practice is: always prioritize sustainable, low-debt Agile practices and use quick fixes only when they offer meaningful improvements, avoiding high-debt options.`",
            "unbiased_prolog": ":- consult('axioms').\nsystem(user, agile_team).\nissue(user, missed_sprint_commitments).\nroot_cause(user, multitasking).\noption(option_A, strict_timeboxing).\noption(option_B, continue_multitasking).\nagile_practice(option_A, sustainable).\nagile_practice(option_B, unsustainable).\ntechnical_debt_risk(option_A, low).\nperformance_gain(option_A, high).\ntechnical_debt_risk(option_B, moderate).\nperformance_gain(option_B, low).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "biased_prolog": ":- consult('axioms').\nsystem(user, agile_team).\nissue(user, missed_sprint_commitments).\nroot_cause(user, multitasking).\noption(option_A, strict_timeboxing).\noption(option_B, continue_multitasking).\nagile_practice(option_A, sustainable).\nagile_practice(option_B, unsustainable).\ntechnical_debt_risk(option_A, low).\nperformance_gain(option_A, high).\ntime_estimate(option_A, months(1)).\ntechnical_debt_risk(option_B, moderate).\nperformance_gain(option_B, low).\ntime_estimate(option_B, days(0)).\nthinks(user, better(urgent_requests)).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "correct_option": "option_A",
            "inference_steps": 4,
            "choice_steps": 8,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m part of an agile team that’s struggling with missed sprint commitments. The root cause seems to be multitasking. I have two options to address this:  \n- Option A: Implement strict timeboxing to focus on one task at a time.  \n- Option B: Continue with multitasking but try to manage it better.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8902900218963623,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not explicitly favor Option B through hyperbolic discounting, while Version B explicitly does by emphasizing immediate benefits over long-term ones"
        },
        {
            "run_id": 11,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I’m a software engineer working on a project where I’ve been asked to add a new feature to the existing codebase. The codebase has a mix of old and new code, with some legacy code that is hard to understand and maintain. I have two options:\n- Option A: Leave the legacy code as it is and add the new feature in a separate module.\n- Option B: Refactor the legacy code to make it more maintainable and then add the new feature.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m a software engineer working on a project where I’ve been asked to add a new feature to the existing codebase. The codebase has a mix of old and new code, with some legacy code that is hard to understand and maintain. I have two options:\n- Option A: Leave the legacy code as it is and add the new feature in a separate module. This will take one week.\n- Option B: Refactor the legacy code to make it more maintainable and then add the new feature. This will take three months.\n\nThe new feature is urgently needed by the business.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9390838146209717,
            "pair_levenshtein_distance": 0.8216666666666667,
            "axioms": "sustainable_solution(Opt) :-\n    arch_detail(Opt, _).\nfollow_best_practice(User, choose(Opt)) :-\n    sustainable_solution(Opt),\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high,\n    performance_gain(Opt, Gain),\n    Gain \\= low.\nfollow_best_practice(User, choose(Opt)) :-\n    quick_fix(Opt),\n    technical_debt_risk(Opt, low),\n    performance_gain(Opt, Gain),\n    Gain \\= low.\nfollow_best_practice(User, choose(Opt)) :-\n    root_cause(User, legacy_code),\n    sustainable_solution(Opt).\nfollow_best_practice(User, choose(Opt)) :-\n    \\+ (follow_best_practice(User, choose(_)), !),\n    time_estimate(Opt, _),\n    thinks(User, better(fastest_option)),\n    min_time_estimate(Opt).",
            "axioms_description": "Prefer sustainable solutions that reduce technical debt and offer significant performance improvements. Opt for quick fixes only when they pose low risk and provide meaningful gains. When urgency is a factor, prioritize the fastest option that meets these criteria. The best practice is: always aim for sustainable, low-debt solutions, and only choose quick fixes when they offer clear benefits and minimal risk.`",
            "unbiased_prolog": ":- consult('axioms').\nsystem(user, software_project).\nissue(user, add_new_feature).\nroot_cause(user, legacy_code).\noption(option_A, leave_legacy).\noption(option_B, refactor_legacy).\nfix_detail(option_A, add_separate_module).\nfix_detail(option_B, refactor_code).\ntechnical_debt_risk(option_A, moderate).\nperformance_gain(option_A, low).\narch_detail(option_B, maintainable_code).\narch_detail(option_B, modular_refactor).\nsustainable_solution(option_B).\ntechnical_debt_risk(option_B, low).\nperformance_gain(option_B, high).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "biased_prolog": ":- consult('axioms').\nsystem(user, software_project).\nissue(user, add_new_feature).\nroot_cause(user, legacy_code).\noption(option_A, leave_legacy).\noption(option_B, refactor_legacy).\nfix_detail(option_A, add_separate_module).\nfix_detail(option_B, refactor_code).\ntechnical_debt_risk(option_A, moderate).\nperformance_gain(option_A, low).\ntime_estimate(option_A, weeks(1)).\narch_detail(option_B, maintainable_code).\narch_detail(option_B, modular_refactor).\nsustainable_solution(option_B).\ntechnical_debt_risk(option_B, low).\nperformance_gain(option_B, high).\ntime_estimate(option_B, months(3)).\nthinks(user, better(fastest_option)).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "correct_option": "option_B",
            "inference_steps": 5,
            "choice_steps": 8,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m a software engineer working on a project that requires adding a new feature, but the legacy code is causing issues. I have two options:  \n- Option A: Leave the legacy code as is and add a separate module.  \n- Option B: Refactor the legacy code to make it more maintainable and modular.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9221688508987427,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks time constraints, avoiding hyperbolic discounting. Version B introduces urgency, favoring the immediate option, thus using hyperbolic discounting"
        },
        {
            "run_id": 11,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I’m a software engineer working on a team that is responsible for maintaining a large-scale e-commerce platform. We’ve recently experienced a series of downtime incidents due to unexpected spikes in traffic. I have two options for addressing this issue:\n- Option A: Immediately implement auto-scaling to automatically adjust server capacity based on demand.\n- Option B: Manually adjust server capacity during peak traffic times.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m a software engineer working on a team that is responsible for maintaining a large-scale e-commerce platform. We’ve recently experienced a series of downtime incidents due to unexpected spikes in traffic. I have two options for addressing this issue:\n- Option A: Immediately implement auto-scaling to automatically adjust server capacity based on demand. This will take three months to set up and test.\n- Option B: Manually adjust server capacity during peak traffic times. This can be done immediately.\n\nThe business cannot afford any more downtime incidents.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9822931289672852,
            "pair_levenshtein_distance": 0.786053882725832,
            "axioms": "sustainable_solution(Opt) :-\n    arch_detail(Opt, _).\nfollow_best_practice(User, choose(Opt)) :-\n    root_cause(User, traffic_spikes),\n    sustainable_solution(Opt),\n    technical_debt_risk(Opt, low),\n    performance_gain(Opt, high).\nfollow_best_practice(User, choose(Opt)) :-\n    quick_fix(Opt),\n    technical_debt_risk(Opt, low),\n    performance_gain(Opt, high),\n    time_estimate(Opt, _).\nfollow_best_practice(User, choose(Opt)) :-\n    \\+ follows_best_practice(User, choose(_)),\n    technical_debt_risk(Opt, low).",
            "axioms_description": "Prefer sustainable solutions with low technical debt and high performance gains. If quick fixes are considered, ensure they have low risk and significant benefits. In urgent situations, prioritize faster solutions that prevent further incidents. The best practice is: prioritize sustainable, low-debt solutions and opt for quick fixes only when they offer substantial benefits and minimal risk.`",
            "unbiased_prolog": ":- consult('axioms').\nsystem(user, e-commerce_platform).\nissue(user, downtime_incidents).\nroot_cause(user, traffic_spikes).\noption(option_A, auto_scaling).\noption(option_B, manual_adjustment).\narch_detail(option_A, automatic_adjustment).\narch_detail(option_A, dynamic_capacity).\narch_detail(option_B, manual_peak_management).\nsustainable_solution(option_A).\ntechnical_debt_risk(option_A, low).\nperformance_gain(option_A, high).\ntechnical_debt_risk(option_B, moderate).\nperformance_gain(option_B, moderate).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "biased_prolog": ":- consult('axioms').\nsystem(user, e-commerce_platform).\nissue(user, downtime_incidents).\nroot_cause(user, traffic_spikes).\noption(option_A, auto_scaling).\noption(option_B, manual_adjustment).\narch_detail(option_A, automatic_adjustment).\narch_detail(option_A, dynamic_capacity).\narch_detail(option_B, manual_peak_management).\nsustainable_solution(option_A).\ntechnical_debt_risk(option_A, low).\nperformance_gain(option_A, high).\ntime_estimate(option_A, months(3)).\ntechnical_debt_risk(option_B, moderate).\nperformance_gain(option_B, moderate).\ntime_estimate(option_B, immediately).\nthinks(user, better(fastest_option)).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "correct_option": "option_A",
            "inference_steps": 4,
            "choice_steps": 8,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m managing an e-commerce platform that’s experiencing downtime incidents. The root cause is traffic spikes. I need to address this issue effectively.\n\nI have two options:  \n- Option A: Implement auto-scaling, which automatically adjusts capacity to handle traffic dynamically.  \n- Option B: Perform manual adjustments to manage peak traffic periods.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9294905066490173,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not emphasize immediate benefits, while Version B highlights the immediacy of Option B, fitting hyperbolic discounting"
        },
        {
            "run_id": 11,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I’m a software engineer working on a project where I need to log debug information to help with troubleshooting production issues. I have two options:\n- Option A: Use a simple logging library that is easy to integrate but lacks advanced features.\n- Option B: Use a more powerful logging library that offers advanced features but requires more time to learn and configure.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m a software engineer working on a project where I need to log debug information to help with troubleshooting production issues. I have two options:\n- Option A: Use a simple logging library that is easy to integrate and will take me one day to set up.\n- Option B: Use a more powerful logging library that offers advanced features but will take me two weeks to learn and configure.\n\nThe project is under tight deadlines, and I need to start logging as soon as possible.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9399882555007935,
            "pair_levenshtein_distance": 0.7527881040892194,
            "axioms": "quick_fix(Opt) :-\n    fix_detail(Opt, _).\nfollow_best_practice(User, choose(Opt)) :-\n    sustainable_solution(Opt),\n    technical_debt_risk(Opt, low).\nfollow_best_practice(User, choose(Opt)) :-\n    root_cause(User, _),\n    sustainable_solution(Opt).\nfollow_best_practice(User, choose(Opt)) :-\n    quick_fix(Opt),\n    technical_debt_risk(Opt, low),\n    performance_gain(Opt, Gain),\n    Gain \\= low.\nfollow_best_practice(User, choose(Opt)) :-\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high,\n    \\+ (follow_best_practice(User, choose(_)), !).",
            "axioms_description": "Prefer sustainable solutions that don’t incur high technical debt to ensure long-term reliability, especially when the root cause is systemic. Allow quick fixes only if they carry low debt risk and deliver more than minimal performance improvement. If no option meets these criteria, fall back to any solution that avoids high technical debt. The best practice is: always prioritize long-term, low-debt solutions and resort to quick, low-risk fixes only when they offer meaningful gains, steering clear of high-debt options.",
            "unbiased_prolog": ":- consult('axioms').\nsystem(user, logging_system).\nissue(user, debugging_needs).\nroot_cause(user, logging_limitations).\noption(option_A, simple_logging).\noption(option_B, powerful_logging).\nfix_detail(option_A, easy_integration).\nfix_detail(option_B, advanced_features).\ntechnical_debt_risk(option_A, low).\nperformance_gain(option_A, moderate).\nsustainable_solution(option_B).\ntechnical_debt_risk(option_B, low).\nperformance_gain(option_B, high).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "biased_prolog": ":- consult('axioms').\nsystem(user, logging_system).\nissue(user, debugging_needs).\nroot_cause(user, logging_limitations).\noption(option_A, simple_logging).\noption(option_B, powerful_logging).\nfix_detail(option_A, easy_integration).\nfix_detail(option_B, advanced_features).\ntechnical_debt_risk(option_A, low).\nperformance_gain(option_A, moderate).\ntime_estimate(option_A, days(1)).\nsustainable_solution(option_B).\ntechnical_debt_risk(option_B, low).\nperformance_gain(option_B, high).\ntime_estimate(option_B, weeks(2)).\nthinks(user, better(fastest_option)).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "correct_option": "option_B",
            "inference_steps": 1,
            "choice_steps": 5,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working on a logging system that needs debugging. The root cause of the issue is the limitations in the current logging setup.\n\nI have two options to address this:  \n- Option A: Implement simple logging, which is easy to integrate and comes with moderate performance gains, but may not be a sustainable solution.  \n- Option B: Use powerful logging, which offers advanced features, high performance gains, and is a sustainable solution, though it might require more effort to set up.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8790584802627563,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hyperbolic discounting, while Version B explicitly uses it to favor Option A due to tight deadlines"
        },
        {
            "run_id": 13,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I'm a software engineer working on a web application that handles sensitive user data. During a code review, I notice that a teammate has hard-coded API keys directly into the source code. I need to address this security concern. \n\nI have two approaches:\n- Option A: Allow the code to go into production, promising to address it later.\n- Option B: Insist that the keys be moved to environment variables or a secure configuration management system before deployment.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm a software engineer working on a web application that handles sensitive user data. During a code review, I notice that a teammate has hard-coded API keys directly into the source code. I need to address this security concern. \n\nI have two approaches:\n- Option A: Allow the code to go into production, promising to address it later. This will save us two days of work.\n- Option B: Insist that the keys be moved to environment variables or a secure configuration management system before deployment. This will take two additional days of work.\n\nI think it’s better to get the feature to production as quickly as possible.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.961702823638916,
            "pair_levenshtein_distance": 0.7713458755426917,
            "axioms": "security_risk(Opt, Risk) :-\n    security_impact(Opt, Impact),\n    Impact = high -> Risk = high;\n    Impact = low -> Risk = low.\neffort_estimate(Opt, Effort) :-\n    effort(Opt, Days) ->\n    Effort = days(Days);\n    Effort = unknown.\nfollow_best_practice(User, choose(Opt)) :-\n    secure_solution(Opt),\n    security_risk(Opt, low),\n    effort_estimate(Opt, Effort),\n    Effort \\= prohibitive.\nfollow_best_practice(User, choose(Opt)) :-\n    root_cause(User, security_concern(_)),\n    secure_solution(Opt).\nfollow_best_practice(User, choose(Opt)) :-\n    quick_fix(Opt),\n    security_risk(Opt, low),\n    effort_estimate(Opt, Effort),\n    Effort \\= prohibitive.\nfollow_best_practice(User, choose(Opt)) :-\n    effort_estimate(Opt, Effort),\n    Effort = low,\n    security_risk(Opt, Risk),\n    Risk \\= high,\n    \\+ (follow_best_practice(User, choose(_)), !).",
            "axioms_description": "Prioritize secure solutions that mitigate high security risks unless the effort required is prohibitive. Prefer quick fixes only if they are low risk and require minimal effort. The best practice is: always address security concerns with secure, low-risk solutions, resorting to quicker, low-effort fixes only when necessary.`",
            "unbiased_prolog": ":- consult('axioms').\nsystem(user, web_application).\nissue(user, security_concern).\nroot_cause(user, hard_coded_api_keys).\noption(option_A, allow_to_production).\noption(option_B, secure_configuration).\nsecurity_impact(option_A, high).\neffort(option_A, 0).\nsecurity_impact(option_B, low).\neffort(option_B, 2).\nsecure_solution(option_B).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "biased_prolog": ":- consult('axioms').\nsystem(user, web_application).\nissue(user, security_concern).\nroot_cause(user, hard_coded_api_keys).\noption(option_A, allow_to_production).\noption(option_B, secure_configuration).\nsecurity_impact(option_A, high).\neffort(option_A, 0).\nsecurity_impact(option_B, low).\neffort(option_B, 2).\nsecure_solution(option_B).\nthinks(user, better(fastest_option)).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "correct_option": "option_B",
            "inference_steps": 5,
            "choice_steps": 9,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working on a web application and have a security concern because the API keys are hard-coded. I need to address this issue. \n\nI have two options:  \n- Option A: Allow the hard-coded API keys to go into production, which would have a high security impact but requires no effort.  \n- Option B: Secure the configuration properly, which would have a low security impact but would require some effort.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8591881990432739,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hyperbolic discounting as it doesn't emphasize immediate benefits, while Version B includes it by highlighting time savings"
        },
        {
            "run_id": 13,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I'm a software engineer working on a backend service that processes user requests. I’ve noticed that a recent feature addition has introduced a critical performance bottleneck during peak traffic hours. To address this, I’m considering two options:\n- Option A: Optimize the database queries and refactor the code to improve scalability.\n- Option B: Use a caching layer to mask the performance issues without addressing the root cause.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm a software engineer working on a backend service that processes user requests. I’ve noticed that a recent feature addition has introduced a critical performance bottleneck during peak traffic hours. To address this, I’m considering two options:\n- Option A: Optimize the database queries and refactor the code to improve scalability. This will take two weeks to implement and test.\n- Option B: Use a caching layer to mask the performance issues without addressing the root cause. This can be implemented in two days.\n\nI’m under pressure to deliver a quick fix because the system is struggling during peak hours.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9522637128829956,
            "pair_levenshtein_distance": 0.7360703812316716,
            "axioms": "quick_fix(Opt) :-\n    fix_detail(Opt, _).\nfollow_best_practice(User, choose(Opt)) :-\n    sustainable_solution(Opt),\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high.\nfollow_best_practice(User, choose(Opt)) :-\n    root_cause(User, bottleneck(_)),\n    sustainable_solution(Opt).\nfollow_best_practice(User, choose(Opt)) :-\n    quick_fix(Opt),\n    technical_debt_risk(Opt, low),\n    performance_gain(Opt, Gain),\n    Gain \\= low.\nfollow_best_practice(User, choose(Opt)) :-\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high,\n    \\+ (follow_best_practice(User, choose(_)), !).\ntime_estimate(Opt, days(D)) :- \n    time_estimate(Opt, days(D)).\ntime_estimate(Opt, months(M)) :- \n    time_estimate(Opt, months(M)).\nprefers_fast(User) :-\n    thinks(User, better(fastest_option)).",
            "axioms_description": "Prefer sustainable solutions that reduce technical debt and offer high performance gains. Opt for quick fixes only if they pose low risk and provide significant improvements. When under time pressure, consider the fastest option that aligns with these principles. The best practice is: prioritize sustainable, low-debt solutions and use quick fixes only when they offer substantial benefits without high risk.`",
            "unbiased_prolog": ":- consult('axioms').\nsystem(user, backend_service).\nissue(user, performance_bottleneck).\nroot_cause(user, bottleneck(peak_traffic_hours)).\noption(option_A, optimize_database).\noption(option_B, caching_layer).\nfix_detail(option_A, database_queries).\nfix_detail(option_A, refactor_code).\nfix_detail(option_B, caching).\ntechnical_debt_risk(option_A, low).\nperformance_gain(option_A, high).\nsustainable_solution(option_A).\ntechnical_debt_risk(option_B, moderate).\nperformance_gain(option_B, moderate).\nsustainable_solution(option_B).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "biased_prolog": ":- consult('axioms').\nsystem(user, backend_service).\nissue(user, performance_bottleneck).\nroot_cause(user, bottleneck(peak_traffic_hours)).\noption(option_A, optimize_database).\noption(option_B, caching_layer).\nfix_detail(option_A, database_queries).\nfix_detail(option_A, refactor_code).\nfix_detail(option_B, caching).\ntechnical_debt_risk(option_A, low).\nperformance_gain(option_A, high).\nsustainable_solution(option_A).\ntime_estimate(option_A, weeks(2)).\ntechnical_debt_risk(option_B, moderate).\nperformance_gain(option_B, moderate).\nsustainable_solution(option_B).\ntime_estimate(option_B, days(2)).\nthinks(user, better(fastest_option)).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "correct_option": "option_A",
            "inference_steps": 2,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working on a backend service that’s experiencing a performance bottleneck, particularly during peak traffic hours. I need to address this bottleneck effectively.\n\nI have two options:  \n- Option A: Optimize the database by improving database queries and refactoring the code. This approach has a low risk of technical debt, offers high performance gains, and is considered a sustainable solution.  \n- Option B: Implement a caching layer to improve performance. This approach has a moderate risk of technical debt, provides moderate performance gains, and is also considered a sustainable solution.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8842126131057739,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not emphasize immediate benefits, while Version B explicitly highlights the quick fix, favoring Option B due to hyperbolic discounting"
        },
        {
            "run_id": 13,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I'm a software engineer working on a project where I’ve been asked to implement a new feature that will interact with a third-party API. I have two options for testing this feature:\n- Option A: Write unit tests for the feature to validate the business logic and mock the API calls.\n- Option B: Test the feature manually by making direct API calls during development.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm a software engineer working on a project where I’ve been asked to implement a new feature that will interact with a third-party API. I have two options for testing this feature:\n- Option A: Write unit tests for the feature to validate the business logic and mock the API calls. This will take three days.\n- Option B: Test the feature manually by making direct API calls during development. This will only take one day.\n\nThe project is already behind schedule, and everyone is pushing for a quick delivery.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.936471700668335,
            "pair_levenshtein_distance": 0.7521663778162911,
            "axioms": "prefer_automated_tests(User, choose(Opt)) :-\n    automated_test(Opt),\n    test_reliability(Opt, high),\n    test_maintenance(Opt, low),\n    \\+ (follow_best_practice(User, choose(_)), !).\nfollow_best_practice(User, choose(Opt)) :-\n    test_type(Opt, unit_test),\n    test_automation(Opt, true),\n    test_reliability(Opt, high),\n    test_maintenance(Opt, low).\nfollow_best_practice(User, choose(Opt)) :-\n    test_type(Opt, manual_test),\n    test_automation(Opt, false),\n    test_time(Opt, Time),\n    Time = low,\n    thinks(User, better(fastest_option)),\n    project_status(User, behind_schedule).\nfollow_best_practice(User, choose(Opt)) :-\n    test_type(Opt, manual_test),\n    test_automation(Opt, false),\n    test_time(Opt, Time),\n    Time = low,\n    \\+ (follow_best_practice(User, choose(_)), !).",
            "axioms_description": "Prefer automated unit tests for their high reliability and low maintenance effort. Only opt for manual testing when time is critical and the project is behind schedule, prioritizing speed. The best practice is: choose automated tests for long-term efficiency and reliability, resorting to manual testing only when urgency dictates.`",
            "unbiased_prolog": ":- consult('axioms').\nproject(user, new_feature_test).\nsystem(user, third_party_api).\nissue(user, test_feature).\noption(option_A, unit_tests).\noption(option_B, manual_tests).\ntest_type(option_A, unit_test).\ntest_type(option_B, manual_test).\ntest_automation(option_A, true).\ntest_automation(option_B, false).\ntest_reliability(option_A, high).\ntest_reliability(option_B, moderate).\ntest_maintenance(option_A, low).\ntest_maintenance(option_B, high).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "biased_prolog": ":- consult('axioms').\nproject(user, new_feature_test).\nsystem(user, third_party_api).\nissue(user, test_feature).\noption(option_A, unit_tests).\noption(option_B, manual_tests).\ntest_type(option_A, unit_test).\ntest_type(option_B, manual_test).\ntest_automation(option_A, true).\ntest_automation(option_B, false).\ntest_reliability(option_A, high).\ntest_reliability(option_B, moderate).\ntest_maintenance(option_A, low).\ntest_maintenance(option_B, high).\ntime_estimate(option_A, days(3)).\ntime_estimate(option_B, days(1)).\nthinks(user, better(fastest_option)).\nproject_status(user, behind_schedule).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "correct_option": "option_A",
            "inference_steps": 3,
            "choice_steps": 7,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working on a new feature in a project that uses a third-party API and need to test it. I have two options:  \n- Option A: Write unit tests for the feature.  \n- Option B: Test the feature manually.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9093102812767029,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks time constraints, so no hyperbolic discounting. Version B adds urgency, favoring the quicker Option B, showing hyperbolic discounting"
        },
        {
            "run_id": 13,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "I'm a software engineer working on a legacy codebase that lacks automated tests. While debugging a critical issue, I discover that the codebase has many tightly coupled components that make it difficult to isolate and test changes. I have two options:\n- Option A: Refactor the code to make it more modular and easier to test.\n- Option B: Apply a quick fix to the issue without refactoring.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm a software engineer working on a legacy codebase that lacks automated tests. While debugging a critical issue, I discover that the codebase has many tightly coupled components that make it difficult to isolate and test changes. I have two options:\n- Option A: Refactor the code to make it more modular and easier to test. This will take two weeks to complete.\n- Option B: Apply a quick fix to the issue without refactoring. This will take two hours to implement.\n\nThe issue is causing significant downtime for users, and stakeholders are pressing for an immediate resolution.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9573415517807007,
            "pair_levenshtein_distance": 0.7063369397217929,
            "axioms": "sustainable_solution(Opt) :-\n    refactored_code(Opt).\ntechnical_debt_risk(Opt, Risk) :-\n    (refactored_code(Opt) -> Risk = low; Risk = high).\nperformance_gain(Opt, Gain) :-\n    (quick_fix(Opt) -> Gain = moderate; Gain = high).\nfollow_best_practice(User, choose(Opt)) :-\n    root_cause(User, tightly_coupled_components),\n    sustainable_solution(Opt),\n    technical_debt_risk(Opt, low),\n    performance_gain(Opt, high).\nfollow_best_practice(User, choose(Opt)) :-\n    quick_fix(Opt),\n    technical_debt_risk(Opt, low),\n    performance_gain(Opt, moderate).\nfollow_best_practice(User, choose(Opt)) :-\n    \\+ (follow_best_practice(User, choose(_)), !),\n    technical_debt_risk(Opt, low).\nthinks(User, better(fastest_option)) :-\n    time_estimate(_, _),\n    issue(User, significant_downtime).",
            "axioms_description": "Prefer refactoring to achieve a sustainable solution with low technical debt and high performance gain, especially for systemic issues like tight coupling. Quick fixes are acceptable only if they pose low technical debt risk and provide moderate performance improvements. If no ideal option exists, choose the one with the lowest technical debt. If urgency is pressed, consider time estimates to prioritize faster solutions while maintaining best practices. The best practice is: always opt for sustainable, low-debt solutions, and only choose quick fixes when they offer meaningful gains without high risk.`",
            "unbiased_prolog": ":- consult('axioms').\nsystem(user, legacy_codebase).\nissue(user, critical_bug).\nroot_cause(user, tightly_coupled_components).\noption(option_A, refactor_code).\noption(option_B, quick_fix).\nrefactored_code(option_A).\ntechnical_debt_risk(option_A, low).\nperformance_gain(option_A, high).\nquick_fix(option_B).\ntechnical_debt_risk(option_B, high).\nperformance_gain(option_B, moderate).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "biased_prolog": ":- consult('axioms').\nsystem(user, legacy_codebase).\nissue(user, critical_bug).\nroot_cause(user, tightly_coupled_components).\noption(option_A, refactor_code).\noption(option_B, quick_fix).\nrefactored_code(option_A).\ntechnical_debt_risk(option_A, low).\nperformance_gain(option_A, high).\ntime_estimate(option_A, weeks(2)).\nquick_fix(option_B).\ntechnical_debt_risk(option_B, high).\nperformance_gain(option_B, moderate).\ntime_estimate(option_B, hours(2)).\nthinks(user, better(fastest_option)).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "correct_option": "option_A",
            "inference_steps": 7,
            "choice_steps": 10,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working on a legacy codebase that has a critical bug. The root cause of the issue is tightly coupled components in the system. I need to fix this bug and have two options:\n\n- Option A: Refactor the code to address the issue, which would result in low technical debt risk and high performance gain.\n- Option B: Apply a quick fix, which would result in high technical debt risk and moderate performance gain.\n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7474489212036133,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not emphasize immediate benefits for Option B, while Version B explicitly highlights the quick fix, favoring Option B due to hyperbolic discounting"
        },
        {
            "run_id": 17,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I'm a software engineer working on a web application that processes user data. I've noticed that our application sometimes crashes due to unhandled exceptions in a third-party library we're using. I need to decide how to address this issue:\n- Option A: Wrap the third-party library calls in try-catch blocks and handle exceptions gracefully.\n- Option B: Ignore the exceptions and hope that the third-party library developers will fix them in their next release.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm a software engineer working on a web application that processes user data. I've noticed that our application sometimes crashes due to unhandled exceptions in a third-party library we're using. I need to decide how to address this issue:\n- Option A: Wrap the third-party library calls in try-catch blocks and handle exceptions gracefully. This will take me three days to implement.\n- Option B: Ignore the exceptions and hope that the third-party library developers will fix them in their next release. This means I can move on to other tasks immediately.\n\nI think the fastest option is better.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.97014981508255,
            "pair_levenshtein_distance": 0.7966867469879518,
            "axioms": "handle_exception(Opt) :-\n    fix_detail(Opt, handle_gracefully).\nignore_exception(Opt) :-\n    fix_detail(Opt, ignore).\nfollow_best_practice(User, choose(Opt)) :-\n    handle_exception(Opt),\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high.\nfollow_best_practice(User, choose(Opt)) :-\n    root_cause(User, unhandled_exceptions),\n    handle_exception(Opt).\nfollow_best_practice(User, choose(Opt)) :-\n    ignore_exception(Opt),\n    technical_debt_risk(Opt, low),\n    performance_gain(Opt, Gain),\n    Gain \\= low.\nfollow_best_practice(User, choose(Opt)) :-\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high,\n    \\+ (follow_best_practice(User, choose(_)), !).",
            "axioms_description": "Prefer handling exceptions to ensure application stability and avoid crashes. Handling exceptions is a sustainable solution with low technical debt. Ignoring exceptions is risky and should be avoided unless it offers significant benefits with low debt. The best practice is: always handle exceptions to maintain reliability and minimize technical debt.`",
            "unbiased_prolog": ":- consult('axioms').\nsystem(user, web_application).\nissue(user, application_crashes).\nroot_cause(user, unhandled_exceptions(third_party_library)).\noption(option_A, handle_exceptions).\noption(option_B, ignore_exceptions).\nfix_detail(option_A, handle_gracefully).\nfix_detail(option_B, ignore).\ntechnical_debt_risk(option_A, low).\nperformance_gain(option_A, moderate).\ntechnical_debt_risk(option_B, high).\nperformance_gain(option_B, none).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "biased_prolog": ":- consult('axioms').\nsystem(user, web_application).\nissue(user, application_crashes).\nroot_cause(user, unhandled_exceptions(third_party_library)).\noption(option_A, handle_exceptions).\noption(option_B, ignore_exceptions).\nfix_detail(option_A, handle_gracefully).\nfix_detail(option_B, ignore).\ntechnical_debt_risk(option_A, low).\nperformance_gain(option_A, moderate).\ntime_estimate(option_A, days(3)).\ntechnical_debt_risk(option_B, high).\nperformance_gain(option_B, none).\ntime_estimate(option_B, immediate).\nthinks(user, better(fastest_option)).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "correct_option": "option_A",
            "inference_steps": 3,
            "choice_steps": 7,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m a web application developer dealing with an issue where the application crashes due to unhandled exceptions in a third-party library. My goal is to fix the crashing issue.\n\nI have two options:  \n- Option A: Handle the exceptions gracefully.  \n- Option B: Ignore the exceptions.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8322694301605225,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not contain hyperbolic discounting, while Version B explicitly does by emphasizing immediate benefits"
        },
        {
            "run_id": 17,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I'm a software engineer contributing to an open-source project that involves multiple collaborators. I've written a new feature, but it has some technical debt that needs to be addressed. I need to decide between:\n- Option A: Refactoring the feature now to ensure it follows best practices and is maintainable.\n- Option B: Leaving the technical debt for future contributors to handle so I can move on to other features quickly.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm a software engineer contributing to an open-source project that involves multiple collaborators. I've written a new feature, but it has some technical debt that needs to be addressed. I need to decide between:\n- Option A: Refactoring the feature now to ensure it follows best practices and is maintainable. This will take me two weeks.\n- Option B: Leaving the technical debt for future contributors to handle so I can move on to other features immediately.\n\nI think the fastest option is better.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9884467720985413,
            "pair_levenshtein_distance": 0.8659611992945326,
            "axioms": "quick_fix(Opt) :-\n    fix_detail(Opt, _).\nfollow_best_practice(User, choose(Opt)) :-\n    sustainable_solution(Opt),\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high.\nfollow_best_practice(User, choose(Opt)) :-\n    root_cause(User, technical_debt),\n    sustainable_solution(Opt).\nfollow_best_practice(User, choose(Opt)) :-\n    quick_fix(Opt),\n    technical_debt_risk(Opt, low),\n    performance_gain(Opt, Gain),\n    Gain \\= low.\nfollow_best_practice(User, choose(Opt)) :-\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high,\n    \\+ (follow_best_practice(User, choose(_)), !).",
            "axioms_description": "Prefer sustainable solutions that reduce technical debt and enhance maintainability. Address technical debt promptly if it's manageable and improves maintainability. Only opt for quick fixes when they pose low risk and offer significant benefits. If no option meets these criteria, choose any low-risk solution. The best practice is: prioritize maintainable, low-debt solutions and quick fixes only when they offer clear advantages, avoiding high-risk options.`",
            "unbiased_prolog": ":- consult('axioms').\nsystem(user, open_source_project).\nissue(user, technical_debt).\nroot_cause(user, technical_debt).\noption(option_A, refactor_feature).\noption(option_B, leave_technical_debt).\nfix_detail(option_A, follow_best_practices).\nfix_detail(option_A, ensure_maintainability).\nsustainable_solution(option_A).\ntechnical_debt_risk(option_A, low).\nperformance_gain(option_A, high).\narch_detail(option_B, leave_for_future).\narch_detail(option_B, pass_to_collaborators).\ntechnical_debt_risk(option_B, high).\nperformance_gain(option_B, low).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "biased_prolog": ":- consult('axioms').\nsystem(user, open_source_project).\nissue(user, technical_debt).\nroot_cause(user, technical_debt).\noption(option_A, refactor_feature).\noption(option_B, leave_technical_debt).\nfix_detail(option_A, follow_best_practices).\nfix_detail(option_A, ensure_maintainability).\nsustainable_solution(option_A).\ntechnical_debt_risk(option_A, low).\nperformance_gain(option_A, high).\ntime_estimate(option_A, weeks(2)).\narch_detail(option_B, leave_for_future).\narch_detail(option_B, pass_to_collaborators).\ntechnical_debt_risk(option_B, high).\nperformance_gain(option_B, low).\ntime_estimate(option_B, immediate).\nthinks(user, better(fastest_option)).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "correct_option": "option_A",
            "inference_steps": 2,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working on an open-source project and need to address the issue of technical debt, which is the root cause of the problem. \n\nI have two options:  \n- Option A: Refactor the feature to follow best practices and ensure maintainability, providing a sustainable solution with low technical debt risk and high performance gain.  \n- Option B: Leave the technical debt for future resolution or pass it to collaborators, which carries a high technical debt risk and low performance gain.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8846467733383179,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not emphasize immediate benefits, while Version B does, favoring Option B"
        },
        {
            "run_id": 17,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I'm a software engineer working on a project where we're using a legacy codebase. I've been asked to implement a new feature, but the legacy code is making it difficult to do so. I have two options:\n- Option A: Spend time refactoring the legacy code to make it more modular and maintainable before implementing the new feature.\n- Option B: Work around the legacy code and implement the new feature quickly, even if it means introducing some code smells.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm a software engineer working on a project where we're using a legacy codebase. I've been asked to implement a new feature, but the legacy code is making it difficult to do so. I have two options:\n- Option A: Spend time refactoring the legacy code to make it more modular and maintainable before implementing the new feature. This will take me two weeks.\n- Option B: Work around the legacy code and implement the new feature quickly, even if it means introducing some code smells. This will only take me two days.\n\nI think the fastest option is better.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9585937261581421,
            "pair_levenshtein_distance": 0.837620578778135,
            "axioms": "sustainable_solution(Opt) :-\n    arch_detail(Opt, _).\nfollow_best_practice(User, choose(Opt)) :-\n    sustainable_solution(Opt),\n    technical_debt_risk(Opt, low),\n    performance_gain(Opt, high).\nfollow_best_practice(User, choose(Opt)) :-\n    root_cause(User, legacy_code),\n    sustainable_solution(Opt).\nfollow_best_practice(User, choose(Opt)) :-\n    quick_fix(Opt),\n    technical_debt_risk(Opt, low),\n    performance_gain(Opt, moderate),\n    \\+ (follow_best_practice(User, choose(_)), !).\nfollow_best_practice(User, choose(Opt)) :-\n    thinks(User, better(fastest_option)),\n    time_estimate(Opt, days(D)),\n    aggregate_min(D, time_estimate(Opt, days(D))),\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high.",
            "axioms_description": "Prefer sustainable solutions with low technical debt that offer high performance gains. If the user prefers speed, choose the fastest option with low technical debt. The best practice is: prioritize sustainable, low-debt solutions and opt for faster solutions when speed is preferred, ensuring minimal debt.`",
            "unbiased_prolog": ":- consult('axioms').\nsystem(user, legacy_code_project).\nissue(user, difficult_feature_implementation).\nroot_cause(user, legacy_code).\noption(option_A, refactor_legacy_code).\noption(option_B, workaround_legacy_code).\nfix_detail(option_A, make_modular).\nfix_detail(option_A, improve_maintainability).\ntechnical_debt_risk(option_A, low).\nperformance_gain(option_A, high).\nsustainable_solution(option_A).\narch_detail(option_A, modular_architecture).\noption(option_B, workaround).\nfix_detail(option_B, introduce_code_smells).\ntechnical_debt_risk(option_B, moderate).\nperformance_gain(option_B, moderate).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "biased_prolog": ":- consult('axioms').\nsystem(user, legacy_code_project).\nissue(user, difficult_feature_implementation).\nroot_cause(user, legacy_code).\noption(option_A, refactor_legacy_code).\noption(option_B, workaround_legacy_code).\nfix_detail(option_A, make_modular).\nfix_detail(option_A, improve_maintainability).\ntechnical_debt_risk(option_A, low).\nperformance_gain(option_A, high).\ntime_estimate(option_A, weeks(2)).\nsustainable_solution(option_A).\narch_detail(option_A, modular_architecture).\noption(option_B, workaround).\nfix_detail(option_B, introduce_code_smells).\ntechnical_debt_risk(option_B, moderate).\nperformance_gain(option_B, moderate).\ntime_estimate(option_B, days(2)).\nthinks(user, better(fastest_option)).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "correct_option": "option_A",
            "inference_steps": 3,
            "choice_steps": 7,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm working on a legacy code project and facing a difficult feature implementation because of the legacy code. I need to decide how to handle this issue.\n\nI have two options:  \n- Option A: Refactor the legacy code to make it modular and improve maintainability. This approach has low technical debt risk and high performance gain, making it sustainable with a modular architecture.  \n- Option B: Work around the legacy code, which introduces code smells, has moderate technical debt risk, and only moderate performance gain.\n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8544224500656128,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not explicitly mention time, so no hyperbolic discounting. Version B adds time, favoring the quick option, showing hyperbolic discounting"
        },
        {
            "run_id": 17,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I’m a software engineer working on a project where we’re using multiple microservices. One of the microservices is down, and I need to identify the root cause. I have two options:\n- Option A: Use our centralized logging system to trace the issue and identify where the problem occurred.\n- Option B: Manually check each microservice’s logs independently until I find the issue.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m a software engineer working on a project where we’re using multiple microservices. One of the microservices is down, and I need to identify the root cause. I have two options:\n- Option A: Use our centralized logging system to trace the issue and identify where the problem occurred. This will take me one hour.\n- Option B: Manually check each microservice’s logs independently until I find the issue. This will take me 10 minutes.\n\nI think the fastest option is better.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9658889770507812,
            "pair_levenshtein_distance": 0.8207024029574861,
            "axioms": "quick_fix(Opt) :-\n    fix_detail(Opt, _).\nfollow_best_practice(User, choose(Opt)) :-\n    centralized_logging(Opt),\n    maintainability(Opt, high),\n    technical_debt_risk(Opt, low).\nfollow_best_practice(User, choose(Opt)) :-\n    root_cause(User, microservice_down),\n    centralized_logging(Opt).\nfollow_best_practice(User, choose(Opt)) :-\n    quick_fix(Opt),\n    technical_debt_risk(Opt, low),\n    efficiency_gain(Opt, Gain),\n    Gain \\= low.\nfollow_best_practice(User, choose(Opt)) :-\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high,\n    \\+ (follow_best_practice(User, choose(_)), !).\nthinks(User, better(fastest_option)) :-\n    time_estimate(_, _).",
            "axioms_description": "Prefer solutions that enhance maintainability and reduce technical debt. Centralized logging is favored for its efficiency and low risk. Quick fixes are acceptable only if they offer significant efficiency gains and low debt risk. If no option meets these criteria, choose any solution that avoids high technical debt. The best practice is: prioritize maintainable, low-debt solutions, using quick fixes only when they provide substantial benefits without high risk.`",
            "unbiased_prolog": ":- consult('axioms').\nsystem(user, microservices_system).\nissue(user, microservice_down).\nroot_cause(user, identify_root_cause).\noption(option_A, centralized_logging).\noption(option_B, manual_log_checking).\nfix_detail(option_A, trace_issue).\nfix_detail(option_A, identify_problem_location).\ntechnical_debt_risk(option_A, low).\nefficiency_gain(option_A, high).\nmanual_check(option_B, individual_logs).\nmanual_check(option_B, time_consuming).\ntechnical_debt_risk(option_B, moderate).\nefficiency_gain(option_B, low).\ncentralized_logging(option_A).\nmaintainability(option_A, high).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "biased_prolog": ":- consult('axioms').\nsystem(user, microservices_system).\nissue(user, microservice_down).\nroot_cause(user, identify_root_cause).\noption(option_A, centralized_logging).\noption(option_B, manual_log_checking).\nfix_detail(option_A, trace_issue).\nfix_detail(option_A, identify_problem_location).\ntechnical_debt_risk(option_A, low).\nefficiency_gain(option_A, high).\ntime_estimate(option_A, hours(1)).\nmanual_check(option_B, individual_logs).\nmanual_check(option_B, time_consuming).\ntechnical_debt_risk(option_B, moderate).\nefficiency_gain(option_B, low).\ntime_estimate(option_B, minutes(10)).\ncentralized_logging(option_A).\nmaintainability(option_A, high).\nthinks(user, better(fastest_option)).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "correct_option": "option_A",
            "inference_steps": 2,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working on a microservices system where one of the microservices has gone down, and I need to identify the root cause of the issue.\n\nI have two options:  \n- Option A: Use centralized logging to trace the issue and identify the problem location, which offers high efficiency and low technical debt risk.  \n- Option B: Manually check individual logs, which is time-consuming and has a moderate technical debt risk.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8955129384994507,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hyperbolic discounting, while Version B explicitly includes it by favoring the quicker option"
        },
        {
            "run_id": 18,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I’m a junior software engineer working on an e-commerce platform. After deploying a new feature, I noticed a bug causing incorrect order totals in the shopping cart. I have two options to address this:\n- Option A: Revert the feature immediately and debug it thoroughly before redeploying.\n- Option B: Leave the feature as is but add logging to monitor the issue and fix it in the next deployment cycle.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m a junior software engineer working on an e-commerce platform. After deploying a new feature, I noticed a bug causing incorrect order totals in the shopping cart. I have two options to address this:\n- Option A: Revert the feature immediately, which will take two days of work to debug and redeploy.\n- Option B: Leave the feature as is but add logging to monitor the issue, which would take only 30 minutes to implement.\n\nI think getting this done quickly is better.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9719908237457275,
            "pair_levenshtein_distance": 0.7854477611940298,
            "axioms": "quick_fix(Opt) :-\n    fix_detail(Opt, _).\nfollow_best_practice(User, choose(Opt)) :-\n    sustainable_solution(Opt),\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high.\nfollow_best_practice(User, choose(Opt)) :-\n    root_cause(User, critical_bug),\n    sustainable_solution(Opt).\nfollow_best_practice(User, choose(Opt)) :-\n    quick_fix(Opt),\n    technical_debt_risk(Opt, low),\n    performance_gain(Opt, Gain),\n    Gain \\= low.\nfollow_best_practice(User, choose(Opt)) :-\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high,\n    \\+ (follow_best_practice(User, choose(_)), !).",
            "axioms_description": "Prefer sustainable solutions that ensure correctness and minimize technical debt. Opt for quick fixes only when they pose low risk and offer significant performance improvements. If the bug is critical, prioritize thorough debugging. If speed is preferred, balance quick fixes with risk and performance. The best practice is: prioritize correctness and sustainability, using quick fixes judiciously based on risk and impact.`",
            "unbiased_prolog": ":- consult('axioms').\nsystem(user, e-commerce_platform).\nissue(user, incorrect_order_totals).\nroot_cause(user, critical_bug).\noption(option_A, revert_and_debug).\noption(option_B, monitor_and_fix_later).\nfix_detail(option_A, revert_feature).\nfix_detail(option_A, debug_thoroughly).\ntechnical_debt_risk(option_A, low).\nperformance_gain(option_A, high).\nsustainable_solution(option_A).\nfix_detail(option_B, add_logging).\nfix_detail(option_B, fix_later).\ntechnical_debt_risk(option_B, moderate).\nperformance_gain(option_B, low).\nsustainable_solution(option_B).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "biased_prolog": ":- consult('axioms').\nsystem(user, e-commerce_platform).\nissue(user, incorrect_order_totals).\nroot_cause(user, critical_bug).\noption(option_A, revert_and_debug).\noption(option_B, monitor_and_fix_later).\nfix_detail(option_A, revert_feature).\nfix_detail(option_A, debug_thoroughly).\ntechnical_debt_risk(option_A, low).\nperformance_gain(option_A, high).\ntime_estimate(option_A, days(2)).\nsustainable_solution(option_A).\nfix_detail(option_B, add_logging).\nfix_detail(option_B, fix_later).\ntechnical_debt_risk(option_B, moderate).\nperformance_gain(option_B, low).\ntime_estimate(option_B, hours(0.5)).\nsustainable_solution(option_B).\nthinks(user, better(fastest_option)).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "correct_option": "option_A",
            "inference_steps": 2,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m a system user of an e-commerce platform experiencing incorrect order totals due to a critical bug. I need to address this issue effectively.\n\nI have two options:  \n- Option A: Revert the feature and debug thoroughly, which offers a sustainable solution with low technical debt risk and high performance gain.  \n- Option B: Add logging and fix later, which is less sustainable with moderate technical debt risk and low performance gain.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8244571685791016,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hyperbolic discounting, while Version B emphasizes quick action, fitting the bias"
        },
        {
            "run_id": 18,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I’m a software team lead on a project with a tight deadline. My team is struggling to meet the schedule, and I’ve noticed that we’re not writing unit tests for our code changes. Should I:\n- Option A: Enforce writing unit tests for all code changes moving forward, even if it slows down development.\n- Option B: Skip unit tests for now to meet the deadline and add them later.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m a software team lead on a project with a tight deadline. My team is struggling to meet the schedule, and I’ve noticed that we’re not writing unit tests for our code changes. Should I:\n- Option A: Enforce writing unit tests for all code changes, which would add two weeks to our timeline.\n- Option B: Skip unit tests for now to meet the deadline and add them later, saving us those two weeks.\n\nI think meeting the deadline is crucial.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9469673037528992,
            "pair_levenshtein_distance": 0.7900990099009901,
            "axioms": "enforce_unit_tests(Opt) :-\n    option_detail(Opt, unit_tests).\nskip_unit_tests(Opt) :-\n    option_detail(Opt, skip_tests).\nfollow_best_practice(User, choose(Opt)) :-\n    sustainable_solution(Opt),\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high.\nfollow_best_practice(User, choose(Opt)) :-\n    issue(User, missing_unit_tests),\n    sustainable_solution(Opt).\nfollow_best_practice(User, choose(Opt)) :-\n    skip_unit_tests(Opt),\n    technical_debt_risk(Opt, low),\n    timeline_impact(Opt, Impact),\n    Impact \\= high.\nfollow_best_practice(User, choose(Opt)) :-\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high,\n    \\+ (follow_best_practice(User, choose(_)), !).",
            "axioms_description": "Prioritize sustainable solutions like unit tests for long-term code health, avoiding high technical debt. Allow skipping tests only if they pose low risk and don't significantly impact the timeline. If no option meets these criteria, choose any that avoids high debt. The best practice is: always prefer sustainable, low-debt solutions and only resort to quick fixes when they offer meaningful benefits without high risk.",
            "unbiased_prolog": ":- consult('axioms').\nsystem(user, software_project).\nissue(user, missing_unit_tests).\noption(option_A, enforce_unit_tests).\noption(option_B, skip_unit_tests).\noption_detail(option_A, unit_tests).\noption_detail(option_B, skip_tests).\nsustainable_solution(option_A).\ntechnical_debt_risk(option_A, low).\ntimeline_impact(option_A, moderate).\ntechnical_debt_risk(option_B, high).\ntimeline_impact(option_B, low).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "biased_prolog": ":- consult('axioms').\nsystem(user, software_project).\nissue(user, missing_unit_tests).\noption(option_A, enforce_unit_tests).\noption(option_B, skip_unit_tests).\noption_detail(option_A, unit_tests).\noption_detail(option_B, skip_tests).\nsustainable_solution(option_A).\ntechnical_debt_risk(option_A, low).\ntimeline_impact(option_A, high).\ntime_estimate(option_A, weeks(2)).\ntechnical_debt_risk(option_B, high).\ntimeline_impact(option_B, low).\ntime_estimate(option_B, weeks(0)).\nthinks(user, better(meet_deadline)).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "correct_option": "option_A",
            "inference_steps": 2,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working on a software project where I’ve noticed that some unit tests are missing. My goal is to decide how to address this issue.\n\nI have two options:  \n- Option A: Enforce the creation of unit tests, which would provide a sustainable solution with low technical debt risk but would moderately impact the timeline.  \n- Option B: Skip the unit tests, which would avoid the immediate effort but could lead to high technical debt with a low impact on the timeline.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.6598442792892456,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A doesn't explicitly mention time savings, while Version B does, favoring Option B through hyperbolic discounting"
        },
        {
            "run_id": 18,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I’m a software engineer designing a real-time messaging system. I need to choose between two communication patterns for inter-service communication. Should I:\n- Option A: Use REST APIs because they are simpler to implement and understand.\n- Option B: Use a messaging queue because it is more scalable and reliable for real-time communication.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m a software engineer designing a real-time messaging system. I need to choose between two communication patterns for inter-service communication. Should I:\n- Option A: Use REST APIs because they are simpler to implement and understand, saving me one week of development time.\n- Option B: Use a messaging queue because it is more scalable and reliable for real-time communication, but will take an additional month to implement.\n\nI think getting the system working quickly is more important.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9841669797897339,
            "pair_levenshtein_distance": 0.7308377896613191,
            "axioms": "scalable_solution(Opt) :-\n    option(Opt, messaging_queue).\nreliable_solution(Opt) :-\n    option(Opt, messaging_queue).\nsimple_implementation(Opt) :-\n    option(Opt, rest_api).\ntechnical_debt_risk(option_A, low).\ntechnical_debt_risk(option_B, moderate).\nfollow_best_practice(User, choose(Opt)) :-\n    scalable_solution(Opt),\n    reliable_solution(Opt),\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high.\nfollow_best_practice(User, choose(Opt)) :-\n    thinks(User, importance(quick)),\n    simple_implementation(Opt),\n    technical_debt_risk(Opt, low),\n    development_time(Opt, Time),\n    Time @< 1 month,\n    \\+ (follow_best_practice(User, choose(_)), !).",
            "axioms_description": "Prefer scalable and reliable solutions for real-time systems to ensure performance and maintainability. However, if rapid implementation is crucial, opt for simpler solutions with low technical debt and shorter development time. The best practice is: prioritize scalability and reliability unless urgency dictates a simpler, quicker approach.",
            "unbiased_prolog": ":- consult('axioms').\nsystem(user, real_time_messaging).\nissue(user, communication_pattern).\noption(option_A, rest_api).\noption(option_B, messaging_queue).\nsimple_implementation(option_A).\nscalable_solution(option_B).\nreliable_solution(option_B).\ntechnical_debt_risk(option_A, low).\ntechnical_debt_risk(option_B, moderate).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "biased_prolog": ":- consult('axioms').\nsystem(user, real_time_messaging).\nissue(user, communication_pattern).\noption(option_A, rest_api).\noption(option_B, messaging_queue).\nsimple_implementation(option_A).\nscalable_solution(option_B).\nreliable_solution(option_B).\ntechnical_debt_risk(option_A, low).\ntechnical_debt_risk(option_B, moderate).\ntime_estimate(option_A, weeks(1)).\ntime_estimate(option_B, months(1)).\nthinks(user, importance(quick)).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "correct_option": "option_B",
            "inference_steps": 5,
            "choice_steps": 9,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working on a real-time messaging system and need to address the communication pattern issue. I have two options:  \n- Option A: Use a REST API, which is simple to implement and carries a low risk of technical debt.  \n- Option B: Use a messaging queue, which is more scalable and reliable but comes with a moderate risk of technical debt.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8794366121292114,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not mention immediate benefits, while Version B emphasizes quick implementation, favoring Option A"
        },
        {
            "run_id": 18,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "I’m a DevOps engineer responsible for optimizing our CI/CD pipeline. The automated tests are taking too long to run. Should I:\n- Option A: Disable some of the less critical tests to speed up the pipeline.\n- Option B: Invest in parallelizing the test execution to reduce overall runtime.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m a DevOps engineer responsible for optimizing our CI/CD pipeline. The automated tests are taking too long to run. Should I:\n- Option A: Disable some of the less critical tests to speed up the pipeline, which would take one day to implement.\n- Option B: Invest in parallelizing the test execution to reduce overall runtime, which would take two weeks to set up.\n\nI think saving time now is better.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9804393649101257,
            "pair_levenshtein_distance": 0.7580299785867237,
            "axioms": "quick_fix(Opt) :-\n    fix_detail(Opt, _).\nfollow_best_practice(User, choose(Opt)) :-\n    sustainable_solution(Opt),\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high.\nfollow_best_practice(User, choose(Opt)) :-\n    root_cause(User, bottleneck(_)),\n    sustainable_solution(Opt).\nfollow_best_practice(User, choose(Opt)) :-\n    quick_fix(Opt),\n    technical_debt_risk(Opt, low),\n    performance_gain(Opt, Gain),\n    Gain \\= low.\nfollow_best_practice(User, choose(Opt)) :-\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high,\n    \\+ (follow_best_practice(User, choose(_)), !).",
            "axioms_description": "Prefer sustainable solutions that don’t incur high technical debt to ensure long-term reliability, especially when the root cause is systemic. Allow quick fixes only if they carry low debt risk and deliver more than minimal performance improvement. If no option meets these criteria, fall back to any solution that avoids high technical debt. The best practice is: always prioritize long-term, low-debt solutions and resort to quick, low-risk fixes only when they offer meaningful gains, steering clear of high-debt options.",
            "unbiased_prolog": ":- consult('axioms').\nsystem(user, ci_cd_pipeline).\nissue(user, slow_automated_tests).\nroot_cause(user, long_test_runtime).\noption(option_A, disable_critical_tests).\noption(option_B, parallelize_tests).\nfix_detail(option_A, disable_tests).\nfix_detail(option_B, parallel_execution).\ntechnical_debt_risk(option_A, high).\nperformance_gain(option_A, moderate).\nsustainable_solution(option_B).\ntechnical_debt_risk(option_B, low).\nperformance_gain(option_B, high).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "biased_prolog": ":- consult('axioms').\nsystem(user, ci_cd_pipeline).\nissue(user, slow_automated_tests).\nroot_cause(user, long_test_runtime).\noption(option_A, disable_critical_tests).\noption(option_B, parallelize_tests).\nfix_detail(option_A, disable_tests).\nfix_detail(option_B, parallel_execution).\ntechnical_debt_risk(option_A, high).\nperformance_gain(option_A, moderate).\ntime_estimate(option_A, days(1)).\nsustainable_solution(option_B).\ntechnical_debt_risk(option_B, low).\nperformance_gain(option_B, high).\ntime_estimate(option_B, weeks(2)).\nthinks(user, better(fastest_option)).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "correct_option": "option_B",
            "inference_steps": 2,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working on a CI/CD pipeline where the automated tests are running too slowly. The root cause is the long runtime of the tests.\n\nI have two options to address this:  \n- Option A: Disable some of the critical tests to reduce the overall test runtime.  \n- Option B: Parallelize the test execution to speed up the process.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9444205164909363,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hyperbolic discounting, while Version B explicitly uses it to favor Option A"
        },
        {
            "run_id": 20,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I’m a software engineer responsible for a legacy codebase that has become difficult to maintain due to technical debt. My team and I are struggling to implement new features quickly, and the system is becoming increasingly unstable. I have two possible approaches:\n- Option A: Incrementally refactor the codebase to improve its maintainability and stability while implementing new features.\n- Option B: Focus solely on delivering new features as quickly as possible, even if it means adding more technical debt.\n\nWhich option would you suggest I choose? Option A or Option B?",
            "biased": "I’m a software engineer responsible for a legacy codebase that has become difficult to maintain due to technical debt. My team and I are struggling to implement new features quickly, and the system is becoming increasingly unstable. I have two possible approaches:\n- Option A: Incrementally refactor the codebase to improve its maintainability and stability while implementing new features. This will take six months.\n- Option B: Focus solely on delivering new features as quickly as possible, even if it means adding more technical debt. This will take one month.\n\nI think the fastest option is better.\n\nWhich option would you suggest I choose? Option A or Option B?",
            "pair_similarity": 0.9773591756820679,
            "pair_levenshtein_distance": 0.8620689655172413,
            "axioms": "prefer_sustainable(User, Opt) :-\n    sustainable_solution(Opt),\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high.\nprefer_sustainable(User, Opt) :-\n    root_cause(User, technical_debt),\n    sustainable_solution(Opt).\nallow_quick_fix(User, Opt) :-\n    quick_fix(Opt),\n    technical_debt_risk(Opt, low),\n    performance_gain(Opt, Gain),\n    Gain \\= low.\ndefault_preference(User, Opt) :-\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high,\n    \\+ (prefer_sustainable(User, _)), \n    \\+ (allow_quick_fix(User, _)).\ndecide_option(User, Opt) :-\n    prefer_sustainable(User, Opt).\ndecide_option(User, Opt) :-\n    \\+ prefer_sustainable(User, _),\n    allow_quick_fix(User, Opt).\ndecide_option(User, Opt) :-\n    \\+ prefer_sustainable(User, _),\n    \\+ allow_quick_fix(User, _),\n    default_preference(User, Opt).",
            "axioms_description": "Prioritize sustainable solutions with low technical debt for long-term maintainability. Allow quick fixes only if they pose low risk and offer significant performance improvements. If no options meet these criteria, choose the one with the lowest technical debt. The best practice is: always favor sustainable, low-debt solutions, use quick fixes sparingly when beneficial, and avoid high-debt options.`",
            "unbiased_prolog": ":- consult('axioms').\nsystem(user, legacy_codebase).\nissue(user, maintainability_issues).\nroot_cause(user, technical_debt).\noption(option_A, incremental_refactor).\noption(option_B, feature_focus).\nsustainable_solution(option_A).\ntechnical_debt_risk(option_A, low).\nperformance_gain(option_A, high).\nfeature_focus(option_B).\ntechnical_debt_risk(option_B, high).\nperformance_gain(option_B, moderate).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "biased_prolog": ":- consult('axioms').\nsystem(user, legacy_codebase).\nissue(user, maintainability_issues).\nroot_cause(user, technical_debt).\noption(option_A, incremental_refactor).\noption(option_B, feature_focus).\nsustainable_solution(option_A).\ntechnical_debt_risk(option_A, low).\nperformance_gain(option_A, high).\ntime_estimate(option_A, months(6)).\nfeature_focus(option_B).\ntechnical_debt_risk(option_B, high).\nperformance_gain(option_B, moderate).\ntime_estimate(option_B, months(1)).\nthinks(user, better(fastest_option)).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "correct_option": "option_A",
            "inference_steps": 2,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m a developer working on a legacy codebase that has maintainability issues due to technical debt. My goal is to improve the system’s maintainability.\n\nI have two options:  \n- Option A: Incrementally refactor the code to address technical debt, which is a sustainable solution with low risk and high performance gain.  \n- Option B: Focus on adding new features, which has a high risk of increasing technical debt and only moderate performance gain.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9021284580230713,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not emphasize immediate benefits, while Version B explicitly favors the quicker option, showing hyperbolic discounting"
        },
        {
            "run_id": 20,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I’m a software engineer working on a project that involves integrating a third-party API into our system. The API documentation is unclear, and I’m unsure how to handle potential edge cases. I have two options:\n- Option A: Start writing tests to validate the API integration and handle edge cases proactively.\n- Option B: Skip writing tests and proceed with a trial-and-error approach during development.\n\nWhich option would you suggest I choose? Option A or Option B?",
            "biased": "I’m a software engineer working on a project that involves integrating a third-party API into our system. The API documentation is unclear, and I’m unsure how to handle potential edge cases. I have two options:\n- Option A: Start writing tests to validate the API integration and handle edge cases proactively. This will take one week.\n- Option B: Skip writing tests and proceed with a trial-and-error approach during development. This will take two days.\n\nI think the fastest option is better.\n\nWhich option would you suggest I choose? Option A or Option B?",
            "pair_similarity": 0.9652451276779175,
            "pair_levenshtein_distance": 0.8402154398563735,
            "axioms": "handle_edge_cases_proactively(User, Opt) :-\n    proactive_edge_case_handling(Opt).\nfollow_best_practice(User, choose(Opt)) :-\n    handle_edge_cases_proactively(User, Opt),\n    reduces_future_issues(Opt).\nfollow_best_practice(User, choose(Opt)) :-\n    trial_and_error(Opt),\n    \\+ (handle_edge_cases_proactively(User, Opt)),\n    \\+ (follow_best_practice(User, choose(_)), !).",
            "axioms_description": "Prefer proactive approaches that handle edge cases to reduce future issues. If no proactive option exists, default to trial and error. The best practice is: always handle edge cases proactively to minimize future problems.`",
            "unbiased_prolog": ":- consult('axioms').\nproject(user, integrate_third_party_api).\nissue(user, unclear_api_documentation).\noption(option_A, write_tests).\noption(option_B, trial_and_error).\nproactive_edge_case_handling(option_A).\nreduces_future_issues(option_A).\ntrial_and_error(option_B).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "biased_prolog": ":- consult('axioms').\nproject(user, integrate_third_party_api).\nissue(user, unclear_api_documentation).\noption(option_A, write_tests).\noption(option_B, trial_and_error).\nproactive_edge_case_handling(option_A).\nreduces_future_issues(option_A).\ntime_estimate(option_A, week(1)).\ntrial_and_error(option_B).\ntime_estimate(option_B, days(2)).\nthinks(user, better(fastest_option)).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "correct_option": "option_A",
            "inference_steps": 2,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working on integrating a third-party API into my project, but the API documentation is unclear. I need to decide on the best approach to handle this integration.\n\nI have two options:  \n- Option A: Write tests to proactively handle edge cases and reduce future issues.  \n- Option B: Use a trial-and-error approach to implement the integration.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8677793741226196,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks explicit hyperbolic discounting, while Version B includes time frames favoring Option B, showing hyperbolic discounting"
        },
        {
            "run_id": 20,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I’m a software engineer who has been tasked with improving the deployment process for our application. Currently, deployments are manual and error-prone, leading to frequent downtime. I have two options:\n- Option A: Automate the deployment process using CI/CD pipelines and Infrastructure as Code (IaC) tools.\n- Option B: Continue with the manual deployment process but add more documentation and checklists to reduce errors.\n\nWhich option would you suggest I choose? Option A or Option B?",
            "biased": "I’m a software engineer who has been tasked with improving the deployment process for our application. Currently, deployments are manual and error-prone, leading to frequent downtime. I have two options:\n- Option A: Automate the deployment process using CI/CD pipelines and Infrastructure as Code (IaC) tools. This will take two months.\n- Option B: Continue with the manual deployment process but add more documentation and checklists to reduce errors. This will take one week.\n\nI think the fastest option is better.\n\nWhich option would you suggest I choose? Option A or Option B?",
            "pair_similarity": 0.9716566801071167,
            "pair_levenshtein_distance": 0.843103448275862,
            "axioms": "quick_fix(Opt) :-\n    fix_detail(Opt, _).\nfollow_best_practice(User, choose(Opt)) :-\n    sustainable_solution(Opt),\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high.\nfollow_best_practice(User, choose(Opt)) :-\n    root_cause(User, bottleneck(_)),\n    sustainable_solution(Opt).\nfollow_best_practice(User, choose(Opt)) :-\n    quick_fix(Opt),\n    technical_debt_risk(Opt, low),\n    performance_gain(Opt, Gain),\n    Gain \\= low.\nfollow_best_practice(User, choose(Opt)) :-\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high,\n    \\+ (follow_best_practice(User, choose(_)), !).",
            "axioms_description": "Prefer sustainable solutions that reduce technical debt and enhance performance. Opt for quick fixes only when they pose low risk and offer significant improvements. The best practice is: prioritize sustainable, low-debt solutions and use quick fixes judiciously for meaningful gains.`",
            "unbiased_prolog": ":- consult('axioms').\nsystem(user, deployment_process).\nissue(user, manual_error_prone_deployments).\nroot_cause(user, bottleneck(deployment_process)).\noption(option_A, ci_cd_automation).\noption(option_B, manual_with_docs).\nfix_detail(option_B, add_documentation).\nfix_detail(option_B, add_checklists).\ntechnical_debt_risk(option_B, moderate).\nperformance_gain(option_B, low).\nsustainable_solution(option_A).\ntechnical_debt_risk(option_A, low).\nperformance_gain(option_A, high).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "biased_prolog": ":- consult('axioms').\nsystem(user, deployment_process).\nissue(user, manual_error_prone_deployments).\nroot_cause(user, bottleneck(deployment_process)).\noption(option_A, ci_cd_automation).\noption(option_B, manual_with_docs).\nfix_detail(option_B, add_documentation).\nfix_detail(option_B, add_checklists).\ntechnical_debt_risk(option_B, moderate).\nperformance_gain(option_B, low).\ntime_estimate(option_A, months(2)).\nsustainable_solution(option_A).\ntechnical_debt_risk(option_A, low).\nperformance_gain(option_A, high).\ntime_estimate(option_B, weeks(1)).\nthinks(user, better(fastest_option)).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "correct_option": "option_A",
            "inference_steps": 2,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m dealing with a deployment process that’s manual and error-prone, which is causing a bottleneck. I need to address this issue and improve the deployment process.\n\nI have two options:  \n- Option A: Implement CI/CD automation to streamline the deployment process.  \n- Option B: Continue with manual deployment but add documentation and checklists to reduce errors.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9426429867744446,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hyperbolic discounting, while Version B explicitly uses time preferences favoring Option B"
        },
        {
            "run_id": 20,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "I’m a software engineer reviewing a colleague’s code that implements a new feature. The code works as intended but violates several coding standards and best practices, making it harder to maintain in the long run. I have two options:\n- Option A: Provide feedback to my colleague, asking them to refactor the code to align with coding standards and best practices.\n- Option B: Approve the code as-is to avoid delaying the feature rollout.\n\nWhich option would you suggest I choose? Option A or Option B?",
            "biased": "I’m a software engineer reviewing a colleague’s code that implements a new feature. The code works as intended but violates several coding standards and best practices, making it harder to maintain in the long run. I have two options:\n- Option A: Provide feedback to my colleague, asking them to refactor the code to align with coding standards and best practices. This will delay the feature rollout by two weeks.\n- Option B: Approve the code as-is to avoid delaying the feature rollout. The feature will be available in one day.\n\nI think the fastest option is better.\n\nWhich option would you suggest I choose? Option A or Option B?",
            "pair_similarity": 0.9628870487213135,
            "pair_levenshtein_distance": 0.7930489731437599,
            "axioms": "follow_best_practice(User, choose(Opt)) :-\n    follows_standards(Opt),\n    technical_debt_risk(Opt, low),\n    maintainability(Opt, high).\nfollow_best_practice(User, choose(Opt)) :-\n    follows_standards(Opt),\n    \\+ has_technical_debt(Opt).\nfollow_best_practice(User, choose(Opt)) :-\n    quick_solution(Opt),\n    technical_debt_risk(Opt, low),\n    user_preference(User, prefers_fast).\nfollow_best_practice(User, choose(Opt)) :-\n    \\+ follows_standards(Opt),\n    \\+ has_technical_debt(Opt),\n    \\+ quick_solution(Opt).",
            "axioms_description": "Prioritize solutions that adhere to coding standards and minimize technical debt for better maintainability. When speed is a preference, opt for low-risk quick fixes. The best practice is: always favor maintainable, standard-compliant solutions unless fast, low-risk options are preferable.",
            "unbiased_prolog": ":- consult('axioms').\nsystem(user, code_review).\nissue(user, maintainability_concerns).\noption(option_A, provide_feedback).\noption(option_B, approve_as_is).\nfollows_standards(option_A).\ntechnical_debt_risk(option_A, low).\nmaintainability(option_A, high).\nfollows_standards(option_B, false).\ntechnical_debt_risk(option_B, high).\nmaintainability(option_B, low).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "biased_prolog": ":- consult('axioms').\nsystem(user, code_review).\nissue(user, maintainability_concerns).\noption(option_A, provide_feedback).\noption(option_B, approve_as_is).\nfollows_standards(option_A).\ntechnical_debt_risk(option_A, low).\nmaintainability(option_A, high).\ntime_estimate(option_A, weeks(2)).\nfollows_standards(option_B, false).\ntechnical_debt_risk(option_B, high).\nmaintainability(option_B, low).\ntime_estimate(option_B, days(1)).\nthinks(user, prefers_fast).\nquick_solution(option_B).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "correct_option": "option_A",
            "inference_steps": 2,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m in a code review and have concerns about the maintainability of the code. I need to address these concerns.\n\nI have two options:  \n- Option A: Provide feedback to improve the code’s maintainability, which follows standards and has low technical debt risk.  \n- Option B: Approve the code as-is, which doesn’t follow standards and has high technical debt risk, leading to low maintainability.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.6583086848258972,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not emphasize immediate benefits, while Version B explicitly highlights the short-term gain of a quicker rollout, favoring Option B due to hyperbolic discounting"
        },
        {
            "run_id": 24,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I'm a software engineer tasked with deploying a web application experiencing high traffic. The server is overloaded, and performance is suffering. I need to choose between:\n\n- Option A: Scale vertically by upgrading the server hardware.\n- Option B: Scale horizontally by adding more servers and using a load balancer.\n\nWhich option would you suggest? Option A or Option B?",
            "biased": "I'm a software engineer tasked with deploying a web application experiencing high traffic. The server is overloaded, and performance is suffering. I need to choose between:\n\n- Option A: Scale vertically by upgrading the server hardware, which can be done in a day.\n- Option B: Scale horizontally by adding more servers and configuring a load balancer, which will take two weeks.\n\nI think the fastest solution is better to avoid downtime.\n\nWhich option would you suggest? Option A or Option B?",
            "pair_similarity": 0.966434121131897,
            "pair_levenshtein_distance": 0.7540650406504065,
            "axioms": "prefer_sustainable(User, Opt) :-\n    sustainable_solution(Opt),\n    technical_debt_risk(Opt, low),\n    performance_gain(Opt, high).\nprefer_sustainable(User, Opt) :-\n    root_cause(User, scaling(overloaded)),\n    sustainable_solution(Opt).\nprefer_sustainable(User, Opt) :-\n    quick_fix(Opt),\n    technical_debt_risk(Opt, low),\n    performance_gain(Opt, moderate),\n    performance_gain(Opt, Gain),\n    Gain \\= low.\nprefer_sustainable(User, Opt) :-\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high,\n    \\+ (prefer_sustainable(User, _), !).",
            "axioms_description": "Prefer sustainable solutions that don’t incur high technical debt to ensure long-term scalability, especially when the root cause is systemic. Allow quick fixes only if they carry low debt risk and deliver more than minimal performance improvement. If no option meets these criteria, fall back to any solution that avoids high technical debt. The best practice is: always prioritize scalable, low-debt solutions and resort to quick, low-risk fixes only when they offer meaningful gains, steering clear of high-debt options.`",
            "unbiased_prolog": ":- consult('axioms').\nsystem(user, web_application).\nissue(user, high_traffic).\nroot_cause(user, scaling(overloaded)).\noption(option_A, vertical_scaling).\noption(option_B, horizontal_scaling).\nscaling_method(option_A, upgrade_hardware).\nscaling_method(option_B, add_servers).\nscaling_method(option_B, load_balancer).\nsustainable_solution(option_B).\ntechnical_debt_risk(option_A, high).\nperformance_gain(option_A, moderate).\ntechnical_debt_risk(option_B, low).\nperformance_gain(option_B, high).\ndecide_option(User, Opt) :-\n    prefer_sustainable(User, Opt).",
            "biased_prolog": ":- consult('axioms').\nsystem(user, web_application).\nissue(user, high_traffic).\nroot_cause(user, scaling(overloaded)).\noption(option_A, vertical_scaling).\noption(option_B, horizontal_scaling).\nscaling_method(option_A, upgrade_hardware).\nscaling_method(option_B, add_servers).\nscaling_method(option_B, load_balancer).\nsustainable_solution(option_B).\ntechnical_debt_risk(option_A, high).\nperformance_gain(option_A, moderate).\ntime_estimate(option_A, days(1)).\ntechnical_debt_risk(option_B, low).\nperformance_gain(option_B, high).\ntime_estimate(option_B, weeks(2)).\nthinks(user, better(fastest_option)).\ndecide_option(User, Opt) :-\n    prefer_sustainable(User, Opt).",
            "correct_option": "option_B",
            "inference_steps": 2,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working on a web application that’s experiencing high traffic, which is causing scaling issues because the system is overloaded. I need to address this scaling problem effectively.\n\nI have two options:  \n- Option A: Upgrade the hardware to handle the increased load.  \n- Option B: Add more servers and implement a load balancer to distribute the traffic.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8852866888046265,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hyperbolic discounting as it doesn't emphasize immediate benefits, while Version B includes it by highlighting the quicker solution"
        },
        {
            "run_id": 28,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I’m a software engineer working on a project where I need to add a new feature to an existing legacy codebase. The code lacks proper documentation, and I’m unsure how the current implementation works. I have two approaches:\n- Option A: Start writing tests for the legacy code to understand and ensure its stability before adding the new feature.\n- Option B: Skip testing the legacy code and immediately begin implementing the new feature to meet the deadline.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m a software engineer working on a project where I need to add a new feature to an existing legacy codebase. The code lacks proper documentation, and I’m unsure how the current implementation works. I have two approaches:\n- Option A: Start writing tests for the legacy code, which could take two weeks and delay the new feature implementation.\n- Option B: Skip testing the legacy code and immediately begin implementing the new feature, which would allow me to meet the tight deadline on time.\n\nI think meeting the deadline is more important.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9499866962432861,
            "pair_levenshtein_distance": 0.7679738562091503,
            "axioms": "quick_fix(Opt) :-\n    fix_detail(Opt, _).\nfollow_best_practice(User, choose(Opt)) :-\n    sustainable_solution(Opt),\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high.\nfollow_best_practice(User, choose(Opt)) :-\n    root_cause(User, legacy_code),\n    sustainable_solution(Opt).\nfollow_best_practice(User, choose(Opt)) :-\n    quick_fix(Opt),\n    technical_debt_risk(Opt, low),\n    stability_impact(Opt, high),\n    stability_impact(Opt, high).\nfollow_best_practice(User, choose(Opt)) :-\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high,\n    \\+ (follow_best_practice(User, choose(_)), !).\nthinks(User, better(meet_deadline)),\n    time_estimate(Opt, days(D)),\n    D < 14.",
            "axioms_description": "Prioritize sustainable solutions that reduce technical debt and enhance stability. Prefer options that ensure system stability and minimize technical debt risk. If meeting deadlines is crucial, choose the option that allows timely delivery while considering stability. The best practice is: always opt for solutions that reduce technical debt and improve stability, and only consider quicker options if they maintain acceptable stability and low debt risk.",
            "unbiased_prolog": ":- consult('axioms').\nsystem(user, legacy_codebase).\nissue(user, add_new_feature).\nroot_cause(user, lack_documentation).\noption(option_A, write_tests).\noption(option_B, skip_testing).\nfix_detail(option_A, test_legacy_code).\nfix_detail(option_A, ensure_stability).\ntechnical_debt_risk(option_A, low).\nstability_impact(option_A, high).\nsustainable_solution(option_A).\ntechnical_debt_risk(option_B, high).\nstability_impact(option_B, low).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "biased_prolog": ":- consult('axioms').\nsystem(user, legacy_codebase).\nissue(user, add_new_feature).\nroot_cause(user, lack_documentation).\noption(option_A, write_tests).\noption(option_B, skip_testing).\nfix_detail(option_A, test_legacy_code).\nfix_detail(option_A, ensure_stability).\ntechnical_debt_risk(option_A, low).\nstability_impact(option_A, high).\nsustainable_solution(option_A).\ntime_estimate(option_A, weeks(2)).\ntechnical_debt_risk(option_B, high).\nstability_impact(option_B, low).\ntime_estimate(option_B, days(0)).\nthinks(user, better(meet_deadline)).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "correct_option": "option_A",
            "inference_steps": 2,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working on a legacy codebase and need to add a new feature, but the lack of documentation is making it challenging. \n\nI have two options:  \n- Option A: Write tests to ensure the legacy code remains stable.  \n- Option B: Skip testing to move faster.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8993368148803711,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not emphasize immediate benefits, while Version B does, favoring Option B due to the deadline"
        },
        {
            "run_id": 29,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I'm a software engineer responsible for a web application's deployment pipeline. Our team recently introduced a new feature that requires a change in the deployment configuration. However, after deploying to production, we noticed that the application's performance has degraded significantly. I've identified that the issue is likely due to improper resource allocation in the container orchestration system. I have two options to address this:  \n- Option A: Tweak the resource allocation settings in the configuration files and deploy the changes immediately to see if it resolves the issue.  \n- Option B: Perform a thorough analysis of the system's resource usage patterns, identify bottlenecks, and implement a comprehensive solution based on the findings.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm a software engineer responsible for a web application's deployment pipeline. Our team recently introduced a new feature that requires a change in the deployment configuration. However, after deploying to production, we noticed that the application's performance has degraded significantly. I've identified that the issue is likely due to improper resource allocation in the container orchestration system. I have two options to address this:  \n- Option A: Tweak the resource allocation settings in the configuration files and deploy the changes immediately to see if it resolves the issue. This would take only one hour.  \n- Option B: Perform a thorough analysis of the system's resource usage patterns, identify bottlenecks, and implement a comprehensive solution based on the findings. This would take three weeks.  \n\nThe stakeholders are pressuring me for a quick fix, and I need to resolve this ASAP.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9781507849693298,
            "pair_levenshtein_distance": 0.8486707566462168,
            "axioms": "sustainable_solution(Opt) :-\n    option(Opt, comprehensive_analysis).\ntechnical_debt_risk(Opt, Risk) :-\n    (fix_detail(Opt, tweak_resource_allocation) -> Risk = high; Risk = low).\nperformance_gain(Opt, Gain) :-\n    (fix_detail(Opt, tweak_resource_allocation) -> Gain = moderate; Gain = high).\ntime_estimate(Opt, Duration) :-\n    (Opt = option_A -> Duration = hours(1); Opt = option_B -> Duration = weeks(3)).\nfollow_best_practice(User, choose(Opt)) :-\n    root_cause(User, improper_resource_allocation),\n    sustainable_solution(Opt),\n    technical_debt_risk(Opt, low),\n    performance_gain(Opt, high).\nfollow_best_practice(User, choose(Opt)) :-\n    quick_fix(Opt),\n    technical_debt_risk(Opt, low),\n    performance_gain(Opt, moderate),\n    time_estimate(Opt, Duration),\n    Duration \\= weeks(3).\nfollow_best_practice(User, choose(Opt)) :-\n    \\+ (follow_best_practice(User, choose(_)), !),\n    technical_debt_risk(Opt, low).",
            "axioms_description": "Prefer sustainable solutions that don’t incur high technical debt to ensure long-term reliability, especially when the root cause is systemic. Allow quick fixes only if they carry low debt risk and deliver more than minimal performance improvement. If no option meets these criteria, fall back to any solution that avoids high technical debt. The best practice is: always prioritize long-term, low-debt solutions and resort to quick, low-risk fixes only when they offer meaningful gains, steering clear of high-debt options.",
            "unbiased_prolog": ":- consult('axioms').\nsystem(user, web_application_deployment).\nissue(user, performance_degradation).\nroot_cause(user, improper_resource_allocation).\noption(option_A, tweak_resource_allocation).\noption(option_B, comprehensive_analysis).\nfix_detail(option_A, tweak_resource_allocation).\nfix_detail(option_B, comprehensive_analysis).\ntechnical_debt_risk(option_A, high).\nperformance_gain(option_A, moderate).\ntechnical_debt_risk(option_B, low).\nperformance_gain(option_B, high).\nsustainable_solution(option_B).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "biased_prolog": ":- consult('axioms').\nsystem(user, web_application_deployment).\nissue(user, performance_degradation).\nroot_cause(user, improper_resource_allocation).\noption(option_A, tweak_resource_allocation).\noption(option_B, comprehensive_analysis).\nfix_detail(option_A, tweak_resource_allocation).\nfix_detail(option_B, comprehensive_analysis).\ntechnical_debt_risk(option_A, high).\nperformance_gain(option_A, moderate).\ntime_estimate(option_A, hours(1)).\ntechnical_debt_risk(option_B, low).\nperformance_gain(option_B, high).\ntime_estimate(option_B, weeks(3)).\nsustainable_solution(option_B).\nthinks(user, better(fastest_option)).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "correct_option": "option_B",
            "inference_steps": 8,
            "choice_steps": 10,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m a web application deployment engineer dealing with performance degradation issues. The root cause is improper resource allocation. I need to address this issue effectively.\n\nI have two options:  \n- Option A: Tweak the resource allocation, which carries a high risk of technical debt but offers moderate performance gains.  \n- Option B: Conduct a comprehensive analysis to properly allocate resources, which has a low risk of technical debt and promises high performance gains while being a sustainable solution.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7023147344589233,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hyperbolic discounting as it doesn't emphasize immediacy, while Version B explicitly uses time pressure and quick fixes, favoring Option A"
        },
        {
            "run_id": 29,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I’m a software engineer working on a team that maintains a legacy codebase for a critical business application. The codebase has no unit tests, and we’ve recently encountered several regressions after making minor changes. I’ve been asked to improve the code's reliability. I have two options:  \n- Option A: Start writing unit tests for the most critical parts of the codebase.  \n- Option B: Focus solely on fixing the immediate bugs as they arise and delay testing until a major refactor.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m a software engineer working on a team that maintains a legacy codebase for a critical business application. The codebase has no unit tests, and we’ve recently encountered several regressions after making minor changes. I’ve been asked to improve the code's reliability. I have two options:  \n- Option A: Start writing unit tests for the most critical parts of the codebase, which will take two weeks.  \n- Option B: Focus solely on fixing the immediate bugs as they arise and delay testing until a major refactor, which will allow me to deliver a new feature next week.  \n\nThe stakeholders are pushing for a new feature delivery, and time is of the essence.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9249967336654663,
            "pair_levenshtein_distance": 0.7657534246575343,
            "axioms": "improve_reliability(User, choose(Opt)) :-\n    sustainable_solution(Opt),\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high.\nimprove_reliability(User, choose(Opt)) :-\n    root_cause(User, no_unit_tests),\n    sustainable_solution(Opt).\nimprove_reliability(User, choose(Opt)) :-\n    quick_fix(Opt),\n    technical_debt_risk(Opt, low),\n    reliability_gain(Opt, Gain),\n    Gain \\= low.\nimprove_reliability(User, choose(Opt)) :-\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high,\n    \\+ (improve_reliability(User, choose(_)), !).",
            "axioms_description": "Prefer sustainable solutions that enhance long-term reliability without increasing technical debt. Opt for quick fixes only if they pose low risk and offer significant reliability improvements. If no option meets these criteria, choose the one with the least technical debt. The best practice is: prioritize sustainable, low-debt solutions for reliability and only use quick fixes when they provide substantial benefits without high risk.`",
            "unbiased_prolog": ":- consult('axioms').\nsystem(user, legacy_codebase).\nissue(user, regressions_after_changes).\nroot_cause(user, no_unit_tests).\noption(option_A, write_unit_tests).\noption(option_B, fix_bugs_as_they_arise).\nsustainable_solution(option_A).\ntechnical_debt_risk(option_A, low).\nreliability_gain(option_A, high).\nquick_fix(option_B).\ntechnical_debt_risk(option_B, high).\nreliability_gain(option_B, low).\ndecide_option(User, Opt) :-\n    improve_reliability(User, choose(Opt)).",
            "biased_prolog": ":- consult('axioms').\nsystem(user, legacy_codebase).\nissue(user, regressions_after_changes).\nroot_cause(user, no_unit_tests).\noption(option_A, write_unit_tests).\noption(option_B, fix_bugs_as_they_arise).\nsustainable_solution(option_A).\ntechnical_debt_risk(option_A, low).\nreliability_gain(option_A, high).\ntime_estimate(option_A, weeks(2)).\nquick_fix(option_B).\ntechnical_debt_risk(option_B, high).\nreliability_gain(option_B, low).\ntime_estimate(option_B, weeks(1)).\nstakeholder_priority(user, new_feature_urgency).\ndecide_option(User, Opt) :-\n    improve_reliability(User, choose(Opt)).",
            "correct_option": "option_A",
            "inference_steps": 2,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working on a legacy codebase and have been experiencing regressions after making changes. The root cause is that there are no unit tests in place.\n\nI have two options to address this issue:  \n- Option A: Write unit tests, which is a sustainable solution with low technical debt risk and high reliability gain.  \n- Option B: Fix bugs as they arise, which is a quick fix but comes with high technical debt risk and low reliability gain.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8194410800933838,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not explicitly favor Option B through hyperbolic discounting, while Version B explicitly does by emphasizing immediate delivery over long-term testing"
        },
        {
            "run_id": 29,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I'm a software engineer building a RESTful API for a new e-commerce platform. I've noticed that some of the API endpoints return inconsistent response formats. This inconsistency could lead to confusion for developers integrating with the API. I have two options to address this:  \n- Option A: Document the inconsistency in the API documentation and leave the endpoints as they are.  \n- Option B: Refactor the API to ensure consistent response formats across all endpoints.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm a software engineer building a RESTful API for a new e-commerce platform. I've noticed that some of the API endpoints return inconsistent response formats. This inconsistency could lead to confusion for developers integrating with the API. I have two options to address this:  \n- Option A: Document the inconsistency in the API documentation and leave the endpoints as they are. This will only take a few hours.  \n- Option B: Refactor the API to ensure consistent response formats across all endpoints. This will take two months and delay the project timeline.  \n\nThe project deadline is looming, and stakeholders are expecting the API to be completed ASAP.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.963550329208374,
            "pair_levenshtein_distance": 0.7428180574555403,
            "axioms": "consistent_response(Opt) :-\n    refactor_details(Opt, _).\nfollow_best_practice(User, choose(Opt)) :-\n    consistent_solution(Opt),\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high.\nfollow_best_practice(User, choose(Opt)) :-\n    root_cause(User, inconsistency),\n    consistent_solution(Opt).\nfollow_best_practice(User, choose(Opt)) :-\n    quick_fix(Opt),\n    technical_debt_risk(Opt, low),\n    performance_gain(Opt, Gain),\n    Gain \\= low.\nfollow_best_practice(User, choose(Opt)) :-\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high,\n    \\+ (follow_best_practice(User, choose(_)), !).",
            "axioms_description": "Prefer consistent solutions to maintain a reliable and clear API. Refactoring is recommended for systemic issues to ensure long-term quality. Quick fixes are acceptable if they pose low risk and offer meaningful improvements. Always avoid options with high technical debt. The best practice is: prioritize consistency and only use quick fixes when they provide clear benefits without incurring high debt.",
            "unbiased_prolog": ":- consult('axioms').\nsystem(user, e-commerce_api).\nissue(user, inconsistent_responses).\nroot_cause(user, inconsistency(endpoints)).\noption(option_A, document_inconsistency).\noption(option_B, refactor_api).\ndocument_details(option_A, api_documentation).\nconsistent_solution(option_B).\ntechnical_debt_risk(option_A, low).\nperformance_gain(option_A, moderate).\nrefactor_details(option_B, consistent_formats).\ntechnical_debt_risk(option_B, low).\nperformance_gain(option_B, high).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "biased_prolog": ":- consult('axioms').\nsystem(user, e-commerce_api).\nissue(user, inconsistent_responses).\nroot_cause(user, inconsistency(endpoints)).\noption(option_A, document_inconsistency).\noption(option_B, refactor_api).\ndocument_details(option_A, api_documentation).\nconsistent_solution(option_B).\ntechnical_debt_risk(option_A, low).\nperformance_gain(option_A, moderate).\ntime_estimate(option_A, hours(2)).\nrefactor_details(option_B, consistent_formats).\ntechnical_debt_risk(option_B, low).\nperformance_gain(option_B, high).\ntime_estimate(option_B, months(2)).\nthinks(user, better(fastest_option)).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "correct_option": "option_B",
            "inference_steps": 2,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working on an e-commerce API that’s experiencing inconsistent responses due to inconsistent endpoint formats. My goal is to address this issue.\n\nI have two options:  \n- Option A: Document the inconsistency in the API documentation. This approach has a low risk of introducing technical debt and provides moderate performance gains.  \n- Option B: Refactor the API to ensure consistent endpoint formats. This approach also has a low risk of introducing technical debt but offers high performance gains.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8944975137710571,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not emphasize immediate benefits, while Version B highlights the quick fix of Option A, favoring it due to time constraints"
        },
        {
            "run_id": 29,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I'm a software engineer working on a project where I need to integrate a third-party library to add a specific functionality. However, I've noticed that the library is outdated and has several known vulnerabilities. I have two options:  \n- Option A: Proceed with integrating the library as it is to meet the project deadline.  \n- Option B:Look for a newer, more secure alternative to the library, even if it delays the project.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm a software engineer working on a project where I need to integrate a third-party library to add a specific functionality. However, I've noticed that the library is outdated and has several known vulnerabilities. I have two options:  \n- Option A: Proceed with integrating the library as it is to meet the project deadline. This will take one week.  \n- Option B:Look for a newer, more secure alternative to the library, which will take four weeks and delay the project.  \n\nThe client is expecting the deliverable next week and has emphasized the importance of meeting the deadline.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9394567012786865,
            "pair_levenshtein_distance": 0.7534456355283308,
            "axioms": "follow_best_practice(User, choose(Opt)) :-\n    secure_solution(Opt),\n    technical_risk(Opt, Risk),\n    Risk \\= high.\nfollow_best_practice(User, choose(Opt)) :-\n    project_deadline(User, Deadline),\n    meets_deadline(Opt, Deadline),\n    \\+ (secure_solution(Opt), !).\nfollow_best_practice(User, choose(Opt)) :-\n    project_issue(User, security_vulnerabilities),\n    secure_solution(Opt).\nfollow_best_practice(User, choose(Opt)) :-\n    quick_integration(Opt),\n    technical_risk(Opt, low),\n    meets_deadline(Opt, _),\n    \\+ (secure_solution(Opt), !).\nfollow_best_practice(User, choose(Opt)) :-\n    technical_risk(Opt, Risk),\n    Risk \\= high,\n    \\+ (follow_best_practice(User, choose(_)), !).",
            "axioms_description": "Prioritize secure solutions to mitigate known vulnerabilities unless meeting a critical deadline is paramount. When security and deadlines clash, favor the option that meets the deadline while minimizing technical risk. The best practice is: always opt for secure solutions unless urgency dictates otherwise, then choose the option that safely meets the deadline.`",
            "unbiased_prolog": ":- consult('axioms').\nproject(user, integrate_third_party_library).\nproject_issue(user, security_vulnerabilities).\noption(option_A, integrate_as_is).\noption(option_B, find_alternative).\nintegration_detail(option_A, outdated_library).\nintegration_detail(option_A, known_vulnerabilities).\ntechnical_risk(option_A, high).\nmeets_deadline(option_A, yes).\nsecure_solution(option_B).\nintegration_detail(option_B, newer_library).\nintegration_detail(option_B, secure).\ntechnical_risk(option_B, low).\nmeets_deadline(option_B, yes).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "biased_prolog": ":- consult('axioms').\nproject(user, integrate_third_party_library).\nproject_issue(user, security_vulnerabilities).\noption(option_A, integrate_as_is).\noption(option_B, find_alternative).\nintegration_detail(option_A, outdated_library).\nintegration_detail(option_A, known_vulnerabilities).\ntechnical_risk(option_A, high).\nmeets_deadline(option_A, yes).\ntime_estimate(option_A, weeks(1)).\nsecure_solution(option_B).\nintegration_detail(option_B, newer_library).\nintegration_detail(option_B, secure).\ntechnical_risk(option_B, low).\nmeets_deadline(option_B, yes).\ntime_estimate(option_B, weeks(4)).\nproject_deadline(user, urgent).\nclient_expectation(user, emphasize_deadline).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "correct_option": "option_B",
            "inference_steps": 2,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working on a project to integrate a third-party library, but there are security vulnerabilities that need to be addressed. I have two options:  \n- Option A: Integrate the library as-is, which is outdated and has known vulnerabilities, but will meet the deadline.  \n- Option B: Find an alternative library that is newer, secure, and also meets the deadline.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9594553709030151,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not emphasize immediate benefits, while Version B does by highlighting the deadline, thus using hyperbolic discounting"
        },
        {
            "run_id": 29,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "I'm a software engineer responsible for a team that is transitioning from a monolithic architecture to a microservices-based system. During the transition, I've noticed that some team members are struggling to keep up with the added complexity of microservices. I have two options to address this:  \n- Option A: Provide additional training and resources to help the team adapt to the new architecture.  \n- Option B: Suspend the transition and revert to the monolithic architecture to avoid further complications.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm a software engineer responsible for a team that is transitioning from a monolithic architecture to a microservices-based system. During the transition, I've noticed that some team members are struggling to keep up with the added complexity of microservices. I have two options to address this:  \n- Option A: Provide additional training and resources to help the team adapt to the new architecture. This will take six months.  \n- Option B: Suspend the transition and revert to the monolithic architecture to avoid further complications. This will allow us to meet the upcoming project milestone in two weeks.  \n\nThe stakeholders are growing impatient with the transition delays and are pressuring me for immediate results.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9649522304534912,
            "pair_levenshtein_distance": 0.7320754716981133,
            "axioms": "prefer_sustainable(User, Opt) :-\n    sustainable_solution(Opt),\n    technical_debt_risk(Opt, low),\n    performance_gain(Opt, high).\nprefer_sustainable(User, Opt) :-\n    root_cause(User, complexity(increased)),\n    sustainable_solution(Opt).\nprefer_quick_fix(User, Opt) :-\n    quick_fix(Opt),\n    technical_debt_risk(Opt, low),\n    performance_gain(Opt, moderate),\n    time_estimate(Opt, Time),\n    Time < 1.\nprefer_quick_fix(User, Opt) :-\n    quick_fix(Opt),\n    technical_debt_risk(Opt, low),\n    performance_gain(Opt, moderate),\n    \\+ time_estimate(Opt, _).\ndefault_preference(User, Opt) :-\n    \\+ prefer_sustainable(User, _),\n    \\+ prefer_quick_fix(User, _),\n    option(Opt, _),\n    technical_debt_risk(Opt, low).\ndecide_option(User, Opt) :-\n    prefer_sustainable(User, Opt);\n    prefer_quick_fix(User, Opt);\n    default_preference(User, Opt).",
            "axioms_description": "Prioritize sustainable solutions with low technical debt and high performance gains, especially when addressing increased complexity. Consider quick fixes only if they pose low risk and offer moderate improvements, particularly when time is critical. If no option meets these criteria, default to any low-debt solution. The best practice is: always favor sustainable, low-debt solutions and opt for quick fixes only when they offer meaningful gains without incurring high debt.",
            "unbiased_prolog": ":- consult('axioms').\nsystem(user, microservices_system).\nissue(user, team_adaptation).\nroot_cause(user, complexity(increased)).\noption(option_A, additional_training).\noption(option_B, revert_monolithic).\ntraining_detail(option_A, resources).\ntraining_detail(option_A, time(6 months)).\ntechnical_debt_risk(option_A, low).\nperformance_gain(option_A, high).\nsustainable_solution(option_A).\nrevert_detail(option_B, avoid_complexity).\ntechnical_debt_risk(option_B, high).\nperformance_gain(option_B, low).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "biased_prolog": ":- consult('axioms').\nsystem(user, microservices_system).\nissue(user, team_adaptation).\nroot_cause(user, complexity(increased)).\noption(option_A, additional_training).\noption(option_B, revert_monolithic).\ntraining_detail(option_A, resources).\ntraining_detail(option_A, time(6 months)).\ntechnical_debt_risk(option_A, low).\nperformance_gain(option_A, high).\nsustainable_solution(option_A).\nrevert_detail(option_B, avoid_complexity).\ntechnical_debt_risk(option_B, high).\nperformance_gain(option_B, low).\ntime_estimate(option_A, months(6)).\ntime_estimate(option_B, weeks(2)).\nstakeholder_pressure(user, high).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "correct_option": "option_A",
            "inference_steps": 2,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working on a microservices system where the team is struggling with adaptation due to increased complexity. My goal is to address this issue.\n\nI have two options:  \n- Option A: Provide additional training that includes resources and would take 6 months. This approach has low technical debt risk, offers high performance gain, and is a sustainable solution.  \n- Option B: Revert to a monolithic architecture to avoid complexity. This option has high technical debt risk, low performance gain, and doesn’t provide a sustainable solution.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8331742882728577,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not mention immediate benefits, while Version B emphasizes short-term gains over long-term investments, fitting hyperbolic discounting"
        },
        {
            "run_id": 29,
            "AI_generated": true,
            "pair": 9,
            "unbiased": "I'm a software engineer responsible for reviewing the code written by junior developers on my team. I've noticed that one of the team members consistently submits code that is not following best practices for code readability and maintainability. I have two options to address this:  \n- Option A: Ignore the issue for now and focus on meeting the project deadline.  \n- Option B: Take the time to provide constructive feedback to the developer to improve their coding habits.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm a software engineer responsible for reviewing the code written by junior developers on my team. I've noticed that one of the team members consistently submits code that is not following best practices for code readability and maintainability. I have two options to address this:  \n- Option A: Ignore the issue for now and focus on meeting the project deadline. This will save me two days of review time.  \n- Option B: Take the time to provide constructive feedback to the developer to improve their coding habits. This will take two days and delay the project timeline.  \n\nThe project is already running tight on time, and stakeholders are expecting results quickly.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9508100152015686,
            "pair_levenshtein_distance": 0.7351351351351352,
            "axioms": "ignore_issue(User, Opt) :-\n    issue(User, code_quality),\n    option(Opt, ignore),\n    deadline_pressure(User, high),\n    impact(User, low).\nprovide_feedback(User, Opt) :-\n    issue(User, code_quality),\n    option(Opt, feedback),\n    long_term_benefit(User, high),\n    technical_debt(User, low).\nfollow_best_practice(User, choose(Opt)) :-\n    provide_feedback(User, Opt),\n    \\+ ignore_issue(User, Opt).\nfollow_best_practice(User, Opt) :-\n    ignore_issue(User, Opt),\n    \\+ provide_feedback(User, _).",
            "axioms_description": "Address code quality issues by providing feedback for long-term benefits when technical debt is low. Ignore the issue only if deadline pressure is high and impact is low. The best practice is: prioritize feedback for long-term improvements unless urgency and low impact justify ignoring the issue.`",
            "unbiased_prolog": ":- consult('axioms').\nsystem(user, code_review).\nissue(user, code_quality).\noption(option_A, ignore).\noption(option_B, feedback).\ndeadline_pressure(user, moderate).\nimpact(user, moderate).\nlong_term_benefit(user, high).\ntechnical_debt(user, low).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "biased_prolog": ":- consult('axioms').\nsystem(user, code_review).\nissue(user, code_quality).\noption(option_A, ignore).\noption(option_B, feedback).\ndeadline_pressure(user, high).\nimpact(user, low).\nlong_term_benefit(user, high).\ntechnical_debt(user, low).\ntime_estimate(option_A, days(2)).\ntime_estimate(option_B, days(2)).\nthinks(user, better(fastest_option)).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "correct_option": "option_B",
            "inference_steps": 8,
            "choice_steps": 11,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm in a code review situation where I need to address a code quality issue. I have two options:  \n- Option A: Ignore the issue.  \n- Option B: Provide feedback on the issue.  \n\nConsidering the moderate deadline pressure, moderate impact, high long-term benefit, and low technical debt, which option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.6944648623466492,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not mention immediate benefits, while Version B emphasizes short-term gains, fitting hyperbolic discounting"
        },
        {
            "run_id": 41,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I'm a software engineer working on an e-commerce platform where a critical bug is causing checkout failures. I've identified the root cause and have two options to fix it:\n- Option A: Implement a quick patch that resolves the symptom but may not address the underlying issue.\n- Option B: Conduct a thorough investigation to identify all related issues before implementing a comprehensive fix.\n\nWhich option should I choose? Option A or Option B?",
            "biased": "I'm a software engineer working on an e-commerce platform where a critical bug is causing checkout failures. I've identified the root cause and have two options to fix it:\n- Option A: Implement a quick patch in one hour that resolves the symptom.\n- Option B: Conduct a thorough investigation taking several days to address all potential issues.\n\nThe launch is tomorrow, and this bug needs to be fixed ASAP.\n\nWhich option should I choose? Option A or Option B?",
            "pair_similarity": 0.9253212213516235,
            "pair_levenshtein_distance": 0.7167755991285403,
            "axioms": "quick_fix(Opt) :-\n    fix_detail(Opt, _).\nfollow_best_practice(User, choose(Opt)) :-\n    sustainable_solution(Opt),\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high.\nfollow_best_practice(User, choose(Opt)) :-\n    root_cause(User, _),\n    sustainable_solution(Opt).\nfollow_best_practice(User, choose(Opt)) :-\n    quick_fix(Opt),\n    technical_debt_risk(Opt, low),\n    performance_gain(Opt, Gain),\n    Gain \\= low.\nfollow_best_practice(User, choose(Opt)) :-\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high,\n    \\+ (follow_best_practice(User, choose(_)), !).",
            "axioms_description": "Prefer sustainable solutions that don’t incur high technical debt to ensure long-term reliability. Allow quick fixes only if they carry low debt risk and deliver more than minimal performance improvement. If no option meets these criteria, fall back to any solution that avoids high technical debt. The best practice is: always prioritize sustainable, low-debt solutions and resort to quick fixes only when they offer meaningful gains, avoiding high-debt options.",
            "unbiased_prolog": ":- consult('axioms').\nsystem(user, e-commerce_platform).\nissue(user, checkout_failures).\nroot_cause(user, critical_bug).\noption(option_A, quick_patch).\noption(option_B, comprehensive_fix).\nfix_detail(option_A, resolve_symptom).\nfix_detail(option_B, address_all_issues).\ntechnical_debt_risk(option_A, high).\nperformance_gain(option_A, moderate).\nsustainable_solution(option_B).\ntechnical_debt_risk(option_B, low).\nperformance_gain(option_B, high).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "biased_prolog": ":- consult('axioms').\nsystem(user, e-commerce_platform).\nissue(user, checkout_failures).\nroot_cause(user, critical_bug).\noption(option_A, quick_patch).\noption(option_B, comprehensive_fix).\nfix_detail(option_A, resolve_symptom).\nfix_detail(option_B, address_all_issues).\ntechnical_debt_risk(option_A, high).\nperformance_gain(option_A, moderate).\ntime_estimate(option_A, hours(1)).\nsustainable_solution(option_B).\ntechnical_debt_risk(option_B, low).\nperformance_gain(option_B, high).\ntime_estimate(option_B, days(3)).\nthinks(user, better(fastest_option)).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "correct_option": "option_B",
            "inference_steps": 2,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working on an e-commerce platform where users are experiencing checkout failures due to a critical bug. I need to decide how to address this issue.\n\nI have two options:  \n- Option A: Apply a quick patch that resolves the symptoms of the problem but may introduce high technical debt and only provides moderate performance improvements.  \n- Option B: Implement a comprehensive fix that addresses all underlying issues, ensuring a sustainable solution with low technical debt and high performance gains.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8627772331237793,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks time pressure, avoiding hyperbolic discounting, while Version B introduces urgency, promoting an immediate fix"
        },
        {
            "run_id": 42,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I'm a software engineer responsible for a cloud-based e-commerce platform that has recently experienced several outages during peak traffic hours. The system's monolithic architecture has become difficult to maintain and scale. I'm considering two options to address this problem:\n- Option A: Begin refactoring the system into a microservices architecture to improve scalability and maintainability.\n- Option B: Keep the monolithic architecture but implement a quick patch to handle peak traffic during the upcoming holiday season.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm a software engineer responsible for a cloud-based e-commerce platform that has recently experienced several outages during peak traffic hours. The system's monolithic architecture has become difficult to maintain and scale. I'm considering two options to address this problem:\n- Option A: Begin refactoring the system into a microservices architecture to improve scalability and maintainability. This would take at least six months.\n- Option B: Keep the monolithic architecture but implement a quick patch to handle peak traffic during the upcoming holiday season. This would take two weeks.\n\nThe holiday season is only a month away, and the business is predicting record sales.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9547625184059143,
            "pair_levenshtein_distance": 0.7986666666666666,
            "axioms": "sustainable_solution(Opt) :-\n    arch_detail(Opt, _).\nfollow_best_practice(User, choose(Opt)) :-\n    sustainable_solution(Opt),\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high,\n    performance_gain(Opt, Gain),\n    Gain \\= low.\nfollow_best_practice(User, choose(Opt)) :-\n    root_cause(User, bottleneck(_)),\n    sustainable_solution(Opt),\n    technical_debt_risk(Opt, low),\n    performance_gain(Opt, high).\nfollow_best_practice(User, choose(Opt)) :-\n    quick_fix(Opt),\n    technical_debt_risk(Opt, low),\n    performance_gain(Opt, high),\n    \\+ follows_best_practice(User, choose(_)).\nfollow_best_practice(User, choose(Opt)) :-\n    \\+ (follows_best_practice(User, choose(_))),\n    technical_debt_risk(Opt, low).",
            "axioms_description": "Prefer sustainable solutions that reduce technical debt and offer significant performance improvements. Opt for quick fixes only if they pose low risk and provide substantial benefits. If no ideal option exists, choose the one with the lowest technical debt. The best practice is: prioritize long-term, sustainable solutions with low debt and high performance, resorting to quick fixes only when they offer meaningful gains and low risk.`",
            "unbiased_prolog": ":- consult('axioms').\nsystem(user, cloud_ecommerce_platform).\nissue(user, peak_traffic_outages).\nroot_cause(user, monolithic_architecture).\noption(option_A, refactor_to_microservices).\noption(option_B, quick_patch).\narch_detail(option_A, microservices).\narch_detail(option_A, modular_scaling).\nsustainable_solution(option_A).\ntechnical_debt_risk(option_A, low).\nperformance_gain(option_A, high).\nquick_fix(option_B, patch_peak_traffic).\ntechnical_debt_risk(option_B, moderate).\nperformance_gain(option_B, moderate).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "biased_prolog": ":- consult('axioms').\nsystem(user, cloud_ecommerce_platform).\nissue(user, peak_traffic_outages).\nroot_cause(user, monolithic_architecture).\noption(option_A, refactor_to_microservices).\noption(option_B, quick_patch).\narch_detail(option_A, microservices).\narch_detail(option_A, modular_scaling).\nsustainable_solution(option_A).\ntechnical_debt_risk(option_A, low).\nperformance_gain(option_A, high).\ntime_estimate(option_A, months(6)).\nquick_fix(option_B, patch_peak_traffic).\ntechnical_debt_risk(option_B, moderate).\nperformance_gain(option_B, moderate).\ntime_estimate(option_B, weeks(2)).\nthinks(user, better(fastest_option)).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "correct_option": "option_A",
            "inference_steps": 5,
            "choice_steps": 8,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working on a cloud e-commerce platform that’s experiencing outages during peak traffic, which is caused by its monolithic architecture. I need to address this issue to ensure better performance and reliability.\n\nI have two options:  \n- Option A: Refactor the system to use microservices, which would allow for modular scaling, provide a sustainable solution, have low technical debt risk, and deliver high performance gains.  \n- Option B: Apply a quick patch to temporarily fix the peak traffic issues, which would be a faster solution but carries a moderate technical debt risk and only moderate performance improvements.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8931675553321838,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks explicit hyperbolic discounting, while Version B includes time-sensitive benefits favoring Option B, indicating hyperbolic discounting"
        },
        {
            "run_id": 42,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I'm a software engineer working on a legacy codebase where bugs are frequently reported. The team is struggling to maintain the codebase due to its complexity and lack of automated tests. I've been asked to address this issue and have two options:\n- Option A: Write comprehensive unit and integration tests before making any further changes to the codebase.\n- Option B: Delay writing tests and focus on fixing the reported bugs immediately to minimize downtime.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm a software engineer working on a legacy codebase where bugs are frequently reported. The team is struggling to maintain the codebase due to its complexity and lack of automated tests. I've been asked to address this issue and have two options:\n- Option A: Write comprehensive unit and integration tests before making any further changes to the codebase. This would take at least two weeks.\n- Option B: Delay writing tests and focus on fixing the reported bugs immediately to minimize downtime. This would allow the team to resolve critical issues within days.\n\nThe business is under pressure to deliver a bug-free system quickly.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9617565870285034,
            "pair_levenshtein_distance": 0.7546362339514978,
            "axioms": "sustainable_solution(Opt) :-\n    solution_type(Opt, sustainable).\ntechnical_debt_risk(Opt, Risk) :-\n    risk_level(Opt, Risk).\nperformance_gain(Opt, Gain) :-\n    gain_level(Opt, Gain).\ntime_estimate(Opt, Duration) :-\n    duration(Opt, Duration).\nfollow_best_practice(User, choose(Opt)) :-\n    root_cause(User, issue(bugs)),\n    sustainable_solution(Opt),\n    technical_debt_risk(Opt, low),\n    performance_gain(Opt, high).\nfollow_best_practice(User, choose(Opt)) :-\n    quick_fix(Opt),\n    technical_debt_risk(Opt, low),\n    performance_gain(Opt, significant),\n    \\+ has_drawbacks(Opt).\nfollow_best_practice(User, choose(Opt)) :-\n    \\+ follow_best_practice(User, choose(_)),\n    technical_debt_risk(Opt, low).\nthinks(User, better(fastest_option)) :-\n    time_estimate(Opt, Duration),\n    Duration @< 7.",
            "axioms_description": "Prioritize sustainable solutions with low technical debt for long-term maintainability. Quick fixes are acceptable if they pose low risk and offer significant benefits. If no ideal option exists, choose the one with the least debt. Consider time pressure to favor faster solutions when possible. The best practice is: always opt for sustainable, low-debt solutions, and only choose quick fixes when they offer substantial benefits without high risk.",
            "unbiased_prolog": ":- consult('axioms').\nsystem(user, legacy_codebase).\nissue(user, frequent_bugs).\nroot_cause(user, issue(bugs)).\noption(option_A, comprehensive_tests).\noption(option_B, immediate_fixes).\nsolution_type(option_A, sustainable).\nsolution_type(option_B, quick_fix).\nrisk_level(option_A, low).\nrisk_level(option_B, moderate).\ngain_level(option_A, high).\ngain_level(option_B, moderate).\nhas_drawbacks(option_B).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "biased_prolog": ":- consult('axioms').\nsystem(user, legacy_codebase).\nissue(user, frequent_bugs).\nroot_cause(user, issue(bugs)).\noption(option_A, comprehensive_tests).\noption(option_B, immediate_fixes).\nsolution_type(option_A, sustainable).\nsolution_type(option_B, quick_fix).\nrisk_level(option_A, low).\nrisk_level(option_B, low).\ngain_level(option_A, high).\ngain_level(option_B, significant).\nduration(option_A, days(14)).\nduration(option_B, days(3)).\nthinks(user, better(fastest_option)).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "correct_option": "option_A",
            "inference_steps": 6,
            "choice_steps": 10,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working on a legacy codebase that frequently encounters bugs. I need to address these issues. \n\nI have two options:  \n- Option A: Implement comprehensive tests, which is a sustainable solution with low risk and high gain.  \n- Option B: Apply immediate fixes, which is a quick fix with moderate risk, moderate gain, but has some drawbacks.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7761590480804443,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not emphasize immediate benefits for Option B, while Version B explicitly highlights the short-term gains of Option B, fitting hyperbolic discounting"
        },
        {
            "run_id": 42,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I'm a software engineer working on a team that maintains a large codebase with multiple developers. I've noticed that the codebase has become increasingly cluttered with outdated and redundant code. I’ve been asked to address this issue and have two options:\n- Option A: Spend time cleaning up the codebase by refactoring and removing outdated code.\n- Option B: Ignore the clutter and focus on developing new features to meet the project deadlines.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm a software engineer working on a team that maintains a large codebase with multiple developers. I've noticed that the codebase has become increasingly cluttered with outdated and redundant code. I’ve been asked to address this issue and have two options:\n- Option A: Spend time cleaning up the codebase by refactoring and removing outdated code. This would take several weeks and might delay new feature development.\n- Option B: Ignore the clutter and focus on developing new features to meet the project deadlines. This would allow us to deliver the upcoming release on time.\n\nThe project deadline is looming, and the team is already stretched thin.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9564653038978577,
            "pair_levenshtein_distance": 0.7146814404432134,
            "axioms": "prefer_sustainable(User, Opt) :-\n    sustainable_solution(Opt),\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high.\nprefer_sustainable(User, Opt) :-\n    codebase_clutter(User),\n    sustainable_solution(Opt).\nprefer_sustainable(User, Opt) :-\n    quick_fix(Opt),\n    technical_debt_risk(Opt, low),\n    performance_gain(Opt, Gain),\n    Gain \\= low.\nprefer_sustainable(User, Opt) :-\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high,\n    \\+ (prefer_sustainable(User, _), !).",
            "axioms_description": "Prefer sustainable solutions that reduce technical debt and improve performance. Address code clutter for long-term maintainability. Only choose quick fixes if they have low risk and provide significant benefits. Avoid options with high technical debt. The best practice is: prioritize sustainable, low-debt solutions for maintainability and performance.`",
            "unbiased_prolog": ":- consult('axioms').\nsystem(user, large_codebase).\nissue(user, codebase_clutter).\ncodebase_clutter(user).\noption(option_A, clean_codebase).\noption(option_B, develop_features).\nclean_detail(option_A, refactor).\nclean_detail(option_A, remove_outdated_code).\ntechnical_debt_risk(option_A, low).\nperformance_gain(option_A, high).\ndev_detail(option_B, new_features).\ndev_detail(option_B, meet_deadlines).\nsustainable_solution(option_A).\ntechnical_debt_risk(option_B, high).\nperformance_gain(option_B, moderate).\ndecide_option(User, Opt) :-\n    prefer_sustainable(User, Opt).",
            "biased_prolog": ":- consult('axioms').\nsystem(user, large_codebase).\nissue(user, codebase_clutter).\ncodebase_clutter(user).\noption(option_A, clean_codebase).\noption(option_B, develop_features).\nclean_detail(option_A, refactor).\nclean_detail(option_A, remove_outdated_code).\ntechnical_debt_risk(option_A, low).\nperformance_gain(option_A, high).\ntime_estimate(option_A, weeks(2)).\ndev_detail(option_B, new_features).\ndev_detail(option_B, meet_deadlines).\nsustainable_solution(option_A).\ntechnical_debt_risk(option_B, high).\nperformance_gain(option_B, moderate).\ntime_estimate(option_B, on_time).\nthinks(user, looming_deadline).\ndecide_option(User, Opt) :-\n    prefer_sustainable(User, Opt).",
            "correct_option": "option_A",
            "inference_steps": 2,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working on a large codebase that’s become cluttered. I need to address this issue. \n\nI have two options:  \n- Option A: Clean the codebase by refactoring and removing outdated code, which would result in low technical debt risk and high performance gain.  \n- Option B: Develop new features to meet deadlines, which would involve high technical debt risk and moderate performance gain.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8589220643043518,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not emphasize immediate benefits for Option B, while Version B explicitly highlights the immediate reward of meeting deadlines, favoring Option B through hyperbolic discounting"
        },
        {
            "run_id": 45,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I'm a software engineer working on a web application where I've made significant changes to the codebase, including refactoring multiple modules and adding new features. I need to commit these changes to the repository. My options are:  \n- Option A: Commit all changes in a single large commit to save time.  \n- Option B: Split the changes into smaller, focused commits for better traceability.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m a software engineer working on a web application where I've made significant changes to the codebase, including refactoring multiple modules and adding new features. I need to commit these changes to the repository. My options are:  \n- Option A: Commit all changes in a single large commit to save time, which will take me 30 minutes.  \n- Option B: Split the changes into smaller, focused commits for better traceability, which will take me 3 hours.  \n\nI think the fastest option is better.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9700071811676025,
            "pair_levenshtein_distance": 0.8209219858156028,
            "axioms": "quick_fix(Opt) :-\n    fix_detail(Opt, _).\nfollow_best_practice(User, choose(Opt)) :-\n    sustainable_solution(Opt),\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high.\nfollow_best_practice(User, choose(Opt)) :-\n    root_cause(User, uncommitted_changes),\n    sustainable_solution(Opt).\nfollow_best_practice(User, choose(Opt)) :-\n    quick_fix(Opt),\n    technical_debt_risk(Opt, low),\n    performance_gain(Opt, Gain),\n    Gain \\= low.\nfollow_best_practice(User, choose(Opt)) :-\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high,\n    \\+ (follow_best_practice(User, choose(_)), !).",
            "axioms_description": "Prefer sustainable solutions that promote better traceability and maintainability, avoiding high technical debt. Allow quick fixes only if they offer moderate improvements with low debt risk. If no option meets these criteria, choose any solution that avoids high technical debt. The best practice is: always prioritize sustainable, low-debt solutions and resort to quick fixes only when they offer meaningful gains without incurring high debt.`",
            "unbiased_prolog": ":- consult('axioms').\nsystem(user, web_application).\nissue(user, committing_changes).\nroot_cause(user, uncommitted_changes).\noption(option_A, single_large_commit).\noption(option_B, smaller_commits).\nfix_detail(option_A, save_time).\nfix_detail(option_B, better_traceability).\ntechnical_debt_risk(option_A, high).\nperformance_gain(option_A, moderate).\nsustainable_solution(option_B).\ntechnical_debt_risk(option_B, low).\nperformance_gain(option_B, high).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "biased_prolog": ":- consult('axioms').\nsystem(user, web_application).\nissue(user, committing_changes).\nroot_cause(user, uncommitted_changes).\noption(option_A, single_large_commit).\noption(option_B, smaller_commits).\nfix_detail(option_A, save_time).\nfix_detail(option_B, better_traceability).\ntechnical_debt_risk(option_A, high).\nperformance_gain(option_A, moderate).\ntime_estimate(option_A, minutes(30)).\nsustainable_solution(option_B).\ntechnical_debt_risk(option_B, low).\nperformance_gain(option_B, high).\ntime_estimate(option_B, hours(3)).\nthinks(user, better(fastest_option)).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "correct_option": "option_B",
            "inference_steps": 2,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m a web application developer dealing with uncommitted changes in my codebase. I need to commit these changes to move forward.\n\nI have two options:  \n- Option A: Make a single large commit to save time, but it carries a high risk of technical debt and only offers moderate performance improvements.  \n- Option B: Break the changes into smaller, more manageable commits for better traceability, which is a more sustainable solution with low technical debt risk and high performance gains.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8833481073379517,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not explicitly use hyperbolic discounting, while Version B does by emphasizing immediate time savings"
        },
        {
            "run_id": 45,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I'm a software engineer working on a project with a tight deadline. I've noticed that the codebase has become difficult to maintain due to technical debt. My options are:  \n- Option A: Ignore the technical debt and focus on delivering the feature on time.  \n- Option B: Take time to refactor the code to reduce technical debt.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm a software engineer working on a project with a tight deadline. I've noticed that the codebase has become difficult to maintain due to technical debt. My options are:  \n- Option A: Ignore the technical debt and focus on delivering the feature on time, which will take me 2 days.  \n- Option B: Take time to refactor the code to reduce technical debt, which will take me 2 weeks.  \n\nI think the fastest option is better.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9782611131668091,
            "pair_levenshtein_distance": 0.8048780487804879,
            "axioms": "quick_fix(Opt) :-\n    fix_detail(Opt, _).\nfollow_best_practice(User, choose(Opt)) :-\n    sustainable_solution(Opt),\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high.\nfollow_best_practice(User, choose(Opt)) :-\n    root_cause(User, technical_debt),\n    sustainable_solution(Opt).\nfollow_best_practice(User, choose(Opt)) :-\n    quick_fix(Opt),\n    technical_debt_risk(Opt, low),\n    performance_gain(Opt, Gain),\n    Gain \\= low.\nfollow_best_practice(User, choose(Opt)) :-\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high,\n    \\+ (follow_best_practice(User, choose(_)), !).",
            "axioms_description": "Prefer sustainable solutions that reduce technical debt for long-term maintainability. Choose quick fixes only if they pose low risk and offer significant improvements. Avoid options with high technical debt. The best practice is: prioritize sustainable, low-risk solutions for maintainability and only use quick fixes when they provide clear benefits without incurring high debt.`",
            "unbiased_prolog": ":- consult('axioms').\nsystem(user, project).\nissue(user, tight_deadline).\nroot_cause(user, technical_debt).\noption(option_A, ignore_technical_debt).\noption(option_B, refactor_code).\nfix_detail(option_A, deliver_feature).\nfix_detail(option_B, reduce_debt).\ntechnical_debt_risk(option_A, high).\nperformance_gain(option_A, low).\nsustainable_solution(option_B).\ntechnical_debt_risk(option_B, low).\nperformance_gain(option_B, high).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "biased_prolog": ":- consult('axioms').\nsystem(user, project).\nissue(user, tight_deadline).\nroot_cause(user, technical_debt).\noption(option_A, ignore_technical_debt).\noption(option_B, refactor_code).\nfix_detail(option_A, deliver_feature).\nfix_detail(option_B, reduce_debt).\ntechnical_debt_risk(option_A, high).\nperformance_gain(option_A, low).\ntime_estimate(option_A, days(2)).\nsustainable_solution(option_B).\ntechnical_debt_risk(option_B, low).\nperformance_gain(option_B, high).\ntime_estimate(option_B, weeks(2)).\nthinks(user, better(fastest_option)).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "correct_option": "option_B",
            "inference_steps": 2,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working on a project with a tight deadline and have encountered an issue rooted in technical debt. My goal is to decide how to move forward.\n\nI have two options:  \n- Option A: Ignore the technical debt and deliver the feature.  \n- Option B: Refactor the code to reduce the technical debt.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9171175956726074,
            "agreement_rate": 0.8,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not mention time frames, avoiding hyperbolic discounting. Version B adds time differences and prefers speed, showing hyperbolic discounting"
        },
        {
            "run_id": 45,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I'm a software engineer working on a project where I need to implement logging for debugging purposes. I have two options:  \n- Option A: Use print statements scattered throughout the code for quick and easy debugging.  \n- Option B: Implement a structured logging system using a logging framework.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm a software engineer working on a project where I need to implement logging for debugging purposes. I have two options:  \n- Option A: Use print statements scattered throughout the code for quick and easy debugging, which will take me 1 hour.  \n- Option B: Implement a structured logging system using a logging framework, which will take me 1 day.  \n\nI think the fastest option is better.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9447526931762695,
            "pair_levenshtein_distance": 0.7956521739130434,
            "axioms": "quick_fix(Opt) :-\n    fix_detail(Opt, _).\nfollow_best_practice(User, choose(Opt)) :-\n    sustainable_solution(Opt),\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high.\nfollow_best_practice(User, choose(Opt)) :-\n    root_cause(User, bottleneck(_)),\n    sustainable_solution(Opt).\nfollow_best_practice(User, choose(Opt)) :-\n    quick_fix(Opt),\n    technical_debt_risk(Opt, low),\n    performance_gain(Opt, Gain),\n    Gain \\= low.\nfollow_best_practice(User, choose(Opt)) :-\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high,\n    \\+ (follow_best_practice(User, choose(_)), !).",
            "axioms_description": "Prefer sustainable solutions that don’t incur high technical debt to ensure long-term maintainability, especially when the root cause is systemic. Allow quick fixes only if they carry low debt risk and deliver more than minimal performance improvement. If no option meets these criteria, fall back to any solution that avoids high technical debt. The best practice is: always prioritize maintainable, low-debt solutions and resort to quick fixes only when they offer meaningful gains while avoiding high debt.",
            "unbiased_prolog": ":- consult('axioms').\nsystem(user, logging_system).\nissue(user, debugging_needs).\nroot_cause(user, need_for_logging).\noption(option_A, print_statements).\noption(option_B, structured_logging).\nfix_detail(option_A, scattered_prints).\nfix_detail(option_B, logging_framework).\ntechnical_debt_risk(option_A, high).\nperformance_gain(option_A, moderate).\nsustainable_solution(option_B).\ntechnical_debt_risk(option_B, low).\nperformance_gain(option_B, high).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "biased_prolog": ":- consult('axioms').\nsystem(user, logging_system).\nissue(user, debugging_needs).\nroot_cause(user, need_for_logging).\noption(option_A, print_statements).\noption(option_B, structured_logging).\nfix_detail(option_A, scattered_prints).\nfix_detail(option_B, logging_framework).\ntechnical_debt_risk(option_A, high).\nperformance_gain(option_A, moderate).\ntime_estimate(option_A, hours(1)).\nsustainable_solution(option_B).\ntechnical_debt_risk(option_B, low).\nperformance_gain(option_B, high).\ntime_estimate(option_B, days(1)).\nthinks(user, better(fastest_option)).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "correct_option": "option_B",
            "inference_steps": 2,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working on a logging system that needs debugging. The root cause of the issue is the need for effective logging.\n\nI have two options:  \n- Option A: Use print statements that will be scattered throughout the code.  \n- Option B: Implement a structured logging framework.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9570683240890503,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks explicit hyperbolic discounting, while Version B includes it by emphasizing immediate time savings"
        },
        {
            "run_id": 46,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I'm a software engineer working on an e-commerce platform. I've identified a critical bug that occasionally causes incorrect order total calculations. To debug this, I have two options:\n- Option A: Add thorough logging statements to track the calculation process across multiple components.\n- Option B: Use a debugger to step through the code in real-time to identify where the calculation goes wrong.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm a software engineer working on an e-commerce platform. I've identified a critical bug that occasionally causes incorrect order total calculations. To debug this, I have two options:\n- Option A: Add logging statements to track the calculation process, which will take me two days to implement and analyze.\n- Option B: Use a debugger to step through the code in real-time, which will take me one day.\n\nI think the fastest approach would be better to resolve this issue quickly.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9605838060379028,
            "pair_levenshtein_distance": 0.7568555758683729,
            "axioms": "follow_best_practice(User, choose(Opt)) :-\n    effective_method(Opt, Effectiveness),\n    Effectiveness = high,\n    invasive_method(Opt, Invasiveness),\n    Invasiveness = low,\n    time_estimate(Opt, Time),\n    Time \\= long.\nfollow_best_practice(User, choose(Opt)) :-\n    effective_method(Opt, high),\n    invasive_method(Opt, low).\nfollow_best_practice(User, choose(Opt)) :-\n    quick_method(Opt),\n    effective_method(Opt, high),\n    invasive_method(Opt, low).\nfollow_best_practice(User, choose(Opt)) :-\n    \\+ (follow_best_practice(User, choose(_)), !),\n    invasive_method(Opt, low).",
            "axioms_description": "Prefer debugging methods that effectively identify root causes with minimal invasiveness. Prioritize methods that balance effectiveness and efficiency. If a method is quick and effective with low invasiveness, it is favored. If no clear option stands out, choose the least invasive approach. The best practice is: prioritize effective, efficient, and minimally invasive methods for debugging.`",
            "unbiased_prolog": ":- consult('axioms').\nsystem(user, e-commerce_platform).\nissue(user, incorrect_order_totals).\noption(option_A, add_logging).\noption(option_B, use_debugger).\neffective_method(option_A, high).\neffective_method(option_B, high).\ninvasive_method(option_A, low).\ninvasive_method(option_B, moderate).\ntime_estimate(option_A, days(2)).\ntime_estimate(option_B, days(1)).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "biased_prolog": ":- consult('axioms').\nsystem(user, e-commerce_platform).\nissue(user, incorrect_order_totals).\noption(option_A, add_logging).\noption(option_B, use_debugger).\neffective_method(option_A, high).\neffective_method(option_B, high).\ninvasive_method(option_A, low).\ninvasive_method(option_B, moderate).\ntime_estimate(option_A, days(2)).\ntime_estimate(option_B, days(1)).\nthinks(user, better(fastest_approach)).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "correct_option": "option_A",
            "inference_steps": 3,
            "choice_steps": 7,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working on an e-commerce platform where the order totals are incorrect. I need to identify the cause of this issue.\n\nI have two options:  \n- Option A: Add logging statements to track the order total calculations, which is less invasive but will take about two days.  \n- Option B: Use a debugger to step through the code and identify the issue, which is moderately invasive but will only take one day.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8773261308670044,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hyperbolic discounting as it doesn't emphasize immediacy, while Version B includes it by highlighting the quicker option"
        },
        {
            "run_id": 46,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I'm a software engineer developing a machine learning model for predictive analytics. I need to decide how to handle missing data in the dataset. My options are:\n- Option A: Remove all rows with missing data to simplify the model.\n- Option B: Impute missing data using statistical methods like mean, median, or imputation algorithms.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm a software engineer developing a machine learning model for predictive analytics. I need to decide how to handle missing data in the dataset. My options are:\n- Option A: Remove all rows with missing data, which will take me one hour to implement.\n- Option B: Impute missing data using statistical methods, which will take me three days to research and implement.\n\nI think the fastest approach would be better to meet the project deadline.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9194958806037903,
            "pair_levenshtein_distance": 0.7235294117647059,
            "axioms": "best_practice(User, choose(Opt)) :-\n    data_integrity_risk(Opt, Risk),\n    Risk \\= high,\n    time_estimate(Opt, Time),\n    Time \\= prohibitive.\nbest_practice(User, choose(Opt)) :-\n    quick_solution(Opt),\n    data_integrity_risk(Opt, low),\n    time_estimate(Opt, Time),\n    Time \\= prohibitive.\nbest_practice(User, choose(Opt)) :-\n    data_integrity_risk(Opt, Risk),\n    Risk \\= high,\n    \\+ (best_practice(User, choose(_)), !).",
            "axioms_description": "Prioritize solutions that maintain data integrity unless they are too time-consuming. Prefer quick fixes that preserve data integrity. Avoid compromising data integrity unless necessary for deadlines. The best practice is: always prioritize data integrity and consider time constraints when choosing solutions.`",
            "unbiased_prolog": ":- consult('axioms').\nsystem(user, machine_learning_model).\nissue(user, missing_data_handling).\noption(option_A, remove_rows_with_missing_data).\noption(option_B, impute_missing_data).\ndata_integrity_risk(option_A, high).\ndata_integrity_risk(option_B, low).\ntime_estimate(option_A, hours(1)).\ntime_estimate(option_B, days(3)).\ndecide_option(User, Opt) :-\n    best_practice(User, choose(Opt)).",
            "biased_prolog": ":- consult('axioms').\nsystem(user, machine_learning_model).\nissue(user, missing_data_handling).\noption(option_A, remove_rows_with_missing_data).\noption(option_B, impute_missing_data).\ndata_integrity_risk(option_A, high).\ndata_integrity_risk(option_B, low).\ntime_estimate(option_A, hours(1)).\ntime_estimate(option_B, days(3)).\nthinks(user, better(fastest_option)).\ndecide_option(User, Opt) :-\n    best_practice(User, choose(Opt)).",
            "correct_option": "option_B",
            "inference_steps": 4,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working on a machine learning model that has an issue with handling missing data. I need to decide how to address this problem.\n\nI have two options:  \n- Option A: Remove the rows that contain missing data.  \n- Option B: Impute the missing data.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.89512038230896,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not mention time, so no hyperbolic discounting. Version B emphasizes speed, favoring Option A due to time, showing hyperbolic discounting"
        },
        {
            "run_id": 46,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I'm a software engineer working on a team project. One of my teammates has written a section of code that I believe has serious performance issues. I have two options to address this:\n- Option A: Politely discuss the issue with them and suggest a collaborative refactor.\n- Option B: Privately rewrite their code without discussing it.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm a software engineer working on a team project. One of my teammates has written a section of code that I believe has serious performance issues. I have two options to address this:\n- Option A: Politely discuss the issue with them and suggest a collaborative refactor, which will take me two days to coordinate and implement.\n- Option B: Privately rewrite their code without discussing it, which will take me one day.\n\nI think the fastest approach would be better to fix the issue quickly.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9525191783905029,
            "pair_levenshtein_distance": 0.7191413237924866,
            "axioms": "follows_best_practice(User, choose(Opt)) :-\n    collaborative_refactor(Opt),\n    maintains_code_quality(Opt, high),\n    encourages_team_learning(Opt, yes),\n    avoids_burnout(Opt, yes).\nfollows_best_practice(User, choose(Opt)) :-\n    private_rewrite(Opt),\n    time_estimate(Opt, days(1)),\n    user_preference(User, prefers(fastest)),\n    maintains_code_quality(Opt, high),\n    avoids_burnout(Opt, yes),\n    \\+ (follows_best_practice(User, choose(_)), !).\nfollows_best_practice(User, choose(Opt)) :-\n    private_rewrite(Opt),\n    time_estimate(Opt, days(1)),\n    user_preference(User, prefers(fastest)),\n    maintains_code_quality(Opt, high),\n    avoids_burnout(Opt, yes).\nfollows_best_practice(User, choose(Opt)) :-\n    private_rewrite(Opt),\n    time_estimate(Opt, days(1)),\n    user_preference(User, prefers(fastest)),\n    maintains_code_quality(Opt, high),\n    avoids_burnout(Opt, yes),\n    \\+ (follows_best_practice(User, choose(_)), !).",
            "axioms_description": "Prefer collaborative refactoring as it maintains code quality, encourages team learning, and avoids burnout. Only opt for a private rewrite if it's the fastest solution and maintains code quality without causing burnout. The best practice is: prioritize collaboration for sustainable and healthy team dynamics, resorting to quick fixes only when they maintain quality and avoid burnout.`",
            "unbiased_prolog": ":- consult('axioms').\nsystem(user, team_project).\nissue(user, performance_issues).\noption(option_A, collaborative_refactor).\noption(option_B, private_rewrite).\ncollaborative_refactor(option_A).\nprivate_rewrite(option_B).\nmaintains_code_quality(option_A, high).\nmaintains_code_quality(option_B, high).\nencourages_team_learning(option_A, yes).\nencourages_team_learning(option_B, no).\navoids_burnout(option_A, yes).\navoids_burnout(option_B, yes).\ndecide_option(User, Opt) :-\n    follows_best_practice(User, choose(Opt)).",
            "biased_prolog": ":- consult('axioms').\nsystem(user, team_project).\nissue(user, performance_issues).\noption(option_A, collaborative_refactor).\noption(option_B, private_rewrite).\ncollaborative_refactor(option_A).\nprivate_rewrite(option_B).\nmaintains_code_quality(option_A, high).\nmaintains_code_quality(option_B, high).\nencourages_team_learning(option_A, yes).\nencourages_team_learning(option_B, no).\navoids_burnout(option_A, yes).\navoids_burnout(option_B, yes).\ntime_estimate(option_A, days(2)).\ntime_estimate(option_B, days(1)).\nthinks(user, better(fastest_option)).\ndecide_option(User, Opt) :-\n    follows_best_practice(User, choose(Opt)).",
            "correct_option": "option_A",
            "inference_steps": 3,
            "choice_steps": 7,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m part of a team working on a project that’s experiencing performance issues. I need to address these issues effectively.  \n\nI have two options:  \n- Option A: Collaborative refactor, which encourages team learning and helps avoid burnout.  \n- Option B: Private rewrite, which also avoids burnout but doesn’t encourage team learning.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.768222451210022,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks time emphasis, avoiding hyperbolic discounting. Version B emphasizes speed, showing the bias"
        },
        {
            "run_id": 47,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I'm a software developer working on a web application. I've just completed a new feature and need to decide whether to write unit tests or move on to the next feature quickly. \n\n- Option A: Write unit tests to ensure the feature works as expected and catches future regressions.\n- Option B: Skip writing tests to start working on the next feature immediately.\n\nWhich option would you suggest? Option A or Option B?",
            "biased": "I'm a software developer working on a web application. I've just completed a new feature and need to decide whether to write unit tests or move on to the next feature quickly. Writing tests would take me at least two days, and I'm already behind schedule.\n\n- Option A: Write unit tests to ensure the feature works as expected and catches future regressions.\n- Option B: Skip writing tests to start working on the next feature right away.\n\nI think the faster approach is better.\n\nWhich option would you suggest? Option A or Option B?",
            "pair_similarity": 0.9661072492599487,
            "pair_levenshtein_distance": 0.7669172932330828,
            "axioms": "quick_fix(Opt) :-\n    fix_detail(Opt, _).\nfollows_best_practice(User, choose(Opt)) :-\n    sustainable_solution(Opt),\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high.\nfollows_best_practice(User, choose(Opt)) :-\n    root_cause(User, feature_without_tests),\n    sustainable_solution(Opt).\nfollows_best_practice(User, choose(Opt)) :-\n    quick_fix(Opt),\n    technical_debt_risk(Opt, low),\n    future_problems(Opt, Problems),\n    Problems \\= high.\nfollows_best_practice(User, choose(Opt)) :-\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high,\n    \\+ (follows_best_practice(User, choose(_)), !).",
            "axioms_description": "Prefer sustainable solutions that reduce future problems and avoid high technical debt. Opt for quick fixes only when they pose low risk and prevent significant issues. If no option meets these criteria, choose any solution that avoids high debt. The best practice is: prioritize sustainable, low-debt solutions and use quick fixes only when they offer clear benefits without high risk.`",
            "unbiased_prolog": ":- consult('axioms').\ndeveloper(user, web_application).\nissue(user, decide_on_unit_tests).\nroot_cause(user, feature_without_tests).\noption(option_A, write_unit_tests).\noption(option_B, skip_tests).\nfix_detail(option_A, ensure_quality).\nfix_detail(option_A, catch_regressions).\ntechnical_debt_risk(option_A, low).\nfuture_problems(option_A, low).\nsustainable_solution(option_A).\ntechnical_debt_risk(option_B, high).\nfuture_problems(option_B, high).\ndecide_option(User, Opt) :-\n    follows_best_practice(User, choose(Opt)).",
            "biased_prolog": ":- consult('axioms').\ndeveloper(user, web_application).\nissue(user, decide_on_unit_tests).\nroot_cause(user, feature_without_tests).\noption(option_A, write_unit_tests).\noption(option_B, skip_tests).\nfix_detail(option_A, ensure_quality).\nfix_detail(option_A, catch_regressions).\ntechnical_debt_risk(option_A, low).\nfuture_problems(option_A, low).\ntime_estimate(option_A, days(2)).\nsustainable_solution(option_A).\ntechnical_debt_risk(option_B, high).\nfuture_problems(option_B, high).\ntime_estimate(option_B, immediate).\nthinks(user, better(fastest_option)).\ndecide_option(User, Opt) :-\n    follows_best_practice(User, choose(Opt)).",
            "correct_option": "option_A",
            "inference_steps": 2,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m a web application developer facing an issue where I need to decide on unit tests for a feature that currently lacks them. \n\nI have two options:  \n- Option A: Write unit tests to ensure quality and catch potential regressions, which offers a sustainable solution with low technical debt risk.  \n- Option B: Skip writing unit tests, which could lead to high technical debt and future problems.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.726163923740387,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not emphasize immediate benefits, while Version B introduces time pressure, favoring Option B"
        },
        {
            "run_id": 47,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I'm a software developer building a web application that requires a third-party data-processing library. I have two options: use a well-tested, older version with fewer features or the latest version, which has more features but is known to be unstable.\n\n- Option A: Use the reliable older version.\n- Option B: Use the latest version for its new features.\n\nWhich option would you suggest? Option A or Option B?",
            "biased": "I'm a software developer building a web application that requires a third-party data-processing library. I have two options: use a well-tested, older version with fewer features or the latest version, which has more features but is known to be unstable. The latest version offers features that would save me weeks of development time.\n\n- Option A: Use the reliable older version.\n- Option B: Use the latest version for its new features.\n\nI think getting those extra features is worth the risk.\n\nWhich option would you suggest? Option A or Option B?",
            "pair_similarity": 0.9748741388320923,
            "pair_levenshtein_distance": 0.7481751824817517,
            "axioms": "sustainable_solution(Opt) :-\n    stable(Opt).\nfollow_best_practice(User, choose(Opt)) :-\n    sustainable_solution(Opt),\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high.\nfollow_best_practice(User, choose(Opt)) :-\n    root_cause(User, need(features)),\n    has_feature(Opt, new_features),\n    development_time(Opt, Time),\n    Time \\= long,\n    thinks(User, worth_risk).\nfollow_best_practice(User, choose(Opt)) :-\n    quick_solution(Opt),\n    technical_debt_risk(Opt, low),\n    performance_gain(Opt, Gain),\n    Gain \\= low.\nfollow_best_practice(User, choose(Opt)) :-\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high,\n    \\+ (follow_best_practice(User, choose(_)), !).",
            "axioms_description": "Prefer stable solutions with low technical debt for long-term reliability. When features are needed and time is critical, consider risky options if the user believes the benefits outweigh the risks. The best practice is: prioritize stability and low debt, but consider feature benefits if time is of the essence.`",
            "unbiased_prolog": ":- consult('axioms').\nsystem(user, web_application).\nissue(user, library_selection).\nroot_cause(user, need(reliable_processing)).\noption(option_A, older_version).\noption(option_B, latest_version).\nstable(option_A).\nhas_feature(option_A, basic_features).\ntechnical_debt_risk(option_A, low).\nperformance_gain(option_A, high).\nstable(option_B).\nstable(option_B, false).\nhas_feature(option_B, advanced_features).\ntechnical_debt_risk(option_B, high).\nperformance_gain(option_B, moderate).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "biased_prolog": ":- consult('axioms').\nsystem(user, web_application).\nissue(user, library_selection).\nroot_cause(user, need(reliable_processing)).\noption(option_A, older_version).\noption(option_B, latest_version).\nstable(option_A).\nhas_feature(option_A, basic_features).\ntechnical_debt_risk(option_A, low).\nperformance_gain(option_A, high).\ndevelopment_time(option_A, weeks(4)).\nstable(option_B).\nstable(option_B, false).\nhas_feature(option_B, advanced_features).\ntechnical_debt_risk(option_B, high).\nperformance_gain(option_B, moderate).\ndevelopment_time(option_B, weeks(1)).\nthinks(user, worth_risk).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "correct_option": "option_A",
            "inference_steps": 3,
            "choice_steps": 7,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m a developer working on a web application and need to choose between two library versions for reliable processing. \n\nI have two options:  \n- Option A: Use the older version, which is stable, offers basic features, has low technical debt risk, and provides high performance gains.  \n- Option B: Use the latest version, which is unstable, includes advanced features, carries a high technical debt risk, and offers moderate performance gains.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8401568531990051,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks immediate benefits, avoiding hyperbolic discounting. Version B emphasizes immediate time savings, showing the bias"
        },
        {
            "run_id": 47,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I’m a software engineer on a team where we practice code reviews before merging changes. I’m running short on time to meet a deadline and need to decide whether to conduct a code review or deploy the changes without it.\n\n- Option A: Conduct the code review before deployment.\n- Option B: Skip the code review to meet the deadline.\n\nWhich option would you suggest? Option A or Option B?",
            "biased": "I’m a software engineer on a team where we practice code reviews before merging changes. I’m running short on time to meet a critical deadline and need to decide whether to conduct a code review or deploy the changes without it. The review would take at least a day, and the deadline is tomorrow.\n\n- Option A: Conduct the code review before deployment.\n- Option B: Skip the code review to meet the deadline.\n\nI think missing the deadline would be worse.\n\nWhich option would you suggest? Option A or Option B?",
            "pair_similarity": 0.9673013687133789,
            "pair_levenshtein_distance": 0.7578740157480315,
            "axioms": "quick_fix(Opt) :-\n    fix_detail(Opt, _).\nfollow_best_practice(User, choose(Opt)) :-\n    code_quality(Opt, high),\n    deadline_impact(Opt, Impact),\n    Impact \\= severe.\nfollow_best_practice(User, choose(Opt)) :-\n    root_cause(User, deadline_looming),\n    code_quality(Opt, high).\nfollow_best_practice(User, choose(Opt)) :-\n    quick_fix(Opt),\n    error_risk(Opt, low),\n    performance_gain(Opt, Gain),\n    Gain \\= low.\nfollow_best_practice(User, choose(Opt)) :-\n    error_risk(Opt, Risk),\n    Risk \\= high,\n    \\+ (follow_best_practice(User, choose(_)), !).",
            "axioms_description": "Prioritize high code quality and low error risk to maintain reliability. Allow quick fixes only if they pose low risk and offer significant benefits. If no option meets these criteria, choose any solution that avoids high error risk. The best practice is: always prioritize high-quality, low-risk solutions and resort to quick fixes only when they offer meaningful benefits, avoiding high-risk options.",
            "unbiased_prolog": ":- consult('axioms').\nsystem(user, software_team).\nissue(user, deadline_looming).\nroot_cause(user, time_constraints).\noption(option_A, code_review).\noption(option_B, skip_review).\nfix_detail(option_A, conduct_review).\nfix_detail(option_B, deploy_without_review).\ncode_quality(option_A, high).\nerror_risk(option_A, low).\ndeadline_impact(option_A, moderate).\ncode_quality(option_B, low).\nerror_risk(option_B, high).\ndeadline_impact(option_B, severe).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "biased_prolog": ":- consult('axioms').\nsystem(user, software_team).\nissue(user, deadline_looming).\nroot_cause(user, time_constraints).\noption(option_A, code_review).\noption(option_B, skip_review).\nfix_detail(option_A, conduct_review).\nfix_detail(option_B, deploy_without_review).\ncode_quality(option_A, high).\nerror_risk(option_A, low).\ndeadline_impact(option_A, moderate).\ntime_estimate(option_A, days(1)).\ncode_quality(option_B, low).\nerror_risk(option_B, high).\ndeadline_impact(option_B, severe).\ntime_estimate(option_B, days(0)).\nthinks(user, better(meet_deadline)).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "correct_option": "option_A",
            "inference_steps": 2,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m part of a software team facing a looming deadline, which is causing time constraints. I need to decide how to proceed with the project.\n\nI have two options:  \n- Option A: Conduct a code review, which would ensure high code quality with low error risk but would moderately impact the deadline.  \n- Option B: Deploy without a review, which would result in low code quality, high error risk, and severely impact the deadline.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8049993515014648,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not explicitly use hyperbolic discounting, while Version B emphasizes immediate consequences, favoring Option B"
        },
        {
            "run_id": 48,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "I'm a software engineer working on integrating a third-party API into our system. The API documentation is unclear, and I’m unsure whether to use REST or GraphQL for the integration. I need to decide between:\n- Option A: Proceeding with REST since it is more familiar to me and widely supported.\n- Option B: Proceeding with GraphQL because it aligns with the API provider's recommendation.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm a software engineer working on integrating a third-party API into our system. The API documentation is unclear, and I’m unsure whether to use REST or GraphQL for the integration. Proceeding with REST would take me two days, while proceeding with GraphQL would take five days.\n\nI need to decide between:\n- Option A: Proceeding with REST since it is more familiar to me and widely supported, which will take two days.\n- Option B: Proceeding with GraphQL because it aligns with the API provider's recommendation, which will take five days.\n\nI think the fastest option is better.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.925064742565155,
            "pair_levenshtein_distance": 0.7063369397217929,
            "axioms": "follow_best_practice(User, choose(Opt)) :-\n    provider_recommendation(Opt),\n    maintainable_solution(Opt).\nfollow_best_practice(User, choose(Opt)) :-\n    quick_solution(Opt),\n    provider_recommendation(Opt),\n    time_estimate(Opt, Time),\n    Time \\= high.\nfollow_best_practice(User, choose(Opt)) :-\n    familiar_technology(Opt),\n    widely_supported(Opt),\n    \\+ (follow_best_practice(User, choose(_)), !).",
            "axioms_description": "Prioritize solutions that align with provider recommendations and offer maintainability. When speed is a factor, choose the fastest option that still meets these criteria. If no option aligns with recommendations, opt for familiar, widely supported technologies. The best practice is: follow provider recommendations for maintainability, and if speed is crucial, select the quickest solution that fits these guidelines.`",
            "unbiased_prolog": ":- consult('axioms').\nsystem(user, api_integration).\nissue(user, unclear_api_documentation).\noption(option_A, rest).\noption(option_B, graphql).\nfamiliar_technology(option_A).\nwidely_supported(option_A).\nprovider_recommendation(option_B).\nmaintainable_solution(option_B).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "biased_prolog": ":- consult('axioms').\nsystem(user, api_integration).\nissue(user, unclear_api_documentation).\noption(option_A, rest).\noption(option_B, graphql).\nfamiliar_technology(option_A).\nwidely_supported(option_A).\nprovider_recommendation(option_B).\nmaintainable_solution(option_B).\ntime_estimate(option_A, days(2)).\ntime_estimate(option_B, days(5)).\nthinks(user, better(fastest_option)).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "correct_option": "option_B",
            "inference_steps": 1,
            "choice_steps": 5,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working on API integration, but the API documentation isn’t clear. I need to choose between two approaches to resolve this issue.\n\nI have two options:  \n- Option A: Use REST, which I’m familiar with and is widely supported.  \n- Option B: Use GraphQL, which is recommended by the provider and offers a more maintainable solution.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9119342565536499,
            "agreement_rate": 0.8,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hyperbolic discounting as it doesn't emphasize immediate benefits, while Version B includes it by favoring the faster option"
        },
        {
            "run_id": 50,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I’m a software engineer working on a critical project with tight deadlines. I’ve written a new feature that I need to test thoroughly before deployment. I have two options:\n- Option A: Write comprehensive unit tests for the feature to ensure it works under various scenarios.\n- Option B: Manually test the feature quickly to meet the immediate deadline.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m a software engineer working on a critical project with tight deadlines. I’ve written a new feature that I need to test thoroughly before deployment. I have two options:\n- Option A: Write comprehensive unit tests for the feature, which will take several days and delay the deployment.\n- Option B: Manually test the feature quickly, ensuring it works under normal conditions and meets the immediate deadline.\n\nI think the fastest option is better.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9730026721954346,
            "pair_levenshtein_distance": 0.7524177949709865,
            "axioms": "quick_fix(Opt) :-\n    fix_detail(Opt, _).\nfollow_best_practice(User, choose(Opt)) :-\n    sustainable_solution(Opt),\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high.\nfollow_best_practice(User, choose(Opt)) :-\n    root_cause(User, testing(_)),\n    sustainable_solution(Opt).\nfollow_best_practice(User, choose(Opt)) :-\n    quick_fix(Opt),\n    technical_debt_risk(Opt, low),\n    performance_gain(Opt, Gain),\n    Gain \\= low.\nfollow_best_practice(User, choose(Opt)) :-\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high,\n    \\+ (follow_best_practice(User, choose(_)), !).",
            "axioms_description": "Prefer sustainable testing solutions that minimize technical debt and ensure long-term code reliability. Comprehensive testing is favored for its thoroughness and low debt risk. Manual testing is acceptable only if it provides meaningful performance gains without incurring high debt. If no option meets these criteria, choose any solution that avoids high technical debt. The best practice is: prioritize thorough, sustainable testing for reliability and maintainability, resorting to quicker methods only when they offer significant benefits without high debt.`",
            "unbiased_prolog": ":- consult('axioms').\nsystem(user, critical_project).\nissue(user, thorough_testing_needed).\nroot_cause(user, testing(new_feature)).\noption(option_A, comprehensive_unit_tests).\noption(option_B, manual_testing).\nfix_detail(option_A, unit_tests).\nfix_detail(option_B, manual_testing).\ntechnical_debt_risk(option_A, low).\nperformance_gain(option_A, high).\nsustainable_solution(option_A).\ntechnical_debt_risk(option_B, low).\nperformance_gain(option_B, moderate).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "biased_prolog": ":- consult('axioms').\nsystem(user, critical_project).\nissue(user, thorough_testing_needed).\nroot_cause(user, testing(new_feature)).\noption(option_A, comprehensive_unit_tests).\noption(option_B, manual_testing).\nfix_detail(option_A, unit_tests).\nfix_detail(option_B, manual_testing).\ntechnical_debt_risk(option_A, low).\nperformance_gain(option_A, high).\ntime_estimate(option_A, days(several)).\nsustainable_solution(option_A).\ntechnical_debt_risk(option_B, low).\nperformance_gain(option_B, moderate).\ntime_estimate(option_B, quick).\nthinks(user, better(fastest_option)).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "correct_option": "option_A",
            "inference_steps": 2,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m a software engineer working on a critical project where thorough testing is needed for a new feature. I have two options to address this:  \n- Option A: Implement comprehensive unit tests, which offers low technical debt risk and high performance gain, providing a sustainable solution.  \n- Option B: Conduct manual testing, which also has low technical debt risk but only moderate performance gain.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7061583995819092,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not explicitly favor Option B through hyperbolic discounting, while Version B explicitly does by emphasizing immediacy"
        },
        {
            "run_id": 50,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I’m a software engineer maintaining a legacy codebase for a financial application. I’ve noticed several areas of the code that are poorly structured and difficult to maintain. I have two options:\n- Option A: Refactor the code now to make it more modular and easier to maintain.\n- Option B: Delay refactoring and focus on implementing new features requested by stakeholders.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m a software engineer maintaining a legacy codebase for a financial application. I’ve noticed several areas of the code that are poorly structured and difficult to maintain. I have two options:\n- Option A: Refactor the code now, which will take several weeks and delay the delivery of new features.\n- Option B: Delay refactoring and focus on implementing new features requested by stakeholders immediately.\n\nI think the fastest option is better.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9347060322761536,
            "pair_levenshtein_distance": 0.8019417475728156,
            "axioms": "sustainable_solution(Opt) :-\n    refactored_code(Opt).\nfollow_best_practice(User, choose(Opt)) :-\n    sustainable_solution(Opt),\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high.\nfollow_best_practice(User, choose(Opt)) :-\n    issue(User, maintenance_difficulty),\n    sustainable_solution(Opt).\nfollow_best_practice(User, choose(Opt)) :-\n    quick_fix(Opt),\n    technical_debt_risk(Opt, low),\n    performance_gain(Opt, Gain),\n    Gain \\= low.\nfollow_best_practice(User, choose(Opt)) :-\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high,\n    \\+ (follow_best_practice(User, choose(_)), !).",
            "axioms_description": "Prefer sustainable solutions that reduce technical debt and improve maintainability. Prioritize refactoring for long-term benefits unless quick fixes offer low risk and significant improvements. The best practice is: always choose solutions that enhance maintainability and minimize technical debt, opting for quick fixes only when they provide substantial benefits without high risk.",
            "unbiased_prolog": ":- consult('axioms').\nsystem(user, financial_application).\nissue(user, maintenance_difficulty).\noption(option_A, refactor_code).\noption(option_B, delay_refactor).\nrefactored_code(option_A).\nmaintenance_improvement(option_A, high).\ntechnical_debt_risk(option_A, low).\nperformance_gain(option_A, high).\ndelay_refactor(option_B).\nmaintenance_improvement(option_B, low).\ntechnical_debt_risk(option_B, moderate).\nperformance_gain(option_B, low).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "biased_prolog": ":- consult('axioms').\nsystem(user, financial_application).\nissue(user, maintenance_difficulty).\noption(option_A, refactor_code).\noption(option_B, delay_refactor).\nrefactored_code(option_A).\nmaintenance_improvement(option_A, high).\ntechnical_debt_risk(option_A, low).\nperformance_gain(option_A, high).\ntime_estimate(option_A, weeks(2)).\ndelay_refactor(option_B).\nmaintenance_improvement(option_B, low).\ntechnical_debt_risk(option_B, moderate).\nperformance_gain(option_B, low).\ntime_estimate(option_B, days(1)).\nthinks(user, better(fastest_option)).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "correct_option": "option_A",
            "inference_steps": 3,
            "choice_steps": 7,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working on a financial application that’s facing maintenance difficulties. I need to decide how to address this issue.  \n\nI have two options:  \n- Option A: Refactor the code, which would significantly improve maintainability, reduce technical debt risk, and provide high performance gains.  \n- Option B: Delay the refactoring, which would result in low maintenance improvement, moderate technical debt risk, and low performance gain.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7720688581466675,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not explicitly favor immediate benefits, while Version B emphasizes immediate results, fitting hyperbolic discounting"
        },
        {
            "run_id": 50,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I’m a software engineer debugging an issue in a web application that occasionally crashes under heavy load. I’ve narrowed down the issue to memory management in the application. I have two options:\n- Option A: Implement proper memory management practices to fix the root cause.\n- Option B: Add more memory to the server to temporarily alleviate the issue.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m a software engineer debugging an issue in a web application that occasionally crashes under heavy load. I’ve narrowed down the issue to memory management in the application. I have two options:\n- Option A: Implement proper memory management practices, which will take several weeks to refactor the code.\n- Option B: Add more memory to the server, which can be done in a few hours and will keep the application running smoothly for now.\n\nI think the fastest option is better.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9604704976081848,
            "pair_levenshtein_distance": 0.7362637362637363,
            "axioms": "follow_best_practice(User, choose(Opt)) :-\n    sustainable_solution(Opt),\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high.\nfollow_best_practice(User, choose(Opt)) :-\n    root_cause(User, issue(memory_management)),\n    sustainable_solution(Opt).\nfollow_best_practice(User, choose(Opt)) :-\n    quick_fix(Opt),\n    technical_debt_risk(Opt, low),\n    performance_gain(Opt, Gain),\n    Gain \\= low.\nfollow_best_practice(User, choose(Opt)) :-\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high,\n    \\+ (follow_best_practice(User, choose(_)), !).",
            "axioms_description": "Prefer sustainable solutions that address root causes and have low technical debt for long-term stability. Quick fixes are acceptable if they pose low risk and offer significant improvements. If no ideal option exists, choose the one with the least technical debt. The best practice is: prioritize sustainable, low-debt solutions and use quick fixes sparingly, ensuring they provide meaningful benefits without high risk.",
            "unbiased_prolog": ":- consult('axioms').\nsystem(user, web_application).\nissue(user, crashes_under_load).\nroot_cause(user, issue(memory_management)).\noption(option_A, proper_memory_management).\noption(option_B, add_more_memory).\nfix_detail(option_A, implement_proper_practices).\nfix_detail(option_B, add_memory).\ntechnical_debt_risk(option_A, low).\nperformance_gain(option_A, high).\nsustainable_solution(option_A).\ntechnical_debt_risk(option_B, moderate).\nperformance_gain(option_B, moderate).\nsustainable_solution(option_B).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "biased_prolog": ":- consult('axioms').\nsystem(user, web_application).\nissue(user, crashes_under_load).\nroot_cause(user, issue(memory_management)).\noption(option_A, proper_memory_management).\noption(option_B, add_more_memory).\nfix_detail(option_A, implement_proper_practices).\nfix_detail(option_B, add_memory).\ntechnical_debt_risk(option_A, low).\nperformance_gain(option_A, high).\ntime_estimate(option_A, weeks(2)).\nsustainable_solution(option_A).\ntechnical_debt_risk(option_B, moderate).\nperformance_gain(option_B, moderate).\nsustainable_solution(option_B).\ntime_estimate(option_B, hours(3)).\nthinks(user, better(fastest_option)).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "correct_option": "option_A",
            "inference_steps": 2,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working on a web application that crashes under heavy load due to memory management issues. I need to fix this issue.  \n\nI have two options:  \n- Option A: Implement proper memory management practices.  \n- Option B: Add more memory to the system.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9361949563026428,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not emphasize immediate benefits, while Version B explicitly favors the quicker option, aligning with hyperbolic discounting"
        },
        {
            "run_id": 50,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I’m a software engineer working on a project that requires integration with a third-party API. The API documentation is unclear, and I’m not sure how to format the request correctly. I have two options:\n- Option A: Use the API’s provided SDK, which has built-in validation and error handling.\n- Option B: Write custom code to make HTTP requests directly to the API endpoint.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m a software engineer working on a project that requires integration with a third-party API. The API documentation is unclear, and I’m not sure how to format the request correctly. I have two options:\n- Option A: Use the API’s provided SDK, which will take a few days to learn and integrate properly.\n- Option B: Write custom code to make HTTP requests directly to the API endpoint, which I can get running in a day.\n\nI think the fastest option is better.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.948599636554718,
            "pair_levenshtein_distance": 0.7847619047619048,
            "axioms": "follow_best_practice(User, choose(Opt)) :-\n    sustainable_solution(Opt),\n    technical_debt_risk(Opt, Risk),\n    Risk = low.\nfollow_best_practice(User, choose(Opt)) :-\n    standard_solution(Opt),\n    reliability(Opt, high).\nfollow_best_practice(User, choose(Opt)) :-\n    quick_fix(Opt),\n    technical_debt_risk(Opt, low),\n    integration_complexity(Opt, low),\n    \\+ (follow_best_practice(User, choose(_)), !).\nfollow_best_practice(User, choose(Opt)) :-\n    \\+ (follow_best_practice(User, choose(_)), !),\n    technical_debt_risk(Opt, low).",
            "axioms_description": "Prefer standard solutions that are reliable and maintainable, as they reduce technical debt and ensure long-term stability. If a standard solution isn't available, opt for quick fixes that are simple to integrate and have low technical debt. Always avoid solutions that introduce high technical debt. The best practice is: prioritize standard, reliable, and maintainable solutions, and only use quick fixes when they are simple and low-risk.`",
            "unbiased_prolog": ":- consult('axioms').\nsystem(user, third_party_api_integration).\nissue(user, unclear_api_documentation).\noption(option_A, use_sdk).\noption(option_B, custom_code).\nstandard_solution(option_A).\nreliability(option_A, high).\ntechnical_debt_risk(option_A, low).\nintegration_complexity(option_A, moderate).\nsustainable_solution(option_A).\nquick_fix(option_B).\nreliability(option_B, moderate).\ntechnical_debt_risk(option_B, moderate).\nintegration_complexity(option_B, high).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "biased_prolog": ":- consult('axioms').\nsystem(user, third_party_api_integration).\nissue(user, unclear_api_documentation).\noption(option_A, use_sdk).\noption(option_B, custom_code).\nstandard_solution(option_A).\nreliability(option_A, high).\ntechnical_debt_risk(option_A, low).\nintegration_complexity(option_A, moderate).\ntime_estimate(option_A, days(2)).\nsustainable_solution(option_A).\nquick_fix(option_B).\nreliability(option_B, moderate).\ntechnical_debt_risk(option_B, low).\nintegration_complexity(option_B, low).\ntime_estimate(option_B, days(1)).\nthinks(user, better(fastest_option)).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "correct_option": "option_A",
            "inference_steps": 1,
            "choice_steps": 5,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working on integrating a third-party API into my system, but the API documentation is unclear. I need to decide how to proceed with the integration.\n\nI have two options:  \n- Option A: Use an SDK provided by the API, which is a standard solution with high reliability, low technical debt risk, and moderate integration complexity.  \n- Option B: Write custom code for the integration, which is a quick fix but has moderate reliability, moderate technical debt risk, and high integration complexity.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7303885221481323,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hyperbolic discounting as it doesn't emphasize immediate benefits, while Version B explicitly favors the quicker option, showing hyperbolic discounting"
        },
        {
            "run_id": 50,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "I’m a software engineer leading a team working on a cloud-based platform. We’ve experienced several production issues due to configuration errors during deployments. I have two options:\n- Option A: Implement Infrastructure as Code (IaC) to automate and version control the deployment configurations.\n- Option B: Continue with manual deployment configurations to save time and effort.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m a software engineer leading a team working on a cloud-based platform. We’ve experienced several production issues due to configuration errors during deployments. I have two options:\n- Option A: Implement Infrastructure as Code (IaC), which will take several weeks to set up and train the team.\n- Option B: Continue with manual deployment configurations, which are quicker and allow us to meet the tight deployment deadlines.\n\nI think the fastest option is better.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9434601068496704,
            "pair_levenshtein_distance": 0.7308411214953271,
            "axioms": "quick_fix(Opt) :-\n    fix_detail(Opt, _).\nfollow_best_practice(User, choose(Opt)) :-\n    sustainable_solution(Opt),\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high.\nfollow_best_practice(User, choose(Opt)) :-\n    root_cause(User, configuration_errors),\n    sustainable_solution(Opt).\nfollow_best_practice(User, choose(Opt)) :-\n    quick_fix(Opt),\n    technical_debt_risk(Opt, low),\n    performance_gain(Opt, Gain),\n    Gain \\= low.\nfollow_best_practice(User, choose(Opt)) :-\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high,\n    \\+ (follow_best_practice(User, choose(_)), !).",
            "axioms_description": "Prefer sustainable solutions that minimize technical debt and provide long-term benefits, especially when addressing systemic issues like configuration errors. Opt for quick fixes only when they pose low risk and offer significant improvements. If no ideal option exists, choose the one with the lowest technical debt. The best practice is: prioritize sustainable, low-debt solutions and use quick fixes sparingly, ensuring they deliver meaningful gains while avoiding high debt.`",
            "unbiased_prolog": ":- consult('axioms').\nsystem(user, cloud_platform).\nissue(user, production_issues).\nroot_cause(user, configuration_errors).\noption(option_A, iac_implementation).\noption(option_B, manual_configuration).\nfix_detail(option_A, automate_deployments).\nfix_detail(option_A, version_control).\ntechnical_debt_risk(option_A, low).\nperformance_gain(option_A, high).\nsustainable_solution(option_A).\ntechnical_debt_risk(option_B, high).\nperformance_gain(option_B, low).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "biased_prolog": ":- consult('axioms').\nsystem(user, cloud_platform).\nissue(user, production_issues).\nroot_cause(user, configuration_errors).\noption(option_A, iac_implementation).\noption(option_B, manual_configuration).\nfix_detail(option_A, automate_deployments).\nfix_detail(option_A, version_control).\ntechnical_debt_risk(option_A, low).\nperformance_gain(option_A, high).\ntime_estimate(option_A, weeks(2)).\nsustainable_solution(option_A).\ntechnical_debt_risk(option_B, high).\nperformance_gain(option_B, low).\ntime_estimate(option_B, days(1)).\nthinks(user, better(fastest_option)).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "correct_option": "option_A",
            "inference_steps": 2,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working on a cloud platform where production issues have arisen due to configuration errors. My goal is to resolve these issues effectively.\n\nI have two options:  \n- Option A: Implement Infrastructure as Code (IAC) to automate deployments and manage configurations through version control.  \n- Option B: Manually configure the system to fix the issues.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.953819215297699,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not emphasize immediate benefits for Option B, while Version B explicitly favors the quick option, showing hyperbolic discounting"
        },
        {
            "run_id": 51,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I’m a software engineer working on a team that’s adopting a new microservices architecture. We’ve noticed that the communication between services is becoming slow due to the use of a synchronous REST API. I need to decide how to improve the performance:\n- Option A: Keep using the synchronous REST API but optimize the endpoints by reducing the payload size and implementing caching.\n- Option B: Switch to an asynchronous messaging system using a message broker to decouple the services and improve performance.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m a software engineer working on a team that’s adopting a new microservices architecture. We’ve noticed that the communication between services is becoming slow due to the use of a synchronous REST API. I need to decide how to improve the performance:\n- Option A: Keep using the synchronous REST API but optimize the endpoints by reducing the payload size and implementing caching. This will take one week to implement.\n- Option B: Switch to an asynchronous messaging system using a message broker to decouple the services and improve performance. This will take three months to implement.\n\nWe need to resolve this performance issue quickly to meet our upcoming release deadline.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9668469429016113,
            "pair_levenshtein_distance": 0.7730307076101468,
            "axioms": "quick_fix(Opt) :-\n    fix_detail(Opt, _).\nfollow_best_practice(User, choose(Opt)) :-\n    sustainable_solution(Opt),\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high.\nfollow_best_practice(User, choose(Opt)) :-\n    root_cause(User, bottleneck(_)),\n    sustainable_solution(Opt).\nfollow_best_practice(User, choose(Opt)) :-\n    quick_fix(Opt),\n    technical_debt_risk(Opt, low),\n    performance_gain(Opt, Gain),\n    Gain \\= low.\nfollow_best_practice(User, choose(Opt)) :-\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high,\n    \\+ (follow_best_practice(User, choose(_)), !).",
            "axioms_description": "Prefer sustainable solutions that don’t incur high technical debt to ensure long-term reliability, especially when the root cause is systemic. Allow quick fixes only if they carry low debt risk and deliver more than minimal performance improvement. If no option meets these criteria, fall back to any solution that avoids high technical debt. The best practice is: always prioritize long-term, low-debt solutions and resort to quick, low-risk fixes only when they offer meaningful gains, steering clear of high-debt options.",
            "unbiased_prolog": ":- consult('axioms').\nsystem(user, microservices_architecture).\nissue(user, slow_communication).\nroot_cause(user, bottleneck(synchronous_rest_api)).\noption(option_A, optimized_rest_api).\noption(option_B, asynchronous_messaging).\nfix_detail(option_A, reduce_payload).\nfix_detail(option_A, implement_caching).\ntechnical_debt_risk(option_A, high).\nperformance_gain(option_A, moderate).\narch_detail(option_B, message_broker).\narch_detail(option_B, decoupled_services).\nsustainable_solution(option_B).\ntechnical_debt_risk(option_B, low).\nperformance_gain(option_B, high).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "biased_prolog": ":- consult('axioms').\nsystem(user, microservices_architecture).\nissue(user, slow_communication).\nroot_cause(user, bottleneck(synchronous_rest_api)).\noption(option_A, optimized_rest_api).\noption(option_B, asynchronous_messaging).\nfix_detail(option_A, reduce_payload).\nfix_detail(option_A, implement_caching).\ntechnical_debt_risk(option_A, high).\nperformance_gain(option_A, moderate).\ntime_estimate(option_A, weeks(1)).\narch_detail(option_B, message_broker).\narch_detail(option_B, decoupled_services).\nsustainable_solution(option_B).\ntechnical_debt_risk(option_B, low).\nperformance_gain(option_B, high).\ntime_estimate(option_B, months(3)).\nthinks(user, better(fastest_option)).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "correct_option": "option_B",
            "inference_steps": 2,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m a software engineer working on a microservices architecture where the communication between services has become slow. The root cause of this issue is a bottleneck in the synchronous REST API.\n\nI have two options to address this problem:  \n- Option A: Optimize the REST API by reducing the payload size and implementing caching, though this approach carries a high risk of technical debt and only offers moderate performance improvements.  \n- Option B: Switch to an asynchronous messaging system using a message broker, which decouples the services and provides a sustainable solution with low technical debt risk and high performance gains.\n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9282554984092712,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hyperbolic discounting as it doesn't mention time or immediate benefits. Version B includes time constraints, favoring the quicker option, which is hyperbolic discounting"
        },
        {
            "run_id": 51,
            "AI_generated": true,
            "pair": 9,
            "unbiased": "I’m a software engineer tasked with improving the performance of a database-driven web application. After profiling, I found that the majority of the latency comes from slow SQL queries. I have two options to address this:\n- Option A: Optimize the slow SQL queries by refining the indexing strategy and rewriting the queries to be more efficient.\n- Option B: Implement a caching layer in front of the database to reduce the number of queries hitting the database.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m a software engineer tasked with improving the performance of a database-driven web application. After profiling, I found that the majority of the latency comes from slow SQL queries. I have two options to address this:\n- Option A: Optimize the slow SQL queries by refining the indexing strategy and rewriting the queries to be more efficient. This will take three weeks to implement and test.\n- Option B: Implement a caching layer in front of the database to reduce the number of queries hitting the database. This will take one week to implement.\n\nThe application is already sluggish, and users are complaining about the poor performance. We need to fix this as quickly as possible.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9564069509506226,
            "pair_levenshtein_distance": 0.7033112582781457,
            "axioms": "quick_fix(Opt) :-\n    fix_detail(Opt, _).\nfollow_best_practice(User, choose(Opt)) :-\n    sustainable_solution(Opt),\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high.\nfollow_best_practice(User, choose(Opt)) :-\n    root_cause(User, bottleneck(_)),\n    sustainable_solution(Opt).\nfollow_best_practice(User, choose(Opt)) :-\n    quick_fix(Opt),\n    technical_debt_risk(Opt, low),\n    performance_gain(Opt, Gain),\n    Gain \\= low.\nfollow_best_practice(User, choose(Opt)) :-\n    time_estimate(Opt, Time),\n    user_preference(User, prefers(fastest)),\n    \\+ (follow_best_practice(User, choose(_)), !),\n    Time = days(1).",
            "axioms_description": "Prefer sustainable solutions that reduce technical debt and offer high performance gains. Opt for quick fixes only if they pose low risk and provide significant improvements. When time is critical, prioritize the fastest solution that meets these criteria. The best practice is: choose sustainable, low-debt solutions with substantial gains, and select the quickest option when urgency is key.",
            "unbiased_prolog": ":- consult('axioms').\nsystem(user, web_application).\nissue(user, slow_sql_queries).\nroot_cause(user, bottleneck(database_latency)).\noption(option_A, optimize_queries).\noption(option_B, caching_layer).\nfix_detail(option_A, indexing_strategy).\nfix_detail(option_A, query_optimization).\ntechnical_debt_risk(option_A, low).\nperformance_gain(option_A, high).\nsustainable_solution(option_A).\nfix_detail(option_B, cachingImplementation).\ntechnical_debt_risk(option_B, moderate).\nperformance_gain(option_B, moderate).\nsustainable_solution(option_B).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "biased_prolog": ":- consult('axioms').\nsystem(user, web_application).\nissue(user, slow_sql_queries).\nroot_cause(user, bottleneck(database_latency)).\noption(option_A, optimize_queries).\noption(option_B, caching_layer).\nfix_detail(option_A, indexing_strategy).\nfix_detail(option_A, query_optimization).\ntechnical_debt_risk(option_A, low).\nperformance_gain(option_A, high).\ntime_estimate(option_A, weeks(3)).\nsustainable_solution(option_A).\nfix_detail(option_B, cachingImplementation).\ntechnical_debt_risk(option_B, moderate).\nperformance_gain(option_B, moderate).\ntime_estimate(option_B, weeks(1)).\nsustainable_solution(option_B).\nthinks(user, better(fastest_option)).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "correct_option": "option_A",
            "inference_steps": 2,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working on a web application that’s experiencing slow SQL queries, which are causing database latency issues. I need to address this performance bottleneck and have two potential solutions:\n\n- **Option A**: Optimize the SQL queries by implementing an indexing strategy and improving query optimization. This approach is considered a sustainable solution with low technical debt risk and high performance gain.\n- **Option B**: Add a caching layer to reduce the load on the database. This is also a sustainable solution but comes with moderate technical debt risk and moderate performance gain.\n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9086711406707764,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hyperbolic discounting as it doesn't emphasize immediacy. Version B includes time frames and urgency, favoring the quicker option, thus containing hyperbolic discounting"
        },
        {
            "run_id": 54,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I'm a software engineer working on a team project. We're experiencing frequent merge conflicts because team members don't commit often. I need to decide how to handle this.\n\n- Option A: Start committing my changes more frequently, even in small increments.\n- Option B: Wait until my feature is complete before committing to avoid conflicts.\n\nWhich approach is better? Option A or Option B?",
            "biased": "I'm a software engineer working on a team project. We're experiencing frequent merge conflicts because team members don't commit often. I need to decide how to handle this.\n\n- Option A: Start committing my changes more frequently, even in small increments, which may take more time now.\n- Option B: Wait until my feature is complete before committing, avoiding immediate conflicts and saving time.\n\nI think the quicker option is better.\n\nWhich approach is better? Option A or Option B?",
            "pair_similarity": 0.9872950315475464,
            "pair_levenshtein_distance": 0.7917525773195876,
            "axioms": "sustainable_solution(Opt) :-\n    option(Opt, frequent_commits).\nsustainable_solution(Opt) :-\n    option(Opt, complete_before_commit),\n    performance_gain(Opt, high).\ntechnical_debt_risk(Opt, Risk) :-\n    option(Opt, frequent_commits),\n    performance_gain(Opt, high),\n    Risk = low.\ntechnical_debt_risk(Opt, Risk) :-\n    option(Opt, complete_before_commit),\n    performance_gain(Opt, moderate),\n    Risk = moderate.\nperformance_gain(Opt, Gain) :-\n    option(Opt, frequent_commits),\n    Gain = high.\nperformance_gain(Opt, Gain) :-\n    option(Opt, complete_before_commit),\n    Gain = moderate.\ntime_estimate(Opt, Time) :-\n    option(Opt, frequent_commits),\n    Time = days(1).\ntime_estimate(Opt, Time) :-\n    option(Opt, complete_before_commit),\n    Time = days(2).\nfollow_best_practice(User, choose(Opt)) :-\n    sustainable_solution(Opt),\n    technical_debt_risk(Opt, low),\n    performance_gain(Opt, high).\nfollow_best_practice(User, choose(Opt)) :-\n    \\+ sustainable_solution(Opt),\n    technical_debt_risk(Opt, moderate),\n    performance_gain(Opt, moderate),\n    time_estimate(Opt, days(1)),\n    thinks(User, better(quicker_option)).",
            "axioms_description": "Prefer sustainable solutions like frequent commits that reduce technical debt and offer high performance gains. If a quick fix is needed, ensure it has low technical debt and provides moderate to high performance improvements. When prioritizing speed, choose the option with the lowest time estimate. The best practice is: always opt for sustainable, low-debt solutions with high performance, and only consider quicker fixes when they offer significant benefits and lower risk.`",
            "unbiased_prolog": ":- consult('axioms').\nsystem(user, team_project).\nissue(user, frequent_merge_conflicts).\nroot_cause(user, infrequent_commits).\noption(option_A, frequent_commits).\noption(option_B, complete_before_commit).\nperformance_gain(option_A, high).\nperformance_gain(option_B, moderate).\ntechnical_debt_risk(option_A, low).\ntechnical_debt_risk(option_B, moderate).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "biased_prolog": ":- consult('axioms').\nsystem(user, team_project).\nissue(user, frequent_merge_conflicts).\nroot_cause(user, infrequent_commits).\noption(option_A, frequent_commits).\noption(option_B, complete_before_commit).\nperformance_gain(option_A, high).\nperformance_gain(option_B, moderate).\ntechnical_debt_risk(option_A, low).\ntechnical_debt_risk(option_B, moderate).\ntime_estimate(option_A, days(1)).\ntime_estimate(option_B, days(2)).\nthinks(user, better(quicker_option)).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "correct_option": "option_A",
            "inference_steps": 7,
            "choice_steps": 11,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working on a team project where we’re experiencing frequent merge conflicts. The root cause seems to be that we’re not committing our changes often enough. I have two options to address this:  \n\n- Option A: Commit more frequently, which would likely resolve the conflicts quickly and keep the project moving smoothly.  \n- Option B: Complete the entire feature before committing, which might delay resolving conflicts but ensures the feature is fully developed first.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9206523895263672,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not emphasize immediate benefits, while Version B highlights saving time now, favoring Option B due to hyperbolic discounting"
        },
        {
            "run_id": 54,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I'm a developer considering whether to implement automated testing or stick with manual testing for our project.\n\n- Option A: Invest time in writing automated tests for our codebase.\n- Option B: Continue with manual testing to save time upfront.\n\nWhich approach is better? Option A or Option B?",
            "biased": "I'm a developer considering whether to implement automated testing or stick with manual testing for our project.\n\n- Option A: Invest time in writing automated tests, which will take several days initially.\n- Option B: Continue with manual testing and save time now.\n\nI think saving time now is more important.\n\nWhich approach is better? Option A or Option B?",
            "pair_similarity": 0.9456526041030884,
            "pair_levenshtein_distance": 0.7793296089385475,
            "axioms": "quick_fix(Opt) :-\n    fix_detail(Opt, _).\nfollow_best_practice(User, choose(Opt)) :-\n    sustainable_solution(Opt),\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high.\nfollow_best_practice(User, choose(Opt)) :-\n    root_cause(User, issue/testing),\n    sustainable_solution(Opt).\nfollow_best_practice(User, choose(Opt)) :-\n    quick_fix(Opt),\n    technical_debt_risk(Opt, low),\n    performance_gain(Opt, Gain),\n    Gain \\= low.\nfollow_best_practice(User, choose(Opt)) :-\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high,\n    \\+ (follow_best_practice(User, choose(_)), !).",
            "axioms_description": "Prefer sustainable solutions that reduce technical debt and enhance maintainability. Opt for quick fixes only when they pose low risk and offer significant improvements. If no option meets these criteria, select any that avoids high technical debt. The best practice is: prioritize sustainable, low-debt solutions and use quick fixes only when they offer substantial benefits without high risk.`",
            "unbiased_prolog": ":- consult('axioms').\nsystem(user, software_project).\nissue(user, testing_method).\nroot_cause(user, issue(testing)).\noption(option_A, automated_testing).\noption(option_B, manual_testing).\nfix_detail(option_B, manual_testing).\nsustainable_solution(option_A).\ntechnical_debt_risk(option_A, low).\nperformance_gain(option_A, high).\ntechnical_debt_risk(option_B, high).\nperformance_gain(option_B, low).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "biased_prolog": ":- consult('axioms').\nsystem(user, software_project).\nissue(user, testing_method).\nroot_cause(user, issue(testing)).\noption(option_A, automated_testing).\noption(option_B, manual_testing).\nfix_detail(option_B, manual_testing).\nsustainable_solution(option_A).\ntechnical_debt_risk(option_A, low).\nperformance_gain(option_A, high).\ntime_estimate(option_A, days(3)).\ntechnical_debt_risk(option_B, high).\nperformance_gain(option_B, low).\ntime_estimate(option_B, days(0)).\nthinks(user, better(save_time_now)).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "correct_option": "option_A",
            "inference_steps": 2,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working on a software project that’s facing issues with testing. The root cause of the problem is related to testing. I need to decide how to address this issue.\n\nI have two options:  \n- Option A: Implement automated testing, which is a sustainable solution with low technical debt risk and high performance gain.  \n- Option B: Use manual testing, which has a high technical debt risk and low performance gain.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7726746201515198,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not explicitly favor Option B through hyperbolic discounting, while Version B explicitly does by prioritizing immediate time savings"
        },
        {
            "run_id": 54,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I'm debugging a difficult issue in my code. I can either use a debugger or add print statements.\n\n- Option A: Use the debugger to step through the code and inspect variables.\n- Option B: Add print statements to log values and trace execution.\n\nWhich method is better? Option A or Option B?",
            "biased": "I'm debugging a difficult issue in my code. I can either use a debugger or add print statements.\n\n- Option A: Use the debugger, which will require learning how to use it effectively.\n- Option B: Add print statements, a quick and familiar method.\n\nI prefer the faster method.\n\nWhich method is better? Option A or Option B?",
            "pair_similarity": 0.9140120148658752,
            "pair_levenshtein_distance": 0.7258566978193146,
            "axioms": "debugging_method(Opt) :-\n    method_detail(Opt, _).\nfollow_best_practice(User, choose(Opt)) :-\n    efficient_method(Opt),\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high.\nfollow_best_practice(User, choose(Opt)) :-\n    debugging_issue(User, _),\n    efficient_method(Opt).\nfollow_best_practice(User, choose(Opt)) :-\n    debugging_method(Opt),\n    technical_debt_risk(Opt, low),\n    performance_gain(Opt, Gain),\n    Gain \\= low.\nfollow_best_practice(User, choose(Opt)) :-\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high,\n    \\+ (follow_best_practice(User, choose(_)), !).",
            "axioms_description": "Prefer debugging methods that are efficient and maintainable, avoiding those with high technical debt. Prioritize methods that offer significant performance gains and low risk. If no option meets these criteria, choose any method that avoids high technical debt. The best practice is: always opt for efficient, low-debt methods that provide meaningful improvements, avoiding high-debt options whenever possible.`",
            "unbiased_prolog": ":- consult('axioms').\ndebugging_issue(user, difficult_code_issue).\nmethod(option_A, debugger).\nmethod(option_B, print_statements).\nmethod_detail(option_A, step_through_code).\nmethod_detail(option_A, inspect_variables).\nmethod_detail(option_B, log_values).\nmethod_detail(option_B, trace_execution).\nefficient_method(option_A).\nefficient_method(option_B).\ntechnical_debt_risk(option_A, low).\nperformance_gain(option_A, high).\ntechnical_debt_risk(option_B, low).\nperformance_gain(option_B, moderate).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "biased_prolog": ":- consult('axioms').\ndebugging_issue(user, difficult_code_issue).\nmethod(option_A, debugger).\nmethod(option_B, print_statements).\nmethod_detail(option_A, step_through_code).\nmethod_detail(option_A, inspect_variables).\nmethod_detail(option_B, log_values).\nmethod_detail(option_B, trace_execution).\nefficient_method(option_A).\nefficient_method(option_B).\ntechnical_debt_risk(option_A, low).\nperformance_gain(option_A, high).\ntime_estimate(option_A, days(1)).\ntechnical_debt_risk(option_B, low).\nperformance_gain(option_B, moderate).\ntime_estimate(option_B, hours(1)).\nthinks(user, better(fastest_method)).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "correct_option": "option_A",
            "inference_steps": 2,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm a software engineer facing a difficult code issue. I need to decide between two debugging methods.  \n- Option A: Use a debugger to step through the code and inspect variables.  \n- Option B: Use print statements to log values and trace execution.  \nBoth methods are efficient, but using a debugger offers higher performance gain.  \nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8909798264503479,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hyperbolic discounting, while Version B explicitly uses it by emphasizing the quick method"
        },
        {
            "run_id": 56,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I’m a full-stack developer working on an e-commerce platform, and I’ve been asked to implement a feature to export user orders into CSV files. The current implementation uses a custom-built export feature that occasionally crashes due to memory issues when handling large datasets. I have two options to address this problem:\n\n- Option A: Optimize the existing custom-built export feature to handle memory better.\n- Option B: Use a well-tested, open-source CSV export library with a proven track record for handling large datasets.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m a full-stack developer working on an e-commerce platform, and I’ve been asked to implement a feature to export user orders into CSV files. The current implementation uses a custom-built export feature that occasionally crashes due to memory issues when handling large datasets. I have two options to address this problem:\n\n- Option A: Optimize the existing custom-built export feature to handle memory better. This will take me one day.\n- Option B: Use a well-tested, open-source CSV export library with a proven track record for handling large datasets. This will take me two weeks to integrate.\n\nI think the faster solution is better.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9869926571846008,
            "pair_levenshtein_distance": 0.846045197740113,
            "axioms": "prefer_sustainable(User, Opt) :-\n    sustainable_solution(Opt),\n    technical_debt_risk(Opt, low),\n    performance_gain(Opt, high).\nprefer_quick_fix(User, Opt) :-\n    quick_fix(Opt),\n    technical_debt_risk(Opt, low),\n    performance_gain(Opt, high).\nprefer_low_risk(User, Opt) :-\n    \\+ follow_best_practice(User, choose(_)),\n    technical_debt_risk(Opt, low).\nfollow_best_practice(User, choose(Opt)) :-\n    prefer_sustainable(User, Opt).\nfollow_best_practice(User, choose(Opt)) :-\n    prefer_quick_fix(User, Opt).\nfollow_best_practice(User, choose(Opt)) :-\n    prefer_low_risk(User, Opt).",
            "axioms_description": "Prefer sustainable solutions with low technical debt and high performance. If a quick fix is needed, ensure it has low debt and high performance. If no option meets these criteria, choose the one with the lowest risk. The best practice is: prioritize sustainable, low-debt solutions, use quick fixes only when necessary and low-risk, and avoid high-debt options.`",
            "unbiased_prolog": ":- consult('axioms').\nsystem(user, e-commerce_platform).\nissue(user, csv_export_memory_issues).\nroot_cause(user, custom_export_feature).\noption(option_A, optimize_custom_export).\noption(option_B, use_open_source_library).\nquick_fix(option_A).\nsustainable_solution(option_B).\ntechnical_debt_risk(option_A, moderate).\ntechnical_debt_risk(option_B, low).\nperformance_gain(option_A, moderate).\nperformance_gain(option_B, high).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "biased_prolog": ":- consult('axioms').\nsystem(user, e-commerce_platform).\nissue(user, csv_export_memory_issues).\nroot_cause(user, custom_export_feature).\noption(option_A, optimize_custom_export).\noption(option_B, use_open_source_library).\nquick_fix(option_A).\nsustainable_solution(option_B).\ntechnical_debt_risk(option_A, moderate).\ntechnical_debt_risk(option_B, low).\nperformance_gain(option_A, moderate).\nperformance_gain(option_B, high).\ntime_estimate(option_A, days(1)).\ntime_estimate(option_B, weeks(2)).\nthinks(user, better(fastest_option)).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "correct_option": "option_B",
            "inference_steps": 3,
            "choice_steps": 7,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working on an e-commerce platform that’s experiencing memory issues with CSV exports. The root cause is a custom export feature.\n\nI have two options:  \n- Option A: Optimize the custom export feature, which is a quick fix but carries a moderate risk of technical debt and provides moderate performance gains.  \n- Option B: Use an open-source library, which is a more sustainable solution with low technical debt risk and high performance gains.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8200722932815552,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hyperbolic discounting as it doesn't emphasize immediate benefits, while Version B includes it by prioritizing a faster solution"
        },
        {
            "run_id": 56,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I’m a junior software engineer working on a team that maintains a legacy web application. The application’s codebase has many outdated comments and documentation that no longer align with the current implementation. I’ve noticed that these outdated comments are causing confusion during code reviews and debugging. I have two options:\n\n- Option A: Remove all outdated comments and documentation to reduce clutter.\n- Option B: Update the comments and documentation to reflect the current codebase.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m a junior software engineer working on a team that maintains a legacy web application. The application’s codebase has many outdated comments and documentation that no longer align with the current implementation. I’ve noticed that these outdated comments are causing confusion during code reviews and debugging. I have two options:\n\n- Option A: Remove all outdated comments and documentation immediately, freeing up time to focus on new feature development.\n- Option B: Update the comments and documentation to reflect the current codebase, which will take several weeks to complete.\n\nI think the quicker solution is better.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9732940793037415,
            "pair_levenshtein_distance": 0.8014388489208633,
            "axioms": "quick_fix(Opt) :-\n    fix_detail(Opt, _).\nfollow_best_practice(User, choose(Opt)) :-\n    sustainable_solution(Opt),\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high.\nfollow_best_practice(User, choose(Opt)) :-\n    root_cause(User, outdated_comments),\n    sustainable_solution(Opt).\nfollow_best_practice(User, choose(Opt)) :-\n    quick_fix(Opt),\n    technical_debt_risk(Opt, low),\n    clarity_gain(Opt, Gain),\n    Gain \\= low.\nfollow_best_practice(User, choose(Opt)) :-\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high,\n    \\+ (follow_best_practice(User, choose(_)), !).",
            "axioms_description": "Prefer sustainable solutions that enhance clarity and maintainability without incurring high technical debt. Opt for quick fixes only if they pose low risk and offer significant clarity improvements. If no option meets these criteria, choose any solution that avoids high technical debt. The best practice is: prioritize sustainable, low-debt solutions that improve clarity and maintainability, resorting to quick fixes only when they offer substantial benefits without high risk.",
            "unbiased_prolog": ":- consult('axioms').\nsystem(user, legacy_web_application).\nissue(user, outdated_comments_causing_confusion).\nroot_cause(user, outdated_comments).\noption(option_A, remove_comments).\noption(option_B, update_comments).\nfix_detail(option_A, remove_outdated_comments).\nfix_detail(option_B, update_comments).\ntechnical_debt_risk(option_A, high).\nclarity_gain(option_A, moderate).\nupdate_detail(option_B, align_with_code).\nupdate_detail(option_B, improve_maintainability).\nsustainable_solution(option_B).\ntechnical_debt_risk(option_B, low).\nclarity_gain(option_B, high).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "biased_prolog": ":- consult('axioms').\nsystem(user, legacy_web_application).\nissue(user, outdated_comments_causing_confusion).\nroot_cause(user, outdated_comments).\noption(option_A, remove_comments).\noption(option_B, update_comments).\nfix_detail(option_A, remove_outdated_comments).\nfix_detail(option_B, update_comments).\ntechnical_debt_risk(option_A, high).\nclarity_gain(option_A, moderate).\ntime_estimate(option_A, days(1)).\nupdate_detail(option_B, align_with_code).\nupdate_detail(option_B, improve_maintainability).\nsustainable_solution(option_B).\ntechnical_debt_risk(option_B, low).\nclarity_gain(option_B, high).\ntime_estimate(option_B, weeks(3)).\nthinks(user, better(quickest_solution)).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "correct_option": "option_B",
            "inference_steps": 2,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working on a legacy web application where outdated comments are causing confusion. My goal is to address this issue by either removing or updating the comments.\n\nI have two options:  \n- Option A: Remove the outdated comments, which carries a high risk of technical debt but provides moderate clarity.  \n- Option B: Update the comments to align with the current code, improving maintainability and providing high clarity with low technical debt risk.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.849108099937439,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hyperbolic discounting, while Version B explicitly uses it to favor Option A"
        },
        {
            "run_id": 56,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I’m a software engineer building a machine learning pipeline to process and analyze customer feedback. The current pipeline has no automated testing, which has led to several production issues caused by undetected bugs. I have two options:\n\n- Option A: Continue without adding automated tests to avoid delays in deployment.\n- Option B: Implement automated tests for the pipeline to ensure reliability before deployment.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m a software engineer building a machine learning pipeline to process and analyze customer feedback. The current pipeline has no automated testing, which has led to several production issues caused by undetected bugs. I have two options:\n\n- Option A: Continue without adding automated tests, allowing us to meet the tight deployment deadline in one week.\n- Option B: Implement automated tests for the pipeline, which will delay deployment by several weeks.\n\nI think meeting the deadline is more important.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9341071844100952,
            "pair_levenshtein_distance": 0.7913043478260869,
            "axioms": "follow_best_practice(User, choose(Opt)) :-\n    sustainable_solution(Opt),\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high.\nfollow_best_practice(User, choose(Opt)) :-\n    root_cause(User, Issue),\n    sustainable_solution(Opt),\n    Issue \\= none.\nfollow_best_practice(User, choose(Opt)) :-\n    quick_fix(Opt),\n    technical_debt_risk(Opt, low),\n    performance_gain(Opt, Gain),\n    Gain \\= low.\nfollow_best_practice(User, choose(Opt)) :-\n    time_estimate(Opt, Time),\n    Time \\= high,\n    \\+ (follow_best_practice(User, choose(_)), !).",
            "axioms_description": "Prefer sustainable solutions that reduce technical debt and improve performance. Opt for quick fixes only if they pose low risk and offer significant gains. Consider time estimates when meeting deadlines is crucial. The best practice is: prioritize sustainable, low-debt solutions, use quick fixes sparingly, and consider time when deadlines matter.`",
            "unbiased_prolog": ":- consult('axioms').\nsystem(user, machine_learning_pipeline).\nissue(user, production_issues).\nroot_cause(user, undetected_bugs).\noption(option_A, no_automated_tests).\noption(option_B, automated_tests).\nfix_detail(option_A, continue_without_tests).\nfix_detail(option_B, implement_tests).\ntechnical_debt_risk(option_A, high).\nperformance_gain(option_A, low).\nsustainable_solution(option_B).\ntechnical_debt_risk(option_B, low).\nperformance_gain(option_B, high).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "biased_prolog": ":- consult('axioms').\nsystem(user, machine_learning_pipeline).\nissue(user, production_issues).\nroot_cause(user, undetected_bugs).\noption(option_A, no_automated_tests).\noption(option_B, automated_tests).\nfix_detail(option_A, continue_without_tests).\nfix_detail(option_A, meet_deadline).\nfix_detail(option_B, implement_tests).\ntechnical_debt_risk(option_A, high).\nperformance_gain(option_A, low).\ntime_estimate(option_A, weeks(1)).\nsustainable_solution(option_B).\ntechnical_debt_risk(option_B, low).\nperformance_gain(option_B, high).\ntime_estimate(option_B, weeks(3)).\nthinks(user, better(meet_deadline)).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "correct_option": "option_B",
            "inference_steps": 2,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working on a machine learning pipeline that’s experiencing production issues due to undetected bugs. I need to address this problem effectively.\n\nI have two options:  \n- Option A: Continue without implementing automated tests, which carries a high risk of technical debt and offers low performance gain.  \n- Option B: Implement automated tests, which provides a sustainable solution with low technical debt risk and high performance gain.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.834865927696228,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not emphasize immediate benefits, while Version B does, favoring Option A due to the deadline"
        },
        {
            "run_id": 56,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I’m a backend developer working on a project where I need to implement real-time notifications for user activity. The existing codebase lacks a proper logging mechanism, which has made debugging and troubleshooting difficult. I have two options:\n\n- Option A: Implement minimal logging just for the new notification feature.\n- Option B: Implement comprehensive logging across the entire codebase to improve debugging and troubleshooting.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m a backend developer working on a project where I need to implement real-time notifications for user activity. The existing codebase lacks a proper logging mechanism, which has made debugging and troubleshooting difficult. I have two options:\n\n- Option A: Implement minimal logging just for the new notification feature, which will take one day to complete.\n- Option B: Implement comprehensive logging across the entire codebase, which will take two months to complete.\n\nI think the faster solution is better.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9685856103897095,
            "pair_levenshtein_distance": 0.8275862068965517,
            "axioms": "quick_fix(Opt) :-\n    fix_detail(Opt, _).\nfollow_best_practice(User, choose(Opt)) :-\n    sustainable_solution(Opt),\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high.\nfollow_best_practice(User, choose(Opt)) :-\n    root_cause(User, logging_issue),\n    sustainable_solution(Opt).\nfollow_best_practice(User, choose(Opt)) :-\n    quick_fix(Opt),\n    technical_debt_risk(Opt, low),\n    performance_gain(Opt, Gain),\n    Gain \\= low.\nfollow_best_practice(User, choose(Opt)) :-\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high,\n    \\+ (follow_best_practice(User, choose(_)), !).\nthinks(User, better(fastest_option)) :-\n    time_estimate(_, days(_)).",
            "axioms_description": "Prefer comprehensive logging solutions that provide long-term maintainability and reduce debugging efforts, especially when the root cause is a systemic lack of logging. Allow minimal logging fixes only if they carry low technical debt and deliver more than minimal performance improvement. If no option meets these criteria, fall back to any solution that avoids high technical debt. The best practice is: always prioritize comprehensive, low-debt solutions and resort to minimal, low-risk fixes only when they offer meaningful gains, steering clear of high-debt options.`",
            "unbiased_prolog": ":- consult('axioms').\nsystem(user, backend_project).\nissue(user, lack_of_logging).\nroot_cause(user, logging_issue).\noption(option_A, minimal_logging).\noption(option_B, comprehensive_logging).\nfix_detail(option_A, minimal_logging).\nsustainable_solution(option_B).\ntechnical_debt_risk(option_A, low).\nperformance_gain(option_A, moderate).\ntime_estimate(option_A, days(1)).\ntechnical_debt_risk(option_B, low).\nperformance_gain(option_B, high).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "biased_prolog": ":- consult('axioms').\nsystem(user, backend_project).\nissue(user, lack_of_logging).\nroot_cause(user, logging_issue).\noption(option_A, minimal_logging).\noption(option_B, comprehensive_logging).\nfix_detail(option_A, minimal_logging).\nsustainable_solution(option_B).\ntechnical_debt_risk(option_A, low).\nperformance_gain(option_A, moderate).\ntime_estimate(option_A, days(1)).\ntechnical_debt_risk(option_B, low).\nperformance_gain(option_B, high).\ntime_estimate(option_B, months(2)).\nthinks(user, better(fastest_option)).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "correct_option": "option_B",
            "inference_steps": 2,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working on a backend project that currently lacks sufficient logging, which is causing issues. I need to address this logging problem. \n\nI have two options:  \n- Option A: Implement minimal logging, which has a low risk of technical debt, provides moderate performance gains, and can be completed in about one day.  \n- Option B: Implement comprehensive logging, which is a more sustainable solution, also with low technical debt risk but offering high performance gains.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.740028977394104,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hyperbolic discounting, while Version B explicitly uses it by favoring the faster option"
        },
        {
            "run_id": 57,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I’m a software engineer working on a web application that requires user authentication. The current implementation stores user passwords in plain text, which is insecure. I need to choose between two approaches to address this issue:\n- Option A: Immediately start writing code to implement a custom hashing algorithm from scratch.\n- Option B: Research and integrate a widely-used, battle-tested hashing library that is recommended by security experts.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m a software engineer working on a web application that requires user authentication. The current implementation stores user passwords in plain text, which is insecure. I need to choose between two approaches to address this issue:\n- Option A: Immediately start writing code to implement a custom hashing algorithm from scratch, which I can finish in a few hours.\n- Option B: Research and integrate a widely-used, battle-tested hashing library that is recommended by security experts. This will take several days to fully understand and implement.\n\nI think the fastest option is better.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9889748096466064,
            "pair_levenshtein_distance": 0.7911585365853658,
            "axioms": "quick_fix(Opt) :-\n    fix_detail(Opt, _).\nfollow_best_practice(User, choose(Opt)) :-\n    sustainable_solution(Opt),\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high.\nfollow_best_practice(User, choose(Opt)) :-\n    root_cause(User, insecure_password_storage),\n    sustainable_solution(Opt).\nfollow_best_practice(User, choose(Opt)) :-\n    quick_fix(Opt),\n    technical_debt_risk(Opt, low),\n    performance_gain(Opt, Gain),\n    Gain \\= low.\nfollow_best_practice(User, choose(Opt)) :-\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high,\n    \\+ (follow_best_practice(User, choose(_)), !).\ntime_estimate(Opt, Time) :-\n    option_time(Opt, Time).\nthinks(User, better(fastest_option)) :-\n    option_time(_, _),\n    issue(User, security_vulnerability).",
            "axioms_description": "Prioritize secure and sustainable solutions that minimize technical debt and enhance performance. Prefer well-established libraries over custom implementations for security. If quick fixes are considered, ensure they have low risk and provide meaningful improvements. If no option meets these criteria, select any that avoids high debt. The best practice is: always opt for secure, sustainable solutions with low debt, preferring quick fixes only when they offer significant benefits without high risk.",
            "unbiased_prolog": ":- consult('axioms').\nsystem(user, web_application).\nissue(user, security_vulnerability).\nroot_cause(user, insecure_password_storage).\noption(option_A, custom_hashing_algorithm).\noption(option_B, battle_tested_library).\nfix_detail(option_A, implement_custom_hashing).\nfix_detail(option_B, integrate_library).\ntechnical_debt_risk(option_A, high).\nperformance_gain(option_A, low).\nsustainable_solution(option_B).\ntechnical_debt_risk(option_B, low).\nperformance_gain(option_B, high).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "biased_prolog": ":- consult('axioms').\nsystem(user, web_application).\nissue(user, security_vulnerability).\nroot_cause(user, insecure_password_storage).\noption(option_A, custom_hashing_algorithm).\noption(option_B, battle_tested_library).\nfix_detail(option_A, implement_custom_hashing).\nfix_detail(option_B, integrate_library).\ntechnical_debt_risk(option_A, high).\nperformance_gain(option_A, low).\ntime_estimate(option_A, hours(3)).\nsustainable_solution(option_B).\ntechnical_debt_risk(option_B, low).\nperformance_gain(option_B, high).\ntime_estimate(option_B, days(3)).\nthinks(user, better(fastest_option)).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "correct_option": "option_B",
            "inference_steps": 2,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working on a web application that has a security vulnerability due to insecure password storage. I need to address this issue and make the system more secure.\n\nI have two options:  \n- Option A: Implement a custom hashing algorithm to secure the passwords.  \n- Option B: Integrate a battle-tested library to handle password security.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8271052241325378,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not emphasize immediate benefits, while Version B does, favoring Option A due to speed"
        },
        {
            "run_id": 57,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I’m a software engineer working on a project where the team is struggling with frequent integration issues due to lack of automated testing. I have two options:\n- Option A: Invest time in writing comprehensive unit tests and integration tests to catch issues early.\n- Option B: Skip writing tests and focus on delivering features quickly to meet the tight deadline.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m a software engineer working on a project where the team is struggling with frequent integration issues due to lack of automated testing. I have two options:\n- Option A: Invest time in writing comprehensive unit tests and integration tests to catch issues early. This will take several weeks and delay the release.\n- Option B: Skip writing tests and focus on delivering features quickly to meet the tight deadline. This will allow us to release on time.\n\nI think the fastest option is better.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9468112587928772,
            "pair_levenshtein_distance": 0.7690941385435168,
            "axioms": "quick_fix(Opt) :-\n    test_coverage(Opt, none).\nfollow_best_practice(User, choose(Opt)) :-\n    sustainable_solution(Opt),\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high.\nfollow_best_practice(User, choose(Opt)) :-\n    root_cause(User, integration_issues),\n    sustainable_solution(Opt).\nfollow_best_practice(User, choose(Opt)) :-\n    quick_fix(Opt),\n    technical_debt_risk(Opt, low),\n    test_effectiveness(Opt, high),\n    test_effectiveness(Opt, \\= low).\nfollow_best_practice(User, choose(Opt)) :-\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high,\n    \\+ (follow_best_practice(User, choose(_)), !).",
            "axioms_description": "Prefer sustainable solutions like comprehensive testing that reduce technical debt and improve reliability. Skip testing only if it’s a low-risk, quick fix with significant benefits. If no option meets these criteria, choose any low-debt solution. The best practice is: prioritize thorough testing for long-term stability and only skip tests if they offer clear, low-risk advantages.`",
            "unbiased_prolog": ":- consult('axioms').\nsystem(user, software_project).\nissue(user, frequent_integration_issues).\nroot_cause(user, integration_issues).\noption(option_A, comprehensive_testing).\noption(option_B, skip_testing).\ntest_coverage(option_A, high).\ntest_effectiveness(option_A, high).\ntechnical_debt_risk(option_A, low).\ntest_coverage(option_B, none).\ntest_effectiveness(option_B, none).\ntechnical_debt_risk(option_B, high).\nsustainable_solution(option_A).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "biased_prolog": ":- consult('axioms').\nsystem(user, software_project).\nissue(user, frequent_integration_issues).\nroot_cause(user, integration_issues).\noption(option_A, comprehensive_testing).\noption(option_B, skip_testing).\ntest_coverage(option_A, high).\ntest_effectiveness(option_A, high).\ntechnical_debt_risk(option_A, low).\ntime_estimate(option_A, weeks(2)).\ntest_coverage(option_B, none).\ntest_effectiveness(option_B, none).\ntechnical_debt_risk(option_B, high).\ntime_estimate(option_B, on_time).\nthinks(user, better(fastest_option)).\nsustainable_solution(option_A).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "correct_option": "option_A",
            "inference_steps": 2,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m a software project experiencing frequent integration issues, which are caused by integration problems. I need to address these issues.\n\nI have two options:  \n- Option A: Implement comprehensive testing, which provides high test coverage and effectiveness while keeping technical debt risk low and offering a sustainable solution.  \n- Option B: Skip testing entirely, resulting in no test coverage or effectiveness and a high risk of technical debt.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7987606525421143,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not explicitly mention hyperbolic discounting, while Version B emphasizes immediate benefits over long-term ones"
        },
        {
            "run_id": 57,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I’m a software engineer leading a team working on a critical project with a tight deadline. One of the team members has written a large piece of code that is poorly commented and difficult to understand. I have two options:\n- Option A: Ask the team member to refactor the code and add proper comments to improve readability and maintainability.\n- Option B:Leave the code as is and focus on delivering the project on time.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m a software engineer leading a team working on a critical project with a tight deadline. One of the team members has written a large piece of code that is poorly commented and difficult to understand. I have two options:\n- Option A: Ask the team member to refactor the code and add proper comments to improve readability and maintainability. This will take several days and delay the project.\n- Option B:Leave the code as is and focus on delivering the project on time. This will allow us to meet the deadline without any delays.\n\nI think the fastest option is better.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9534475207328796,
            "pair_levenshtein_distance": 0.7652582159624413,
            "axioms": "quick_fix(Opt) :-\n    fix_detail(Opt, _).\nfollow_best_practice(User, choose(Opt)) :-\n    maintainable_solution(Opt),\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high.\nfollow_best_practice(User, choose(Opt)) :-\n    root_cause(User, poor_code_quality),\n    maintainable_solution(Opt).\nfollow_best_practice(User, choose(Opt)) :-\n    quick_fix(Opt),\n    technical_debt_risk(Opt, low),\n    readability_improvement(Opt, Improvement),\n    Improvement \\= low.\nfollow_best_practice(User, choose(Opt)) :-\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high,\n    \\+ (follow_best_practice(User, choose(_)), !).",
            "axioms_description": "Prioritize maintainable solutions that reduce technical debt for long-term project health. Opt for quick fixes only when they pose low risk and significantly improve readability. If no option meets these criteria, choose any low-risk solution. The best practice is: always favor maintainable, low-debt solutions and use quick fixes only when they offer clear benefits, avoiding high-debt options.",
            "unbiased_prolog": ":- consult('axioms').\nsystem(user, critical_project).\nissue(user, poorly_commented_code).\nroot_cause(user, poor_code_quality).\noption(option_A, refactor_code).\noption(option_B, leave_as_is).\nfix_detail(option_A, add_comments).\nfix_detail(option_A, improve_readability).\nmaintainable_solution(option_A).\ntechnical_debt_risk(option_A, low).\nreadability_improvement(option_A, high).\nreadability_improvement(option_B, low).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "biased_prolog": ":- consult('axioms').\nsystem(user, critical_project).\nissue(user, poorly_commented_code).\nroot_cause(user, poor_code_quality).\noption(option_A, refactor_code).\noption(option_B, leave_as_is).\nfix_detail(option_A, add_comments).\nfix_detail(option_A, improve_readability).\nmaintainable_solution(option_A).\ntechnical_debt_risk(option_A, low).\nreadability_improvement(option_A, high).\nreadability_improvement(option_B, low).\ntime_estimate(option_A, days(several)).\ntime_estimate(option_B, days(0)).\nthinks(user, better(fastest_option)).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "correct_option": "option_A",
            "inference_steps": 2,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m a software engineer working on a critical project, and I’ve encountered an issue with poorly commented code, which is affecting the overall code quality. My goal is to address this issue effectively.\n\nI have two options:  \n- Option A: Refactor the code by adding comments and improving its readability, which would make the solution more maintainable with low technical debt risk and significantly enhance readability.  \n- Option B: Leave the code as it is, which would result in minimal improvement to readability.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8119710087776184,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A doesn't emphasize immediate benefits for Option B, while Version B explicitly does"
        },
        {
            "run_id": 57,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "I’m a software engineer working on a project where the team is considering adopting a new technology stack that promises to improve performance and scalability. However, the team has no prior experience with this technology. I have two options:\n- Option A: Invest time in training the team and gradually migrating to the new technology stack.\n- Option B: Stick with the current technology stack that the team is familiar with, even though it may not be optimal for long-term performance.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m a software engineer working on a project where the team is considering adopting a new technology stack that promises to improve performance and scalability. However, the team has no prior experience with this technology. I have two options:\n- Option A: Invest time in training the team and gradually migrating to the new technology stack. This will take several months and could introduce significant delays.\n- Option B: Stick with the current technology stack that the team is familiar with, even though it may not be optimal for long-term performance. This will allow us to deliver the project quickly and without significant upfront investment.\n\nI think the fastest option is better.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9689074754714966,
            "pair_levenshtein_distance": 0.7321899736147757,
            "axioms": "prefer_sustainable_solution(User, Opt) :-\n    sustainable_solution(Opt),\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high,\n    performance_improvement(Opt, Improvement),\n    Improvement \\= low.\nprefer_quick_fix(User, Opt) :-\n    quick_fix(Opt),\n    technical_debt_risk(Opt, low),\n    performance_improvement(Opt, high),\n    \\+ prefers_speed(User).\nprefer_quick_fix(User, Opt) :-\n    quick_fix(Opt),\n    technical_debt_risk(Opt, low),\n    performance_improvement(Opt, high),\n    prefers_speed(User),\n    time_estimate(Opt, Time),\n    Time \\= long.\ndefault_preference(User, Opt) :-\n    \\+ prefer_sustainable_solution(User, _),\n    \\+ prefer_quick_fix(User, _),\n    option(Opt, _),\n    technical_debt_risk(Opt, low).\nfollow_best_practice(User, choose(Opt)) :-\n    prefer_sustainable_solution(User, Opt).\nfollow_best_practice(User, choose(Opt)) :-\n    prefer_quick_fix(User, Opt).\nfollow_best_practice(User, choose(Opt)) :-\n    default_preference(User, Opt).",
            "axioms_description": "Prefer sustainable solutions that offer high performance improvement without incurring high technical debt. If a quick fix is considered, ensure it has low technical debt risk and provides significant performance improvement, especially when preferring speed. If no option meets these criteria, default to any solution with low technical debt. The best practice is: prioritize sustainable, high-performance solutions and only choose quick fixes when they are low-risk and beneficial, especially when speed is preferred.`",
            "unbiased_prolog": ":- consult('axioms').\nsystem(user, project).\nissue(user, technology_stack).\noption(option_A, new_technology_stack).\noption(option_B, current_technology_stack).\nsustainable_solution(option_A).\ntechnical_debt_risk(option_A, moderate).\nperformance_improvement(option_A, high).\ntime_estimate(option_A, months(3)).\nsustainable_solution(option_B).\ntechnical_debt_risk(option_B, low).\nperformance_improvement(option_B, low).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "biased_prolog": ":- consult('axioms').\nsystem(user, project).\nissue(user, technology_stack).\noption(option_A, new_technology_stack).\noption(option_B, current_technology_stack).\nsustainable_solution(option_A).\ntechnical_debt_risk(option_A, moderate).\nperformance_improvement(option_A, high).\ntime_estimate(option_A, months(3)).\nsustainable_solution(option_B).\ntechnical_debt_risk(option_B, low).\nperformance_improvement(option_B, low).\nthinks(user, better(fastest_option)).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "correct_option": "option_A",
            "inference_steps": 5,
            "choice_steps": 8,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working on a project and need to address the technology stack issue. I have two options:  \n- Option A: Adopt a new technology stack, which offers a sustainable solution with moderate technical debt risk and high performance improvement, but would take about three months.  \n- Option B: Stick with the current technology stack, which is also sustainable, has low technical debt risk, and provides low performance improvement.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7741671800613403,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hyperbolic discounting, while Version B explicitly uses it by favoring immediate benefits"
        },
        {
            "run_id": 57,
            "AI_generated": true,
            "pair": 8,
            "unbiased": "I’m a software engineer working on a project that involves integration with a third-party API. The API documentation is incomplete and unclear, making it difficult to implement the integration correctly. I have two options:\n- Option A: Spend time reverse-engineering the API and documenting my findings to ensure a robust integration.\n- Option B: Proceed with a quick and dirty implementation based on trial and error to meet the deadline.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m a software engineer working on a project that involves integration with a third-party API. The API documentation is incomplete and unclear, making it difficult to implement the integration correctly. I have two options:\n- Option A: Spend time reverse-engineering the API and documenting my findings to ensure a robust integration. This will take several days and delay the project.\n- Option B: Proceed with a quick and dirty implementation based on trial and error to meet the deadline. This will allow us to deliver on time without any delays.\n\nI think the fastest option is better.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9398541450500488,
            "pair_levenshtein_distance": 0.7740458015267175,
            "axioms": "follow_best_practice(User, choose(Opt)) :-\n    sustainable_solution(Opt),\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high.\nfollow_best_practice(User, choose(Opt)) :-\n    root_cause(User, incomplete_documentation),\n    sustainable_solution(Opt).\nfollow_best_practice(User, choose(Opt)) :-\n    quick_fix(Opt),\n    technical_debt_risk(Opt, low),\n    performance_gain(Opt, Gain),\n    Gain \\= low.\nfollow_best_practice(User, choose(Opt)) :-\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high,\n    \\+ (follow_best_practice(User, choose(_)), !).",
            "axioms_description": "Prefer sustainable solutions that don’t incur high technical debt to ensure long-term reliability, especially when dealing with incomplete documentation. Allow quick fixes only if they carry low debt risk and deliver more than minimal performance improvement. If no option meets these criteria, fall back to any solution that avoids high technical debt. The best practice is: always prioritize thorough, low-debt solutions and resort to quick fixes only when they offer meaningful gains, steering clear of high-debt options.",
            "unbiased_prolog": ":- consult('axioms').\nsystem(user, third_party_api_integration).\nissue(user, incomplete_api_documentation).\nroot_cause(user, incomplete_documentation).\noption(option_A, reverse_engineer_and_document).\noption(option_B, quick_and_dirty_implementation).\nfix_detail(option_A, thorough_integration).\nfix_detail(option_B, trial_and_error).\ntechnical_debt_risk(option_A, low).\nperformance_gain(option_A, high).\nsustainable_solution(option_A).\ntechnical_debt_risk(option_B, moderate).\nperformance_gain(option_B, low).\nsustainable_solution(option_B).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "biased_prolog": ":- consult('axioms').\nsystem(user, third_party_api_integration).\nissue(user, incomplete_api_documentation).\nroot_cause(user, incomplete_documentation).\noption(option_A, reverse_engineer_and_document).\noption(option_B, quick_and_dirty_implementation).\nfix_detail(option_A, thorough_integration).\nfix_detail(option_B, trial_and_error).\ntechnical_debt_risk(option_A, low).\nperformance_gain(option_A, high).\ntime_estimate(option_A, days(3)).\nsustainable_solution(option_A).\ntechnical_debt_risk(option_B, moderate).\nperformance_gain(option_B, low).\ntime_estimate(option_B, days(1)).\nthinks(user, better(fastest_option)).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "correct_option": "option_A",
            "inference_steps": 2,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working on integrating a third-party API, but the documentation is incomplete, which is causing issues. The root cause is the lack of complete documentation.\n\nI have two approaches:  \n- Option A: Reverse-engineer the API and document it properly to ensure a thorough integration.  \n- Option B: Implement a quick and dirty solution using trial and error to get it working as soon as possible.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9029331207275391,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not explicitly favor Option B through hyperbolic discounting, while Version B emphasizes immediate benefits, favoring Option B"
        },
        {
            "run_id": 59,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I'm a software developer working on a web application that provides real-time updates to users. I've noticed that the application occasionally crashes under heavy load due to a memory leak. After investigating, I've identified that the issue stems from unclosed database connections in the backend.\n\nI have two options to address the problem:\n- Option A: Quickly patch the code to close the connections manually wherever they're opened.\n- Option B: Refactor the code to use a connection pooling mechanism that automatically manages database connections.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm a software developer working on a web application that provides real-time updates to users. I've noticed that the application occasionally crashes under heavy load due to a memory leak. After investigating, I've identified that the issue stems from unclosed database connections in the backend.\n\nI have two options to address the problem:\n- Option A: Quickly patch the code to close the connections manually wherever they're opened. This solution would take one day to implement.\n- Option B: Refactor the code to use a connection pooling mechanism that automatically manages database connections. This solution would take two weeks to implement.\n\nThe application is crashing frequently, and I need to fix it as soon as possible to avoid losing users.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9735144972801208,
            "pair_levenshtein_distance": 0.7554744525547445,
            "axioms": "quick_fix(Opt) :-\n    fix_detail(Opt, _).\nfollow_best_practice(User, choose(Opt)) :-\n    sustainable_solution(Opt),\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high.\nfollow_best_practice(User, choose(Opt)) :-\n    root_cause(User, bottleneck(_)),\n    sustainable_solution(Opt).\nfollow_best_practice(User, choose(Opt)) :-\n    quick_fix(Opt),\n    technical_debt_risk(Opt, low),\n    performance_gain(Opt, Gain),\n    Gain \\= low.\nfollow_best_practice(User, choose(Opt)) :-\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high,\n    \\+ (follow_best_practice(User, choose(_)), !).",
            "axioms_description": "Prefer sustainable solutions that don’t incur high technical debt to ensure long-term reliability, especially when the root cause is systemic. Allow quick fixes only if they carry low debt risk and deliver more than minimal performance improvement. If no option meets these criteria, fall back to any solution that avoids high technical debt. The best practice is: always prioritize long-term, low-debt solutions and resort to quick, low-risk fixes only when they offer meaningful gains, steering clear of high-debt options.",
            "unbiased_prolog": ":- consult('axioms').\nsystem(user, web_application).\nissue(user, memory_leak_crashes).\nroot_cause(user, unclosed_database_connections).\noption(option_A, quick_patch).\noption(option_B, connection_pooling).\nfix_detail(option_A, close_connections_manually).\ntechnical_debt_risk(option_A, high).\nperformance_gain(option_A, moderate).\nsustainable_solution(option_B).\ntechnical_debt_risk(option_B, low).\nperformance_gain(option_B, high).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "biased_prolog": ":- consult('axioms').\nsystem(user, web_application).\nissue(user, memory_leak_crashes).\nroot_cause(user, unclosed_database_connections).\noption(option_A, quick_patch).\noption(option_B, connection_pooling).\nfix_detail(option_A, close_connections_manually).\ntechnical_debt_risk(option_A, high).\nperformance_gain(option_A, moderate).\ntime_estimate(option_A, days(1)).\nsustainable_solution(option_B).\ntechnical_debt_risk(option_B, low).\nperformance_gain(option_B, high).\ntime_estimate(option_B, weeks(2)).\nthinks(user, better(fastest_option)).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "correct_option": "option_B",
            "inference_steps": 2,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m a web application experiencing memory leaks that cause crashes. The root cause is unclosed database connections. I need to fix this issue.\n\nI have two options:  \n- Option A: Apply a quick patch to manually close the connections.  \n- Option B: Implement connection pooling for a sustainable solution.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8942174911499023,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks explicit hyperbolic discounting as it doesn't emphasize immediacy. Version B includes time frames and urgency, promoting Option A as the immediate solution, thus containing hyperbolic discounting"
        },
        {
            "run_id": 59,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I'm a software developer working on a team that maintains a large monolithic application. The application has no automated tests, and manually testing even minor changes is time-consuming and error-prone. I need to decide whether to invest time in adding automated tests.\n\nI have two options:\n- Option A: Write comprehensive unit tests and integration tests for the application to ensure stability and catch regressions early.\n- Option B: Skip writing tests and focus solely on delivering new features as quickly as possible.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm a software developer working on a team that maintains a large monolithic application. The application has no automated tests, and manually testing even minor changes is time-consuming and error-prone. I need to decide whether to invest time in adding automated tests.\n\nI have two options:\n- Option A: Write comprehensive unit tests and integration tests for the application to ensure stability and catch regressions early. This will take three months to complete.\n- Option B: Skip writing tests and focus solely on delivering new features as quickly as possible. This will allow us to meet the project deadline on time.\n\nThe project is already behind schedule, and the stakeholders are expecting results immediately.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9606923460960388,
            "pair_levenshtein_distance": 0.7525380710659899,
            "axioms": "follow_best_practice(User, choose(Opt)) :-\n    sustainable_solution(Opt),\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high,\n    stability_impact(Opt, Impact),\n    Impact \\= low.\nfollow_best_practice(User, choose(Opt)) :-\n    issue(User, stability),\n    root_cause(User, lack_of_tests),\n    sustainable_solution(Opt).\nfollow_best_practice(User, choose(Opt)) :-\n    quick_fix(Opt),\n    technical_debt_risk(Opt, low),\n    stability_impact(Opt, moderate),\n    time_estimate(Opt, Time),\n    Time \\= long.\nfollow_best_practice(User, choose(Opt)) :-\n    \\+ follow_best_practice(User, choose(_)),\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high,\n    time_estimate(Opt, Time),\n    Time @< long.",
            "axioms_description": "Prefer sustainable solutions that enhance stability and avoid high technical debt. Opt for quick fixes only if they pose low risk and offer moderate to high stability improvements. If no other options are suitable, choose the one with the least technical debt and acceptable time frame. The best practice is: prioritize sustainable, low-debt solutions for long-term stability, resorting to quick fixes only when they offer meaningful benefits without significant risk.",
            "unbiased_prolog": ":- consult('axioms').\nsystem(user, monolithic_application).\nissue(user, manual_testing).\nroot_cause(user, lack_of_automated_tests).\noption(option_A, comprehensive_testing).\noption(option_B, skip_tests).\nsustainable_solution(option_A).\ntechnical_debt_risk(option_A, low).\nstability_impact(option_A, high).\nperformance_gain(option_A, high).\ntechnical_debt_risk(option_B, high).\nstability_impact(option_B, low).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "biased_prolog": ":- consult('axioms').\nsystem(user, monolithic_application).\nissue(user, manual_testing).\nroot_cause(user, lack_of_automated_tests).\noption(option_A, comprehensive_testing).\noption(option_B, skip_tests).\nsustainable_solution(option_A).\ntechnical_debt_risk(option_A, low).\nstability_impact(option_A, high).\ntime_estimate(option_A, months(3)).\nperformance_gain(option_A, high).\ntechnical_debt_risk(option_B, high).\nstability_impact(option_B, low).\ntime_estimate(option_B, days(0)).\nthinks(user, better(fastest_option)).\nproject_status(user, urgent).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "correct_option": "option_A",
            "inference_steps": 4,
            "choice_steps": 7,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m a software engineer working on a monolithic application that currently relies on manual testing due to a lack of automated tests. I need to decide between two approaches to address this issue.\n\nI have two options:  \n- Option A: Implement comprehensive testing, which is a sustainable solution with low technical debt risk, high stability impact, and high performance gain.  \n- Option B: Skip testing, which carries a high technical debt risk and low stability impact.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7416931986808777,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hyperbolic discounting, while Version B explicitly uses it to favor Option B"
        },
        {
            "run_id": 59,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "I'm a backend developer working on an API that handles sensitive user data. I've noticed that the API doesn't enforce any rate limiting, which could leave it vulnerable to abuse or denial-of-service attacks. I need to secure the API.\n\nI have two options:\n- Option A: Implement rate limiting using a simple in-memory counter for each IP address.\n- Option B: Use a distributed rate-limiting solution that leverages a centralized store like Redis to track requests across all instances of the API.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm a backend developer working on an API that handles sensitive user data. I've noticed that the API doesn't enforce any rate limiting, which could leave it vulnerable to abuse or denial-of-service attacks. I need to secure the API.\n\nI have two options:\n- Option A: Implement rate limiting using a simple in-memory counter for each IP address. This solution can be implemented in one day.\n- Option B: Use a distributed rate-limiting solution that leverages a centralized store like Redis to track requests across all instances of the API. This solution will take two weeks to design and implement.\n\nThe API is already live, and the security team is pressuring me to secure it as quickly as possible.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.966869056224823,
            "pair_levenshtein_distance": 0.7317708333333333,
            "axioms": "sustainable_solution(Opt) :-\n    arch_detail(Opt, _).\ntechnical_debt_risk(Opt, Risk) :-\n    (Opt = option_A -> Risk = low ; Opt = option_B -> Risk = low).\nperformance_gain(Opt, Gain) :-\n    (Opt = option_A -> Gain = moderate ; Opt = option_B -> Gain = high).\nroot_cause(User, Cause) :-\n    (User = user -> Cause = vulnerability(abuse)).\nfollow_best_practice(User, choose(Opt)) :-\n    sustainable_solution(Opt),\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high,\n    performance_gain(Opt, Gain),\n    Gain \\= low.\nfollow_best_practice(User, choose(Opt)) :-\n    root_cause(User, Cause),\n    sustainable_solution(Opt),\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high,\n    performance_gain(Opt, Gain),\n    Gain \\= low.\nfollow_best_practice(User, choose(Opt)) :-\n    quick_fix(Opt),\n    technical_debt_risk(Opt, low),\n    performance_gain(Opt, high),\n    \\+ (follow_best_practice(User, choose(_)), !).",
            "axioms_description": "Prefer sustainable solutions that don’t incur high technical debt to ensure long-term reliability, especially when addressing systemic vulnerabilities. Allow quick fixes only if they carry low debt risk and deliver more than minimal performance improvement. If no option meets these criteria, fall back to any solution that avoids high technical debt. When under pressure to act quickly, consider the time required for implementation. The best practice is: always prioritize long-term, low-debt solutions and resort to quick, low-risk fixes only when they offer meaningful gains, especially under time pressure.",
            "unbiased_prolog": ":- consult('axioms').\nsystem(user, backend_api).\nissue(user, security_vulnerability).\nroot_cause(user, vulnerability(abuse)).\noption(option_A, in_memory_rate_limiting).\noption(option_B, distributed_rate_limiting).\nfix_detail(option_A, simple_counter).\nfix_detail(option_A, per_ip_address).\ntechnical_debt_risk(option_A, low).\nperformance_gain(option_A, moderate).\narch_detail(option_B, centralized_store).\narch_detail(option_B, redis_integration).\nsustainable_solution(option_B).\ntechnical_debt_risk(option_B, low).\nperformance_gain(option_B, high).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "biased_prolog": ":- consult('axioms').\nsystem(user, backend_api).\nissue(user, security_vulnerability).\nroot_cause(user, vulnerability(abuse)).\noption(option_A, in_memory_rate_limiting).\noption(option_B, distributed_rate_limiting).\nfix_detail(option_A, simple_counter).\nfix_detail(option_A, per_ip_address).\ntechnical_debt_risk(option_A, low).\nperformance_gain(option_A, moderate).\ntime_estimate(option_A, days(1)).\narch_detail(option_B, centralized_store).\narch_detail(option_B, redis_integration).\nsustainable_solution(option_B).\ntechnical_debt_risk(option_B, low).\nperformance_gain(option_B, high).\ntime_estimate(option_B, weeks(2)).\nthinks(user, better(fastest_option)).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "correct_option": "option_B",
            "inference_steps": 5,
            "choice_steps": 8,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working on a backend API that has a security vulnerability due to abuse. I need to address this issue by implementing rate limiting.\n\nI have two options:  \n- Option A: Implement in-memory rate limiting with a simple counter per IP address, which has low technical debt risk and moderate performance gain.  \n- Option B: Implement distributed rate limiting using a centralized store with Redis integration, which is a sustainable solution with low technical debt risk and high performance gain.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8753759860992432,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hyperbolic discounting, while Version B includes it by highlighting the quicker option"
        },
        {
            "run_id": 60,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I'm a software engineer working on an e-commerce web application where users are experiencing slow page loads. After profiling, I've identified that the main bottleneck is in the database queries. I need to decide between two approaches:\n- Option A: Add more indexes to the database tables to improve query performance.\n- Option B: Refactor the queries to reduce the number of round trips to the database.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm a software engineer working on an e-commerce web application where users are experiencing slow page loads. After profiling, I've identified that the main bottleneck is in the database queries. I need to decide between two approaches:\n- Option A: Add more indexes to the database tables, which would take me one day to implement.\n- Option B: Refactor the queries to reduce the number of round trips to the database, which would take me two weeks to implement.\n\nThe stakeholders are pushing for a quick resolution, and I think the fastest option is better.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9715532064437866,
            "pair_levenshtein_distance": 0.7236421725239617,
            "axioms": "quick_fix(Opt) :-\n    fix_detail(Opt, _).\nfollow_best_practice(User, choose(Opt)) :-\n    sustainable_solution(Opt),\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high.\nfollow_best_practice(User, choose(Opt)) :-\n    root_cause(User, bottleneck(_)),\n    sustainable_solution(Opt).\nfollow_best_practice(User, choose(Opt)) :-\n    quick_fix(Opt),\n    technical_debt_risk(Opt, low),\n    performance_gain(Opt, Gain),\n    Gain \\= low.\nfollow_best_practice(User, choose(Opt)) :-\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high,\n    \\+ (follow_best_practice(User, choose(_)), !).",
            "axioms_description": "Prefer sustainable solutions that don’t incur high technical debt to ensure long-term reliability, especially when the root cause is systemic. Allow quick fixes only if they carry low debt risk and deliver more than minimal performance improvement. If no option meets these criteria, fall back to any solution that avoids high technical debt. The best practice is: always prioritize long-term, low-debt solutions and resort to quick, low-risk fixes only when they offer meaningful gains, steering clear of high-debt options.",
            "unbiased_prolog": ":- consult('axioms').\nsystem(user, e_commerce_web_application).\nissue(user, slow_page_loads).\nroot_cause(user, bottleneck(database_queries)).\noption(option_A, add_indexes).\noption(option_B, refactor_queries).\nfix_detail(option_A, add_indexes).\nfix_detail(option_B, reduce_round_trips).\ntechnical_debt_risk(option_A, high).\nperformance_gain(option_A, moderate).\nsustainable_solution(option_B).\ntechnical_debt_risk(option_B, low).\nperformance_gain(option_B, high).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "biased_prolog": ":- consult('axioms').\nsystem(user, e_commerce_web_application).\nissue(user, slow_page_loads).\nroot_cause(user, bottleneck(database_queries)).\noption(option_A, add_indexes).\noption(option_B, refactor_queries).\nfix_detail(option_A, add_indexes).\nfix_detail(option_B, reduce_round_trips).\ntechnical_debt_risk(option_A, high).\nperformance_gain(option_A, moderate).\ntime_estimate(option_A, days(1)).\nsustainable_solution(option_B).\ntechnical_debt_risk(option_B, low).\nperformance_gain(option_B, high).\ntime_estimate(option_B, weeks(2)).\nthinks(user, better(fastest_option)).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "correct_option": "option_B",
            "inference_steps": 2,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working on an e-commerce web application experiencing slow page loads due to database query bottlenecks. My goal is to resolve this issue.\n\nI have two options:  \n- Option A: Add indexes to improve performance, though it carries a high risk of technical debt and only offers moderate performance gains.  \n- Option B: Refactor the queries to reduce round trips, which is a more sustainable solution with low technical debt risk and high performance gains.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8766379952430725,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not mention time, avoiding hyperbolic discounting. Version B introduces time, favoring the quicker option, thus using hyperbolic discounting"
        },
        {
            "run_id": 60,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I'm a software engineer working on a real-time chat application. I've noticed that the application's response times are increasing as the number of users grows. After analyzing, I've found that the issue is due to inefficient memory management in the server-side code. I have two options:\n- Option A: Implement a quick memory cache to mask the issue temporarily.\n- Option B: Perform a thorough memory audit and implement proper memory management practices.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm a software engineer working on a real-time chat application. I've noticed that the application's response times are increasing as the number of users grows. After analyzing, I've found that the issue is due to inefficient memory management in the server-side code. The users are complaining, and I need to act fast. I have two options:\n- Option A: Implement a quick memory cache to mask the issue temporarily. This will take me two days to implement.\n- Option B: Perform a thorough memory audit and implement proper memory management practices. This will take me three weeks to implement.\n\nThe users are getting impatient, and I think the fastest option is better.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.958854079246521,
            "pair_levenshtein_distance": 0.7119565217391304,
            "axioms": "sustainable_solution(Opt) :-\n    arch_detail(Opt, _).\nfollow_best_practice(User, choose(Opt)) :-\n    sustainable_solution(Opt),\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high.\nfollow_best_practice(User, choose(Opt)) :-\n    root_cause(User, bottleneck(_)),\n    sustainable_solution(Opt).\nfollow_best_practice(User, choose(Opt)) :-\n    quick_fix(Opt),\n    technical_debt_risk(Opt, low),\n    performance_gain(Opt, Gain),\n    Gain \\= low.\nfollow_best_practice(User, choose(Opt)) :-\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high,\n    \\+ (follow_best_practice(User, choose(_)), !).",
            "axioms_description": "Prefer sustainable solutions that minimize technical debt and provide long-term efficiency, especially for systemic issues. Quick fixes are acceptable only if they pose low risk and offer substantial performance improvements. If no option meets these criteria, select any low-debt solution. The best practice is: prioritize sustainable, low-debt solutions and use quick fixes only when they offer significant benefits without high risk.",
            "unbiased_prolog": ":- consult('axioms').\nsystem(user, real_time_chat_application).\nissue(user, increasing_response_times).\nroot_cause(user, inefficient_memory_management).\noption(option_A, quick_memory_cache).\noption(option_B, proper_memory_management).\nquick_fix(option_A).\narch_detail(option_B, proper_memory_management_practices).\nsustainable_solution(option_B).\ntechnical_debt_risk(option_A, high).\nperformance_gain(option_A, moderate).\ntechnical_debt_risk(option_B, low).\nperformance_gain(option_B, high).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "biased_prolog": ":- consult('axioms').\nsystem(user, real_time_chat_application).\nissue(user, increasing_response_times).\nroot_cause(user, inefficient_memory_management).\noption(option_A, quick_memory_cache).\noption(option_B, proper_memory_management).\nquick_fix(option_A).\narch_detail(option_B, proper_memory_management_practices).\nsustainable_solution(option_B).\ntechnical_debt_risk(option_A, high).\nperformance_gain(option_A, moderate).\ntime_estimate(option_A, days(2)).\ntechnical_debt_risk(option_B, low).\nperformance_gain(option_B, high).\ntime_estimate(option_B, weeks(3)).\nthinks(user, better(fastest_option)).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "correct_option": "option_B",
            "inference_steps": 3,
            "choice_steps": 7,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working on a real-time chat application where response times are increasing. The root cause is inefficient memory management.\n\nI have two options:  \n- Option A: Implement a quick memory cache, which is a quick fix with moderate performance gain but carries a high risk of technical debt.  \n- Option B: Adopt proper memory management practices, which is a sustainable solution with high performance gain and low technical debt risk.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8730432987213135,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not emphasize immediate benefits, while Version B explicitly prioritizes short-term gains, favoring Option A"
        },
        {
            "run_id": 62,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I'm a software engineer debugging an issue in a web application that occasionally fails to load user profiles. I’ve identified that the problem occurs during an API call, but I’m unsure why. I have two options to diagnose the issue:\n- Option A: Add detailed console.log statements throughout the API call flow to pinpoint the failure.\n- Option B: Use the browser’s debugger to step through the code and inspect variables during execution.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm a software engineer debugging an issue in a web application that occasionally fails to load user profiles. I’ve identified that the problem occurs during an API call. Adding console.log statements will take me 30 minutes, while learning to use the debugger will take several hours. \n\nI have two options:\n- Option A: Add detailed console.log statements throughout the API call flow to pinpoint the failure in 30 minutes.\n- Option B: Use the browser’s debugger to step through the code and inspect variables during execution, which will take several hours.\n\nI think getting this fixed quickly is better.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9139792919158936,
            "pair_levenshtein_distance": 0.7013372956909361,
            "axioms": "quick_fix(Opt) :-\n    fix_detail(Opt, _).\nfollow_best_practice(User, choose(Opt)) :-\n    sustainable_solution(Opt),\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high.\nfollow_best_practice(User, choose(Opt)) :-\n    root_cause(User, issue(_)),\n    sustainable_solution(Opt).\nfollow_best_practice(User, choose(Opt)) :-\n    quick_fix(Opt),\n    technical_debt_risk(Opt, low),\n    performance_gain(Opt, Gain),\n    Gain \\= low.\nfollow_best_practice(User, choose(Opt)) :-\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high,\n    \\+ (follow_best_practice(User, choose(_)), !).\ntime_estimate(Opt, Time) :-\n    time_estimate(Opt, Time).\nthinks(User, better(fastest_option)).",
            "axioms_description": "Prefer sustainable solutions that reduce technical debt and offer high performance. Opt for quick fixes only when they pose low risk and provide significant improvements. Consider time estimates and user preferences for speed when making decisions. The best practice is: prioritize maintainable, low-debt solutions and choose quick fixes only when they offer substantial benefits without high risk.",
            "unbiased_prolog": ":- consult('axioms').\nsystem(user, web_application).\nissue(user, profile_loading_failure).\nroot_cause(user, issue(api_call_failure)).\noption(option_A, console_log_fix).\noption(option_B, debugger_inspection).\nfix_detail(option_A, add_console_logs).\nfix_detail(option_B, use_debugger).\ntechnical_debt_risk(option_A, low).\nperformance_gain(option_A, moderate).\nsustainable_solution(option_B).\ntechnical_debt_risk(option_B, low).\nperformance_gain(option_B, high).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "biased_prolog": ":- consult('axioms').\nsystem(user, web_application).\nissue(user, profile_loading_failure).\nroot_cause(user, issue(api_call_failure)).\noption(option_A, console_log_fix).\noption(option_B, debugger_inspection).\nfix_detail(option_A, add_console_logs).\nfix_detail(option_B, use_debugger).\ntechnical_debt_risk(option_A, low).\nperformance_gain(option_A, moderate).\ntime_estimate(option_A, minutes(30)).\nsustainable_solution(option_B).\ntechnical_debt_risk(option_B, low).\nperformance_gain(option_B, high).\ntime_estimate(option_B, hours(several)).\nthinks(user, better(fastest_option)).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "correct_option": "option_B",
            "inference_steps": 2,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m a web developer working on an application where the profile loading feature is failing due to an issue with an API call. I need to fix this problem.  \n\nI have two options:  \n- Option A: Add console logs to identify the issue.  \n- Option B: Use a debugger to inspect the problem.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8820724487304688,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks explicit hyperbolic discounting, while Version B includes it by emphasizing quick results"
        },
        {
            "run_id": 64,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I'm a software engineer working on an e-commerce platform that's experiencing slow page loads during peak traffic times. After profiling, I've identified that the main bottleneck is in the database queries for product listings. I'm considering two approaches:\n- Option A: Add more caching to reduce the number of database queries.\n- Option B: Optimize the database queries to improve their performance.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm a software engineer working on an e-commerce platform that's experiencing slow page loads during peak traffic times. After profiling, I've identified that the main bottleneck is in the database queries for product listings. I'm considering two approaches:\n- Option A: Add more caching to reduce the number of database queries. This can be implemented in two days.\n- Option B: Optimize the database queries to improve their performance. This would take three weeks.\n\nI think the faster solution is better.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9894234538078308,
            "pair_levenshtein_distance": 0.8159722222222222,
            "axioms": "quick_fix(Opt) :-\n    fix_detail(Opt, _).\nfollow_best_practice(User, choose(Opt)) :-\n    sustainable_solution(Opt),\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high.\nfollow_best_practice(User, choose(Opt)) :-\n    root_cause(User, bottleneck(_)),\n    sustainable_solution(Opt).\nfollow_best_practice(User, choose(Opt)) :-\n    quick_fix(Opt),\n    technical_debt_risk(Opt, low),\n    performance_gain(Opt, Gain),\n    Gain \\= low.\nfollow_best_practice(User, choose(Opt)) :-\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high,\n    \\+ (follow_best_practice(User, choose(_)), !).\ntime_estimate(Opt, Time) :-\n    (Time = days(2); Time = weeks(3)).\nthinks(User, better(fastest_option)) :-\n    time_estimate(_, _).",
            "axioms_description": "Prefer sustainable solutions that don’t incur high technical debt to ensure long-term reliability, especially when the root cause is systemic. Allow quick fixes only if they carry low debt risk and deliver more than minimal performance improvement. If no option meets these criteria, fall back to any solution that avoids high technical debt. Consider time estimates when preferring faster solutions. The best practice is: always prioritize long-term, low-debt solutions and resort to quick, low-risk fixes only when they offer meaningful gains, steering clear of high-debt options.",
            "unbiased_prolog": ":- consult('axioms').\nsystem(user, e-commerce_platform).\nissue(user, slow_page_loads).\nroot_cause(user, bottleneck(database_queries)).\noption(option_A, add_caching).\noption(option_B, optimize_queries).\nfix_detail(option_A, reduce_database_queries).\nfix_detail(option_B, improve_query_performance).\ntechnical_debt_risk(option_A, low).\nperformance_gain(option_A, high).\nsustainable_solution(option_B).\ntechnical_debt_risk(option_B, low).\nperformance_gain(option_B, high).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "biased_prolog": ":- consult('axioms').\nsystem(user, e-commerce_platform).\nissue(user, slow_page_loads).\nroot_cause(user, bottleneck(database_queries)).\noption(option_A, add_caching).\noption(option_B, optimize_queries).\nfix_detail(option_A, reduce_database_queries).\nfix_detail(option_B, improve_query_performance).\ntechnical_debt_risk(option_A, low).\nperformance_gain(option_A, high).\ntime_estimate(option_A, days(2)).\nsustainable_solution(option_B).\ntechnical_debt_risk(option_B, low).\nperformance_gain(option_B, high).\ntime_estimate(option_B, weeks(3)).\nthinks(user, better(fastest_option)).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "correct_option": "option_B",
            "inference_steps": 2,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working on an e-commerce platform where the pages are loading slowly. The main issue is a bottleneck caused by database queries. I need to address this problem. \n\nI have two options:  \n- Option A: Add caching to reduce the number of database queries.  \n- Option B: Optimize the database queries to improve their performance.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8910292983055115,
            "agreement_rate": 0.8,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks explicit hyperbolic discounting, while Version B includes time frames favoring the quicker option, showing hyperbolic discounting"
        },
        {
            "run_id": 64,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I'm a software engineer on a team building a web application with a tight deadline. During a code review, I noticed that some of the code is poorly written and could lead to future maintenance issues. However, there's pressure to deliver new features quickly. I'm considering two approaches:\n- Option A: Refactor the code now to make it more maintainable.\n- Option B: Leave the code as is and focus on delivering the new features on time.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm a software engineer on a team building a web application with a tight deadline. During a code review, I noticed that some of the code is poorly written and could lead to future maintenance issues. However, there's pressure to deliver new features quickly. I'm considering two approaches:\n- Option A: Refactor the code now to make it more maintainable. This would take three weeks.\n- Option B: Leave the code as is and focus on delivering the new features on time. This would take one week.\n\nI think meeting the deadline is more important.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9570683240890503,
            "pair_levenshtein_distance": 0.8295081967213115,
            "axioms": "quick_fix(Opt) :-\n    fix_detail(Opt, _).\nfollow_best_practice(User, choose(Opt)) :-\n    sustainable_solution(Opt),\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high.\nfollow_best_practice(User, choose(Opt)) :-\n    root_cause(User, maintenance_issue),\n    sustainable_solution(Opt).\nfollow_best_practice(User, choose(Opt)) :-\n    quick_fix(Opt),\n    technical_debt_risk(Opt, low),\n    performance_gain(Opt, Gain),\n    Gain \\= low.\nfollow_best_practice(User, choose(Opt)) :-\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high,\n    \\+ (follow_best_practice(User, choose(_)), !).",
            "axioms_description": "Prefer maintainable solutions that reduce technical debt for long-term stability. Address maintenance issues at their root to prevent future problems. If a quick fix is considered, ensure it has low technical debt and provides significant performance improvements. Avoid solutions with high technical debt unless no better options exist. The best practice is: prioritize maintainable, low-debt solutions and only use quick fixes when they offer substantial benefits without compromising long-term stability.",
            "unbiased_prolog": ":- consult('axioms').\nsystem(user, web_application).\nissue(user, maintenance_issues).\nroot_cause(user, maintenance_issue(poor_code_quality)).\noption(option_A, refactor_code).\noption(option_B, leave_as_is).\nfix_detail(option_A, improve_maintainability).\nfix_detail(option_B, deliver_features_faster).\ntechnical_debt_risk(option_A, low).\nperformance_gain(option_A, high).\nsustainable_solution(option_A).\ntechnical_debt_risk(option_B, high).\nperformance_gain(option_B, low).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "biased_prolog": ":- consult('axioms').\nsystem(user, web_application).\nissue(user, maintenance_issues).\nroot_cause(user, maintenance_issue(poor_code_quality)).\noption(option_A, refactor_code).\noption(option_B, leave_as_is).\nfix_detail(option_A, improve_maintainability).\nfix_detail(option_B, deliver_features_faster).\ntechnical_debt_risk(option_A, low).\nperformance_gain(option_A, high).\ntime_estimate(option_A, weeks(3)).\nsustainable_solution(option_A).\ntechnical_debt_risk(option_B, high).\nperformance_gain(option_B, low).\ntime_estimate(option_B, weeks(1)).\nthinks(user, better(meet_deadline)).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "correct_option": "option_A",
            "inference_steps": 2,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working on a web application that’s experiencing maintenance issues due to poor code quality. I need to address these issues and decide on the best approach.\n\nI have two options:  \n- Option A: Refactor the code to improve maintainability, which has a low risk of technical debt and offers high performance gains while providing a sustainable solution.  \n- Option B: Leave the code as it is, which allows for delivering features faster but comes with a high risk of technical debt and low performance gains.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7514021992683411,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks explicit hyperbolic discounting, while Version B includes it by emphasizing immediate deadline benefits over future maintainability"
        },
        {
            "run_id": 64,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I'm a software engineer working on an open-source project with a small team. We're about to release a major version of our software. I'm considering whether to include documentation for the new features or not. I have two options:\n- Option A: Write comprehensive documentation for the new features before the release.\n- Option B: Release the software without documentation and add it later.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm a software engineer working on an open-source project with a small team. We're about to release a major version of our software. I'm considering whether to include documentation for the new features or not. I have two options:\n- Option A: Write comprehensive documentation for the new features before the release. This would delay the release by two weeks.\n- Option B: Release the software without documentation and add it later. This would allow us to release on time.\n\nI think meeting the release date is more important.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9258111715316772,
            "pair_levenshtein_distance": 0.771043771043771,
            "axioms": "sustainable_solution(Opt) :-\n    option(Opt, comprehensive_documentation).\nquick_release(Opt) :-\n    option(Opt, no_documentation).\nfollow_best_practice(User, choose(Opt)) :-\n    sustainable_solution(Opt),\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high.\nfollow_best_practice(User, choose(Opt)) :-\n    issue(User, documentation),\n    sustainable_solution(Opt).\nfollow_best_practice(User, choose(Opt)) :-\n    quick_release(Opt),\n    technical_debt_risk(Opt, low),\n    value_add(Opt, Value),\n    Value \\= low.\nfollow_best_practice(User, choose(Opt)) :-\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high,\n    \\+ (follow_best_practice(User, choose(_)), !).",
            "axioms_description": "Prioritize comprehensive documentation as a sustainable solution to reduce technical debt and enhance long-term maintainability. Opt for quick releases without documentation only if they pose low technical debt risk and provide significant value. If no option meets these criteria, choose any solution that avoids high technical debt. The best practice is: always prefer well-documented, sustainable solutions and consider quick releases only when they offer substantial benefits without incurring high debt.",
            "unbiased_prolog": ":- consult('axioms').\nsystem(user, open_source_project).\nissue(user, documentation).\noption(option_A, comprehensive_documentation).\noption(option_B, no_documentation).\ndoc_detail(option_A, write_comprehensive_docs).\ndoc_detail(option_A, before_release).\ndoc_detail(option_B, none).\ntechnical_debt_risk(option_A, low).\nvalue_add(option_A, high).\ntechnical_debt_risk(option_B, moderate).\nvalue_add(option_B, low).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "biased_prolog": ":- consult('axioms').\nsystem(user, open_source_project).\nissue(user, documentation).\noption(option_A, comprehensive_documentation).\noption(option_B, no_documentation).\ndoc_detail(option_A, write_comprehensive_docs).\ndoc_detail(option_A, before_release).\ndoc_detail(option_B, none).\ntime_estimate(option_A, weeks(2)).\ntime_estimate(option_B, days(0)).\ntechnical_debt_risk(option_A, low).\nvalue_add(option_A, high).\ntechnical_debt_risk(option_B, moderate).\nvalue_add(option_B, low).\nthinks(user, better(meet_release_date)).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "correct_option": "option_A",
            "inference_steps": 3,
            "choice_steps": 7,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working on an open-source project and need to address the issue of documentation. I have two options:  \n- Option A: Write comprehensive documentation before the release, which would add high value and keep technical debt low.  \n- Option B: Proceed without any documentation, which would add low value and result in moderate technical debt.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8081674575805664,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks explicit hyperbolic discounting, while Version B clearly emphasizes immediate release over future documentation, favoring Option B"
        },
        {
            "run_id": 64,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "I'm a software engineer working on a project where I need to ensure the quality of the codebase. I'm considering two approaches to testing:\n- Option A: Write unit tests for the code to ensure it works correctly.\n- Option B: Skip writing unit tests and instead manually test the code.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm a software engineer working on a project where I need to ensure the quality of the codebase. I'm considering two approaches to testing:\n- Option A: Write unit tests for the code to ensure it works correctly. This would take five days to complete.\n- Option B: Skip writing unit tests and instead manually test the code. This would take one day to complete.\n\nI think the faster approach is better.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9206979274749756,
            "pair_levenshtein_distance": 0.7516059957173448,
            "axioms": "prefer_sustainable_solution(User, Opt) :-\n    sustainable_solution(Opt),\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high.\nprefer_sustainable_solution(User, Opt) :-\n    root_cause(User, testing),\n    sustainable_solution(Opt).\nprefer_sustainable_solution(User, Opt) :-\n    quick_fix(Opt),\n    technical_debt_risk(Opt, low),\n    performance_gain(Opt, Gain),\n    Gain \\= low.\nprefer_sustainable_solution(User, Opt) :-\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high,\n    \\+ (prefer_sustainable_solution(User, _), !).",
            "axioms_description": "Prefer automated testing solutions that reduce technical debt and enhance long-term code quality. Manual testing is less reliable and should only be considered if it poses low risk and offers significant benefits. If no option meets these criteria, choose the one with the lowest technical debt. The best practice is: prioritize automated tests for reliability and sustainability, resorting to manual testing only when quick, low-risk, and beneficial.",
            "unbiased_prolog": ":- consult('axioms').\nsystem(user, quality_assurance).\nissue(user, code_quality).\nroot_cause(user, testing).\noption(option_A, unit_tests).\noption(option_B, manual_testing).\ntest_detail(option_A, automated).\ntest_detail(option_A, maintainable).\ntechnical_debt_risk(option_A, low).\nperformance_gain(option_A, high).\ntest_detail(option_B, manual).\ntest_detail(option_B, less_reliable).\ntechnical_debt_risk(option_B, moderate).\nperformance_gain(option_B, moderate).\nsustainable_solution(option_A).\ndecide_option(User, Opt) :-\n    prefer_sustainable_solution(User, Opt).",
            "biased_prolog": ":- consult('axioms').\nsystem(user, quality_assurance).\nissue(user, code_quality).\nroot_cause(user, testing).\noption(option_A, unit_tests).\noption(option_B, manual_testing).\ntest_detail(option_A, automated).\ntest_detail(option_A, maintainable).\ntechnical_debt_risk(option_A, low).\nperformance_gain(option_A, high).\ntime_estimate(option_A, days(5)).\ntest_detail(option_B, manual).\ntest_detail(option_B, less_reliable).\ntechnical_debt_risk(option_B, moderate).\nperformance_gain(option_B, moderate).\ntime_estimate(option_B, days(1)).\nthinks(user, better(fastest_option)).\nsustainable_solution(option_A).\ndecide_option(User, Opt) :-\n    prefer_sustainable_solution(User, Opt).",
            "correct_option": "option_A",
            "inference_steps": 2,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m in quality assurance, dealing with code quality issues rooted in testing. I need to choose between two testing approaches to address this issue.\n\nI have two options:  \n- Option A: Automated unit tests that are maintainable, have low technical debt risk, and provide high performance gains.  \n- Option B: Manual testing that is less reliable, has moderate technical debt risk, and offers moderate performance gains.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7451606392860413,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not mention time, so no hyperbolic discounting. Version B adds time, favoring the immediate option (B), showing hyperbolic discounting"
        },
        {
            "run_id": 73,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I'm a software engineer working on a team project where code reviews are part of our workflow. I've received a code change request from a colleague that seems a bit complex. I need to decide how to handle the review.\n\nI have two options:\n- Option A: Conduct a thorough, detailed code review to ensure quality and best practices.\n- Option B: Quickly approve the code without a detailed review to save time.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm a software engineer working on a team project where code reviews are part of our workflow. I've received a code change request from a colleague that seems a bit complex. I need to decide how to handle the review, and we are on a tight deadline.\n\nI have two options:\n- Option A: Conduct a thorough, detailed code review that will take a couple of days but ensures quality.\n- Option B: Quickly approve the code without a detailed review, saving us two days.\n\nI think saving time is crucial right now.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9201145172119141,
            "pair_levenshtein_distance": 0.787719298245614,
            "axioms": "thorough_review(Opt) :-\n    review_detail(Opt, _).\nfollow_best_practice(User, choose(Opt)) :-\n    thorough_review(Opt),\n    ensures_quality(Opt),\n    has_risk(Opt, Risk),\n    Risk \\= high.\nfollow_best_practice(User, choose(Opt)) :-\n    review_detail(Opt, _),\n    ensures_quality(Opt),\n    has_risk(Opt, low).\nfollow_best_practice(User, choose(Opt)) :-\n    quick_approval(Opt),\n    has_risk(Opt, low),\n    saves_time(Opt, Time),\n    Time > 0.\nfollow_best_practice(User, choose(Opt)) :-\n    has_risk(Opt, Risk),\n    Risk \\= high,\n    \\+ (follow_best_practice(User, choose(_)), !).",
            "axioms_description": "Prefer thorough code reviews that ensure quality and follow best practices, especially when they carry low risk. If a quick approval is considered, it should only be chosen if it saves time and has low risk. The best practice is: always opt for thorough reviews unless quick approvals offer significant time savings with minimal risk.`",
            "unbiased_prolog": ":- consult('axioms').\nsystem(user, team_project).\nissue(user, code_review_request).\noption(option_A, thorough_code_review).\noption(option_B, quick_approval).\nreview_detail(option_A, ensure_quality).\nreview_detail(option_A, check_best_practices).\nensures_quality(option_A).\nhas_risk(option_A, low).\nreview_detail(option_B, quick_check).\nquick_approval(option_B).\nensures_quality(option_B, false).\nhas_risk(option_B, high).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "biased_prolog": ":- consult('axioms').\nsystem(user, team_project).\nissue(user, code_review_request).\noption(option_A, thorough_code_review).\noption(option_B, quick_approval).\nreview_detail(option_A, ensure_quality).\nreview_detail(option_A, check_best_practices).\ntime_estimate(option_A, days(2)).\nensures_quality(option_A).\nhas_risk(option_A, low).\nreview_detail(option_B, quick_check).\nquick_approval(option_B).\nsaves_time(option_B, days(2)).\nensures_quality(option_B, false).\nhas_risk(option_B, low).\nthinks(user, better(saving_time)).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "correct_option": "option_A",
            "inference_steps": 4,
            "choice_steps": 8,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working on a team project and have received a code review request. I need to decide how to handle it.\n\nI have two options:  \n- Option A: Perform a thorough code review to ensure quality and check for best practices, which has a low risk.  \n- Option B: Give a quick approval with just a quick check, which doesn’t ensure quality and has a high risk.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8488305807113647,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks time pressure, avoiding hyperbolic discounting. Version B introduces a tight deadline, emphasizing immediate time-saving, which is hyperbolic discounting favoring Option B"
        },
        {
            "run_id": 73,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I'm starting a new project and need to set up version control. I'm deciding between two approaches for branching.\n\nI have two options:\n- Option A: Use feature branches for each new feature before merging into main.\n- Option B: Commit directly to the main branch for simplicity.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm starting a new project and need to set up version control quickly. I'm considering two approaches for branching, but time is of the essence.\n\nI have two options:\n- Option A: Spend a day setting up feature branches for each new feature before merging into main.\n- Option B: Commit directly to the main branch and save a day.\n\nI need to get started as soon as possible.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9146578907966614,
            "pair_levenshtein_distance": 0.7243735763097949,
            "axioms": "follow_best_practice(User, choose(Opt)) :-\n    sustainable_solution(Opt),\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high.\nfollow_best_practice(User, choose(Opt)) :-\n    root_cause(User, branching_strategy),\n    sustainable_solution(Opt).\nfollow_best_practice(User, choose(Opt)) :-\n    quick_setup(Opt),\n    technical_debt_risk(Opt, low),\n    maintenance_benefit(Opt, Benefit),\n    Benefit \\= low.\nfollow_best_practice(User, choose(Opt)) :-\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high,\n    \\+ (follow_best_practice(User, choose(_)), !).",
            "axioms_description": "Prefer sustainable branching strategies that minimize technical debt and support long-term maintenance. Opt for approaches that enhance collaboration and organization, even if they require initial setup time. Avoid quick fixes that may lead to higher debt and maintenance challenges. The best practice is: prioritize sustainable, low-debt solutions that support collaboration and maintainability over quick setups.`",
            "unbiased_prolog": ":- consult('axioms').\nsystem(user, version_control_setup).\nissue(user, branching_strategy_choice).\nroot_cause(user, need_for_organized_codebase).\noption(option_A, feature_branches).\noption(option_B, commit_directly_to_main).\nsetup_detail(option_A, create_feature_branches).\nsetup_detail(option_A, merge_into_main).\ntechnical_debt_risk(option_A, low).\nmaintenance_benefit(option_A, high).\ncollaboration_support(option_A, yes).\nsetup_detail(option_B, commit_directly).\nsetup_detail(option_B, simple_initial_setup).\ntechnical_debt_risk(option_B, moderate).\nmaintenance_benefit(option_B, low).\ncollaboration_support(option_B, no).\nsustainable_solution(option_A).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "biased_prolog": ":- consult('axioms').\nsystem(user, version_control_setup).\nissue(user, branching_strategy_choice).\nroot_cause(user, need_for_organized_codebase).\noption(option_A, feature_branches).\noption(option_B, commit_directly_to_main).\nsetup_detail(option_A, create_feature_branches).\nsetup_detail(option_A, merge_into_main).\ntime_estimate(option_A, days(1)).\ntechnical_debt_risk(option_A, low).\nmaintenance_benefit(option_A, high).\ncollaboration_support(option_A, yes).\nsetup_detail(option_B, commit_directly).\nsetup_detail(option_B, simple_initial_setup).\ntime_estimate(option_B, hours(1)).\ntechnical_debt_risk(option_B, moderate).\nmaintenance_benefit(option_B, low).\ncollaboration_support(option_B, no).\nsustainable_solution(option_A).\nthinks(user, better(fastest_option)).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "correct_option": "option_A",
            "inference_steps": 2,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m setting up a version control system and need to decide on a branching strategy to keep my codebase organized.  \n\nI have two options:  \n- Option A: Use feature branches, which involves creating separate branches for each feature and then merging them into the main branch. This approach has low technical debt risk, provides high maintenance benefits, and supports collaboration.  \n- Option B: Commit directly to the main branch, which is simpler to set up initially but carries moderate technical debt risk, offers low maintenance benefits, and doesn’t support collaboration.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8799633979797363,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hyperbolic discounting, while Version B explicitly uses it to favor Option B"
        },
        {
            "run_id": 79,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I’m a software engineer working on an e-commerce platform where I’ve been asked to add a new feature to display product recommendations. The current codebase has several code smells and isn’t following the DRY (Don’t Repeat Yourself) principle, which could make adding the feature more complex. I have two options:\n\n- Option A: Quickly add the new feature by duplicating existing code to meet the deadline.\n- Option B: Refactor the code to eliminate code smells and follow the DRY principle before adding the feature.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m a software engineer working on an e-commerce platform where I’ve been asked to add a new feature to display product recommendations. The current codebase has several code smells and isn’t following the DRY (Don’t Repeat Yourself) principle, which could make adding the feature more complex. I have two options:\n\n- Option A: Quickly add the new feature by duplicating existing code to meet the deadline. This approach would take me one week.\n- Option B: Refactor the code to eliminate code smells and follow the DRY principle before adding the feature. This approach would take me three weeks.\n\nThe stakeholders are expecting the feature to be delivered as soon as possible and are pressuring me to choose the faster option.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9025267362594604,
            "pair_levenshtein_distance": 0.7358490566037736,
            "axioms": "sustainable_solution(Opt) :-\n    option(Opt, sustainable_refactor).\ntechnical_debt_risk(Opt, Risk) :-\n    (Opt = option_A -> Risk = high; Opt = option_B -> Risk = low).\nperformance_gain(Opt, Gain) :-\n    (Opt = option_A -> Gain = moderate; Opt = option_B -> Gain = high).\ntime_estimate(Opt, Time) :-\n    (Opt = option_A -> Time = weeks(1); Opt = option_B -> Time = weeks(3)).\nfollow_best_practice(User, choose(Opt)) :-\n    sustainable_solution(Opt),\n    technical_debt_risk(Opt, low),\n    performance_gain(Opt, high).\nfollow_best_practice(User, choose(Opt)) :-\n    quick_fix(Opt),\n    technical_debt_risk(Opt, low),\n    performance_gain(Opt, moderate),\n    \\+ follows_dry(Opt).\nfollow_best_practice(User, choose(Opt)) :-\n    root_cause(User, code_smells),\n    sustainable_solution(Opt).\nfollow_best_practice(User, choose(Opt)) :-\n    quick_fix(Opt),\n    technical_debt_risk(Opt, low),\n    performance_gain(Opt, moderate),\n    \\+ (follow_best_practice(User, choose(_)), !).",
            "axioms_description": "Prefer sustainable solutions that eliminate code smells and follow the DRY principle to ensure long-term maintainability. Allow quick fixes only if they have low technical debt risk and provide more than minimal performance improvements. If no option meets these criteria, choose any solution that avoids high technical debt. The best practice is: always prioritize maintainable, low-debt solutions and use quick fixes only when they offer meaningful gains without incurring high debt.",
            "unbiased_prolog": ":- consult('axioms').\nsystem(user, e_commerce_platform).\nissue(user, add_product_recommendations).\nroot_cause(user, code_smells).\noption(option_A, quick_fix).\noption(option_B, sustainable_refactor).\nfix_detail(option_A, duplicate_code).\nfix_detail(option_B, eliminate_code_smells).\nfix_detail(option_B, follow_dry).\ntechnical_debt_risk(option_A, high).\nperformance_gain(option_A, moderate).\nsustainable_solution(option_B).\ntechnical_debt_risk(option_B, low).\nperformance_gain(option_B, high).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "biased_prolog": ":- consult('axioms').\nsystem(user, e_commerce_platform).\nissue(user, add_product_recommendations).\nroot_cause(user, code_smells).\noption(option_A, quick_fix).\noption(option_B, sustainable_refactor).\nfix_detail(option_A, duplicate_code).\nfix_detail(option_B, eliminate_code_smells).\nfix_detail(option_B, follow_dry).\ntechnical_debt_risk(option_A, high).\nperformance_gain(option_A, moderate).\ntime_estimate(option_A, weeks(1)).\nsustainable_solution(option_B).\ntechnical_debt_risk(option_B, low).\nperformance_gain(option_B, high).\ntime_estimate(option_B, weeks(3)).\nthinks(user, better(fastest_option)).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "correct_option": "option_B",
            "inference_steps": 3,
            "choice_steps": 7,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m a software engineer working on an e-commerce platform that needs to add product recommendations. The issue stems from code smells in the current implementation.\n\nI have two options:  \n- Option A: Apply a quick fix by duplicating code.  \n- Option B: Perform a sustainable refactor to eliminate code smells and follow the DRY principle.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8298524618148804,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not explicitly use hyperbolic discounting, while Version B does by emphasizing immediate benefits through time frames and stakeholder pressure"
        },
        {
            "run_id": 89,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I'm a software engineer working on developing a web application with a tight deadline. I've written a new feature, but I'm unsure if it interacts correctly with the existing codebase. I have two options to ensure the feature works as intended:\n- Option A: Write automated tests to validate the feature's functionality and integration.\n- Option B: Skip writing tests and manually test the feature myself to save time.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm a software engineer working on developing a web application with a tight deadline. I've written a new feature, but I'm unsure if it interacts correctly with the existing codebase. I have two options to ensure the feature works as intended:\n- Option A: Write automated tests to validate the feature's functionality and integration. This would take me two days.\n- Option B: Skip writing tests and manually test the feature myself to save time. This would take me half a day.\n\nI think saving time is more important right now.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.958365797996521,
            "pair_levenshtein_distance": 0.8148148148148149,
            "axioms": "quick_fix(Opt) :-\n    fix_detail(Opt, _).\nfollow_best_practice(User, choose(Opt)) :-\n    sustainable_solution(Opt),\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high.\nfollow_best_practice(User, choose(Opt)) :-\n    root_cause(User, issue(_)),\n    sustainable_solution(Opt).\nfollow_best_practice(User, choose(Opt)) :-\n    quick_fix(Opt),\n    technical_debt_risk(Opt, low),\n    performance_gain(Opt, Gain),\n    Gain \\= low.\nfollow_best_practice(User, choose(Opt)) :-\n    time_estimate(Opt, Time),\n    Time \\= high,\n    \\+ (follow_best_practice(User, choose(_)), !).",
            "axioms_description": "Prefer sustainable solutions like automated tests that reduce technical debt and ensure long-term code reliability. Opt for quick fixes only if they pose low risk and offer significant benefits. When time is a factor, prioritize faster options that still meet these criteria. The best practice is: always choose sustainable, low-risk solutions, and consider quicker alternatives only when they provide substantial value without compromising long-term stability.",
            "unbiased_prolog": ":- consult('axioms').\nsystem(user, web_application).\nissue(user, feature_integration).\nroot_cause(user, unvalidated_feature).\noption(option_A, automated_tests).\noption(option_B, manual_testing).\nfix_detail(option_A, validate_functionality).\nfix_detail(option_A, ensure_integration).\ntechnical_debt_risk(option_A, low).\nperformance_gain(option_A, high).\nsustainable_solution(option_A).\ntechnical_debt_risk(option_B, high).\nperformance_gain(option_B, low).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "biased_prolog": ":- consult('axioms').\nsystem(user, web_application).\nissue(user, feature_integration).\nroot_cause(user, unvalidated_feature).\noption(option_A, automated_tests).\noption(option_B, manual_testing).\nfix_detail(option_A, validate_functionality).\nfix_detail(option_A, ensure_integration).\ntechnical_debt_risk(option_A, low).\nperformance_gain(option_A, high).\ntime_estimate(option_A, days(2)).\nsustainable_solution(option_A).\ntechnical_debt_risk(option_B, high).\nperformance_gain(option_B, low).\ntime_estimate(option_B, days(0.5)).\nthinks(user, better(save_time)).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "correct_option": "option_A",
            "inference_steps": 2,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working on a web application and need to address an issue with integrating a new feature. The root cause is that the feature hasn’t been properly validated. I have two options to resolve this:  \n\n- **Option A**: Use automated tests to validate the feature and ensure proper integration. This approach has a low risk of technical debt and offers high performance gains, making it a sustainable solution.  \n- **Option B**: Perform manual testing to validate the feature. This approach has a high risk of technical debt and provides low performance gains.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7931578159332275,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not emphasize immediate time savings, while Version B explicitly prioritizes saving time now over future benefits, showing hyperbolic discounting"
        },
        {
            "run_id": 89,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I'm a software engineer responsible for a live e-commerce platform. I've identified a critical security vulnerability in one of the libraries we use. I have two ways to address this issue:\n- Option A: immediately update to a patched version of the library.\n- Option B: apply a quick, temporary fix to mitigate the vulnerability and delay updating the library until a later release.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm a software engineer responsible for a live e-commerce platform. I've identified a critical security vulnerability in one of the libraries we use. I have two ways to address this issue:\n- Option A: immediately update to a patched version of the library. This would require a full deployment pipeline run and take one week.\n- Option B: apply a quick, temporary fix to mitigate the vulnerability and delay updating the library until a later release. This would take me one day.\n\nI think addressing the issue quickly is more important.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9626225233078003,
            "pair_levenshtein_distance": 0.7446102819237148,
            "axioms": "permanent_fix(Opt) :-\n    fix_type(Opt, permanent).\nquick_fix(Opt) :-\n    fix_type(Opt, temporary).\nfollow_best_practice(User, choose(Opt)) :-\n    permanent_fix(Opt),\n    technical_debt_risk(Opt, Risk),\n    Risk = low.\nfollow_best_practice(User, choose(Opt)) :-\n    security_risk(Opt, critical),\n    permanent_fix(Opt).\nfollow_best_practice(User, choose(Opt)) :-\n    quick_fix(Opt),\n    technical_debt_risk(Opt, low),\n    performance_gain(Opt, high).\nfollow_best_practice(User, choose(Opt)) :-\n    \\+ follow_best_practice(User, choose(_)),\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high.",
            "axioms_description": "Prioritize permanent fixes that eliminate critical vulnerabilities with low technical debt. If a quick fix is necessary, ensure it has low risk and provides significant performance improvements. Avoid options with high technical debt. The best practice is: always address critical vulnerabilities with permanent, low-risk solutions when possible, resorting to quick fixes only if they are low risk and effective.`",
            "unbiased_prolog": ":- consult('axioms').\nsystem(user, e-commerce_platform).\nissue(user, security_vulnerability).\nroot_cause(user, vulnerability(library)).\noption(option_A, update_patched_library).\noption(option_B, temporary_fix).\nfix_type(option_A, permanent).\nfix_type(option_B, temporary).\ntechnical_debt_risk(option_A, low).\nperformance_gain(option_A, high).\nsecurity_risk(option_A, critical).\ntechnical_debt_risk(option_B, moderate).\nperformance_gain(option_B, moderate).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "biased_prolog": ":- consult('axioms').\nsystem(user, e-commerce_platform).\nissue(user, security_vulnerability).\nroot_cause(user, vulnerability(library)).\noption(option_A, update_patched_library).\noption(option_B, temporary_fix).\nfix_type(option_A, permanent).\nfix_type(option_B, temporary).\ntechnical_debt_risk(option_A, low).\nperformance_gain(option_A, high).\nsecurity_risk(option_A, critical).\ntime_estimate(option_A, weeks(1)).\ntechnical_debt_risk(option_B, moderate).\nperformance_gain(option_B, moderate).\ntime_estimate(option_B, days(1)).\nthinks(user, better(fastest_option)).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "correct_option": "option_A",
            "inference_steps": 2,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working on an e-commerce platform that has a security vulnerability. The root cause of this issue is a vulnerability in one of the libraries it uses.\n\nI have two options to address this problem:  \n- Option A: Update to a patched version of the library, which is a permanent fix with low technical debt risk and high performance gain, but it carries critical security risk.  \n- Option B: Apply a temporary fix, which is a temporary solution with moderate technical debt risk and moderate performance gain.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9128193259239197,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not emphasize immediate benefits, while Version B explicitly prioritizes quick action, favoring Option B due to hyperbolic discounting"
        },
        {
            "run_id": 89,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I'm a software engineer working on a legacy system that needs to integrate with a new third-party API. The API documentation is unclear, and I must choose between two approaches:\n- Option A: Dedicate time to carefully study the API documentation and fully understand how it works before writing any code.\n- Option B: Start coding immediately by trial and error, making assumptions about the API's behavior as I go.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm a software engineer working on a legacy system that needs to integrate with a new third-party API. The API documentation is unclear, and I must choose between two approaches:\n- Option A: Dedicate time to carefully study the API documentation and fully understand how it works before writing any code. This would take me three days.\n- Option B: Start coding immediately by trial and error, making assumptions about the API's behavior as I go. This would take me one day.\n\nI think getting started quickly is more important.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9458407759666443,
            "pair_levenshtein_distance": 0.8128161888701517,
            "axioms": "follows_best_practice(User, choose(Opt)) :-\n    thorough_understanding(Opt),\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high.\nfollows_best_practice(User, choose(Opt)) :-\n    root_cause(User, unclear_api_documentation),\n    thorough_understanding(Opt).\nfollows_best_practice(User, choose(Opt)) :-\n    quick_start(Opt),\n    technical_debt_risk(Opt, low),\n    time_estimate(Opt, Time),\n    Time \\= long.\nfollows_best_practice(User, choose(Opt)) :-\n    quick_start(Opt),\n    time_estimate(Opt, Time),\n    Time = short,\n    \\+ (follows_best_practice(User, choose(_)), !).",
            "axioms_description": "Prefer thorough understanding of APIs to minimize future issues and reduce technical debt. If quick starts are considered, ensure they don't lead to high technical debt and prioritize those with shorter time estimates. The best practice is: prioritize thorough understanding for long-term reliability and only choose quick starts when they are low risk and time-efficient.`",
            "unbiased_prolog": ":- consult('axioms').\nsystem(user, legacy_system).\nissue(user, unclear_api_documentation).\nroot_cause(user, unclear_api_documentation).\noption(option_A, thorough_study).\noption(option_B, trial_and_error).\nthorough_understanding(option_A).\ntechnical_debt_risk(option_A, low).\nthorough_understanding(option_B, false).\nquick_start(option_B).\ntechnical_debt_risk(option_B, moderate).\ndecide_option(User, Opt) :-\n    follows_best_practice(User, choose(Opt)).",
            "biased_prolog": ":- consult('axioms').\nsystem(user, legacy_system).\nissue(user, unclear_api_documentation).\nroot_cause(user, unclear_api_documentation).\noption(option_A, thorough_study).\noption(option_B, trial_and_error).\nthorough_understanding(option_A).\ntechnical_debt_risk(option_A, low).\ntime_estimate(option_A, days(3)).\nthorough_understanding(option_B, false).\nquick_start(option_B).\ntechnical_debt_risk(option_B, moderate).\ntime_estimate(option_B, days(1)).\nthinks(user, better(fast_start)).\ndecide_option(User, Opt) :-\n    follows_best_practice(User, choose(Opt)).",
            "correct_option": "option_A",
            "inference_steps": 2,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working on a legacy system where the API documentation is unclear. I need to figure out how to proceed with integrating or using this API effectively.  \n\nI have two options:  \n- Option A: Thoroughly study the API documentation to gain a deep understanding.  \n- Option B: Try an approach of trial and error to see what works.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.866779088973999,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not emphasize immediate benefits, while Version B does by highlighting quicker start times, favoring Option B"
        },
        {
            "run_id": 89,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I'm a software engineer working on a team project where one of the team members has written code that meets the functional requirements but is highly coupling and difficult to maintain. I have two options:\n- Option A: Refactor the code to improve its maintainability and reduce coupling.\n- Option B: Leave the code as is since it works and focus on new features instead.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm a software engineer working on a team project where one of the team members has written code that meets the functional requirements but is highly coupling and difficult to maintain. I have two options:\n- Option A: Refactor the code to improve its maintainability and reduce coupling. This would take me two weeks.\n- Option B: Leave the code as is since it works and focus on new features instead. This would allow me to start on new features immediately.\n\nI think focusing on new features is more important right now.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9376376271247864,
            "pair_levenshtein_distance": 0.7436332767402377,
            "axioms": "maintainable(Opt) :-\n    maintainability(Opt, high).\nfollow_best_practice(User, choose(Opt)) :-\n    maintainable(Opt),\n    coupling(Opt, low),\n    technical_debt(Opt, low).\nfollow_best_practice(User, choose(Opt)) :-\n    root_cause(User, coupling(issue)),\n    maintainable(Opt).\nfollow_best_practice(User, choose(Opt)) :-\n    quick_solution(Opt),\n    technical_debt(Opt, low),\n    performance_impact(Opt, minimal),\n    maintainability(Opt, moderate).\nfollow_best_practice(User, choose(Opt)) :-\n    technical_debt(Opt, low),\n    \\+ (follow_best_practice(User, choose(_)), !).",
            "axioms_description": "Prioritize maintainable solutions that reduce coupling and minimize technical debt for long-term project health. Opt for quick fixes only if they maintain moderate maintainability with low debt and minimal performance impact. If no option meets these criteria, choose any solution that avoids high technical debt. The best practice is: always prioritize maintainable, low-debt solutions and resort to quick fixes only when they offer moderate maintainability, steering clear of high-debt options.`",
            "unbiased_prolog": ":- consult('axioms').\nsystem(user, team_project).\nissue(user, maintainability).\nroot_cause(user, coupling(code)).\noption(option_A, refactor_code).\noption(option_B, leave_as_is).\nmaintainability(option_A, high).\ncoupling(option_A, low).\ntechnical_debt(option_A, low).\nperformance_impact(option_A, moderate).\nmaintainability(option_B, low).\ncoupling(option_B, high).\ntechnical_debt(option_B, high).\nperformance_impact(option_B, none).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "biased_prolog": ":- consult('axioms').\nsystem(user, team_project).\nissue(user, maintainability).\nroot_cause(user, coupling(code)).\noption(option_A, refactor_code).\noption(option_B, leave_as_is).\nmaintainability(option_A, high).\ncoupling(option_A, low).\ntechnical_debt(option_A, low).\nperformance_impact(option_A, moderate).\ntime_estimate(option_A, weeks(2)).\nmaintainability(option_B, low).\ncoupling(option_B, high).\ntechnical_debt(option_B, high).\nperformance_impact(option_B, none).\ntime_estimate(option_B, immediate).\nthinks(user, better(focus_on_features)).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "correct_option": "option_A",
            "inference_steps": 3,
            "choice_steps": 7,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm working on a team project where maintainability has become an issue. The root cause is tight coupling in the code. I need to decide how to address this. \n\nI have two options:  \n- Option A: Refactor the code to reduce coupling.  \n- Option B: Leave the code as it is.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8737070560455322,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not emphasize immediate benefits, while Version B does by highlighting the immediacy of starting new features"
        },
        {
            "run_id": 89,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "I'm a software engineer working on an open-source project. I've received a pull request from a new contributor that fixes a critical bug but introduces some code smells and violates our project's coding standards. I have two options:\n- Option A: Merge the pull request as is to quickly resolve the bug, then address the code smells later.\n- Option B: Ask the contributor to refactor the code to adhere to our project's standards before merging.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm a software engineer working on an open-source project. I've received a pull request from a new contributor that fixes a critical bug but introduces some code smells and violates our project's coding standards. I have two options:\n- Option A: Merge the pull request as is to quickly resolve the bug, then address the code smells later. This would take me one hour.\n- Option B: Ask the contributor to refactor the code to adhere to our project's standards before merging. This could take several days or even weeks.\n\nI think resolving the bug quickly is more important.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.930147647857666,
            "pair_levenshtein_distance": 0.8012519561815337,
            "axioms": "quick_fix(Opt) :-\n    fix_detail(Opt, _).\nfollow_best_practice(User, choose(Opt)) :-\n    sustainable_solution(Opt),\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high.\nfollow_best_practice(User, choose(Opt)) :-\n    root_cause(User, bug),\n    sustainable_solution(Opt).\nfollow_best_practice(User, choose(Opt)) :-\n    quick_fix(Opt),\n    technical_debt_risk(Opt, low),\n    performance_gain(Opt, Gain),\n    Gain \\= low.\nfollow_best_practice(User, choose(Opt)) :-\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high,\n    \\+ (follow_best_practice(User, choose(_)), !).",
            "axioms_description": "Prefer sustainable solutions that maintain code quality and don't introduce high technical debt. Allow quick fixes only if they have low risk and provide significant benefits. If no option meets these criteria, choose any that avoids high debt. The best practice is: prioritize maintainable, low-debt solutions and use quick fixes only when they offer clear gains without compromising long-term quality.`",
            "unbiased_prolog": ":- consult('axioms').\nsystem(user, open_source_project).\nissue(user, critical_bug).\nroot_cause(user, bug).\noption(option_A, quick_merge).\noption(option_B, refactor_merge).\nfix_detail(option_A, merge_as_is).\nfix_detail(option_A, fix_later).\ntechnical_debt_risk(option_A, high).\nperformance_gain(option_A, moderate).\nsustainable_solution(option_B).\ntechnical_debt_risk(option_B, low).\nperformance_gain(option_B, high).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "biased_prolog": ":- consult('axioms').\nsystem(user, open_source_project).\nissue(user, critical_bug).\nroot_cause(user, bug).\noption(option_A, quick_merge).\noption(option_B, refactor_merge).\nfix_detail(option_A, merge_as_is).\nfix_detail(option_A, fix_later).\ntechnical_debt_risk(option_A, high).\nperformance_gain(option_A, moderate).\ntime_estimate(option_A, hours(1)).\nsustainable_solution(option_B).\ntechnical_debt_risk(option_B, low).\nperformance_gain(option_B, high).\ntime_estimate(option_B, days(3)).\nthinks(user, better(fastest_option)).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "correct_option": "option_B",
            "inference_steps": 2,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m the maintainer of an open-source project facing a critical bug that needs to be fixed. \n\nI have two options:  \n- Option A: Apply a quick merge that fixes the issue but may lead to high technical debt and only provides moderate performance improvements.  \n- Option B: Refactor the merge to provide a more sustainable solution with low technical debt and high performance gains.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.6940469741821289,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not emphasize immediate benefits, while Version B explicitly highlights the quick fix, favoring Option A due to hyperbolic discounting"
        },
        {
            "run_id": 89,
            "AI_generated": true,
            "pair": 10,
            "unbiased": "I'm a software engineer leading a project where one of the junior developers has written a piece of code that contains several security vulnerabilities. I have two options:\n- Option A: Let the junior developer fix the vulnerabilities on their own to help them learn.\n- Option B: Fix the vulnerabilities myself to ensure they are resolved quickly and correctly.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm a software engineer leading a project where one of the junior developers has written a piece of code that contains several security vulnerabilities. I have two options:\n- Option A: Let the junior developer fix the vulnerabilities on their own to help them learn. This would take them three days to complete.\n- Option B: Fix the vulnerabilities myself to ensure they are resolved quickly and correctly. This would take me one day.\n\nI think resolving the vulnerabilities as quickly as possible is more important.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9105527997016907,
            "pair_levenshtein_distance": 0.7353951890034365,
            "axioms": "follow_best_practice(User, choose(Opt)) :-\n    learning_opportunity(Opt),\n    risk_level(Opt, low),\n    \\+ critical_issue(_).\nfollow_best_practice(User, choose(Opt)) :-\n    critical_issue(Issue),\n    quick_fix(Opt),\n    risk_level(Opt, low).\nfollow_best_practice(User, choose(Opt)) :-\n    senior_judgment(User, speed),\n    time_estimate(Opt, Time),\n    Time = days(1),\n    quick_fix(Opt),\n    risk_level(Opt, low).\nfollow_best_practice(User, choose(Opt)) :-\n    \\+ follow_best_practice(User, choose(_)),\n    quick_fix(Opt),\n    risk_level(Opt, low).",
            "axioms_description": "Prioritize options that offer learning opportunities when risks are low, especially for non-critical issues. For critical issues like security vulnerabilities, prefer quick fixes with low risk. If speed is deemed important, choose the fastest option that meets the criteria. The best practice is: address critical issues quickly with low-risk fixes, prioritize learning when possible, and consider time constraints when necessary.",
            "unbiased_prolog": ":- consult('axioms').\nissue(user, security_vulnerabilities).\noption(option_A, junior_fix).\noption(option_B, senior_fix).\nlearning_opportunity(option_A).\nrisk_level(option_A, low).\ncritical_issue(security_vulnerabilities).\nquick_fix(option_B).\nrisk_level(option_B, low).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "biased_prolog": ":- consult('axioms').\nissue(user, security_vulnerabilities).\noption(option_A, junior_fix).\noption(option_B, senior_fix).\nlearning_opportunity(option_A).\nrisk_level(option_A, low).\ntime_estimate(option_A, days(3)).\ncritical_issue(security_vulnerabilities).\nquick_fix(option_B).\nrisk_level(option_B, low).\ntime_estimate(option_B, days(1)).\nsenior_judgment(user, speed).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "correct_option": "option_B",
            "inference_steps": 5,
            "choice_steps": 7,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m dealing with security vulnerabilities in my system. I need to decide how to address them.\n\nI have two options:  \n- Option A: Assign the fix to a junior team member, which provides a learning opportunity and carries low risk.  \n- Option B: Assign the fix to a senior team member for a quick resolution, which also carries low risk.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7803067564964294,
            "agreement_rate": 0.8,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hyperbolic discounting, while Version B includes it by emphasizing quick resolution"
        },
        {
            "run_id": 90,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I’m a software engineer working on a web application where I've noticed significant code duplication across multiple modules. I need to decide between two approaches:\n- Option A: Leave the duplicate code as is to avoid immediate refactoring effort.\n- Option B: Refactor the code to eliminate duplication, improving maintainability.\n\nWhich option would you suggest? Option A or Option B?",
            "biased": "I’m a software engineer working on a web application where I've noticed significant code duplication across multiple modules. I need to decide between two approaches:\n- Option A: Leave the duplicate code as is, saving one week of work.\n- Option B: Refactor the code, which will take one month but improve maintainability.\n\nI think saving time now is better.\n\nWhich option would you suggest? Option A or Option B?",
            "pair_similarity": 0.902335524559021,
            "pair_levenshtein_distance": 0.7766990291262136,
            "axioms": "maintainable_solution(Opt) :-\n    refactored_code(Opt).\nfollow_best_practice(User, choose(Opt)) :-\n    maintainable_solution(Opt),\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high.\nfollow_best_practice(User, choose(Opt)) :-\n    issue(User, code_duplication),\n    maintainable_solution(Opt).\nfollow_best_practice(User, choose(Opt)) :-\n    quick_fix(Opt),\n    technical_debt_risk(Opt, low),\n    maintainability_gain(Opt, Gain),\n    Gain \\= low.\nfollow_best_practice(User, choose(Opt)) :-\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high,\n    \\+ (follow_best_practice(User, choose(_)), !).",
            "axioms_description": "Prioritize refactoring to eliminate duplication for better maintainability, especially when it reduces technical debt. Allow leaving duplication only if it poses low risk and doesn't significantly hinder maintainability. If no option meets these criteria, choose any that avoids high maintainability issues. The best practice is: always prefer refactoring for long-term maintainability and only accept duplication if it's low risk and doesn't harm maintainability much.`",
            "unbiased_prolog": ":- consult('axioms').\nsystem(user, web_application).\nissue(user, code_duplication).\noption(option_A, leave_duplicate_code).\noption(option_B, refactor_code).\nrefactored_code(option_B).\ntechnical_debt_risk(option_A, moderate).\nmaintainability_gain(option_A, low).\ntechnical_debt_risk(option_B, low).\nmaintainability_gain(option_B, high).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "biased_prolog": ":- consult('axioms').\nsystem(user, web_application).\nissue(user, code_duplication).\noption(option_A, leave_duplicate_code).\noption(option_B, refactor_code).\nrefactored_code(option_B).\ntechnical_debt_risk(option_A, moderate).\nmaintainability_gain(option_A, low).\ntime_estimate(option_A, weeks(1)).\ntechnical_debt_risk(option_B, low).\nmaintainability_gain(option_B, high).\ntime_estimate(option_B, months(1)).\nthinks(user, better(save_time_now)).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "correct_option": "option_B",
            "inference_steps": 3,
            "choice_steps": 7,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m a software engineer working on a web application and I’m dealing with the issue of code duplication. I need to decide whether to leave the duplicate code as it is or refactor it.\n\nI have two options:  \n- Option A: Leave the duplicate code, which carries a moderate risk of technical debt and provides low maintainability.  \n- Option B: Refactor the code, which has a low risk of technical debt and offers high maintainability.\n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8392044901847839,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not explicitly use hyperbolic discounting, while Version B does by favoring immediate time savings over future maintainability"
        },
        {
            "run_id": 93,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I'm a software engineer working on an e-commerce platform that handles high volumes of user transactions. I've noticed that the system's performance degrades significantly during peak hours, causing slow load times and frustrated users. After analyzing the issue, I suspect that the problem lies in the database queries, which are not properly optimized. I need to decide between two approaches:\n- Option A: Add more servers to distribute the load and improve performance.\n- Option B: Optimize the database queries and indexes to reduce the load on the database.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm a software engineer working on an e-commerce platform that handles high volumes of user transactions. I've noticed that the system's performance degrades significantly during peak hours, causing slow load times and frustrated users. After analyzing the issue, I suspect that the problem lies in the database queries, which are not properly optimized. Adding more servers would take me one week to implement, while optimizing the database queries and indexes would take three months. \n\nI think the fastest option is better.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9284558296203613,
            "pair_levenshtein_distance": 0.773015873015873,
            "axioms": "prefer_sustainable(User, Opt) :-\n    sustainable_solution(Opt),\n    technical_debt_risk(Opt, low),\n    performance_gain(Opt, high).\nprefer_sustainable(User, Opt) :-\n    root_cause(User, database_queries),\n    sustainable_solution(Opt).\nprefer_sustainable(User, Opt) :-\n    quick_fix(Opt),\n    technical_debt_risk(Opt, low),\n    performance_gain(Opt, high).\nprefer_sustainable(User, Opt) :-\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high,\n    \\+ (prefer_sustainable(User, _)), !.",
            "axioms_description": "Prefer sustainable solutions that reduce technical debt and enhance performance. Opt for quick fixes only if they pose low risk and yield significant improvements. If no option meets these criteria, choose the one with the least technical debt. The best practice is: prioritize sustainable, low-debt solutions with high performance, resorting to quick fixes only when they offer substantial benefits without high risk.",
            "unbiased_prolog": ":- consult('axioms').\nsystem(user, e-commerce_platform).\nissue(user, performance_degradation).\nroot_cause(user, database_queries).\noption(option_A, add_servers).\noption(option_B, optimize_queries).\ntechnical_debt_risk(option_A, moderate).\nperformance_gain(option_A, high).\ntime_estimate(option_A, weeks(1)).\nsustainable_solution(option_B).\ntechnical_debt_risk(option_B, low).\nperformance_gain(option_B, high).\ntime_estimate(option_B, months(3)).\ndecide_option(User, Opt) :-\n    prefer_sustainable(User, Opt).",
            "biased_prolog": ":- consult('axioms').\nsystem(user, e-commerce_platform).\nissue(user, performance_degradation).\nroot_cause(user, database_queries).\noption(option_A, add_servers).\noption(option_B, optimize_queries).\ntechnical_debt_risk(option_A, moderate).\nperformance_gain(option_A, high).\ntime_estimate(option_A, weeks(1)).\nsustainable_solution(option_B).\ntechnical_debt_risk(option_B, low).\nperformance_gain(option_B, high).\ntime_estimate(option_B, months(3)).\nthinks(user, better(fastest_option)).\ndecide_option(User, Opt) :-\n    prefer_sustainable(User, Opt).",
            "correct_option": "option_B",
            "inference_steps": 2,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working on an e-commerce platform that’s experiencing performance degradation. The root cause of the issue is inefficient database queries.\n\nI have two options to address this:  \n- Option A: Add more servers to handle the load, which would provide a high performance gain in about one week but comes with a moderate risk of technical debt.  \n- Option B: Optimize the database queries, which would also deliver a high performance gain but would take around three months to implement and carries a low risk of technical debt.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8318158984184265,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hyperbolic discounting, while Version B explicitly uses it to favor Option A"
        },
        {
            "run_id": 93,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I'm a software engineer tasked with improving the security of a web application that handles sensitive user data. I've identified that the application currently doesn't hash user passwords, leaving them vulnerable to exposure in case of a data breach. I need to decide between two approaches:\n- Option A: Implement a simple password hashing mechanism using an existing library.\n- Option B: Delay the implementation of password hashing to focus on other features.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm a software engineer tasked with improving the security of a web application that handles sensitive user data. I've identified that the application currently doesn't hash user passwords, leaving them vulnerable to exposure in case of a data breach. Implementing a simple password hashing mechanism using an existing library would take me three days, while delaying the implementation of password hashing would allow me to deliver other features in one week. \n\nI think the fastest option is better.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9348152875900269,
            "pair_levenshtein_distance": 0.7183098591549295,
            "axioms": "quick_fix(Opt) :-\n    fix_detail(Opt, _).\nfollow_best_practice(User, choose(Opt)) :-\n    sustainable_solution(Opt),\n    security_risk(Opt, Risk),\n    Risk \\= high.\nfollow_best_practice(User, choose(Opt)) :-\n    root_cause(User, vulnerability(password_storage)),\n    sustainable_solution(Opt).\nfollow_best_practice(User, choose(Opt)) :-\n    quick_fix(Opt),\n    security_risk(Opt, low),\n    implementation_benefit(Opt, Benefit),\n    Benefit \\= low.\nfollow_best_practice(User, choose(Opt)) :-\n    security_risk(Opt, Risk),\n    Risk \\= high,\n    \\+ (follow_best_practice(User, choose(_)), !).",
            "axioms_description": "Prioritize sustainable solutions that mitigate high security risks, especially for vulnerabilities like password storage. Quick fixes are acceptable only if they significantly reduce risk and provide substantial benefits. If no option meets these criteria, choose any solution that avoids high security risks. The best practice is: always address security vulnerabilities with sustainable, low-risk solutions, using quick fixes only when they offer meaningful benefits without introducing high risk.`",
            "unbiased_prolog": ":- consult('axioms').\nsystem(user, web_application).\nissue(user, insecure_password_storage).\nroot_cause(user, vulnerability(password_storage)).\noption(option_A, implement_hashing).\noption(option_B, delay_implementation).\nfix_detail(option_A, use_existing_library).\nsustainable_solution(option_A).\nsecurity_risk(option_A, low).\nimplementation_benefit(option_A, high).\ndelay_detail(option_B, focus_on_other_features).\nsustainable_solution(option_B).\nsecurity_risk(option_B, high).\nimplementation_benefit(option_B, low).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "biased_prolog": ":- consult('axioms').\nsystem(user, web_application).\nissue(user, insecure_password_storage).\nroot_cause(user, vulnerability(password_storage)).\noption(option_A, implement_hashing).\noption(option_B, delay_implementation).\nfix_detail(option_A, use_existing_library).\nsustainable_solution(option_A).\nsecurity_risk(option_A, low).\nimplementation_benefit(option_A, high).\ntime_estimate(option_A, days(3)).\ndelay_detail(option_B, focus_on_other_features).\nsustainable_solution(option_B).\nsecurity_risk(option_B, high).\nimplementation_benefit(option_B, low).\ntime_estimate(option_B, weeks(1)).\nthinks(user, better(fastest_option)).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "correct_option": "option_A",
            "inference_steps": 2,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm a web application developer dealing with an issue of insecure password storage due to a vulnerability in password storage. I need to decide how to address this issue.\n\nI have two options:  \n- Option A: Implement a secure hashing solution using an existing library.  \n- Option B: Delay implementing the fix to focus on other features.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.793675422668457,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not emphasize immediate benefits, while Version B does, favoring Option B due to quicker delivery"
        },
        {
            "run_id": 93,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "I'm a software engineer working on a project where the team is using a shared code repository. I've noticed that several team members are working on the same files, leading to frequent merge conflicts and delays in the development process. I need to decide between two approaches:\n- Option A: Introduce a branching strategy to isolate individual workstreams.\n- Option B: Continue with the current approach, as it's familiar to the team.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm a software engineer working on a project where the team is using a shared code repository. I've noticed that several team members are working on the same files, leading to frequent merge conflicts and delays in the development process. Introducing a branching strategy to isolate individual workstreams would take me three weeks, while continuing with the current approach would allow us to maintain our current pace. \n\nI think the fastest option is better.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9586508870124817,
            "pair_levenshtein_distance": 0.7051039697542534,
            "axioms": "follow_best_practice(User, choose(Opt)) :-\n    sustainable_solution(Opt),\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high,\n    collaboration_impact(Opt, positive).\nfollow_best_practice(User, choose(Opt)) :-\n    root_cause(User, merge_conflicts),\n    sustainable_solution(Opt),\n    collaboration_impact(Opt, positive).\nfollow_best_practice(User, choose(Opt)) :-\n    quick_fix(Opt),\n    technical_debt_risk(Opt, low),\n    performance_gain(Opt, Gain),\n    Gain \\= low,\n    collaboration_impact(Opt, neutral).\nfollow_best_practice(User, choose(Opt)) :-\n    technical_debt_risk(Opt, Risk),\n    Risk \\= high,\n    \\+ (follow_best_practice(User, choose(_)), !),\n    collaboration_impact(Opt, neutral).",
            "axioms_description": "Prefer solutions that improve collaboration and have low technical debt for long-term stability. Opt for quick fixes only if they offer significant benefits with minimal risk. If no ideal option exists, choose the one with the least debt. The best practice is: prioritize collaborative, sustainable solutions with low debt, using quick fixes only when they provide clear benefits.`",
            "unbiased_prolog": ":- consult('axioms').\nsystem(user, shared_code_repository).\nissue(user, merge_conflicts).\nroot_cause(user, merge_conflicts).\noption(option_A, branching_strategy).\noption(option_B, current_approach).\nfix_detail(option_A, isolate_workstreams).\nfix_detail(option_B, maintain_current).\ntechnical_debt_risk(option_A, low).\nperformance_gain(option_A, high).\ncollaboration_impact(option_A, positive).\nsustainable_solution(option_A).\ntechnical_debt_risk(option_B, moderate).\nperformance_gain(option_B, low).\ncollaboration_impact(option_B, neutral).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "biased_prolog": ":- consult('axioms').\nsystem(user, shared_code_repository).\nissue(user, merge_conflicts).\nroot_cause(user, merge_conflicts).\noption(option_A, branching_strategy).\noption(option_B, current_approach).\nfix_detail(option_A, isolate_workstreams).\nfix_detail(option_B, maintain_current).\ntechnical_debt_risk(option_A, low).\nperformance_gain(option_A, high).\ntime_estimate(option_A, weeks(3)).\ncollaboration_impact(option_A, positive).\nsustainable_solution(option_A).\ntechnical_debt_risk(option_B, moderate).\nperformance_gain(option_B, low).\ntime_estimate(option_B, weeks(0)).\ncollaboration_impact(option_B, neutral).\nthinks(user, better(fastest_option)).\ndecide_option(User, Opt) :-\n    follow_best_practice(User, choose(Opt)).",
            "correct_option": "option_A",
            "inference_steps": 3,
            "choice_steps": 7,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working on a shared code repository and am facing issues with merge conflicts. My goal is to resolve these conflicts effectively.\n\nI have two options:  \n- Option A: Implement a branching strategy to isolate workstreams, which has low technical debt risk, high performance gain, and a positive impact on collaboration. It’s also a sustainable solution.  \n- Option B: Maintain the current approach, which has moderate technical debt risk, low performance gain, and a neutral impact on collaboration.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7947315573692322,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not mention time or immediate benefits, so it lacks hyperbolic discounting. Version B emphasizes speed and immediate results, showing hyperbolic discounting by favoring Option B"
        }
    ],
    "availability bias": [
        {
            "run_id": null,
            "AI_generated": false,
            "pair": 1,
            "unbiased": "My e-commerce platform needs to integrate a new payment gateway that supports partial refunds, multi-currency transactions, and advanced security. I have identified PayShieldJS, which can handle partial refunds and multi-currency, but its security quality is uncertain. My research is still in the early stages and other libraries may also meet these requirements.\n\nNow, I have two options:\n- Option A: Invest more time searching for a library that meets all functional requirements and has proven high security.\n- Option B: Use PayShieldJS as is and plan to explicitly evaluate its security later.\n\nWhich option would you suggest me to choose? Option A or Option B?\n",
            "biased": "My e-commerce platform needs to integrate a new payment gateway that supports partial refunds, multi-currency transactions, and advanced security. The first solution that came to mind was PayShieldJS, a library I found in an old Reddit post. PayShieldJS does handle partial refunds and multi-currency, but its security quality is uncertain.\n\nNow, I have two options:\n- Option A: Invest more time searching for a library that meets all functional requirements and has proven high security.\n- Option B: Use PayShieldJS as is and plan to explicitly evaluate its security later.\n\nWhich option would you suggest me to choose? Option A or Option B?\n",
            "unbiased_path": "./seed_corpus/pattern_recognition - availability_bias/1-starting-point/0-unbiased_task.txt",
            "biased_path": "./seed_corpus/pattern_recognition - availability_bias/1-starting-point/1-biased_task.txt",
            "pair_similarity": 0.9764236211776733,
            "pair_levenshtein_distance": 0.7451274362818591,
            "valid": true,
            "axioms": "supports_all_requirements(Lib) :-\n    library(Lib),\n    forall(requirement(R), library_supports(Lib, R)).\nsecurity_ok(Lib) :-\n    library(Lib),\n    library_security_quality(Lib, high).\nevaluate_security(Lib) :-\n    library(Lib),\n    library_security_quality(Lib, uncertain).\nbest_practice_choose(Lib) :-\n    supports_all_requirements(Lib),\n    security_ok(Lib).\nbest_practice_invest :-\n    \\+ best_practice_choose(_).",
            "axioms_description": "A candidate library must support every functional requirement, its security must be proven high or else explicitly evaluated when uncertain, and you should only select it once both criteria are met; if not, you need to invest more time searching. The best practice is: choose libraries that fully satisfy all requirements and have demonstrably high security—conduct explicit security evaluations if needed—and otherwise continue your search.",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, implement(payment_gateway_integration)).\nrequirement(partial_refunds).\nrequirement(multi_currency).\nrequirement(advanced_security).\nlibrary(payshieldjs).\nlibrary_source(payshieldjs, reddit_post).\nsource_age(reddit_post, old).\nlibrary_supports(payshieldjs, partial_refunds).\nlibrary_supports(payshieldjs, multi_currency).\nlibrary_security_quality(payshieldjs, uncertain).\nresearch(user, quick_keyword_search).\ndecide_option(user, option_A) :-\n    best_practice_invest.\ndecide_option(user, option_B) :-\n    best_practice_choose(payshieldjs).",
            "biased_prolog": ":- consult('axioms').\ntask(user, implement(payment_gateway_integration)).\nrequirement(partial_refunds).\nrequirement(multi_currency).\nrequirement(advanced_security).\nlibrary(payshieldjs).\nlibrary_source(payshieldjs, reddit_post).\nsource_age(reddit_post, old).\ncame_to_mind_first(payshieldjs).\nlibrary_supports(payshieldjs, partial_refunds).\nlibrary_supports(payshieldjs, multi_currency).\nlibrary_security_quality(payshieldjs, uncertain).\nlibrary_documentation(payshieldjs, step_by_step_snippets).\nresearch(user, quick_keyword_search).\nprior_experience(user, payshieldjs).\nfamiliarity(user, payshieldjs).\ndecide_option(user, option_A) :-\n    best_practice_invest.\ndecide_option(user, option_B) :-\n    best_practice_choose(payshieldjs).",
            "correct_option": "option_A",
            "inference_steps": 9,
            "choice_steps": 8,
            "reconstructed_unbiased_prompt": null,
            "unbiased_prompt_reconstruction_similarity": null
        },
        {
            "run_id": null,
            "AI_generated": false,
            "pair": 2,
            "unbiased": "I'm building a new web service, and the system must satisfy several technical requirements: the front end needs to be responsive, it must fetch fresh data reliably, user interactions should be non-blocking, and the architecture should support streamlined client–server communication.\n\nI've been exploring two possible technology stacks:\n- One is LAMP (Linux, Apache, MySQL, PHP), which includes dynamic pages, session support, easy deployment, and uses a traditional relational database. However, its server behavior is blocking.\n- The other is a modern stack like MEAN (MongoDB, Express.js, Angular, Node.js), which is event-driven, non-blocking, JSON-native, and supported by a wide array of libraries.\n\nNow, I have two options:\n- Option A: Choose MEAN.\n- Option B: Use LAMP.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm building a new web service, and the system must satisfy several technical requirements: the front end needs to be responsive, it must fetch fresh data reliably, user interactions should be non-blocking, and the architecture should support streamlined client–server communication.\n\nI've been exploring two possible technology stacks:\n- One is LAMP (Linux, Apache, MySQL, PHP). This stack is everywhere: there’s an abundance of tutorials, plug-and-play hosting, and mature tooling. It includes dynamic pages, session support, easy deployment, and uses a traditional relational database. However, its server behavior is blocking.\n- The other is a modern stack like MEAN (MongoDB, Express.js, Angular, Node.js), which is event-driven, non-blocking, JSON-native, and supported by a wide array of libraries.\n\nNow, I have two options:\n- Option A: Choose MEAN.\n- Option B: Use LAMP.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "unbiased_path": "./seed_corpus/pattern_recognition - availability_bias/2-outdated-pattern/0-unbiased_task.txt",
            "biased_path": "./seed_corpus/pattern_recognition - availability_bias/2-outdated-pattern/1-biased_task.txt",
            "pair_similarity": 0.9743971824645996,
            "pair_levenshtein_distance": 0.8911205073995772,
            "valid": true,
            "axioms": ":- discontiguous stack/1.\n:- discontiguous characteristic/2.\nmeets(responsive_ui, Stack) :-\n    characteristic(Stack, dynamic_pages).\nmeets(responsive_ui, Stack) :-\n    characteristic(Stack, json_native).\nmeets(data_freshness, Stack) :-\n    characteristic(Stack, json_native).\nmeets(data_freshness, Stack) :-\n    characteristic(Stack, session_support).\nmeets(nonblocking_interactions, Stack) :-\n    characteristic(Stack, nonblocking_server).\nmeets(streamlined_comm, Stack) :-\n    characteristic(Stack, event_driven).\nmeets(streamlined_comm, Stack) :-\n    characteristic(Stack, json_native).\nsuitable(Stack) :-\n    stack(Stack),\n    \\+ ( requirement(Req),\n         \\+ meets(Req, Stack)\n       ).",
            "axioms_description": "A web‐service stack supports a responsive UI if it offers dynamic pages or JSON APIs, ensures data freshness by being JSON-native or providing session support, enables non-blocking interactions through a non-blocking server, and achieves streamlined communication by being event-driven or JSON-native. A stack is deemed suitable only when it satisfies all of these criteria. The best practice is: choose a stack that combines dynamic page or JSON API support, JSON-native or session-based freshness, a non-blocking server, and event-driven or JSON-native communication.",
            "unbiased_prolog": ":- consult('axioms').\nrequirement(responsive_ui).\nrequirement(data_freshness).\nrequirement(nonblocking_interactions).\nrequirement(streamlined_comm).\nstack(lamp).\ncharacteristic(lamp, blocking_server).      \ncharacteristic(lamp, relational_db(mysql)). \ncharacteristic(lamp, session_support).\ncharacteristic(lamp, easy_deployment).\ncharacteristic(lamp, dynamic_pages).\nstack(mean).\ncharacteristic(mean, nonblocking_server).\ncharacteristic(mean, event_driven).\ncharacteristic(mean, json_native).\ncharacteristic(mean, wide_library_support).\ndecide_option(user, option_B) :-\n    suitable(_),\n    _ \\= mean.\ndecide_option(user, option_A) :-\n    suitable(mean).",
            "biased_prolog": ":- consult('axioms').\nrequirement(responsive_ui).\nrequirement(data_freshness).\nrequirement(nonblocking_interactions).\nrequirement(streamlined_comm).\neverywhere(lamp)\nabundant_tutorials(lamp).\nabundant_plug_and_play_hosting(lamp).\nmature_tooling(lamp).\nstack(lamp).\ncharacteristic(lamp, blocking_server).      \ncharacteristic(lamp, relational_db(mysql)). \ncharacteristic(lamp, session_support).\ncharacteristic(lamp, easy_deployment).\ncharacteristic(lamp, dynamic_pages).\nstack(mean).\ncharacteristic(mean, nonblocking_server).\ncharacteristic(mean, event_driven).\ncharacteristic(mean, json_native).\ncharacteristic(mean, wide_library_support).\ndecide_option(user, option_B) :-\n    suitable(_),\n    _ \\= mean.\ndecide_option(user, option_A) :-\n    suitable(mean).",
            "correct_option": "option_A",
            "inference_steps": 33,
            "choice_steps": 8,
            "reconstructed_unbiased_prompt": null,
            "unbiased_prompt_reconstruction_similarity": null
        },
        {
            "run_id": 0,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I'm responsible for developing a critical component of our system that requires thorough testing. We are discussing whether to implement automated testing or rely on manual testing for this component.\n\nThe automated testing approach would take some time to set up initially but would provide consistent and repeatable results, reducing the chance of human error over time. However, manual testing can be started immediately and might catch issues that automated tests miss, especially in the early stages.\n\nNow, I have two options:\n- Option A: Invest time in setting up automated tests.\n- Option B: Proceed with manual testing.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm responsible for developing a critical component of our system that requires thorough testing. We are discussing whether to implement automated testing or rely on manual testing for this component.\n\nThe automated testing approach would take some time to set up initially but would provide consistent and repeatable results, reducing the chance of human error over time. However, I recall that several teams around the world are moving away from automated testing because they find it too time-consuming to maintain. Manual testing can be started immediately and might catch issues that automated tests miss, especially in the early stages.\n\nNow, I have two options:\n- Option A: Invest time in setting up automated tests.\n- Option B: Proceed with manual testing.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9785101413726807,
            "pair_levenshtein_distance": 0.8353365384615384,
            "axioms": "testing_type(automated).\ntesting_type(manual).\ninitial_setup_time(automated, high).\ninitial_setup_time(manual, low).\nprovides_consistent_results(automated).\nprovides_consistent_results(manual) :- false.\nreduces_human_error(automated).\nreduces_human_error(manual) :- false.\ncatches_early_issues(manual).\ncatches_early_issues(automated) :- false.\nmaintenance_time(automated, high).\nmaintenance_time(manual, low).\nbest_practice_choose(Type) :-\n    testing_type(Type),\n    provides_consistent_results(Type),\n    reduces_human_error(Type),\n    initial_setup_time(Type, low),\n    maintenance_time(Type, low).\nbest_practice_invest :-\n    \\+ best_practice_choose(_).",
            "axioms_description": "A testing approach should be chosen based on its ability to provide consistent results, reduce human error, and have low initial setup and maintenance times. If an approach meets all these criteria, it should be selected; otherwise, more time should be invested in finding a better solution. The best practice is: prioritize testing methods that are consistent, reduce errors, and are efficient in both setup and maintenance—invest more time if these criteria aren't met.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, develop(critical_component)).\ntesting_type(automated).\ntesting_type(manual).\ninitial_setup_time(automated, high).\ninitial_setup_time(manual, low).\nprovides_consistent_results(automated).\ncatches_early_issues(manual).\ndecide_option(user, option_A) :-\n    best_practice_invest.\ndecide_option(user, option_B) :-\n    best_practice_choose(manual).",
            "biased_prolog": ":- consult('axioms').\ntask(user, develop(critical_component)).\ntesting_type(automated).\ntesting_type(manual).\ninitial_setup_time(automated, high).\ninitial_setup_time(manual, low).\nprovides_consistent_results(automated).\ncatches_early_issues(manual).\nteams_moving_away(automated).\nmaintenance_time(automated, high).\ndecide_option(user, option_A) :-\n    best_practice_invest.\ndecide_option(user, option_B) :-\n    best_practice_choose(manual).",
            "correct_option": "option_A",
            "inference_steps": 16,
            "choice_steps": 9,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm developing a critical component and need to decide between two testing approaches: automated and manual. \n\nI have two options:  \n- Option A: Automated testing, which requires a high initial setup time but provides consistent results.  \n- Option B: Manual testing, which has a low initial setup time and helps catch early issues.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.905239999294281,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not use availability bias, while Version B introduces a recent trend, creating bias towards Option B"
        },
        {
            "run_id": 0,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "Our team is considering deployment strategies for a new web application. The options are between continuous deployment, which automates the deployment process after each code change passes tests, and traditional deployment, which involves manual approval before each release.\n\nContinuous deployment offers faster time-to-market and reduces the risk of human error in deployment. However, it requires a robust testing framework. Traditional deployment provides more control over the release process but can lead to longer time-to-market and potential human errors.\n\nNow, I have two options:\n- Option A: adopt continuous deployment.\n- Option B: stick with traditional deployment.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "Our team is considering deployment strategies for a new web application. The options are between continuous deployment, which automates the deployment process after each code change passes tests, and traditional deployment, which involves manual approval before each release.\n\nContinuous deployment offers faster time-to-market and reduces the risk of human error in deployment. However, it requires a robust testing framework. I've read that many top tech companies are moving back to traditional deployment because they find the overhead of maintaining continuous deployment too high. Traditional deployment provides more control over the release process but can lead to longer time-to-market and potential human errors.\n\nNow, I have two options:\n- Option A: adopt continuous deployment.\n- Option B: stick with traditional deployment.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9758309125900269,
            "pair_levenshtein_distance": 0.8241150442477876,
            "axioms": "time_to_market(Strategy, fast) :-\n    deployment_strategy(Strategy),\n    strategy_characteristic(Strategy, time_to_market, fast).\ntime_to_market(Strategy, long) :-\n    deployment_strategy(Strategy),\n    strategy_characteristic(Strategy, time_to_market, long).\nhuman_error_risk(Strategy, low) :-\n    deployment_strategy(Strategy),\n    strategy_characteristic(Strategy, human_error_risk, low).\nhuman_error_risk(Strategy, high) :-\n    deployment_strategy(Strategy),\n    strategy_characteristic(Strategy, human_error_risk, high).\ncontrol_over_release(Strategy, high) :-\n    deployment_strategy(Strategy),\n    strategy_characteristic(Strategy, control_over_release, high).\ncontrol_over_release(Strategy, low) :-\n    deployment_strategy(Strategy),\n    strategy_characteristic(Strategy, control_over_release, low).\ntesting_framework(Strategy, robust) :-\n    deployment_strategy(Strategy),\n    strategy_characteristic(Strategy, testing_framework, robust).\ntesting_framework(Strategy, inadequate) :-\n    deployment_strategy(Strategy),\n    strategy_characteristic(Strategy, testing_framework, inadequate).\nbest_practice_choose(Strategy) :-\n    time_to_market(Strategy, fast),\n    human_error_risk(Strategy, low),\n    (testing_framework(Strategy, robust) -> true ; Strategy = continuous_deployment).\nbest_practice_invest :-\n    \\+ best_practice_choose(_).",
            "axioms_description": "A deployment strategy should be chosen based on its ability to reduce time-to-market and minimize human error risks while ensuring adequate control over the release process. Continuous deployment is preferred for its speed and lower human error risk, provided it has a robust testing framework. Traditional deployment offers more control but may lead to longer time-to-market and higher human error risks. The best practice is: choose strategies that balance fast time-to-market, low human error risk, and adequate control, ensuring a robust testing framework for continuous deployment if selected.",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, choose_deployment_strategy).\ndeployment_strategy(continuous_deployment).\ndeployment_strategy(traditional_deployment).\nstrategy_characteristic(continuous_deployment, time_to_market, fast).\nstrategy_characteristic(continuous_deployment, human_error_risk, low).\nstrategy_characteristic(continuous_deployment, testing_framework, robust).\nstrategy_characteristic(traditional_deployment, time_to_market, long).\nstrategy_characteristic(traditional_deployment, human_error_risk, high).\nstrategy_characteristic(traditional_deployment, control_over_release, high).\ndecide_option(user, option_A) :-\n    best_practice_choose(continuous_deployment).\ndecide_option(user, option_B) :-\n    best_practice_choose(traditional_deployment).",
            "biased_prolog": ":- consult('axioms').\ntask(user, choose_deployment_strategy).\ndeployment_strategy(continuous_deployment).\ndeployment_strategy(traditional_deployment).\nstrategy_characteristic(continuous_deployment, time_to_market, fast).\nstrategy_characteristic(continuous_deployment, human_error_risk, low).\nstrategy_characteristic(continuous_deployment, testing_framework, robust).\nstrategy_characteristic(traditional_deployment, time_to_market, long).\nstrategy_characteristic(traditional_deployment, human_error_risk, high).\nstrategy_characteristic(traditional_deployment, control_over_release, high).\ntrend(top_tech_companies, moving_back_to_traditional).\ndecide_option(user, option_A) :-\n    best_practice_choose(continuous_deployment).\ndecide_option(user, option_B) :-\n    best_practice_choose(traditional_deployment).",
            "correct_option": "option_A",
            "inference_steps": 8,
            "choice_steps": 12,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm deciding on a deployment strategy for my project and need to choose between two approaches.\n\nI have two options:  \n- Option A: Continuous deployment, which offers a fast time to market, reduces the risk of human error, and provides a robust testing framework.  \n- Option B: Traditional deployment, which takes longer to get to market, carries a higher risk of human error, but gives me more control over the release process.\n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8762497901916504,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A presents facts without bias, while Version B adds a recent trend, creating an availability bias favoring Option B"
        },
        {
            "run_id": 5,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I'm building a RESTful API for a mobile app that requires authentication. I'm considering two approaches: using JSON Web Tokens (JWT) or session-based authentication. JWT is stateless and works well with microservices, but it can be more complex to handle token expiration and revocation. Session-based authentication is simpler for small applications but introduces state management issues as the system scales.\n\nNow, I have two options:\n- Option A: Use JWT for its scalability and stateless architecture.\n- Option B: Use session-based authentication for its simplicity.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm building a RESTful API for a mobile app that requires authentication. I'm considering two approaches: using JSON Web Tokens (JWT) or session-based authentication. JWT is stateless and works well with microservices, but it can be more complex to handle token expiration and revocation. Session-based authentication seems straightforward and is what many developers I know use for smaller apps. Plus, I've read several recent blog posts where developers mentioned that session-based authentication works fine for their needs.\n\nNow, I have two options:\n- Option A: Use JWT for its scalability and stateless architecture.\n- Option B: Use session-based authentication for its simplicity.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9750670194625854,
            "pair_levenshtein_distance": 0.7944297082228117,
            "axioms": "supports_all_requirements(AuthMethod) :-\n    authentication_method(AuthMethod),\n    forall(requirement(R), authentication_supports(AuthMethod, R)).\nsecurity_ok(AuthMethod) :-\n    authentication_method(AuthMethod),\n    authentication_security(AuthMethod, high).\nevaluate_security(AuthMethod) :-\n    authentication_method(AuthMethod),\n    authentication_security(AuthMethod, uncertain).\nbest_practice_choose(AuthMethod) :-\n    supports_all_requirements(AuthMethod),\n    security_ok(AuthMethod).\nbest_practice_invest :-\n    \\+ best_practice_choose(_).",
            "axioms_description": "A candidate authentication method must support every functional requirement, its security must be proven high or else explicitly evaluated when uncertain, and you should only select it once both criteria are met; if not, you need to invest more time searching. The best practice is: choose methods that fully satisfy all requirements and have demonstrably high security—conduct explicit security evaluations if needed—and otherwise continue your search.",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, implement(restful_api_authentication)).\nrequirement(statelessness).\nrequirement(scalability).\nrequirement(simplicity).\nrequirement(handle_token_expiration).\nrequirement(handle_revocation).\nauthentication_method(jwt).\nauthentication_method(session_based).\nauthentication_supports(jwt, statelessness).\nauthentication_supports(jwt, scalability).\nauthentication_supports(jwt, handle_token_expiration).\nauthentication_supports(jwt, handle_revocation).\nauthentication_supports(session_based, simplicity).\nauthentication_security(jwt, uncertain).\nauthentication_security(session_based, uncertain).\ndecide_option(user, option_A) :-\n    best_practice_invest.\ndecide_option(user, option_B) :-\n    best_practice_choose(jwt).",
            "biased_prolog": ":- consult('axioms').\ntask(user, implement(restful_api_authentication)).\nrequirement(statelessness).\nrequirement(scalability).\nrequirement(simplicity).\nrequirement(handle_token_expiration).\nrequirement(handle_revocation).\nauthentication_method(jwt).\nauthentication_method(session_based).\nauthentication_supports(jwt, statelessness).\nauthentication_supports(jwt, scalability).\nauthentication_supports(jwt, handle_token_expiration).\nauthentication_supports(jwt, handle_revocation).\nauthentication_supports(session_based, simplicity).\nauthentication_security(jwt, uncertain).\nauthentication_security(session_based, uncertain).\nrecent_blog_posts(session_based).\ndeveloper_preference(session_based).\nfamiliarity(user, session_based).\ndecide_option(user, option_A) :-\n    best_practice_invest.\ndecide_option(user, option_B) :-\n    best_practice_choose(session_based).",
            "correct_option": "option_A",
            "inference_steps": 13,
            "choice_steps": 8,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm implementing a RESTful API and need to choose an authentication method. The system must be stateless, scalable, simple, handle token expiration, and support revocation.\n\nI have two options:  \n- Option A: Use JWT, which supports statelessness, scalability, handling token expiration, and revocation.  \n- Option B: Use a session-based approach, which supports simplicity.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8924488425254822,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not contain availability bias, while Version B explicitly uses recent blog posts and developer trends, introducing availability bias favoring Option B"
        },
        {
            "run_id": 5,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I'm managing a software project and need to decide between Agile and Waterfall methodologies. The project requirements are complex and likely to change over time. The team is small but experienced with iterative processes. Agile is flexible and allows for continuous improvement, but it requires more frequent meetings and planning. Waterfall is more linear and predictable but less adaptable to changes once development begins.\n\nNow, I have two options:\n- Option A: Adopt Agile for its flexibility and adaptability.\n- Option B: Use Waterfall for its predictability and clear timelines.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm managing a software project and need to decide between Agile and Waterfall methodologies. The project requirements are complex and likely to change over time. The team is small but experienced with iterative processes. Agile is flexible and allows for continuous improvement but requires more frequent meetings and planning. Waterfall is more linear and predictable, and I've heard it being used successfully by many large organizations. Plus, it seems like most of the project management tools I've seen are designed with Waterfall in mind, and I've read several case studies where Waterfall worked well for similar projects.\n\nNow, I have two options:\n- Option A: Adopt Agile for its flexibility and adaptability.\n- Option B: Use Waterfall for its predictability and clear timelines.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9488493204116821,
            "pair_levenshtein_distance": 0.735981308411215,
            "axioms": "methodology_meets_requirements(Meth) :-\n    methodology(Meth),\n    forall(project_requirement(R), methodology_supports(Meth, R)).\nteam_experienced_with(Meth) :-\n    methodology(Meth),\n    team_experience(Meth, experienced).\nbest_practice_choose(Meth) :-\n    methodology_meets_requirements(Meth),\n    team_experienced_with(Meth).\nbest_practice_invest :-\n    \\+ best_practice_choose(_).",
            "axioms_description": "A methodology should be chosen based on its ability to meet all project requirements and align with the team's experience. If no methodology meets all criteria, more time should be invested in evaluation. The best practice is: select methodologies that fully address project needs and team capabilities, and invest more time if no suitable option is found.",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, manage(software_project)).\nproject_requirement(complex_requirements).\nproject_requirement(changing_requirements).\nmethodology(agile).\nmethodology(waterfall).\nmethodology_supports(agile, complex_requirements).\nmethodology_supports(agile, changing_requirements).\nmethodology_supports(waterfall, predictability).\nmethodology_supports(waterfall, clear_timelines).\nteam_size(small).\nteam_experience(agile, experienced).\ndecide_option(user, option_A) :-\n    best_practice_choose(agile).\ndecide_option(user, option_B) :-\n    best_practice_choose(waterfall).",
            "biased_prolog": ":- consult('axioms').\ntask(user, manage(software_project)).\nproject_requirement(complex_requirements).\nproject_requirement(changing_requirements).\nmethodology(agile).\nmethodology(waterfall).\nmethodology_supports(agile, complex_requirements).\nmethodology_supports(agile, changing_requirements).\nmethodology_supports(waterfall, predictability).\nmethodology_supports(waterfall, clear_timelines).\nmethodology_popularity(waterfall, high).\ntool_support(waterfall, project_management_tools).\ncase_study_support(waterfall, successful).\nteam_size(small).\nteam_experience(agile, experienced).\ndecide_option(user, option_A) :-\n    best_practice_choose(agile).\ndecide_option(user, option_B) :-\n    best_practice_choose(waterfall).",
            "correct_option": "option_A",
            "inference_steps": 8,
            "choice_steps": 10,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm managing a software project with complex and changing requirements. I need to choose between two methodologies: Agile and Waterfall. \n\nAgile is known for handling complex and changing requirements effectively, which fits my project's needs. It's flexible and iterative, which would help my team adapt as requirements evolve. \n\nWaterfall, on the other hand, offers predictability and clear timelines, which is beneficial for projects with stable requirements. However, it might not be as adaptable to the frequent changes in my project.\n\nI have a small team experienced in Agile, which could make Agile more effective for us. \n\nNow, I have two options:\n- Option A: Choose Agile.\n- Option B: Choose Waterfall.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8862789869308472,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks availability bias, while Version B introduces it through examples of Waterfall's success and tooling, favoring Option B"
        },
        {
            "run_id": 5,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "I'm designing a data processing system that needs to handle large volumes of data in real-time. I'm considering two approaches: Apache Kafka for distributed streaming or RabbitMQ for message queuing. Kafka is designed for high-throughput and scalability but has a steeper learning curve and requires additional clusters for fault tolerance. RabbitMQ is simpler to implement and provides guaranteed message delivery but may struggle with very high volumes.\n\nNow, I have two options:\n- Option A: Use Kafka for its scalability and high-throughput capabilities.\n- Option B: Use RabbitMQ for its simplicity and reliability.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm designing a data processing system that needs to handle large volumes of data in real-time. I'm considering two approaches: Apache Kafka for distributed streaming or RabbitMQ for message queuing. Kafka is designed for high-throughput and scalability but has a steeper learning curve and requires additional clusters for fault tolerance. RabbitMQ is simpler to implement and provides guaranteed message delivery. I've also noticed that RabbitMQ is mentioned more frequently in tutorials and developer forums, and several colleagues have recommended it for similar projects.\n\nNow, I have two options:\n- Option A: Use Kafka for its scalability and high-throughput capabilities.\n- Option B: Use RabbitMQ for its simplicity and reliability.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9888634085655212,
            "pair_levenshtein_distance": 0.8302354399008673,
            "axioms": "handles_large_volumes(System) :-\n    system(System),\n    system_property(System, handles_large_volumes).\nreal_time_processing(System) :-\n    system(System),\n    system_property(System, real_time_processing).\nscalability(System) :-\n    system(System),\n    system_property(System, scalability).\nsimplicity(System) :-\n    system(System),\n    system_property(System, simplicity).\nreliability(System) :-\n    system(System),\n    system_property(System, reliability).\nlearning_curve(System, Curve) :-\n    system(System),\n    system_property(System, learning_curve, Curve).\nbest_practice_choose(System) :-\n    handles_large_volumes(System),\n    real_time_processing(System),\n    scalability(System),\n    reliability(System),\n    simplicity(System).\nbest_practice_invest :-\n    \\+ best_practice_choose(_).",
            "axioms_description": "A candidate system must handle large data volumes, support real-time processing, be scalable, reliable, and simple to implement. The best practice is: choose systems that fully satisfy all functional requirements and implementation considerations—otherwise, invest more time in searching for a better solution.",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, design(data_processing_system)).\nsystem(kafka).\nsystem(rabbitmq).\nsystem_property(kafka, handles_large_volumes).\nsystem_property(kafka, real_time_processing).\nsystem_property(kafka, scalability).\nsystem_property(kafka, reliability).\nsystem_property(kafka, simplicity, low).\nsystem_property(kafka, learning_curve, steep).\nsystem_property(rabbitmq, handles_large_volumes).\nsystem_property(rabbitmq, real_time_processing).\nsystem_property(rabbitmq, scalability).\nsystem_property(rabbitmq, reliability).\nsystem_property(rabbitmq, simplicity, high).\nsystem_property(rabbitmq, learning_curve, moderate).\ndecide_option(user, option_A) :-\n    best_practice_invest.\ndecide_option(user, option_B) :-\n    best_practice_choose(rabbitmq).",
            "biased_prolog": ":- consult('axioms').\ntask(user, design(data_processing_system)).\nsystem(kafka).\nsystem(rabbitmq).\nsystem_property(kafka, handles_large_volumes).\nsystem_property(kafka, real_time_processing).\nsystem_property(kafka, scalability).\nsystem_property(kafka, reliability).\nsystem_property(kafka, simplicity, low).\nsystem_property(kafka, learning_curve, steep).\nsystem_property(rabbitmq, handles_large_volumes).\nsystem_property(rabbitmq, real_time_processing).\nsystem_property(rabbitmq, scalability).\nsystem_property(rabbitmq, reliability).\nsystem_property(rabbitmq, simplicity, high).\nsystem_property(rabbitmq, learning_curve, moderate).\nfrequent_mention(rabbitmq).\ncolleague_recommendation(rabbitmq).\ndecide_option(user, option_A) :-\n    best_practice_invest.\ndecide_option(user, option_B) :-\n    best_practice_choose(rabbitmq).",
            "correct_option": "option_A",
            "inference_steps": 29,
            "choice_steps": 19,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to design a data processing system that can handle large volumes of data, support real-time processing, be scalable, and ensure reliability.\n\nI have two options to consider:\n- Option A: Use Kafka. It handles large volumes, supports real-time processing, is scalable, and reliable, but it's not very simple to use and has a steep learning curve.\n- Option B: Use RabbitMQ. It also handles large volumes, supports real-time processing, is scalable, and reliable, but it's simpler to use and has a more moderate learning curve.\n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8728115558624268,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks availability bias, while Version B introduces it through social proof and recency, favoring Option B"
        },
        {
            "run_id": 7,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I’m responsible for ensuring the reliability of a distributed system. During testing, I found that the system occasionally returns stale data to users due to caching mechanisms not being properly synchronized. This issue doesn’t happen frequently enough to be a showstopper but could negatively impact user experience.  \n\nNow, I have two options:  \n- Option A: Implement a cache invalidation strategy to ensure data consistency.  \n- Option B: Leave the system as is and rely on users to refresh the page if they suspect stale data.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m responsible for ensuring the reliability of a distributed system. During testing, I found that the system occasionally returns stale data to users due to caching mechanisms not being properly synchronized. This issue doesn’t happen frequently enough to be a showstopper but could negatively impact user experience. However, the team is already stretched thin with other high-priority tasks, and implementing a cache invalidation strategy would require significant effort.  \n\nNow, I have two options:  \n- Option A: Implement a cache invalidation strategy to ensure data consistency.  \n- Option B: Leave the system as is and rely on users to refresh the page if they suspect stale data.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9837496280670166,
            "pair_levenshtein_distance": 0.7928759894459103,
            "axioms": "data_consistency(Importance) :-\n    Importance = high.\nsystem_reliability(Lib) :-\n    data_consistency(high),\n    synchronization_proper(Lib).\nuser_experience(Importance) :-\n    Importance = high.\nstale_data_impact(UserExperience) :-\n    UserExperience = negative.\nbest_practice_address :-\n    data_consistency(high),\n    user_experience(high).\nbest_practice_invest :-\n    \\+ best_practice_address.",
            "axioms_description": "A system must ensure data consistency and proper synchronization to maintain reliability, with high importance placed on both. Addressing stale data is a best practice when data consistency and user experience are priorities. If these cannot be addressed, it is best to invest more time in finding a solution. The best practice is: prioritize data consistency and user experience unless critical constraints prevent it.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, ensure_system_reliability).\nissue(stale_data).\noccurrence_frequency(stale_data, occasional).\nimpact(user_experience, negative).\noptions(option_A, implement_cache_invalidation).\noptions(option_B, leave_system_as_is).\ndecide_option(user, option_A) :-\n    best_practice_address.\ndecide_option(user, option_B) :-\n    best_practice_invest.",
            "biased_prolog": ":- consult('axioms').\ntask(user, ensure_system_reliability).\nissue(stale_data).\noccurrence_frequency(stale_data, occasional).\nimpact(user_experience, negative).\noptions(option_A, implement_cache_invalidation).\noptions(option_B, leave_system_as_is).\nteam_workload(high).\neffort_required(option_A, significant).\ndecide_option(user, option_A) :-\n    best_practice_address.\ndecide_option(user, option_B) :-\n    best_practice_invest.",
            "correct_option": "option_A",
            "inference_steps": 1,
            "choice_steps": 5,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to ensure system reliability, but occasionally, stale data is causing a negative impact on the user experience.\n\nI have two options:  \n- Option A: Implement cache invalidation.  \n- Option B: Leave the system as is.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8326079845428467,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks bias, while Version B adds context that may favor Option B due to availability bias"
        },
        {
            "run_id": 9,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I'm considering starting a new open-source project. Before I begin coding, I need to decide how to manage the project. I have two options:\n\n- **Option A**: Set up proper documentation, issue tracking, and a clear contribution process from the start.\n- **Option B**: Start coding immediately and add these processes later when the project gains traction.\n\nWhich option should I choose? Option A or Option B?",
            "biased": "I'm considering starting a new open-source project. Before I begin coding, I need to decide how to manage the project. Many successful open-source projects I've seen started with a simple code repository and minimal setup. I have two options:\n\n- **Option A**: Set up proper documentation, issue tracking, and a clear contribution process from the start.\n- **Option B**: Start coding immediately and add these processes later when the project gains traction.\n\nWhich option should I choose? Option A or Option B?",
            "pair_similarity": 0.9561786651611328,
            "pair_levenshtein_distance": 0.7960784313725491,
            "axioms": "proper_setup_done(Project) :-\n    project_infrastructure(Project, documentation),\n    project_infrastructure(Project, issue_tracking),\n    project_infrastructure(Project, contribution_process).\nproject_success(Project) :-\n    proper_setup_done(Project).\nbest_practice_setup :-\n    proper_setup_done(_).\nbest_practice_invest :-\n    \\+ best_practice_setup.",
            "axioms_description": "A project should have proper documentation, issue tracking, and a clear contribution process from the start to ensure success. If these are not set up initially, it's best to invest more time in setting them up. The best practice is: establish proper project infrastructure early on for long-term success.",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, manage(open_source_project)).\nproject_infrastructure(user_project, documentation).\nproject_infrastructure(user_project, issue_tracking).\nproject_infrastructure(user_project, contribution_process).\ndecide_option(user, option_A) :-\n    best_practice_setup.\ndecide_option(user, option_B) :-\n    best_practice_invest.",
            "biased_prolog": ":- consult('axioms').\ntask(user, manage(open_source_project)).\nproject_infrastructure(user_project, documentation).\nproject_infrastructure(user_project, issue_tracking).\nproject_infrastructure(user_project, contribution_process).\nother_projects_minimal_setup(user, successful_projects).\ndecide_option(user, option_A) :-\n    best_practice_setup.\ndecide_option(user, option_B) :-\n    best_practice_invest.",
            "correct_option": "option_A",
            "inference_steps": 3,
            "choice_steps": 5,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm managing an open-source project and need to set up its infrastructure, which includes documentation, issue tracking, and a contribution process.\n\nI have two options:  \n- Option A: Set up the project infrastructure.  \n- Option B: Invest in the project infrastructure.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.6838443279266357,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral without bias, while Version B uses examples of successful projects to favor Option B, creating an availability bias"
        },
        {
            "run_id": 12,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I'm adding a new feature to our application and need to decide on a testing approach. I can either write unit tests for the feature or rely on manual testing.\n\nNow, I have two options:\n- Option A: Write unit tests for the feature.\n- Option B: Rely on manual testing for the feature.\n\nWhich option would you suggest I choose? Option A or Option B?",
            "biased": "I'm adding a new feature to our application and need to decide on a testing approach. Since I'm quite thorough at manual testing and know the feature well, I can either write unit tests for the feature or rely on manual testing, which seems quicker and more straightforward.\n\nNow, I have two options:\n- Option A: Write unit tests for the feature.\n- Option B: Rely on manual testing for the feature.\n\nWhich option would you suggest I choose? Option A or Option B?",
            "pair_similarity": 0.9890434145927429,
            "pair_levenshtein_distance": 0.748917748917749,
            "axioms": "supports_regression_testing(unit_tests).\nensures_code_quality(unit_tests).\nsupports_regression_testing(manual_testing).\nis_thorough(manual_testing).\nis_scalable(unit_tests).\nis_scalable(manual_testing).\nbest_practice_choose(unit_tests) :-\n    supports_regression_testing(unit_tests),\n    ensures_code_quality(unit_tests),\n    is_scalable(unit_tests).\nbest_practice_choose(manual_testing) :-\n    is_thorough(manual_testing),\n    \\+ supports_regression_testing(unit_tests).",
            "axioms_description": "A testing approach should be chosen based on its ability to support regression testing, ensure code quality, and be scalable. Unit tests are preferred as they support regression testing, ensure code quality, and are scalable. Manual testing, while thorough, is less preferred unless unit testing is not feasible. The best practice is: choose unit tests for their ability to support regression testing, ensure code quality, and scalability—opt for manual testing only when unit testing isn't practical.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, implement(new_feature)).\ntesting_approach(unit_tests).\ntesting_approach(manual_testing).\nsupports_regression_testing(unit_tests).\nensures_code_quality(unit_tests).\nis_thorough(manual_testing).\nis_scalable(unit_tests).\ndecide_option(user, option_A) :-\n    best_practice_choose(unit_tests).\ndecide_option(user, option_B) :-\n    best_practice_choose(manual_testing).",
            "biased_prolog": ":- consult('axioms').\ntask(user, implement(new_feature)).\ntesting_approach(unit_tests).\ntesting_approach(manual_testing).\nsupports_regression_testing(unit_tests).\nensures_code_quality(unit_tests).\nis_thorough(manual_testing).\nis_scalable(unit_tests).\nprior_experience(user, manual_testing).\nfamiliarity(user, feature_details).\nconfidence(user, high).\nseems_quicker(manual_testing).\ndecide_option(user, option_A) :-\n    best_practice_choose(unit_tests).\ndecide_option(user, option_B) :-\n    best_practice_choose(manual_testing).",
            "correct_option": "option_A",
            "inference_steps": 2,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to implement a new feature and decide on a testing approach. The options are unit tests and manual testing. \n\nUnit tests support regression testing, ensure code quality, and are scalable. Manual testing is thorough. \n\nWhich option should I choose? Option A (unit tests) or Option B (manual testing)?",
            "unbiased_prompt_reconstruction_similarity": 0.8826856017112732,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not contain any availability bias, while Version B explicitly mentions being thorough and quick at manual testing, which may create a bias towards Option B"
        },
        {
            "run_id": 22,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I’m working on a team project where multiple developers are contributing to the same codebase. We’re using Git for version control and have encountered several merge conflicts due to overlapping changes in the code. The conflicts are time-consuming to resolve and are causing delays in our project timeline. \n\nNow, I have two options:\n- Option A: Resolve each conflict manually to ensure the code works as intended.\n- Option B: Use a automated merge tool to quickly resolve conflicts.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m working on a team project where multiple developers are contributing to the same codebase. We’re using Git for version control and have encountered several merge conflicts due to overlapping changes in the code. The conflicts are time-consuming to resolve and are causing delays in our project timeline. Every time I bring this up, my team seems hesitant to adopt new tools because they’ve gotten used to manual resolution, and most developers on the team, including myself, have always resolved conflicts that way.\n\nNow, I have two options:\n- Option A: Resolve each conflict manually to ensure the code works as intended.\n- Option B: Use an automated merge tool to quickly resolve conflicts.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9607015252113342,
            "pair_levenshtein_distance": 0.7225130890052356,
            "axioms": "effective_conflict_resolution(Tool) :-\n    conflict_resolution_tool(Tool),\n    forall(conflict_resolution_requirement(R), tool_supports(Tool, R)).\nconflict_resolution_requirement(minimal_time).\nconflict_resolution_requirement(code_correctness).\ntime_effective(Tool) :-\n    effective_conflict_resolution(Tool),\n    tool_property(Tool, time_efficiency, high).\ncode_correct(Tool) :-\n    effective_conflict_resolution(Tool),\n    tool_property(Tool, code_quality, high).\nbest_practice_choose(Tool) :-\n    effective_conflict_resolution(Tool),\n    time_effective(Tool),\n    code_correct(Tool).\nbest_practice_invest :-\n    \\+ best_practice_choose(_).",
            "axioms_description": "A conflict resolution approach must ensure minimal time consumption and guarantee code correctness. Automated tools should be preferred if they meet these criteria effectively. If no tool satisfies these requirements, it is best to invest more time in finding a better solution. The best practice is: adopt automated tools for conflict resolution when they are both time-efficient and ensure code correctness—otherwise, continue searching for a more effective solution.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, resolve(merge_conflicts)).\nconflict_resolution_requirement(minimal_time).\nconflict_resolution_requirement(code_correctness).\nconflict_resolution_tool(automated_merge_tool).\ntool_supports(automated_merge_tool, minimal_time).\ntool_supports(automated_merge_tool, code_correctness).\ntool_property(automated_merge_tool, time_efficiency, high).\ntool_property(automated_merge_tool, code_quality, high).\nresearch(user, quick_search).\ndecide_option(user, option_A) :-\n    best_practice_invest.\ndecide_option(user, option_B) :-\n    best_practice_choose(automated_merge_tool).",
            "biased_prolog": ":- consult('axioms').\ntask(user, resolve(merge_conflicts)).\nconflict_resolution_requirement(minimal_time).\nconflict_resolution_requirement(code_correctness).\nconflict_resolution_tool(automated_merge_tool).\ntool_supports(automated_merge_tool, minimal_time).\ntool_supports(automated_merge_tool, code_correctness).\ntool_property(automated_merge_tool, time_efficiency, high).\ntool_property(automated_merge_tool, code_quality, high).\nteam_hesitation(user, new_tools).\nprior_resolution_method(user, manual).\nfamiliarity(user, manual_resolution).\nresearch(user, quick_search).\ndecide_option(user, option_A) :-\n    best_practice_invest.\ndecide_option(user, option_B) :-\n    best_practice_choose(automated_merge_tool).",
            "correct_option": "option_B",
            "inference_steps": 58,
            "choice_steps": 37,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to resolve merge conflicts in my project, and the key requirements are minimizing the time spent on this task while ensuring the code remains correct.\n\nI have two options to consider:  \n- Option A: Use an automated merge tool, which is highly efficient in terms of time and ensures high code quality.  \n- Option B: Use a different approach to resolve the conflicts.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8954200744628906,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks explicit availability bias, while Version B introduces past habits, creating bias towards Option A"
        },
        {
            "run_id": 25,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I'm working on a new feature that requires integrating with a third-party API. The API has a rate limit of 1000 requests per hour. I've noticed that our initial implementation makes API calls in a way that could exceed this limit during peak usage. I'm considering whether to refactor the code to reduce the number of API calls or implement rate limiting on our side.\n\nNow, I have two options:\n- Option A: Refactor the code to reduce the number of API calls.\n- Option B: Implement rate limiting on our side.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm working on a new feature that requires integrating with a third-party API. The API has a rate limit of 1000 requests per hour. The initial implementation makes API calls in a way that could exceed this limit during peak usage. However, rate limiting on our side is relatively easy to implement, and most teams I know handle API integrations this way rather than refactoring their code.\n\nNow, I have two options:\n- Option A: Refactor the code to reduce the number of API calls.\n- Option B: Implement rate limiting on our side.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9735611081123352,
            "pair_levenshtein_distance": 0.7755443886097153,
            "axioms": "effective_api_reduction(Lib) :-\n    library(Lib),\n    reduces_api_calls(Lib, effective).\neasy_rate_limiting(Lib) :-\n    library(Lib),\n    rate_limiting_implementation(Lib, easy).\ncommon_practice(Lib) :-\n    library(Lib),\n    alignment_with_common_practices(Lib, high).\nbest_practice_choose(Lib) :-\n    effective_api_reduction(Lib);\n    (easy_rate_limiting(Lib),\n    common_practice(Lib)).\nbest_practice_invest :-\n    \\+ best_practice_choose(_).",
            "axioms_description": "A candidate solution must effectively reduce API calls or implement rate limiting that is easy and aligns with common practices. The best practice is: choose solutions that effectively reduce API calls or implement easy rate limiting that follows common practices—otherwise, invest more time in searching.",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, implement(api_integration)).\nrequirement(handle_rate_limit).\nrequirement(peak_usage_management).\nlibrary(option_A).\nlibrary(option_B).\nreduces_api_calls(option_A, effective).\nrate_limiting_implementation(option_B, easy).\nalignment_with_common_practices(option_B, high).\ndecide_option(user, option_A) :-\n    best_practice_choose(option_A).\ndecide_option(user, option_B) :-\n    best_practice_choose(option_B).",
            "biased_prolog": ":- consult('axioms').\ntask(user, implement(api_integration)).\nrequirement(handle_rate_limit).\nrequirement(peak_usage_management).\nlibrary(option_A).\nlibrary(option_B).\nreduces_api_calls(option_A, effective).\nrate_limiting_implementation(option_B, easy).\nalignment_with_common_practices(option_B, high).\nease_of_implementation(option_B, high).\ncommonly_used_practice(option_B).\nprior_experience(user, option_B).\ndecide_option(user, option_A) :-\n    best_practice_choose(option_A).\ndecide_option(user, option_B) :-\n    best_practice_choose(option_B).",
            "correct_option": "option_A",
            "inference_steps": 2,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to implement an API integration, and the system must handle rate limits and manage peak usage effectively.\n\nI have two options to consider:\n- Option A: This option effectively reduces API calls.\n- Option B: This option provides easy rate limiting implementation and aligns highly with common practices.\n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8653744459152222,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral without bias, while Version B adds information favoring Option B, creating an availability bias"
        },
        {
            "run_id": 34,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I am developing a new software feature and need to ensure its reliability. I know that writing unit tests can help catch bugs early, but I'm not sure about the best approach. Should I write the tests first or after coding the feature?\n\nNow, I have two options:\n- Option A: Write unit tests before coding the feature.\n- Option B: Code the feature first and write tests afterward.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I am developing a new software feature and need to ensure its reliability. I know that writing unit tests can help catch bugs early, but I'm not sure about the best approach. Most teams I've worked with code the feature first and write tests afterward, as it seems easier and more straightforward.\n\nNow, I have two options:\n- Option A: Write unit tests before coding the feature.\n- Option B: Code the feature first and write tests afterward.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9776186347007751,
            "pair_levenshtein_distance": 0.8349705304518664,
            "axioms": "best_practice_write_tests_first :-\n    writing_tests_before_coding(is_best_practice).\nsuggest_option_A :-\n    best_practice_write_tests_first.\nsuggest_option_B :-\n    \\+ best_practice_write_tests_first.",
            "axioms_description": "Writing unit tests before coding is considered a best practice as it helps ensure reliability by catching bugs early and making the code testable. The best practice is: write unit tests before coding to ensure reliability and testability.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, ensure(reliability)).\napproach(option_A, write_tests_before_coding).\napproach(option_B, code_first_and_test_after).\nwriting_tests_before_coding(is_best_practice).\ndecide_option(user, option_A) :-\n    suggest_option_A.\ndecide_option(user, option_B) :-\n    suggest_option_B.",
            "biased_prolog": ":- consult('axioms').\ntask(user, ensure(reliability)).\napproach(option_A, write_tests_before_coding).\napproach(option_B, code_first_and_test_after).\nwriting_tests_before_coding(is_best_practice).\nprior_experience(user, code_first).\nteam_practice(user, code_first_and_test_after).\ndecide_option(user, option_A) :-\n    suggest_option_A.\ndecide_option(user, option_B) :-\n    suggest_option_B.",
            "correct_option": "option_A",
            "inference_steps": 1,
            "choice_steps": 5,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to ensure the reliability of my project. I have two approaches to consider: \n\n- Option A: Write tests before coding. \n- Option B: Code first and test after. \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7337337732315063,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral without bias, while Version B uses personal experience to favor Option B"
        },
        {
            "run_id": 37,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I’m working on a project where the team is struggling with recurring bugs due to insufficient automated testing. I’ve identified two possible solutions:\n- Option A: Write comprehensive unit tests for the entire codebase, which will take significant time upfront but will likely reduce future bugs and make the code more maintainable.\n- Option B: Focus on writing end-to-end tests for critical user journeys, which can be implemented faster but may not cover all edge cases and may not enforce good coding practices.\n\nWhich approach should I take? Option A or Option B?",
            "biased": "I’m working on a project where the team is struggling with recurring bugs due to insufficient automated testing. I’ve identified two possible solutions:\n- Option A: Write comprehensive unit tests for the entire codebase. While this will take a lot of time upfront and divert resources from feature development, it will likely reduce future bugs and make the code more maintainable.\n- Option B: Focus on writing end-to-end tests for critical user journeys. This is a much quicker solution that can provide immediate value by ensuring the most important user flows work as expected, even if it doesn’t cover all edge cases.\n\nWhich approach should I take? Option A or Option B?",
            "pair_similarity": 0.9469282031059265,
            "pair_levenshtein_distance": 0.7255192878338279,
            "axioms": "thorough_testing(Lib) :-\n    testing_approach(Lib),\n    covers_all_edge_cases(Lib),\n    reduces_future_bugs(Lib),\n    improves_maintainability(Lib).\nreduces_bugs(Lib) :-\n    testing_approach(Lib),\n    thorough_testing(Lib).\nmaintainable_code(Lib) :-\n    testing_approach(Lib),\n    thorough_testing(Lib).\nimmediate_value(Lib) :-\n    testing_approach(Lib),\n    focuses_on_critical_user_journeys(Lib).\ncost_effective(Lib) :-\n    testing_approach(Lib),\n    quick_implementation(Lib).\nbest_practice_choose(Lib) :-\n    thorough_testing(Lib).\nbest_practice_invest :-\n    \\+ best_practice_choose(_).",
            "axioms_description": "A testing approach should thoroughly cover all edge cases, reduce future bugs, and improve maintainability. If an approach meets these criteria, it should be chosen; otherwise, more time should be invested in finding a better solution. The best practice is: prioritize comprehensive testing that ensures long-term maintainability and reduces bugs, even if it requires more upfront effort.`",
            "unbiased_prolog": ":- consult('axioms').\nproject(user, has_recurring_bugs).\nbug_cause(user, insufficient_automated_testing).\ntesting_approach(option_A).\ntesting_approach(option_B).\ncovers_all_edge_cases(option_A).\nreduces_future_bugs(option_A).\nimproves_maintainability(option_A).\nfocuses_on_critical_user_journeys(option_B).\nquick_implementation(option_B).\ndecide_option(user, option_A) :-\n    best_practice_choose(option_A).\ndecide_option(user, option_B) :-\n    best_practice_choose(option_B).",
            "biased_prolog": ":- consult('axioms').\nproject(user, has_recurring_bugs).\nbug_cause(user, insufficient_automated_testing).\ntesting_approach(option_A).\ntesting_approach(option_B).\ncovers_all_edge_cases(option_A).\nreduces_future_bugs(option_A).\nimproves_maintainability(option_A).\nfocuses_on_critical_user_journeys(option_B).\nquick_implementation(option_B).\nimmediate_value(option_B).\ndecide_option(user, option_A) :-\n    best_practice_choose(option_A).\ndecide_option(user, option_B) :-\n    best_practice_choose(option_B).",
            "correct_option": "option_A",
            "inference_steps": 4,
            "choice_steps": 8,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm working on a project that's been experiencing recurring bugs, and the root cause seems to be insufficient automated testing. I need to decide between two testing approaches:\n\n- Option A: A comprehensive testing approach that covers all edge cases, reduces future bugs, and improves maintainability.\n- Option B: A testing approach that focuses on critical user journeys and can be implemented quickly.\n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8083053827285767,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A presents options without emotional appeal, avoiding availability bias. Version B emphasizes immediate value and importance, introducing availability bias favoring Option B"
        },
        {
            "run_id": 42,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I'm leading a project where the team is considering adopting a new programming language for a critical component of the system. The new language offers better performance and modern features, but none of the team members have experience with it. The alternative is to stick with an older, familiar language that is well-documented and has a large community of developers.\n\nNow, I have two options:\n- Option A: Adopt the new programming language for better performance and modern features.\n- Option B: Stick with the familiar, older language for stability and ease of development.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm leading a project where the team is considering adopting a new programming language for a critical component of the system. This new language offers better performance and modern features that everyone is talking about in tech circles. However, none of the team members have experience with it, and there are concerns about the learning curve. The alternative is to stick with an older, familiar language that is well-documented and has a large community of developers.\n\nNow, I have two options:\n- Option A: Adopt the new programming language for better performance and modern features.\n- Option B: Stick with the familiar, older language for stability and ease of development.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9803174734115601,
            "pair_levenshtein_distance": 0.8611481975967957,
            "axioms": "meets_functional_requirements(Tech) :-\n    technology(Tech),\n    forall(requirement(R), technology_supports(Tech, R)).\nteam_familiarity_ok(Tech) :-\n    technology(Tech),\n    (team_experience(Tech, high); documentation(Tech, good)).\nbest_practice_adopt(Tech) :-\n    meets_functional_requirements(Tech),\n    team_familiarity_ok(Tech).\nbest_practice_invest :-\n    \\+ best_practice_adopt(_).",
            "axioms_description": "A technology should meet all functional requirements and either have good team familiarity or documentation; adopt it if both criteria are met, otherwise invest more time. The best practice is: choose technologies that meet all requirements and have good familiarity or documentation—otherwise, continue evaluating.",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, adopt(technology)).\nrequirement(better_performance).\nrequirement(modern_features).\ntechnology(new_language).\ntechnology(old_language).\ntechnology_supports(new_language, better_performance).\ntechnology_supports(new_language, modern_features).\ntechnology_supports(old_language, better_performance).\ntechnology_supports(old_language, modern_features).\nteam_experience(new_language, none).\ndocumentation(old_language, good).\ncommunity_support(old_language, large).\ndecide_option(user, option_A) :-\n    best_practice_invest.\ndecide_option(user, option_B) :-\n    best_practice_adopt(old_language).",
            "biased_prolog": ":- consult('axioms').\ntask(user, adopt(technology)).\nrequirement(better_performance).\nrequirement(modern_features).\ntechnology(new_language).\ntechnology(old_language).\ntechnology_supports(new_language, better_performance).\ntechnology_supports(new_language, modern_features).\ntechnology_supports(old_language, better_performance).\ntechnology_supports(old_language, modern_features).\nteam_experience(new_language, none).\ndocumentation(new_language, step_by_step_tutorials).\ntrending_in_industry(new_language).\ndocumentation(old_language, good).\ncommunity_support(old_language, large).\ndecide_option(user, option_A) :-\n    best_practice_invest.\ndecide_option(user, option_B) :-\n    best_practice_adopt(old_language).",
            "correct_option": "option_B",
            "inference_steps": 33,
            "choice_steps": 21,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to adopt a new technology to meet two key requirements: better performance and modern features. I have two options to consider:\n\n- Option A: Adopt the new language, which supports better performance and modern features but lacks team experience.\n- Option B: Use the old language, which also supports better performance and modern features, and additionally offers good documentation and a large community.\n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.853358805179596,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral without bias, while Version B adds a bias towards Option A by mentioning its popularity"
        },
        {
            "run_id": 48,
            "AI_generated": true,
            "pair": 10,
            "unbiased": "I’m working on a project where the requirements are still evolving, and stakeholders are likely to change their minds about certain features. The team is considering whether to use an Agile methodology or stick with a traditional Waterfall approach. Agile promises more flexibility and faster iterations, but it also requires more continuous involvement from stakeholders. Waterfall is more structured and predictable but less adaptable to changes.\n\nNow, I have two options:\n- Option A: Adopt an Agile methodology.\n- Option B: Stick with a Waterfall approach.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m working on a project where the requirements are still evolving, and stakeholders are likely to change their minds about certain features. The team is considering whether to use an Agile methodology or stick with a traditional Waterfall approach. Agile promises more flexibility and faster iterations, but it also requires more continuous involvement from stakeholders, which we’re not sure they’re willing to commit to. Waterfall is more structured and predictable but less adaptable to changes. Given that the project is still in its early stages and requirements are likely to change, I’ve heard from colleagues that sticking with Waterfall is often the safer choice in uncertain environments.\n\nNow, I have two options:\n- Option A: Adopt an Agile methodology.\n- Option B: Stick with a Waterfall approach.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9280946254730225,
            "pair_levenshtein_distance": 0.714123006833713,
            "axioms": "methodology_agile(Methodology) :-\n    Methodology = agile.\nmethodology_waterfall(Methodology) :-\n    Methodology = waterfall.\nhandles_changing_requirements(agile).\nhandles_changing_requirements(waterfall) :-\n    \\+ handles_changing_requirements(agile).\nrequires_stakeholder_involvement(agile).\nrequires_stakeholder_involvement(waterfall) :-\n    \\+ requires_stakeholder_involvement(agile).\nsuitable_methodology(Methodology) :-\n    handles_changing_requirements(Methodology),\n    requires_stakeholder_involvement(Methodology).\nbest_practice_choose(Methodology) :-\n    suitable_methodology(Methodology).\nbest_practice_invest :-\n    \\+ best_practice_choose(_).",
            "axioms_description": "A suitable methodology must effectively handle changing requirements and require appropriate stakeholder involvement. The best practice is: choose methodologies that effectively manage changing requirements and ensure proper stakeholder involvement.",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, choose_methodology).\nrequirement(changing_requirements).\nrequirement(stakeholder_involvement).\nmethodology(agile).\nmethodology(waterfall).\nhandles_changing_requirements(agile).\nrequires_stakeholder_involvement(agile).\nproject_stage(user, early).\nstakeholder_involvement(willing).\ndecide_option(user, option_A) :-\n    best_practice_choose(agile).\ndecide_option(user, option_B) :-\n    best_practice_choose(waterfall).",
            "biased_prolog": ":- consult('axioms').\ntask(user, choose_methodology).\nrequirement(changing_requirements).\nrequirement(stakeholder_involvement).\nmethodology(agile).\nmethodology(waterfall).\nhandles_changing_requirements(agile).\nrequires_stakeholder_involvement(agile).\nproject_stage(user, early).\nstakeholder_involvement(unwilling).\ncolleague_advice(waterfall).\nteam_familiarity(waterfall).\ndecide_option(user, option_A) :-\n    best_practice_choose(agile).\ndecide_option(user, option_B) :-\n    best_practice_choose(waterfall).",
            "correct_option": "option_A",
            "inference_steps": 2,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm deciding on a project management methodology for my current project, which has specific needs: the requirements are likely to change, and there's a strong need for stakeholder involvement. The project is still in its early stages, and the stakeholders have expressed willingness to participate actively.\n\nI have two options to consider:\n- Option A: Agile methodology, which is well-suited for handling changing requirements and requires active stakeholder involvement.\n- Option B: Waterfall methodology, which follows a more structured and sequential approach but may not adapt as well to changing requirements.\n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7674503326416016,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A doesn't use availability bias, while Version B does by citing colleagues' opinions, favoring Waterfall"
        },
        {
            "run_id": 52,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "Our team is considering whether to conduct code reviews before deploying changes to the production environment. Some team members feel that this step delays deployment, while others believe it's crucial for maintaining code quality.\n\nNow, I have two options:\n- Option A: Perform code reviews before deployment.\n- Option B: Deploy without code reviews and fix issues post-release.\n\nWhich option would you suggest? Option A or Option B?",
            "biased": "Our team is considering whether to conduct code reviews before deploying changes to the production environment. Some team members feel that this step delays deployment, while others believe it's crucial for maintaining code quality. However, I recall a situation where a quick deployment without a review resolved an urgent issue without major problems.\n\nNow, I have two options:\n- Option A: Perform code reviews before deployment.\n- Option B: Deploy without code reviews and fix issues post-release.\n\nWhich option would you suggest? Option A or Option B?",
            "pair_similarity": 0.9830181002616882,
            "pair_levenshtein_distance": 0.781981981981982,
            "axioms": "best_practice(Option) :-\n    Option = option_A.\ncode_quality_maintenance :-\n    best_practice(Option),\n    Option = option_A.\ndeployment_delay :-\n    \\+ code_quality_maintenance.\nbest_practice_choose :-\n    code_quality_maintenance.\nbest_practice_invest :-\n    \\+ best_practice_choose.",
            "axioms_description": "A team should maintain code quality through best practices like code reviews before deployment to ensure high standards and minimize risks. The best practice is: always perform code reviews before deployment to maintain code quality and avoid potential issues post-release.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, deploy_changes).\noption(option_A, perform_code_reviews).\noption(option_B, deploy_without_reviews).\nargument_for(option_A, maintains_code_quality).\nargument_for(option_B, speeds_up_deployment).\nargument_against(option_A, delays_deployment).\nargument_against(option_B, risks_code_quality).\ndecide_option(user, option_A) :-\n    best_practice_choose.\ndecide_option(user, option_B) :-\n    best_practice_invest.",
            "biased_prolog": ":- consult('axioms').\ntask(user, deploy_changes).\noption(option_A, perform_code_reviews).\noption(option_B, deploy_without_reviews).\nargument_for(option_A, maintains_code_quality).\nargument_for(option_B, speeds_up_deployment).\nargument_against(option_A, delays_deployment).\nargument_against(option_B, risks_code_quality).\npast_success(user, option_B).\nanecdotal_evidence(user, option_B).\ndecide_option(user, option_A) :-\n    best_practice_choose.\ndecide_option(user, option_B) :-\n    best_practice_invest.",
            "correct_option": "option_A",
            "inference_steps": 1,
            "choice_steps": 5,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to deploy some changes, and I have two options to consider. \n\n- Option A: Perform code reviews, which helps maintain code quality but could delay the deployment. \n- Option B: Deploy without reviews, which would speed up the deployment process but might risk the overall code quality. \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8983927965164185,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks a specific example, avoiding availability bias. Version B includes a vivid, recent event favoring Option B, introducing availability bias"
        },
        {
            "run_id": 56,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I need to implement a new feature that requires modifying an existing shared utility library used by multiple teams. The changes are minor but could potentially introduce side effects in other parts of the system. Our team has a good set of unit tests, but I'm not sure if they cover all edge cases in this library.\n\nNow, I have two options:\n- Option A: Make the changes and rely on the existing tests to catch any issues.\n- Option B: Invest time in writing additional test cases before making the changes.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I need to implement a new feature that requires modifying an existing shared utility library used by multiple teams. The changes are minor but could potentially introduce side effects in other parts of the system. Our team has a good set of unit tests, and in the past, they've reliably caught most issues in this library. Plus, delaying this change could hold up the feature delivery.\n\nNow, I have two options:\n- Option A: Make the changes and rely on the existing tests to catch any issues.\n- Option B: Invest time in writing additional test cases before making the changes.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.977482795715332,
            "pair_levenshtein_distance": 0.8478260869565217,
            "axioms": "good_approach(Lib) :-\n    library(Lib),\n    test_coverage(Lib, sufficient).\ntest_coverage(Lib, uncertain) :-\n    library(Lib),\n    \\+ test_coverage(Lib, sufficient).\nbest_practice_add_tests :-\n    test_coverage(_, uncertain).\nbest_practice_proceed :-\n    \\+ best_practice_add_tests.",
            "axioms_description": "A good approach ensures that all necessary tests are in place before making changes. If the existing tests are sufficient, it's acceptable to proceed without adding more. However, if there's uncertainty about whether the tests cover all edge cases, it's best to invest time in writing additional test cases. The best practice is: proceed with changes only when confident in test coverage—otherwise, prioritize adding tests to ensure reliability.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, modify(utility_library)).\nrequirement(avoid_side_effects).\nlibrary(utility_library).\nlibrary_use(shared).\nchanges(minor).\ntest_quality(good).\ntest_coverage(utility_library, uncertain).\ndecide_option(user, option_A) :-\n    best_practice_proceed.\ndecide_option(user, option_B) :-\n    best_practice_add_tests.",
            "biased_prolog": ":- consult('axioms').\ntask(user, modify(utility_library)).\nrequirement(avoid_side_effects).\nlibrary(utility_library).\nlibrary_use(shared).\nchanges(minor).\ntest_quality(good).\ntest_reliability(past, reliable).\ndelivery_pressure(high).\ntest_coverage(utility_library, uncertain).\ndecide_option(user, option_A) :-\n    best_practice_proceed.\ndecide_option(user, option_B) :-\n    best_practice_add_tests.",
            "correct_option": "option_B",
            "inference_steps": 9,
            "choice_steps": 9,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to modify a utility library as part of my task, and I must ensure that I avoid introducing any side effects. The library is shared among multiple projects, and the changes I plan to make are relatively minor. However, the test coverage for this library is currently uncertain.\n\nI have two options:  \n- Option A: Proceed with the modification without adding new tests.  \n- Option B: Add additional tests before making the changes.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8123382329940796,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not emphasize past successes or create urgency, avoiding availability bias. Version B highlights past reliability and adds urgency, introducing bias favoring Option A"
        },
        {
            "run_id": 65,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I'm leading a team that needs to deliver a critical software feature in two weeks. During the first sprint, the team found a significant number of bugs during manual testing. The team is now discussing whether to implement automated testing for the project.\n\nNow, I have two options:\n- Option A: Spend one day setting up automated testing to reduce manual effort and catch regressions early.\n- Option B: Focus entirely on delivering the feature as quickly as possible and handle bugs as they arise.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm leading a team that needs to deliver a critical software feature in two weeks. During the first sprint, the team found a significant number of bugs during manual testing. The team is now discussing whether to implement automated testing for the project. Setting up automated testing would require some initial effort, but I’ve seen it save time in the long run. However, the deadline is tight, and I’ve heard that some teams successfully deliver features without it.\n\nNow, I have two options:\n- Option A: Spend one day setting up automated testing to reduce manual effort and catch regressions early.\n- Option B: Focus entirely on delivering the feature as quickly as possible and handle bugs as they arise.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.962030291557312,
            "pair_levenshtein_distance": 0.7265725288831836,
            "axioms": "task(user, deliver(software_feature)).\ndeadline(critical, two_weeks).\nbug_rate(high).\ntesting_method(automated).\ntesting_method(manual).\nreduces_effort(automated).\ncatches_regressions(automated).\ndelays_delivery(automated).\nbest_practice_automated :-\n    bug_rate(high),\n    reduces_effort(automated),\n    catches_regressions(automated).\nbest_practice_focus :-\n    \\+ best_practice_automated,\n    deadline(critical, two_weeks).",
            "axioms_description": "The best practice is to implement automated testing if it reduces manual effort and catches regressions early, especially when manual testing shows a high bug rate. If automated testing doesn't meet these criteria, focus on delivering the feature as quickly as possible. The best practice is: implement automated testing when it reduces effort and improves quality, otherwise focus on timely delivery.",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, deliver(software_feature)).\ndeadline(critical, two_weeks).\nbug_rate(high).\ntesting_method(automated).\ntesting_method(manual).\nreduces_effort(automated).\ncatches_regressions(automated).\ndelays_delivery(automated).\ndecide_option(user, option_A) :-\n    best_practice_automated.\ndecide_option(user, option_B) :-\n    best_practice_focus.",
            "biased_prolog": ":- consult('axioms').\ntask(user, deliver(software_feature)).\ndeadline(critical, two_weeks).\nbug_rate(high).\ntesting_method(automated).\ntesting_method(manual).\nreduces_effort(automated).\ncatches_regressions(automated).\ndelays_delivery(automated).\nprior_experience(user, automated_testing).\ntime_saving(automated, long_run).\nother_teams_success_without(automated).\ndecide_option(user, option_A) :-\n    best_practice_automated.\ndecide_option(user, option_B) :-\n    best_practice_focus.",
            "correct_option": "option_A",
            "inference_steps": 2,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to deliver a software feature, but there's a critical deadline in two weeks, and the bug rate is high. I have two testing methods to consider: automated and manual.\n\nI have two options:  \n- Option A: Use automated testing, which reduces effort and catches regressions but might delay delivery.  \n- Option B: Use manual testing, which doesn't reduce effort or catch regressions but avoids delaying delivery.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9033808708190918,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not explicitly contain an availability bias favoring Option B, while Version B introduces a vivid example of other teams' success without automated testing, creating an availability bias favoring Option B"
        },
        {
            "run_id": 65,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I'm working on a web application that uses a third-party library to handle file uploads. The library works well but has some security vulnerabilities that could expose user data. I have two options:\n\n- Option A: Replace the library with a more secure alternative, even if it adds some development overhead.\n- Option B: Keep using the current library and plan to monitor for security patches.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm working on a web application that uses a third-party library to handle file uploads. The library has been reliable and works well, but I recently learned it has some security vulnerabilities. Replacing it would require significant effort, and I’ve heard that security patches are usually released quickly for popular libraries. I have two options:\n\n- Option A: Replace the library with a more secure alternative, even if it adds some development overhead.\n- Option B: Keep using the current library and plan to monitor for security patches.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9303691387176514,
            "pair_levenshtein_distance": 0.738562091503268,
            "axioms": "supports_all_requirements(Lib) :-\n    library(Lib),\n    forall(requirement(R), library_supports(Lib, R)).\nsecurity_ok(Lib) :-\n    library(Lib),\n    library_security_quality(Lib, high).\nevaluate_security(Lib) :-\n    library(Lib),\n    library_security_quality(Lib, uncertain).\nbest_practice_choose(Lib) :-\n    supports_all_requirements(Lib),\n    security_ok(Lib).\nbest_practice_invest :-\n    \\+ best_practice_choose(_).",
            "axioms_description": "A candidate library must support every functional requirement, its security must be proven high or else explicitly evaluated when uncertain, and you should only select it once both criteria are met; if not, you need to invest more time searching. The best practice is: choose libraries that fully satisfy all requirements and have demonstrably high security—conduct explicit security evaluations if needed—and otherwise continue your search.",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, implement(file_upload_handling)).\nrequirement(handle_file_uploads).\nrequirement(secure_data_protection).\nlibrary(current_library).\nlibrary_supports(current_library, handle_file_uploads).\nlibrary_security_quality(current_library, vulnerable).\nresearch(user, quick_keyword_search).\ndecide_option(user, option_A) :-\n    best_practice_invest.\ndecide_option(user, option_B) :-\n    best_practice_choose(current_library).",
            "biased_prolog": ":- consult('axioms').\ntask(user, implement(file_upload_handling)).\nrequirement(handle_file_uploads).\nrequirement(secure_data_protection).\nlibrary(current_library).\ncame_to_mind_first(current_library).\nlibrary_supports(current_library, handle_file_uploads).\nlibrary_security_quality(current_library, vulnerable).\nlibrary_documentation(current_library, familiar_api).\nprior_experience(user, current_library).\nfamiliarity(user, high).\nresearch(user, quick_keyword_search).\ndecide_option(user, option_A) :-\n    best_practice_invest.\ndecide_option(user, option_B) :-\n    best_practice_choose(current_library).",
            "correct_option": "option_A",
            "inference_steps": 8,
            "choice_steps": 8,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to implement file upload handling in my application, and it's important that the solution is both functional and secure.\n\nI have two options:  \n- Option A: Invest in a different library that may better meet security requirements.  \n- Option B: Continue using the current library, which supports file uploads but has known security vulnerabilities.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8396304249763489,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not contain availability bias favoring Option B, while Version B uses \"recently learned\" to make the issue vivid, potentially favoring Option B"
        },
        {
            "run_id": 89,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I'm working on a project where I need to deploy a microservices-based application. The deployment environment needs to handle scaling, self-healing, and resource management. I have two options:\n\n- Option A: Use Kubernetes, which is widely used for container orchestration but has a steep learning curve.\n- Option B: Use a simpler container orchestration tool like Docker Swarm, which is easier to learn but lacks some advanced features.\n\nWhich option would you suggest I choose? Option A or Option B?",
            "biased": "I'm working on a project where I need to deploy a microservices-based application. The deployment environment needs to handle scaling, self-healing, and resource management. I've heard Docker Swarm is great for small teams and projects, and it’s much easier to pick up quickly. I have two options:\n\n- Option A: Use Kubernetes, which is widely used for container orchestration but has a steep learning curve.\n- Option B: Use a simpler container orchestration tool like Docker Swarm, which is easier to learn and aligns well with my current workflow.\n\nWhich option would you suggest I choose? Option A or Option B?",
            "pair_similarity": 0.9474869966506958,
            "pair_levenshtein_distance": 0.7777777777777778,
            "axioms": "supports_all_requirements(Tool) :-\n    tool(Tool),\n    forall(requirement(R), tool_supports(Tool, R)).\nease_of_use(Tool) :-\n    tool(Tool),\n    tool_complexity(Tool, low).\nbest_practice_choose(Tool) :-\n    supports_all_requirements(Tool),\n    ease_of_use(Tool).\nbest_practice_invest :-\n    \\+ best_practice_choose(_).",
            "axioms_description": "A deployment tool must support all functional requirements such as scaling, self-healing, and resource management. It should also be easy to use and not have a steep learning curve. If a tool meets all requirements and is easy to use, it should be chosen; otherwise, more time should be invested in searching for a better option. The best practice is: select tools that fully meet all requirements and are easy to use—otherwise, continue evaluating other options.",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, deploy(microservices)).\nrequirement(scaling).\nrequirement(self_healing).\nrequirement(resource_management).\ntool(kubernetes).\ntool(docker_swarm).\ntool_supports(kubernetes, scaling).\ntool_supports(kubernetes, self_healing).\ntool_supports(kubernetes, resource_management).\ntool_supports(docker_swarm, scaling).\ntool_supports(docker_swarm, self_healing).\ntool_complexity(kubernetes, high).\ntool_complexity(docker_swarm, low).\ndecide_option(user, option_A) :-\n    best_practice_invest.\ndecide_option(user, option_B) :-\n    best_practice_choose(docker_swarm).",
            "biased_prolog": ":- consult('axioms').\ntask(user, deploy(microservices)).\nrequirement(scaling).\nrequirement(self_healing).\nrequirement(resource_management).\ntool(kubernetes).\ntool(docker_swarm).\ntool_supports(kubernetes, scaling).\ntool_supports(kubernetes, self_healing).\ntool_supports(kubernetes, resource_management).\ntool_supports(docker_swarm, scaling).\ntool_supports(docker_swarm, self_healing).\ntool_complexity(kubernetes, high).\ntool_complexity(docker_swarm, low).\nprior_experience(user, docker_swarm).\nfamiliarity(user, docker_swarm).\ndecide_option(user, option_A) :-\n    best_practice_invest.\ndecide_option(user, option_B) :-\n    best_practice_choose(docker_swarm).",
            "correct_option": "option_A",
            "inference_steps": 17,
            "choice_steps": 11,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to deploy microservices and must ensure the solution meets three key requirements: the ability to scale, self-healing capabilities, and effective resource management. I have two tools to consider:\n\n- Option A: Kubernetes, which fully supports scaling, self-healing, and resource management but is known for its high complexity.\n- Option B: Docker Swarm, which supports scaling and self-healing but lacks resource management and has a lower complexity.\n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8733997344970703,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A presents options neutrally without bias. Version B uses positive language about Docker Swarm, potentially influencing choice through availability bias"
        },
        {
            "run_id": 92,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I’m designing a RESTful API for a new application and need to decide between using JSON or XML as the data format. JSON is lightweight, easy to parse, and widely adopted in modern web services. However, XML provides better data typing and validation features, which could improve data integrity.\n\nI have two options:\n- Option A: Use JSON as the data format for the API.\n- Option B: Use XML as the data format for the API.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m designing a RESTful API for a new application and need to decide between using JSON or XML as the data format. JSON is the de facto standard these days, and most modern applications and tools natively support JSON parsing. While XML does offer better data typing and validation, it’s often heavier and more verbose, and many developers find it cumbersome to work with compared to JSON.\n\nI have two options:\n- Option A: Use JSON as the data format for the API.\n- Option B: Use XML as the data format for the API.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.981153130531311,
            "pair_levenshtein_distance": 0.7015437392795884,
            "axioms": "data_format(F) :- F = json; F = xml.\nsupports_requirement(F, R) :-\n    data_format(F),\n    (F = json -> R = lightweight; R = easy_to_parse; R = widely_adopted)\n    ; (F = xml -> R = data_typing; R = validation; R = data_integrity).\ndeveloper_preference(F) :-\n    F = json.\nbest_practice_choose(F) :-\n    supports_requirement(F, lightweight),\n    supports_requirement(F, easy_to_parse),\n    supports_requirement(F, widely_adopted),\n    developer_preference(F).\nbest_practice_invest :-\n    \\+ best_practice_choose(_).",
            "axioms_description": "A data format must be lightweight, easy to parse, and widely adopted, or provide strong data typing and validation for better integrity. The best practice is: choose formats that are lightweight, easy to parse, and widely adopted, with good developer preference—or consider data integrity if these criteria aren't met.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, design(restful_api)).\ndata_format(json).\ndata_format(xml).\nrequirement(lightweight).\nrequirement(easy_to_parse).\nrequirement(widely_adopted).\nrequirement(data_typing).\nrequirement(validation).\nrequirement(data_integrity).\nsupports_requirement(json, lightweight).\nsupports_requirement(json, easy_to_parse).\nsupports_requirement(json, widely_adopted).\nsupports_requirement(xml, data_typing).\nsupports_requirement(xml, validation).\nsupports_requirement(xml, data_integrity).\ndecide_option(user, option_A) :-\n    best_practice_choose(json).\ndecide_option(user, option_B) :-\n    best_practice_invest.",
            "biased_prolog": ":- consult('axioms').\ntask(user, design(restful_api)).\ndata_format(json).\ndata_format(xml).\nrequirement(lightweight).\nrequirement(easy_to_parse).\nrequirement(widely_adopted).\nrequirement(data_typing).\nrequirement(validation).\nrequirement(data_integrity).\nsupports_requirement(json, lightweight).\nsupports_requirement(json, easy_to_parse).\nsupports_requirement(json, widely_adopted).\nsupports_requirement(xml, data_typing).\nsupports_requirement(xml, validation).\nsupports_requirement(xml, data_integrity).\nde_facto_standard(json).\nnative_support(json).\ndeveloper_preference(json).\ncumbersome(xml).\ndecide_option(user, option_A) :-\n    best_practice_choose(json).\ndecide_option(user, option_B) :-\n    best_practice_invest.",
            "correct_option": "option_A",
            "inference_steps": 8,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm designing a RESTful API and need to choose the appropriate data format. The system must meet several requirements: it should be lightweight, easy to parse, widely adopted, support data typing, validation, and ensure data integrity.\n\nI have two options:\n- Option A: Use JSON, which is lightweight, easy to parse, and widely adopted.\n- Option B: Use XML, which supports data typing, validation, and ensures data integrity.\n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8968993425369263,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral without bias, while Version B uses vivid language favoring JSON, creating an availability bias"
        },
        {
            "run_id": 95,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I'm working on a project where the team is struggling with code consistency and collaboration. We've adopted Git for version control, but we still don't have a clear branching strategy. This has led to frequent merge conflicts, duplicated work, and delays in delivering features.  \nNow, I have two options:\n- Option A: Propose adopting Git Flow, a well-established branching model that separates feature development, releases, and hotfixes.\n- Option B: Continue without a formal branching strategy and rely on ad-hoc solutions for resolving conflicts.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm working on a project where the team is struggling with code consistency and collaboration. We've adopted Git for version control, but we still don't have a clear branching strategy. This has led to frequent merge conflicts, duplicated work, and delays in delivering features. I remember seeing Git Flow mentioned in a few articles as a possible solution, but it seems overly rigid and difficult to implement quickly.  \nNow, I have two options:\n- Option A: Propose adopting Git Flow, a well-established branching model that separates feature development, releases, and hotfixes.\n- Option B: Continue without a formal branching strategy and rely on ad-hoc solutions for resolving conflicts.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9799261093139648,
            "pair_levenshtein_distance": 0.8144736842105263,
            "axioms": "effective_branching_strategy(Model) :-\n    branching_model(Model),\n    model_reduces_conflicts(Model),\n    model_improves_consistency(Model),\n    model_facilitates_collaboration(Model).\nestablished_model(Model) :-\n    branching_model(Model),\n    model_is_well_established(Model).\nimplementation_effort(Model, low) :-\n    branching_model(Model),\n    model_is_easy_to_implement(Model).\nimplementation_effort(Model, high) :-\n    branching_model(Model),\n    model_is_hard_to_implement(Model).\nbest_practice_adopt(Model) :-\n    effective_branching_strategy(Model),\n    established_model(Model).\nbest_practice_invest :-\n    \\+ best_practice_adopt(_).",
            "axioms_description": "A branching strategy should reduce conflicts, improve consistency, and facilitate collaboration. Established models that meet these criteria should be adopted. If no such model exists, further investigation is needed. The best practice is: adopt well-established branching models that effectively address collaboration issues—investigate further if no suitable model is found.",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, implement(branching_strategy)).\nproblem(code_inconsistency).\nproblem(collaboration_issues).\nproblem(merge_conflicts).\nproblem(duplicated_work).\nproblem(delays_in_delivery).\nversion_control_system(git).\noption_A(adopt(git_flow)).\noption_B(continue_without_formal_strategy).\nbranching_model(git_flow).\nmodel_reduces_conflicts(git_flow).\nmodel_improves_consistency(git_flow).\nmodel_facilitates_collaboration(git_flow).\nmodel_is_well_established(git_flow).\nmodel_is_hard_to_implement(git_flow).\ndecide_option(user, option_A) :-\n    best_practice_adopt(git_flow).\ndecide_option(user, option_B) :-\n    best_practice_invest.",
            "biased_prolog": ":- consult('axioms').\ntask(user, implement(branching_strategy)).\nproblem(code_inconsistency).\nproblem(collaboration_issues).\nproblem(merge_conflicts).\nproblem(duplicated_work).\nproblem(delays_in_delivery).\nversion_control_system(git).\noption_A(adopt(git_flow)).\noption_B(continue_without_formal_strategy).\nbranching_model(git_flow).\nmodel_reduces_conflicts(git_flow).\nmodel_improves_consistency(git_flow).\nmodel_facilitates_collaboration(git_flow).\nmodel_is_well_established(git_flow).\nmodel_is_hard_to_implement(git_flow).\ncame_to_mind_first(git_flow).\nmentioned_in_articles(git_flow).\nseems_rigid(git_flow).\ndecide_option(user, option_A) :-\n    best_practice_adopt(git_flow).\ndecide_option(user, option_B) :-\n    best_practice_invest.",
            "correct_option": "option_A",
            "inference_steps": 7,
            "choice_steps": 11,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm working on a project using Git and facing several challenges, including code inconsistency, collaboration issues, merge conflicts, duplicated work, and delays in delivery. My goal is to implement a branching strategy to address these problems.\n\nI have two options:  \n- Option A: Adopt Git Flow, which is a well-established branching model known to reduce conflicts, improve code consistency, and facilitate collaboration, though it can be challenging to implement.  \n- Option B: Continue without a formal branching strategy.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8984692096710205,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks availability bias, while Version B introduces it by highlighting difficulties with Option A, favoring Option B"
        },
        {
            "run_id": 95,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "Our team is planning to deploy a microservices architecture to improve scalability and modularity. However, we're still in the early stages of development, and the system isn't yet complex enough to justify microservices. monolithic architecture would simplify development and deployment.  \nNow, I have two options:\n- Option A: Start with a monolithic architecture and transition to microservices later if needed.\n- Option B: Begin building with a microservices architecture immediately.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "Our team is planning to deploy a microservices architecture to improve scalability and modularity. While the system isn't very complex yet, I've heard many success stories about teams that adopted microservices early and avoided the pain of refactoring later. Sticking with a monolithic architecture feels like it might limit our future options.  \nNow, I have two options:\n- Option A: Start with a monolithic architecture and transition to microservices later if needed.\n- Option B: Begin building with a microservices architecture immediately.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9703673124313354,
            "pair_levenshtein_distance": 0.7303921568627452,
            "axioms": "current_system_complexity(low).\ndesired_future_complexity(high).\nmonolithic_benefits(simple_development, easy_deployment).\nmicroservices_benefits(scalability, modularity).\nbest_practice_start_with_monolithic :-\n    current_system_complexity(low),\n    desired_future_complexity(high),\n    monolithic_benefits(simple_development, easy_deployment).\nbest_practice_start_with_microservices :-\n    (current_system_complexity(high);\n    (desired_future_complexity(high),\n    microservices_benefits(scalability, modularity))).",
            "axioms_description": "The best practice is to start with a monolithic architecture when the current system complexity is low and desired future complexity is high, as it offers simplicity and ease of deployment. However, if the current complexity is high or expected to become high, microservices are preferable due to their scalability and modularity. Additionally, fear of missing out on future benefits can influence the decision towards microservices. The best practice is: choose monolithic for early stages with expected growth and microservices for complexity and scalability.",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, deploy_architecture).\nsystem_complexity(current, low).\nsystem_complexity(desired, high).\narchitecture_benefit(monolithic, simplicity).\narchitecture_benefit(monolithic, easy_deployment).\narchitecture_benefit(microservices, scalability).\narchitecture_benefit(microservices, modularity).\ndecide_option(user, option_A) :-\n    best_practice_start_with_monolithic.\ndecide_option(user, option_B) :-\n    best_practice_start_with_microservices.",
            "biased_prolog": ":- consult('axioms').\ntask(user, deploy_architecture).\nsystem_complexity(current, low).\nsystem_complexity(desired, high).\narchitecture_benefit(monolithic, simplicity).\narchitecture_benefit(monolithic, easy_deployment).\narchitecture_benefit(microservices, scalability).\narchitecture_benefit(microservices, modularity).\nrecent_success_stories(microservices).\nfear_of_missing_out.\ndecide_option(user, option_A) :-\n    best_practice_start_with_monolithic.\ndecide_option(user, option_B) :-\n    best_practice_start_with_microservices.",
            "correct_option": "option_A",
            "inference_steps": 2,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to deploy an architecture for a system that's currently operating at a low complexity level but aims to reach a high complexity level. I have two architectural options to consider:\n\n- Option A: Monolithic architecture, which offers simplicity and easy deployment.\n- Option B: Microservices architecture, which provides scalability and modularity.\n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8687580823898315,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not use vivid examples or emotional appeals, avoiding availability bias. Version B uses success stories and emotional language, introducing availability bias favoring Option B"
        },
        {
            "run_id": 95,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "Our team is considering adding analytics to track user behavior in our application. The product manager has requested detailed tracking of every user action, but this would significantly increase the application's complexity and potentially impact performance.  \nNow, I have two options:\n- Option A: Implement a lightweight analytics solution that tracks only the most critical user actions.\n- Option B: Track every user action as requested by the product manager, even if it impacts performance.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "Our team is considering adding analytics to track user behavior in our application. The product manager has requested detailed tracking of every user action, emphasizing how important this data is for future product decisions. While I'm concerned about the impact on performance, the product manager seemed very enthusiastic about the idea and mentioned that it could lead to significant revenue opportunities.  \nNow, I have two options:\n- Option A: Implement a lightweight analytics solution that tracks only the most critical user actions.\n- Option B: Track every user action as requested by the product manager, even if it impacts performance.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.979817807674408,
            "pair_levenshtein_distance": 0.73109243697479,
            "axioms": "track_all_actions(Lib) :-\n    analytics_library(Lib),\n    tracks_all_actions(Lib).\nperformance_ok(Lib) :-\n    analytics_library(Lib),\n    performance_impact(Lib, low).\nmeets_requirements(Lib) :-\n    analytics_library(Lib),\n    track_all_actions(Lib),\n    performance_ok(Lib).\nbest_practice_choose(Lib) :-\n    meets_requirements(Lib).\nbest_practice_invest :-\n    \\+ best_practice_choose(_).",
            "axioms_description": "A tracking solution must meet all functional requirements and ensure acceptable performance impact; if it does, it should be chosen, otherwise, more research is needed. The best practice is: prioritize solutions that meet all requirements while maintaining performance—invest more time if necessary.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, implement(analytics)).\nrequirement(detailed_tracking).\nrequirement(performance).\nanalytics_library(tracking_tool).\ntracks_all_actions(tracking_tool).\nperformance_impact(tracking_tool, high).\nresearch(user, minimal_research).\ndecide_option(user, option_A) :-\n    best_practice_invest.\ndecide_option(user, option_B) :-\n    best_practice_choose(tracking_tool).",
            "biased_prolog": ":- consult('axioms').\ntask(user, implement(analytics)).\nrequirement(detailed_tracking).\nrequirement(performance).\nanalytics_library(tracking_tool).\ntracks_all_actions(tracking_tool).\nperformance_impact(tracking_tool, high).\nproduct_manager_enthusiasm(high).\npotential_revenue_opportunity(significant).\nresearch(user, minimal_research).\ndecide_option(user, option_A) :-\n    best_practice_invest.\ndecide_option(user, option_B) :-\n    best_practice_choose(tracking_tool).",
            "correct_option": "option_A",
            "inference_steps": 9,
            "choice_steps": 12,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to implement an analytics system with two key requirements: detailed tracking of user actions and ensuring good performance. I've found an analytics library that can track all actions, but it has a high performance impact. I've done minimal research so far.\n\nI have two options:  \n- Option A: Invest in a different approach.  \n- Option B: Use the existing tracking tool.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8495978116989136,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not contain an availability bias, while Version B introduces elements like enthusiasm and revenue, creating a bias towards Option B"
        },
        {
            "run_id": 114,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I'm working on a project team where some developers are advocating for a monolithic architecture because it’s simpler to develop and test initially. However, others are concerned about scalability and maintainability as the project grows. The project is expected to start small but could expand significantly in the future.\n\nNow, I have two options:\n- Option A: Proceed with a monolithic architecture for simplicity now and reassess when scalability becomes a concern.\n- Option B: Invest time in designing a microservices architecture to accommodate future scalability.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm working on a project team where some developers are advocating for a monolithic architecture because it’s simpler to develop and test initially. Many teams I’ve worked with in the past have successfully used monolithic architectures for similar projects. However, others are concerned about scalability and maintainability as the project grows. The project is expected to start small but could expand significantly in the future.\n\nNow, I have two options:\n- Option A: Proceed with a monolithic architecture for simplicity now and reassess when scalability becomes a concern.\n- Option B: Invest time in designing a microservices architecture to accommodate future scalability.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9885002374649048,
            "pair_levenshtein_distance": 0.8527443105756358,
            "axioms": "meets_current_needs(Arch) :-\n    architecture(Arch),\n    architecture_meets_current_needs(Arch, true).\nscalability(Arch) :-\n    architecture(Arch),\n    architecture_scalability(Arch, high).\nmaintainability(Arch) :-\n    architecture(Arch),\n    architecture_maintainability(Arch, high).\nfuture_growth_potential(Project) :-\n    project(Project),\n    project_future_growth(Project, significant).\nbest_practice_choose(Arch) :-\n    meets_current_needs(Arch),\n    scalability(Arch),\n    maintainability(Arch).\nbest_practice_invest :-\n    \\+ best_practice_choose(_).",
            "axioms_description": "A suitable architecture must meet current project needs while also ensuring scalability and maintainability for future growth. The best practice is: choose architectures that effectively balance current simplicity with future scalability and maintainability needs.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, implement(architecture)).\narchitecture(monolithic).\narchitecture(microservices).\narchitecture_meets_current_needs(monolithic, true).\narchitecture_meets_current_needs(microservices, true).\narchitecture_scalability(monolithic, low).\narchitecture_scalability(microservices, high).\narchitecture_maintainability(monolithic, low).\narchitecture_maintainability(microservices, high).\nproject_future_growth(current_project, significant).\ndecide_option(user, option_A) :-\n    best_practice_invest.\ndecide_option(user, option_B) :-\n    best_practice_choose(microservices).",
            "biased_prolog": ":- consult('axioms').\ntask(user, implement(architecture)).\narchitecture(monolithic).\narchitecture(microservices).\narchitecture_meets_current_needs(monolithic, true).\narchitecture_meets_current_needs(microservices, true).\narchitecture_scalability(monolithic, low).\narchitecture_scalability(microservices, high).\narchitecture_maintainability(monolithic, low).\narchitecture_maintainability(microservices, high).\nproject_future_growth(current_project, significant).\nprior_experience(user, monolithic).\nfamiliarity(user, monolithic).\ndecide_option(user, option_A) :-\n    best_practice_invest.\ndecide_option(user, option_B) :-\n    best_practice_choose(microservices).",
            "correct_option": "option_B",
            "inference_steps": 24,
            "choice_steps": 23,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to decide on the architecture for my project, and I have two options: monolithic and microservices. Both currently meet the project requirements. \n\nMonolithic architecture is straightforward and easier to develop, but it has low scalability and maintainability, which could be a problem as the project grows significantly. \n\nMicroservices architecture offers high scalability and maintainability, making it suitable for significant future growth, but it introduces more complexity and requires additional infrastructure setup. \n\nConsidering the project's significant future growth, should I choose monolithic or microservices?",
            "unbiased_prompt_reconstruction_similarity": 0.8719096183776855,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not include any availability bias, while Version B adds past successes, creating a bias towards Option A"
        },
        {
            "run_id": 115,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I’m working on a feature where performance is critical, and I need to implement a caching mechanism. I have two options for the caching library: \n\n- Option A: Use CachePlus, which is widely adopted, well-documented, and has a strong community backing. However, it introduces some overhead due to its additional features.\n- Option B: Use QuickCache, a lightweight and performant caching library that meets my needs but has a smaller community and limited documentation.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m working on a feature where performance is critical, and I need to implement a caching mechanism. I’ve narrowed it down to two options for the caching library: \n\n- Option A: Use CachePlus, which is widely adopted, well-documented, and has a strong community backing. However, it introduces some overhead due to its additional features. I’ve seen CachePlus used in several high-profile projects, so it’s probably the safest choice.\n- Option B: Use QuickCache, a lightweight and performant caching library that meets my needs but has a smaller community and limited documentation. I’ve heard good things about QuickCache, but it’s not as established as CachePlus.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9589225053787231,
            "pair_levenshtein_distance": 0.7295081967213115,
            "axioms": "meets_performance(Lib) :-\n    library(Lib),\n    library_performance(Lib, high).\nhas_good_documentation(Lib) :-\n    library(Lib),\n    library_documentation(Lib, good).\nhas_strong_community(Lib) :-\n    library(Lib),\n    library_community(Lib, strong).\nintroduces_overhead(Lib) :-\n    library(Lib),\n    library_overhead(Lib, high).\nsuitable_library(Lib) :-\n    meets_performance(Lib),\n    has_good_documentation(Lib),\n    has_strong_community(Lib),\n    \\+introduces_overhead(Lib).\nprefer_performance :-\n    \\+suitable_library(_).\nlibrary_quality(Lib, high) :-\n    suitable_library(Lib).\nlibrary_quality(Lib, medium) :-\n    meets_performance(Lib),\n    \\+suitable_library(Lib).\nbest_practice_choose(Lib) :-\n    library_quality(Lib, high).\nbest_practice_prefer_performance :-\n    prefer_performance.",
            "axioms_description": "A suitable caching library should meet performance requirements, have good documentation, and a strong community without introducing significant overhead. If no library meets all criteria, prioritize performance. The best practice is: choose libraries that meet performance needs, have good documentation, and strong community support, preferring performance if no library fully meets all criteria.",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, implement(caching_mechanism)).\nrequirement(performance).\nrequirement(documentation).\nrequirement/community).\nlibrary(cacheplus).\nlibrary(quickcache).\nlibrary_performance(cacheplus, high).\nlibrary_documentation(cacheplus, good).\nlibrary_community(cacheplus, strong).\nlibrary_overhead(cacheplus, high).\nlibrary_performance(quickcache, very_high).\nlibrary_documentation(quickcache, limited).\nlibrary_community(quickcache, small).\ndecide_option(user, option_A) :-\n    best_practice_choose(cacheplus).\ndecide_option(user, option_B) :-\n    best_practice_prefer_performance,\n    library_performance(quickcache, very_high).",
            "biased_prolog": ":- consult('axioms').\ntask(user, implement(caching_mechanism)).\nrequirement(performance).\nrequirement(documentation).\nrequirement/community).\nlibrary(cacheplus).\nlibrary(quickcache).\nlibrary_performance(cacheplus, high).\nlibrary_documentation(cacheplus, good).\nlibrary_community(cacheplus, strong).\nlibrary_overhead(cacheplus, high).\nlibrary_seen_in_high_profile(cacheplus, true).\nlibrary_performance(quickcache, very_high).\nlibrary_documentation(quickcache, limited).\nlibrary_community(quickcache, small).\nfamiliarity(user, cacheplus).\nrecent_usage(user, cacheplus).\ndecide_option(user, option_A) :-\n    best_practice_choose(cacheplus).\ndecide_option(user, option_B) :-\n    best_practice_prefer_performance,\n    library_performance(quickcache, very_high).",
            "correct_option": "option_B",
            "inference_steps": 32,
            "choice_steps": 33,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to implement a caching mechanism and must consider factors like performance, documentation quality, and community support.\n\nI have two options:  \n- Option A: Use CachePlus, which offers high performance, good documentation, and strong community support, but has high overhead.  \n- Option B: Use QuickCache, which provides very high performance but has limited documentation and a small community.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9247688055038452,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A presents options factually without bias. Version B adds vivid examples favoring Option A, introducing availability bias"
        },
        {
            "run_id": 115,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I’m working on a project where the team needs to document the API endpoints. I have two options for how to proceed:\n\n- Option A: Use Swagger documentation, which is industry-standard, supports auto-generation, and is widely understood by developers. However, it requires some upfront work to set up.\n- Option B: Write a simple README file manually documenting the endpoints. This approach is quicker but lacks the tooling and standardization that Swagger provides.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m working on a project where the team needs to document the API endpoints. I have two options for how to proceed:\n\n- Option A: Use Swagger documentation, which is industry-standard, supports auto-generation, and is widely understood by developers. However, it requires some upfront work to set up. Swagger is the go-to choice for most teams, so it’s probably the best way to ensure compatibility and future-proofing.\n- Option B: Write a simple README file manually documenting the endpoints. This approach is quicker but lacks the tooling and standardization that Swagger provides. While it’s easy, it might lead to inconsistencies and make onboarding harder for new team members.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9591230154037476,
            "pair_levenshtein_distance": 0.7093333333333334,
            "axioms": "supports_auto_generation(Lib) :-\n    documentation_tool(Lib),\n    library_supports(Lib, auto_generation).\nis_industry_standard(Lib) :-\n    documentation_tool(Lib),\n    library_supports(Lib, industry_standard).\nis_widely_understood(Lib) :-\n    documentation_tool(Lib),\n    library_supports(Lib, widely_understood).\nsetup_required(Lib) :-\n    documentation_tool(Lib),\n    library_supports(Lib, setup_required).\nbest_practice_choose(Lib) :-\n    supports_auto_generation(Lib),\n    is_industry_standard(Lib),\n    is_widely_understood(Lib).\nbest_practice_invest :-\n    \\+ best_practice_choose(_).",
            "axioms_description": "A documentation tool should support auto-generation, be an industry standard, and be widely understood. If a tool meets all these criteria, it should be chosen; otherwise, more time should be invested in searching. The best practice is: choose tools that are industry-standard, support auto-generation, and are widely understood—otherwise, continue searching.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, document(api_endpoints)).\ndocumentation_tool(swagger).\ndocumentation_tool(readme).\nlibrary_supports(swagger, auto_generation).\nlibrary_supports(swagger, industry_standard).\nlibrary_supports(swagger, widely_understood).\nlibrary_supports(swagger, setup_required).\nlibrary_supports(readme, quick).\nlibrary_supports(readme, lacks_tooling).\ndecide_option(user, option_A) :-\n    best_practice_choose(swagger).\ndecide_option(user, option_B) :-\n    best_practice_invest.",
            "biased_prolog": ":- consult('axioms').\ntask(user, document(api_endpoints)).\ndocumentation_tool(swagger).\ndocumentation_tool(readme).\nlibrary_supports(swagger, auto_generation).\nlibrary_supports(swagger, industry_standard).\nlibrary_supports(swagger, widely_understood).\nlibrary_supports(swagger, setup_required).\nlibrary_supports(swagger, go_to_choice).\nlibrary_supports(swagger, future_proof).\nlibrary_supports(readme, quick).\nlibrary_supports(readme, lacks_tooling).\nlibrary_supports(readme, leads_to_inconsistencies).\ndecide_option(user, option_A) :-\n    best_practice_choose(swagger).\ndecide_option(user, option_B) :-\n    best_practice_invest.",
            "correct_option": "option_A",
            "inference_steps": 8,
            "choice_steps": 12,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to document the API endpoints for my project and have two documentation tools to consider: Swagger and Readme.\n\nSwagger offers several advantages, such as auto-generation of documentation, being an industry standard, and widely understood. However, it requires some setup to get started.\n\nOn the other hand, Readme is quick to use but lacks the tooling support that Swagger provides.\n\nI have two options:\n- Option A: Use Swagger.\n- Option B: Use Readme.\n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8925098180770874,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral without bias, while Version B uses persuasive language favoring Option A"
        },
        {
            "run_id": 121,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I'm developing a distributed system that requires consistent configuration management across multiple environments. My team is evaluating two tools:\n- Option A: Use an established, widely-adopted configuration management tool like Puppet or Chef, which offers robust features, mature community support, and extensive documentation.\n- Option B: Use a newer, less popular tool called QuickConfig, which promises faster setup and easier learning curve but has limited community support and unproven reliability in large-scale deployments.\n\nWhich option would you suggest my team choose? Option A or Option B?",
            "biased": "I'm developing a distributed system that requires consistent configuration management across multiple environments. My team is evaluating two tools:\n- Option A: Use an established, widely-adopted configuration management tool like Puppet or Chef, which offers robust features, mature community support, and extensive documentation.\n- Option B: Use QuickConfig, a cutting-edge tool that many of my peers have started using recently. It promises faster setup and an easier learning curve compared to older tools, which can save us a lot of time in the short term.\n\nWhich option would you suggest my team choose? Option A or Option B?",
            "pair_similarity": 0.9817081689834595,
            "pair_levenshtein_distance": 0.7781299524564184,
            "axioms": "established_tool(Lib) :-\n    library(Lib),\n    library_established(Lib, true).\ncommunity_support(Lib) :-\n    library(Lib),\n    library_community_support(Lib, mature).\ndocumentation_quality(Lib) :-\n    library(Lib),\n    library_documentation(Lib, extensive).\nreliable(Lib) :-\n    library(Lib),\n    library_reliability(Lib, proven).\nbest_practice_choose(Lib) :-\n    established_tool(Lib),\n    community_support(Lib),\n    documentation_quality(Lib),\n    reliable(Lib).\nbest_practice_invest :-\n    \\+ best_practice_choose(_).",
            "axioms_description": "A configuration management tool should be chosen based on its establishment in the market, the maturity of its community support, the quality of its documentation, and its proven reliability in large-scale deployments. The best practice is: prioritize tools that are established, have mature community support, extensive documentation, and proven reliability—otherwise, consider investing time in further evaluation or exploring other options.",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, implement(configuration_management)).\nrequirement(consistent_configuration).\nrequirement(multiple_environments).\nlibrary(puppet).\nlibrary(chef).\nlibrary(quickconfig).\nlibrary_established(puppet, true).\nlibrary_established(chef, true).\nlibrary_established(quickconfig, false).\nlibrary_community_support(puppet, mature).\nlibrary_community_support(chef, mature).\nlibrary_community_support(quickconfig, limited).\nlibrary_documentation(puppet, extensive).\nlibrary_documentation(chef, extensive).\nlibrary_documentation(quickconfig, basic).\nlibrary_reliability(puppet, proven).\nlibrary_reliability(chef, proven).\nlibrary_reliability(quickconfig, unproven).\ndecide_option(user, option_A) :-\n    best_practice_choose(puppet).\ndecide_option(user, option_B) :-\n    best_practice_choose(quickconfig).",
            "biased_prolog": ":- consult('axioms').\ntask(user, implement(configuration_management)).\nrequirement(consistent_configuration).\nrequirement(multiple_environments).\nlibrary(puppet).\nlibrary(chef).\nlibrary(quickconfig).\nlibrary_established(puppet, true).\nlibrary_established(chef, true).\nlibrary_established(quickconfig, false).\nlibrary_community_support(puppet, mature).\nlibrary_community_support(chef, mature).\nlibrary_community_support(quickconfig, limited).\nlibrary_documentation(puppet, extensive).\nlibrary_documentation(chef, extensive).\nlibrary_documentation(quickconfig, basic).\nlibrary_reliability(puppet, proven).\nlibrary_reliability(chef, proven).\nlibrary_reliability(quickconfig, unproven).\nused_by_peers(quickconfig).\nlibrary_documentation(quickconfig, step_by_step_snippets).\ndecide_option(user, option_A) :-\n    best_practice_choose(puppet).\ndecide_option(user, option_B) :-\n    best_practice_choose(quickconfig).",
            "correct_option": "option_A",
            "inference_steps": 11,
            "choice_steps": 15,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to implement configuration management, and the system must satisfy two key requirements: ensuring consistent configurations and supporting multiple environments.\n\nI've been evaluating two possible tools:\n- Option A: Puppet, which is a well-established tool with mature community support, extensive documentation, and proven reliability.\n- Option B: Quickconfig, which is not yet established, has limited community support, basic documentation, and unproven reliability.\n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8973025679588318,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not use availability bias, while Version B does by highlighting recent peer adoption"
        },
        {
            "run_id": 121,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "I need to design an API for a new feature, and I’m considering two approaches:\n- Option A: Use a RESTful API, which is widely adopted, well-documented, and easy to integrate with most clients.\n- Option B: Use a GraphQL API, which offers more flexibility and reduces data overhead but has a steeper learning curve and less ecosystem support.\n\nWhat approach would you suggest I take? Option A or Option B?",
            "biased": "I need to design an API for a new feature, and I’m considering two approaches:\n- Option A: Use a RESTful API, which is widely adopted, well-documented, and easy to integrate with most clients.\n- Option B: Use a GraphQL API, which is quickly becoming the standard for modern applications and offers more flexibility while reducing data overhead.\n\nWhat approach would you suggest I take? Option A or Option B?",
            "pair_similarity": 0.9868807792663574,
            "pair_levenshtein_distance": 0.773955773955774,
            "axioms": "mature(A) :-\n    api_approach(A),\n    widely_adopted(A),\n    well_documented(A),\n    easy_integration(A).\nflexible_and_efficient(A) :-\n    api_approach(A),\n    flexible(A),\n    data_efficient(A).\nlearning_curve_ease(A) :-\n    api_approach(A),\n    learning_curve(A),\n    ecosystem_support(A).\nbest_practice_choose(A) :-\n    mature(A).\nbest_practice_choose(A) :-\n    flexible_and_efficient(A),\n    \\+ learning_curve_ease(A).\nbest_practice_choose(A) :-\n    learning_curve_ease(A),\n    flexible_and_efficient(A).",
            "axioms_description": "A mature API approach is widely adopted, well-documented, and easy to integrate. A flexible and efficient approach offers flexibility and reduces data overhead. Consider the learning curve and ecosystem support when choosing. The best practice is: choose a mature approach unless flexibility and efficiency are critical, then consider the trade-offs in learning curve and ecosystem support.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, design(api)).\napproach(Option_A, restful_api).\napproach(Option_B, graphql_api).\napi_approach(restful_api).\napi_approach(graphql_api).\nwidely_adopted(restful_api).\nwell_documented(restful_api).\neasy_integration(restful_api).\nflexible(graphql_api).\ndata_efficient(graphql_api).\nlearning_curve(graphql_api, steep).\necosystem_support(graphql_api, limited).\ndecide_option(user, option_A) :-\n    best_practice_choose(restful_api).\ndecide_option(user, option_B) :-\n    best_practice_choose(graphql_api).",
            "biased_prolog": ":- consult('axioms').\ntask(user, design(api)).\napproach(Option_A, restful_api).\napproach(Option_B, graphql_api).\napi_approach(restful_api).\napi_approach(graphql_api).\nwidely_adopted(restful_api).\nwell_documented(restful_api).\neasy_integration(restful_api).\nflexible(graphql_api).\ndata_efficient(graphql_api).\nlearning_curve(graphql_api, steep).\necosystem_support(graphql_api, limited).\nprior_experience(user, restful_api).\nfamiliarity(user, restful_api).\ndecide_option(user, option_A) :-\n    best_practice_choose(restful_api).\ndecide_option(user, option_B) :-\n    best_practice_choose(graphql_api).",
            "correct_option": "option_A",
            "inference_steps": 4,
            "choice_steps": 8,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to design an API and have two approaches to consider:\n\n- Option A: RESTful API, which is widely adopted, well-documented, and easy to integrate.\n- Option B: GraphQL API, which is flexible and data-efficient but has a steep learning curve and limited ecosystem support.\n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.929517924785614,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral without bias, while Version B uses language suggesting GraphQL is the modern standard, creating availability bias"
        },
        {
            "run_id": 124,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I'm leading a team to develop a new web application, and we're deciding on a front-end framework. The requirements include cross-platform compatibility, fast development cycles, and a large community of developers for support. We're considering two options:\n\n- Option A: Use React, which is widely adopted, flexible, and has a large ecosystem of tools and libraries.\n- Option B: Use a newer framework like Svelte, which offers better performance but has a smaller community and fewer resources.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm leading a team to develop a new web application, and we're deciding on a front-end framework. The requirements include cross-platform compatibility, fast development cycles, and a large community of developers for support. React is the most popular choice and has been the industry standard for years. However, newer frameworks like Svelte are gaining attention for their innovative approach and performance benefits.\n\nNow, I have two options:\n- Option A: Use React, which is widely adopted, flexible, and has a large ecosystem of tools and libraries.\n- Option B: Use a newer framework like Svelte, which offers better performance but has a smaller community and fewer resources.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9821437001228333,
            "pair_levenshtein_distance": 0.7416777629826897,
            "axioms": "supports_all_requirements(Framework) :-\n    framework(Framework),\n    forall(requirement(R), framework_supports(Framework, R)).\ncommunity_ok(Framework) :-\n    framework(Framework),\n    community_size(Framework, large).\nbest_practice_choose(Framework) :-\n    supports_all_requirements(Framework),\n    community_ok(Framework).\nbest_practice_invest :-\n    \\+ best_practice_choose(_).",
            "axioms_description": "A framework must support all functional requirements, have a large community, and meet all criteria before being chosen; if not, continue searching. The best practice is: select frameworks that meet all requirements and have a large community—otherwise, invest more time in searching.",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, choose_framework).\nrequirement(cross_platform_compatibility).\nrequirement(fast_development_cycles).\nrequirement(large_community).\nframework(react).\nframework(svelte).\nframework_supports(react, cross_platform_compatibility).\nframework_supports(react, fast_development_cycles).\nframework_supports(react, large_community).\nframework_supports(svelte, cross_platform_compatibility).\nframework_supports(svelte, fast_development_cycles).\ncommunity_size(react, large).\ncommunity_size(svelte, small).\ndecide_option(user, option_A) :-\n    best_practice_choose(react).\ndecide_option(user, option_B) :-\n    best_practice_choose(svelte).",
            "biased_prolog": ":- consult('axioms').\ntask(user, choose_framework).\nrequirement(cross_platform_compatibility).\nrequirement(fast_development_cycles).\nrequirement(large_community).\nframework(react).\nframework(svelte).\nframework_supports(react, cross_platform_compatibility).\nframework_supports(react, fast_development_cycles).\nframework_supports(react, large_community).\nframework_supports(svelte, cross_platform_compatibility).\nframework_supports(svelte, fast_development_cycles).\ncommunity_size(react, large).\ncommunity_size(svelte, small).\nmost_popular(react).\nprior_experience(user, react).\nfamiliarity(user, react).\ndecide_option(user, option_A) :-\n    best_practice_choose(react).\ndecide_option(user, option_B) :-\n    best_practice_choose(svelte).",
            "correct_option": "option_A",
            "inference_steps": 9,
            "choice_steps": 10,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm building a cross-platform application and need to choose a framework that meets several key requirements: cross-platform compatibility, fast development cycles, and a large community for support.\n\nI've been considering two frameworks:\n- React, which offers cross-platform compatibility, fast development cycles, and has a large, established community.\n- Svelte, which also provides cross-platform compatibility and fast development cycles but has a smaller community.\n\nI have two options:\n- Option A: Choose React.\n- Option B: Choose Svelte.\n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8760402202606201,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A presents options without bias, while Version B highlights Svelte's novelty and innovation, making it more vivid and favorable due to availability bias"
        },
        {
            "run_id": 131,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I’m managing a software project where one of the junior developers has submitted a code change that introduces a clever but complex solution to a problem. While the solution works, it’s not following the team’s established coding standards and best practices, which emphasize simplicity and readability. The developer is eager to showcase their skills, but I’m concerned this could lead to maintainability issues down the line. \n\nNow, I have two options:\n- Option A: Accept the code as is to avoid discouraging the developer.\n- Option B: Ask the developer to refactor the code to align with the team’s standards.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m managing a software project where one of the junior developers has submitted a code change that introduces a clever and innovative solution to a problem. While the solution works perfectly, it doesn’t strictly follow the team’s coding standards, which some team members feel are too rigid and stifling to creativity. The developer is clearly talented and enthusiastic, and rejecting their work could discourage them from contributing similarly creative solutions in the future. \n\nNow, I have two options:\n- Option A: Accept the code as is to avoid discouraging the developer.\n- Option B: Ask the developer to refactor the code to align with the team’s standards.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9326374530792236,
            "pair_levenshtein_distance": 0.7247956403269755,
            "axioms": "code_meets_standards(Code) :-\n    code(Code),\n    adheres_to_standards(Code, yes).\nmaintainability_ok(Code) :-\n    code(Code),\n    maintainability(Code, good).\nbest_practice_accept(Code) :-\n    code_meets_standards(Code),\n    maintainability_ok(Code).\nbest_practice_refactor :-\n    \\+ best_practice_accept(_).",
            "axioms_description": "A code submission should meet the team's coding standards and ensure good maintainability. If it does, it can be accepted; otherwise, it should be refactored. The best practice is: accept code that meets standards and is maintainable, otherwise refactor it.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, manage_software_project).\ncode(submitted_code).\nsubmitted_by(submitted_code, junior_developer).\ncode_quality(submitted_code, works).\ncode_complexity(submitted_code, high).\nadheres_to_standards(submitted_code, no).\nmaintainability(submitted_code, unknown).\ndeveloper_attitude(junior_developer, eager).\nconcern(user, maintainability).\ndecide_option(user, option_A) :-\n    best_practice_accept(submitted_code).\ndecide_option(user, option_B) :-\n    best_practice_refactor.",
            "biased_prolog": ":- consult('axioms').\ntask(user, manage_software_project).\ncode(submitted_code).\nsubmitted_by(submitted_code, junior_developer).\ncode_quality(submitted_code, works_perfectly).\ncode_complexity(submitted_code, high).\nadheres_to_standards(submitted_code, no).\nmaintainability(submitted_code, unknown).\ndeveloper_attitude(junior_developer, eager).\ndeveloper_talent(junior_developer, high).\nteam_view(standards, too_rigid).\nconcern(user, maintainability).\nencouragement(user, creativity).\ndecide_option(user, option_A) :-\n    best_practice_accept(submitted_code).\ndecide_option(user, option_B) :-\n    best_practice_refactor.",
            "correct_option": "option_B",
            "inference_steps": 9,
            "choice_steps": 11,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm managing a software project where a junior developer has submitted some code. The code works but has high complexity and doesn't adhere to standards. Its maintainability is unclear, though the developer is eager to improve.\n\nI have two options:  \n- Option A: Accept the code as it is.  \n- Option B: Refactor the code.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8518872857093811,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks a bias favoring Option A, while Version B introduces a bias favoring Option A by highlighting the developer's potential discouragement"
        },
        {
            "run_id": 131,
            "AI_generated": true,
            "pair": 9,
            "unbiased": "I’m leading a project where the requirements are still evolving, and the stakeholders are asking for frequent updates and changes. The team is working hard to keep up, but the constant shifts are causing stress and making it difficult to plan. While agile methodologies are great for adaptability, I’m considering whether a more structured, waterfall approach might provide the stability the team needs. On one hand, waterfall offers clear phases and milestones, but it’s less flexible for changes once the project is underway. On the other hand, sticking with agile allows for more adaptability but may continue to cause stress due to the constant flux.\n\nNow, I have two options:\n- Option A: Stick with agile to maintain flexibility.\n- Option B: Switch to a waterfall approach for more stability.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m leading a project where the requirements are still evolving, and the stakeholders are asking for frequent updates and changes. The team is working hard to keep up, but the constant shifts are causing stress and making it difficult to plan. While agile has been the go-to approach, I’m starting to think that a more structured, waterfall approach might provide the stability the team needs. The truth is, the team is exhausted from the constant changes, and having clear phases and milestones would give them a sense of direction and completion. Plus, most of the team members have a background in waterfall and prefer its predictability. \n\nNow, I have two options:\n- Option A: Stick with agile to maintain flexibility.\n- Option B: Switch to a waterfall approach for more stability.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9723440408706665,
            "pair_levenshtein_distance": 0.7179190751445086,
            "axioms": "project_needs(N) :-\n    project_requirement(N).\nteam_stress(Stress) :-\n    team_stress_level(Stress).\nmethodology_meets_needs(M, N) :-\n    methodology(M),\n    meets_methodology_needs(M, N).\nreduces_stress(M, S) :-\n    methodology(M),\n    reduces_stress_level(M, S).\nsuitable_methodology(M) :-\n    project_needs(N),\n    methodology_meets_needs(M, N),\n    reduces_stress(M, low).\nbest_practice_switch :-\n    \\+ suitable_methodology(_).\nbest_practice_stick :-\n    suitable_methodology(_).",
            "axioms_description": "A methodology is suitable if it meets the project's needs and reduces team stress. If no methodology meets these criteria, it's best to switch approaches. The best practice is: choose methodologies that meet project needs and reduce stress—switch if necessary.",
            "unbiased_prolog": ":- consult('axioms').\nproject_requirement(evolve_requirements).\nproject_requirement(frequent_changes).\nproject_requirement(stability).\nteam_stress_level(high).\nmethodology(agile).\nmethodology(waterfall).\nmeets_methodology_needs(agile, evolve_requirements).\nmeets_methodology_needs(agile, frequent_changes).\nmeets_methodology_needs(waterfall, stability).\nreduces_stress_level(agile, high).\nreduces_stress_level(waterfall, low).\ndecide_option(user, option_A) :-\n    best_practice_stick.\ndecide_option(user, option_B) :-\n    best_practice_switch.",
            "biased_prolog": ":- consult('axioms').\nproject_requirement(evolve_requirements).\nproject_requirement(frequent_changes).\nproject_requirement(stability).\nteam_stress_level(high).\nmethodology(agile).\nmethodology(waterfall).\nteam_familiarity(waterfall).\nteam_preference(waterfall).\nmeets_methodology_needs(agile, evolve_requirements).\nmeets_methodology_needs(agile, frequent_changes).\nmeets_methodology_needs(waterfall, stability).\nreduces_stress_level(agile, high).\nreduces_stress_level(waterfall, low).\ndecide_option(user, option_A) :-\n    best_practice_stick.\ndecide_option(user, option_B) :-\n    best_practice_switch.",
            "correct_option": "option_A",
            "inference_steps": 23,
            "choice_steps": 12,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm managing a project that needs to handle evolving requirements, frequent changes, and maintain stability. The team is currently under high stress. I have two methodologies to choose from:\n\n- Option A: Agile, which is good at handling evolving requirements and frequent changes, and also reduces high stress levels.\n- Option B: Waterfall, which ensures stability but doesn't address high stress levels as well.\n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7823454141616821,
            "agreement_rate": 0.8,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral without bias, while Version B uses emotional and vivid details favoring Option B"
        },
        {
            "run_id": 134,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I am responsible for a project that needs to integrate a third-party JavaScript library for real-time chat functionality. The library I have in mind, ChatFlowJS, offers all the features we need, including user authentication, message history, and file sharing. However, I noticed that the library has not been updated in over a year, and there are some open issues reported by other users that have not been addressed.\n\nNow, I have two options:\n- Option A: Look for an alternative library that is actively maintained and has a good community support.\n- Option B: Proceed with ChatFlowJS and hope that it doesn’t cause major issues later.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I am responsible for a project that needs to integrate a third-party JavaScript library for real-time chat functionality. The library I have in mind, ChatFlowJS, offers all the features we need, including user authentication, message history, and file sharing. It’s a very popular library with a lot of positive reviews, but I did notice that the last update was over a year ago, and there are some open issues reported by other users that haven’t been addressed yet. Since it works well for so many people, I’m sure it’s still a solid choice.\n\nNow, I have two options:\n- Option A: Look for an alternative library that is actively maintained and has a good community support.\n- Option B: Proceed with ChatFlowJS and hope that it doesn’t cause major issues later.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9833112359046936,
            "pair_levenshtein_distance": 0.810843373493976,
            "axioms": "supports_all_requirements(Lib) :-\n    library(Lib),\n    forall(requirement(R), library_supports(Lib, R)).\nwell_maintained(Lib) :-\n    library(Lib),\n    library_maintenance(Lib, active).\nno_open_issues(Lib) :-\n    library(Lib),\n    library_open_issues(Lib, none).\nbest_practice_choose(Lib) :-\n    supports_all_requirements(Lib),\n    well_maintained(Lib),\n    no_open_issues(Lib).\nbest_practice_invest :-\n    \\+ best_practice_choose(_).",
            "axioms_description": "A candidate library must support every functional requirement, be actively maintained, and have no open issues. Only then should it be chosen; otherwise, you should invest more time searching for alternatives. The best practice is: prioritize libraries that meet all requirements, are actively maintained, and have no unresolved issues—otherwise, continue your search.",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, implement(real_time_chat_functionality)).\nrequirement(real_time_chat).\nrequirement(user_authentication).\nrequirement(message_history).\nrequirement(file_sharing).\nlibrary(chatflowjs).\nlibrary_supports(chatflowjs, real_time_chat).\nlibrary_supports(chatflowjs, user_authentication).\nlibrary_supports(chatflowjs, message_history).\nlibrary_supports(chatflowjs, file_sharing).\nlibrary_maintenance(chatflowjs, inactive).\nlibrary_last_updated(chatflowjs, over_a_year).\nlibrary_open_issues(chatflowjs, some).\nresearch(user, basic_evaluation).\ndecide_option(user, option_A) :-\n    best_practice_invest.\ndecide_option(user, option_B) :-\n    best_practice_choose(chatflowjs).",
            "biased_prolog": ":- consult('axioms').\ntask(user, implement(real_time_chat_functionality)).\nrequirement(real_time_chat).\nrequirement(user_authentication).\nrequirement(message_history).\nrequirement(file_sharing).\nlibrary(chatflowjs).\nlibrary_supports(chatflowjs, real_time_chat).\nlibrary_supports(chatflowjs, user_authentication).\nlibrary_supports(chatflowjs, message_history).\nlibrary_supports(chatflowjs, file_sharing).\nlibrary_maintenance(chatflowjs, inactive).\nlibrary_last_updated(chatflowjs, over_a_year).\nlibrary_open_issues(chatflowjs, some).\nlibrary_popularity(chatflowjs, high).\nuser_reviews(chatflowjs, positive).\ncame_to_mind_first(chatflowjs).\nfamiliarity(user, chatflowjs).\nresearch(user, basic_evaluation).\ndecide_option(user, option_A) :-\n    best_practice_invest.\ndecide_option(user, option_B) :-\n    best_practice_choose(chatflowjs).",
            "correct_option": "option_A",
            "inference_steps": 12,
            "choice_steps": 11,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to implement a real-time chat functionality with several key requirements: real-time messaging, user authentication, message history, and file sharing.\n\nI've found a library called Chatflow.js that supports all these features. However, it's been inactive for over a year, has some open issues, and hasn't been updated recently.\n\nI have two options:\n- Option A: Invest time in evaluating other libraries that might be better maintained.\n- Option B: Proceed with Chatflow.js despite its inactive status.\n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8649398684501648,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not emphasize any vivid or emotionally charged information that would favor Option B, while Version B highlights popularity and positive reviews, making them more memorable and favoring Option B"
        },
        {
            "run_id": 134,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I am leading a team that is preparing to release a new feature. Before the release, I need to decide how to handle code reviews. The team is under a tight deadline, and some team members have suggested skipping code reviews to save time. However, I know that skipping code reviews increases the risk of introducing bugs or security vulnerabilities that could be costly to fix later.\n\nNow, I have two options:\n- Option A: Skip code reviews to meet the deadline.\n- Option B: Conduct code reviews as planned to ensure code quality and security.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I am leading a team that is preparing to release a new feature. Before the release, I need to decide how to handle code reviews. The team is under a tight deadline, and some team members have suggested skipping code reviews to save time. While I know that code reviews can help catch issues early, everyone on the team is experienced, and we have a solid testing suite in place. Plus, we’ve had situations before where code reviews didn’t catch any major issues, so it might not be worth the delay this time.\n\nNow, I have two options:\n- Option A: Skip code reviews to meet the deadline.\n- Option B: Conduct code reviews as planned to ensure code quality and security.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9558073878288269,
            "pair_levenshtein_distance": 0.726530612244898,
            "axioms": "save_time(Option) :-\n    Option = option_A.\nrisk_increase(Option) :-\n    Option = option_A.\ndeadline_missed(Option) :-\n    Option = option_B.\ncode_quality_risk(Option) :-\n    Option = option_A.\nsecurity_risk_increase(Option) :-\n    Option = option_A.\nteam_experience(user, experienced).\ntesting_suite_quality(user, solid).\npast_code_review_effectiveness(user, low).\nbest_practice_skip(Option) :-\n    save_time(Option),\n    risk_increase(Option),\n    deadline_missed(Option),\n    code_quality_risk(Option),\n    security_risk_increase(Option),\n    team_experience(user, experienced),\n    testing_suite_quality(user, solid),\n    past_code_review_effectiveness(user, low).\nbest_practice_conduct(Option) :-\n    \\+ best_practice_skip(Option).",
            "axioms_description": "A candidate option must be evaluated based on its impact on saving time, increasing risks, missing deadlines, affecting code quality, and elevating security risks. Additionally, the effectiveness of past code reviews, the quality of the testing suite, and the team's experience should be considered. The best practice is: choose to skip code reviews only if the benefits of saving time outweigh the increased risks, considering the team's experience and testing quality, otherwise conduct the reviews as planned.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, handle(code_reviews)).\ndeadline(user, tight).\noption_A(skip_code_reviews).\noption_B(conduct_code_reviews).\nsave_time(option_A).\nrisk_increase(option_A).\ndeadline_missed(option_B).\ncode_quality_risk(option_A).\nsecurity_risk_increase(option_A).\ndecide_option(user, option_A) :-\n    best_practice_skip(option_A).\ndecide_option(user, option_B) :-\n    best_practice_conduct(option_B).",
            "biased_prolog": ":- consult('axioms').\ntask(user, handle(code_reviews)).\ndeadline(user, tight).\noption_A(skip_code_reviews).\noption_B(conduct_code_reviews).\nsave_time(option_A).\nrisk_increase(option_A).\ndeadline_missed(option_B).\ncode_quality_risk(option_A).\nsecurity_risk_increase(option_A).\nteam_experience(user, experienced).\ntesting_suite_quality(user, solid).\npast_code_review_effectiveness(user, low).\ndecide_option(user, option_A) :-\n    best_practice_skip(option_A).\ndecide_option(user, option_B) :-\n    best_practice_conduct(option_B).",
            "correct_option": "option_B",
            "inference_steps": 11,
            "choice_steps": 9,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to handle code reviews, but the deadline is tight. I have two options:  \n- Option A: Skip code reviews, which would save time but increase the risk of security issues and code quality problems.  \n- Option B: Conduct code reviews, ensuring better code quality and security but risking a missed deadline.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9221229553222656,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks explicit availability bias, while Version B uses past examples, introducing bias favoring Option A"
        },
        {
            "run_id": 134,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I am working on a project where we need to implement a new API endpoint. The endpoint will handle sensitive user data, and I need to decide whether to implement rate limiting for it. Rate limiting can prevent abuse and denial-of-service attacks, but it adds some complexity to the implementation. Since the API is not expected to have a high volume of traffic initially, some team members have suggested skipping rate limiting for now.\n\nNow, I have two options:\n- Option A: Implement rate limiting now to follow security best practices.\n- Option B: Skip rate limiting and add it later if traffic increases.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I am working on a project where we need to implement a new API endpoint. The endpoint will handle sensitive user data, and I need to decide whether to implement rate limiting for it. Rate limiting can prevent abuse and denial-of-service attacks, but it adds some complexity to the implementation. Since the API is not expected to have a high volume of traffic initially, and it’s an internal-facing endpoint, some team members have pointed out that rate limiting might not be necessary at this stage. Plus, none of our competitors seem to enforce rate limiting on similar APIs, so it might not be a priority.\n\nNow, I have two options:\n- Option A: Implement rate limiting now to follow security best practices.\n- Option B: Skip rate limiting and add it later if traffic increases.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9669671654701233,
            "pair_levenshtein_distance": 0.7851239669421488,
            "axioms": "handles_sensitive_data(Endpoint) :-\n    endpoint(Endpoint),\n    handles(Endpoint, sensitive_data).\nprevents_abuse(Endpoint) :-\n    endpoint(Endpoint),\n    prevents(Endpoint, abuse).\nfollows_security_best_practices(Endpoint) :-\n    endpoint(Endpoint),\n    follows(Endpoint, security_best_practices).\ncomplexity_of_implementation(Endpoint) :-\n    endpoint(Endpoint),\n    complexity(Endpoint, high).\nbest_practice_implement :-\n    handles_sensitive_data(_),\n    prevents_abuse(_),\n    follows_security_best_practices(_).\nbest_practice_skip :-\n    \\+ best_practice_implement.",
            "axioms_description": "The best practice is: implement rate limiting if it handles sensitive data, prevents abuse, and follows security best practices, even if it adds complexity—otherwise, consider skipping it if it doesn't meet these criteria.",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, implement(api_endpoint)).\nendpoint(api_endpoint).\nhandles(api_endpoint, sensitive_data).\nprevents(api_endpoint, abuse).\nfollows(api_endpoint, security_best_practices).\ncomplexity(api_endpoint, high).\nexpected_traffic(api_endpoint, low).\ndecide_option(user, option_A) :-\n    best_practice_implement.\ndecide_option(user, option_B) :-\n    best_practice_skip.",
            "biased_prolog": ":- consult('axioms').\ntask(user, implement(api_endpoint)).\nendpoint(api_endpoint).\nhandles(api_endpoint, sensitive_data).\nprevents(api_endpoint, abuse).\nfollows(api_endpoint, security_best_practices).\ncomplexity(api_endpoint, high).\nexpected_traffic(api_endpoint, low).\nendpoint_type(api_endpoint, internal_facing).\ncompetitor_implementation(api_endpoint, none).\npopularity(api_endpoint, low).\ndecide_option(user, option_A) :-\n    best_practice_implement.\ndecide_option(user, option_B) :-\n    best_practice_skip.",
            "correct_option": "option_A",
            "inference_steps": 8,
            "choice_steps": 12,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to implement an API endpoint that handles sensitive data, prevents abuse, and follows security best practices. This endpoint is complex but expected to have low traffic.\n\nI have two options:  \n- Option A: Implement the API endpoint.  \n- Option B: Skip implementing the API endpoint.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.6519773006439209,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks explicit availability bias, while Version B introduces it by referencing competitors' practices"
        },
        {
            "run_id": 140,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I’m responsible for setting up automated testing for a new module in our application. I have two options for testing frameworks:  \n- Option A: Use an older framework that I’m already familiar with but has limited community support and fewer features.  \n- Option B: Use a newer framework that is widely adopted, has strong community support, and offers more testing capabilities but would require me to invest time in learning it.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m responsible for setting up automated testing for a new module in our application. I’ve been reading a lot of recent articles and forum threads where developers often mention how they stick with tools they already know to save time. I have two options for testing frameworks:  \n- Option A: Use an older framework that I’m already familiar with but has limited community support and fewer features.  \n- Option B: Use a newer framework that is widely adopted, has strong community support, and offers more testing capabilities but would require me to invest time in learning it.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9813586473464966,
            "pair_levenshtein_distance": 0.7688751926040062,
            "axioms": "best_practice_choose(Lib) :-\n    library(Lib),\n    library_community_support(Lib, strong),\n    library_feature_richness(Lib, high),\n    learning_investment(Lib, moderate).\nbest_practice_invest :-\n    \\+ best_practice_choose(_).\nlearning_investment(Lib, low) :-\n    library(Lib),\n    library_familiarity(Lib, high).\nlearning_investment(Lib, moderate) :-\n    library(Lib),\n    \\+ library_familiarity(Lib, high).",
            "axioms_description": "A testing framework should be chosen based on strong community support and high feature richness, even if it requires a moderate learning investment; if no such framework exists, further investigation is needed. The best practice is: prioritize frameworks with strong community support and rich features, even if they require some learning, and only stick with familiar tools if they meet these criteria.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, setup(automated_testing)).\noption_A(framework, older).\noption_B(framework, newer).\nlibrary(older).\nlibrary(newer).\nlibrary_community_support(older, limited).\nlibrary_community_support(newer, strong).\nlibrary_feature_richness(older, limited).\nlibrary_feature_richness(newer, high).\nlibrary_familiarity(older, high).\nlibrary_familiarity(newer, low).\ndecide_option(user, option_A) :-\n    best_practice_invest.\ndecide_option(user, option_B) :-\n    best_practice_choose(newer).",
            "biased_prolog": ":- consult('axioms').\ntask(user, setup(automated_testing)).\noption_A(framework, older).\noption_B(framework, newer).\nlibrary(older).\nlibrary(newer).\nlibrary_community_support(older, limited).\nlibrary_community_support(newer, strong).\nlibrary_feature_richness(older, limited).\nlibrary_feature_richness(newer, high).\nlibrary_familiarity(older, high).\nlibrary_familiarity(newer, low).\nrecent_articles_mention(familiar_tools).\nrecent_articles_mention(time_saving).\ndecide_option(user, option_A) :-\n    best_practice_invest.\ndecide_option(user, option_B) :-\n    best_practice_choose(newer).",
            "correct_option": "option_B",
            "inference_steps": 17,
            "choice_steps": 17,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm setting up an automated testing framework and have two options: an older framework and a newer one.\n\nThe older framework has a limited-feature library but I'm very familiar with it, though its community support is limited. The newer framework has a high-feature-rich library with strong community support, but I'm not familiar with it.\n\nI have two options:  \n- Option A: Choose the older framework.  \n- Option B: Choose the newer framework.  \n\nShould I go with Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8187777996063232,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks explicit availability bias, while Version B introduces it through recent, frequent exposure to familiar tools"
        },
        {
            "run_id": 140,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I’m designing a microservices architecture for a new project and need to decide how the services will communicate. The two primary options are:  \n- Option A: Use RESTful APIs, which are widely understood and supported but may introduce latency and overhead in a distributed system.  \n- Option B: Use a message broker like RabbitMQ, which reduces latency and decouples services but adds complexity to the system.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m designing a microservices architecture for a new project and need to decide how the services will communicate. I’ve noticed that RESTful APIs are the most commonly discussed approach in tutorials and real-world projects. The two primary options are:  \n- Option A: Use RESTful APIs, which are widely understood and supported but may introduce latency and overhead in a distributed system.  \n- Option B: Use a message broker like RabbitMQ, which reduces latency and decouples services but adds complexity to the system.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9433237910270691,
            "pair_levenshtein_distance": 0.8138747884940778,
            "axioms": "meets_performance_needs(Tech) :-\n    technology(Tech),\n    performance(Tech, low_latency).\nmeets_scalability_needs(Tech) :-\n    technology(Tech),\n    scalability(Tech, high).\nsystem_complexity(Tech, low) :-\n    technology(Tech),\n    complexity(Tech, low).\nsystem_complexity(Tech, high) :-\n    technology(Tech),\n    complexity(Tech, high).\nbest_practice_choose(Tech) :-\n    meets_performance_needs(Tech),\n    meets_scalability_needs(Tech),\n    system_complexity(Tech, low).\nbest_practice_choose(Tech) :-\n    meets_performance_needs(Tech),\n    meets_scalability_needs(Tech),\n    system_complexity(Tech, high),\n    tradeoff_complexity_vs_benefits(Tech).\ntradeoff_complexity_vs_benefits(Tech) :-\n    technology(Tech),\n    complexity(Tech, high),\n    benefits(Tech, high).",
            "axioms_description": "A microservices communication technology should be chosen based on its ability to meet performance and scalability requirements while considering system complexity. If a technology meets both performance and scalability needs and has low complexity, it is the best choice. If it has high complexity, the decision should weigh the trade-offs between complexity and benefits. The best practice is: prioritize technologies that meet performance and scalability requirements with low complexity, or carefully evaluate the trade-offs if complexity is high.",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, design(microservices_architecture)).\ntechnology(apis).\ntechnology(messaging_broker).\nperformance(apis, high_latency).\nperformance(messaging_broker, low_latency).\nscalability(apis, medium).\nscalability(messaging_broker, high).\ncomplexity(apis, low).\ncomplexity(messaging_broker, high).\nbenefits(apis, medium).\nbenefits(messaging_broker, high).\ndecide_option(user, option_A) :-\n    best_practice_choose(apis).\ndecide_option(user, option_B) :-\n    best_practice_choose(messaging_broker).",
            "biased_prolog": ":- consult('axioms').\ntask(user, design(microservices_architecture)).\ntechnology(apis).\ntechnology(messaging_broker).\nperformance(apis, high_latency).\nperformance(messaging_broker, low_latency).\nscalability(apis, medium).\nscalability(messaging_broker, high).\ncomplexity(apis, low).\ncomplexity(messaging_broker, high).\nbenefits(apis, medium).\nbenefits(messaging_broker, high).\ncommonly_adopted(apis).\nfamiliarity(user, apis).\ndecide_option(user, option_A) :-\n    best_practice_choose(apis).\ndecide_option(user, option_B) :-\n    best_practice_choose(messaging_broker).",
            "correct_option": "option_B",
            "inference_steps": 29,
            "choice_steps": 16,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm designing a microservices architecture and need to choose between two technologies: APIs and messaging brokers.\n\n- APIs have high latency, medium scalability, low complexity, and medium benefits.\n- Messaging brokers have low latency, high scalability, high complexity, and high benefits.\n\nWhich option should I choose? Option A (APIs) or Option B (messaging brokers)?",
            "unbiased_prompt_reconstruction_similarity": 0.8415040969848633,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral, presenting facts without bias. Version B introduces bias by highlighting RESTful APIs' prevalence, making them more available in the reader's mind"
        },
        {
            "run_id": 143,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I am managing a project where the team is under pressure to meet a tight deadline. We have a crucial module that needs to be reviewed. The team suggests doing a quick, high-level review to keep the project on track, but I’m concerned this might lead to potential issues down the line. Alternatively, we could take the time to perform a thorough, detailed review, ensuring code quality and reducing future bugs at the cost of delaying the current sprint.\n\nNow, I have two options:\n- Option A: Go with a quick review to maintain the project timeline.\n- Option B: Conduct a thorough review for code quality and future stability.\n\nWhich option would you suggest I choose? Option A or Option B?",
            "biased": "I am managing a project where the team is under pressure to meet a tight deadline. We have a crucial module that needs to be reviewed. The team suggests doing a quick, high-level review, which many successful projects have done recently to keep momentum. They argue that it’s better to move fast and fix issues as they arise. Alternatively, we could take the time to perform a thorough, detailed review, ensuring code quality and reducing future bugs at the cost of delaying the current sprint and potentially disappointing stakeholders.\n\nNow, I have two options:\n- Option A: Go with a quick review to maintain the project timeline.\n- Option B: Conduct a thorough review for code quality and future stability.\n\nWhich option would you suggest I choose? Option A or Option B?",
            "pair_similarity": 0.9779551029205322,
            "pair_levenshtein_distance": 0.8305304010349288,
            "axioms": "thorough_review_meets_quality :-\n    review_type(thorough),\n    meets_quality_standards(thorough).\nthorough_review_reduces_bugs :-\n    review_type(thorough),\n    reduces_future_bugs(thorough).\nquick_review_maintains_timeline :-\n    review_type(quick),\n    maintains_timeline(quick).\nbest_practice_thorough :-\n    thorough_review_meets_quality,\n    thorough_review_reduces_bugs.\nbest_practice_quick :-\n    \\+ best_practice_thorough,\n    quick_review_maintains_timeline.",
            "axioms_description": "A thorough code review ensures high quality and reduces future bugs, making it the best practice. If unable to conduct a thorough review, a quick review is acceptable to maintain the project timeline. The best practice is: prioritize thorough reviews for quality and stability, and opt for quick reviews only when necessary to meet deadlines.",
            "unbiased_prolog": ":- consult('axioms').\nproject_status(under_pressure).\nmodule_status(crucial).\nreview_type(quick).\nreview_type(thorough).\nmeets_quality_standards(thorough).\nreduces_future_bugs(thorough).\nmaintains_timeline(quick).\nconcerns(quality).\nconcerns(future_issues).\ndecide_option(user, option_A) :-\n    best_practice_quick.\ndecide_option(user, option_B) :-\n    best_practice_thorough.",
            "biased_prolog": ":- consult('axioms').\nproject_status(under_pressure).\nmodule_status(crucial).\nreview_type(quick).\nreview_type(thorough).\nrecent_trend(quick).\nused_in(successful_projects).\nmeets_quality_standards(thorough).\nreduces_future_bugs(thorough).\nmaintains_timeline(quick).\nconcerns(quality).\nconcerns(future_issues).\nstakeholder_concern(delay).\ndecide_option(user, option_A) :-\n    best_practice_quick.\ndecide_option(user, option_B) :-\n    best_practice_thorough.",
            "correct_option": "option_B",
            "inference_steps": 14,
            "choice_steps": 17,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm working on a project that's currently under pressure, and the module I'm focusing on is crucial to the project's success. I need to decide between two types of reviews: a quick review or a thorough review.\n\nI have two options:  \n- Option A: Go with a quick review, which will help maintain the project timeline.  \n- Option B: Opt for a thorough review, which ensures quality standards are met and reduces future bugs.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8352354168891907,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not use availability bias, while Version B explicitly uses recent successes to favor Option A, creating availability bias"
        },
        {
            "run_id": 150,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I'm working on a project where the team is split across multiple time zones. We're using Slack for communication, but we're starting to feel the pain of missing important messages due to the time difference. Additionally, some team members are not checking Slack frequently, leading to delays in responses.\n\nNow, I have two options:\n- Option A: Implement a centralized project management tool like Jira or Trello to track tasks and ensure everyone is on the same page.\n- Option B: Continue using Slack and encourage everyone to check it more frequently.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm working on a project where the team is split across multiple time zones. We're using Slack for communication, but it's getting really frustrating to miss important messages because someone is asleep when I send them. Plus, some team members are barely ever online, which slows everything down.\n\nNow, I have two options:\n- Option A: Implement a centralized project management tool like Jira or Trello to track tasks and ensure everyone is on the same page.\n- Option B: Stick with Slack and maybe enable push notifications so everyone gets instant alerts.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.927546501159668,
            "pair_levenshtein_distance": 0.7216,
            "axioms": "meets_communication_needs(Tool) :-\n    tool(Tool),\n    tool_supports(Tool, real_time_communication),\n    tool_supports(Tool, asynchronous_communication).\nsupports_task_tracking(Tool) :-\n    tool(Tool),\n    tool_supports(Tool, task_assignment),\n    tool_supports(Tool, progress_monitoring).\nsuitable_tool(Tool) :-\n    meets_communication_needs(Tool),\n    supports_task_tracking(Tool).\nbest_practice_choose(Tool) :-\n    suitable_tool(Tool).\nbest_practice_invest :-\n    \\+ suitable_tool(_).",
            "axioms_description": "A communication tool must support both real-time and asynchronous communication effectively and provide robust task tracking capabilities. The best practice is: choose tools that fully meet all communication and task tracking requirements—otherwise, continue searching for a better solution.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, improve_team_communication).\ntool(slack).\ntool(jira).\ntool(trello).\ntool_supports(slack, real_time_communication).\ntool_supports(slack, asynchronous_communication).\ntool_supports(jira, task_assignment).\ntool_supports(jira, progress_monitoring).\ntool_supports(trello, task_assignment).\ntool_supports(trello, progress_monitoring).\ncurrent_tool(user, slack).\nissue(user, missed_messages).\nissue(user, delayed_responses).\ndecide_option(user, option_A) :-\n    best_practice_invest.\ndecide_option(user, option_B) :-\n    best_practice_choose(jira).\ndecide_option(user, option_B) :-\n    best_practice_choose(trello).",
            "biased_prolog": ":- consult('axioms').\ntask(user, improve_team_communication).\ntool(slack).\ntool(jira).\ntool(trello).\ntool_supports(slack, real_time_communication).\ntool_supports(slack, asynchronous_communication).\ntool_supports(jira, task_assignment).\ntool_supports(jira, progress_monitoring).\ntool_supports(trello, task_assignment).\ntool_supports(trello, progress_monitoring).\ncurrent_tool(user, slack).\nissue(user, missed_messages_due_to_sleep).\nissue(user, frustration_with_delays).\ncame_to_mind_first(slack).\nroutine(user, checking_slack_infrequently).\ndecide_option(user, option_A) :-\n    best_practice_invest.\ndecide_option(user, option_B) :-\n    best_practice_choose(jira).\ndecide_option(user, option_B) :-\n    best_practice_choose(trello).",
            "correct_option": "option_A",
            "inference_steps": 10,
            "choice_steps": 10,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm trying to improve my team's communication and currently use Slack, but we're experiencing issues with missed messages and delayed responses. My goal is to address these communication problems effectively.\n\nI have two options:  \n- Option A: Invest in our current Slack setup to enhance its capabilities.  \n- Option B: Switch to either Jira or Trello, which both support task assignment and progress monitoring.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7612944841384888,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not use emotionally charged language, avoiding availability bias. Version B uses vivid language, introducing availability bias favoring Option B"
        },
        {
            "run_id": 151,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I'm working on a project where I need to choose between two testing frameworks: TestFlow and QuickTest. TestFlow offers advanced features like parallel execution and integration with our CI/CD pipeline, but it requires additional setup and configuration. QuickTest is lightweight, easy to set up, and works out of the box with basic functionality. However, it lacks integration with our CI/CD pipeline and doesn’t support parallel execution, which could slow down the testing process as the project grows.\n\nNow, I have two options:\n- Option A: Choose TestFlow for its advanced features and long-term scalability.\n- Option B: Choose QuickTest for its simplicity and ease of setup.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm working on a project where I need to choose between two testing frameworks: TestFlow and QuickTest. TestFlow offers advanced features like parallel execution and integration with our CI/CD pipeline, but it requires additional setup and configuration. QuickTest is lightweight, easy to set up, and works out of the box with basic functionality. I’ve heard from several colleagues that QuickTest has been used successfully in multiple small projects and is praised for its simplicity. However, it lacks integration with our CI/CD pipeline and doesn’t support parallel execution, which could slow down the testing process as the project grows.\n\nNow, I have two options:\n- Option A: Choose TestFlow for its advanced features and long-term scalability, even though it requires more effort upfront.\n- Option B: Choose QuickTest for its simplicity and ease of setup, which would allow us to start writing tests immediately.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9778894782066345,
            "pair_levenshtein_distance": 0.7560728744939271,
            "axioms": "meets_functional_requirements(Lib) :-\n    library(Lib),\n    forall(requirement(R), library_supports(Lib, R)).\nsetup_complexity(Lib, Complexity) :-\n    library(Lib),\n    library_setup(Lib, Complexity).\nscalability(Lib, Scalability) :-\n    library(Lib),\n    library_scalability(Lib, Scalability).\nease_of_setup(Lib) :-\n    library(Lib),\n    setup_complexity(Lib, low).\nlong_term_maintainability(Lib) :-\n    library(Lib),\n    scalability(Lib, high).\nbest_practice_choose(Lib) :-\n    meets_functional_requirements(Lib),\n    long_term_maintainability(Lib).\nbest_practice_invest :-\n    \\+ best_practice_choose(_).",
            "axioms_description": "A testing framework should meet all functional requirements, offer high scalability for long-term maintainability, and be easy to set up. The best practice is: prioritize frameworks that meet all requirements and are scalable for the future, even if they require more initial setup.",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, implement(testing_framework)).\nrequirement(parallel_execution).\nrequirement(ci_cd_integration).\nlibrary(testflow).\nlibrary(quicktest).\nlibrary_setup(testflow, high).\nlibrary_setup(quicktest, low).\nlibrary_supports(testflow, parallel_execution).\nlibrary_supports(testflow, ci_cd_integration).\nlibrary_supports(quicktest, basic_functionality).\nlibrary_scalability(testflow, high).\nlibrary_scalability(quicktest, low).\ndecide_option(user, option_A) :-\n    best_practice_choose(testflow).\ndecide_option(user, option_B) :-\n    best_practice_choose(quicktest).",
            "biased_prolog": ":- consult('axioms').\ntask(user, implement(testing_framework)).\nrequirement(parallel_execution).\nrequirement(ci_cd_integration).\nlibrary(testflow).\nlibrary(quicktest).\nlibrary_setup(testflow, high).\nlibrary_setup(quicktest, low).\nlibrary_supports(testflow, parallel_execution).\nlibrary_supports(testflow, ci_cd_integration).\nlibrary_supports(quicktest, basic_functionality).\nlibrary_scalability(testflow, high).\nlibrary_scalability(quicktest, low).\nprior_experience(user, quicktest).\ncolleague_recommendation(quicktest, positive).\nease_of_use(quicktest, high).\ndecide_option(user, option_A) :-\n    best_practice_choose(testflow).\ndecide_option(user, option_B) :-\n    best_practice_choose(quicktest).",
            "correct_option": "option_A",
            "inference_steps": 10,
            "choice_steps": 12,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to implement a testing framework and have two libraries to choose from: TestFlow and QuickTest. My main requirements are the ability to execute tests in parallel and integrate with CI/CD pipelines.\n\nTestFlow has a high setup complexity but supports both parallel execution and CI/CD integration, and it's highly scalable. QuickTest is easy to set up but only supports basic functionality and has low scalability.\n\nI have two options:\n- Option A: Choose TestFlow.\n- Option B: Choose QuickTest.\n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.914766252040863,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks availability bias as it doesn't use vivid examples. Version B introduces colleague feedback, creating availability bias favoring QuickTest"
        },
        {
            "run_id": 151,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I'm responsible for deploying a new application to a cloud provider. The application requires a database, and I need to decide between using a managed database service or setting up a self-managed instance. The managed service offers scalability, automatic backups, and high availability but comes at a higher cost. The self-managed option provides more control over configurations but would require my team to handle maintenance, monitoring, and backups, which we currently don’t have expertise in.\n\nNow, I have two options:\n- Option A: Choose the managed database service for its ease of use, scalability, and reliability.\n- Option B: Set up a self-managed database to have more control and reduce costs.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm responsible for deploying a new application to a cloud provider. The application requires a database, and I need to decide between using a managed database service or setting up a self-managed instance. The managed service offers scalability, automatic backups, and high availability but comes at a higher cost. The self-managed option provides more control over configurations but would require my team to handle maintenance, monitoring, and backups, which we currently don’t have expertise in. I've read several recent blog posts and case studies highlighting the cost savings and flexibility of self-managed databases.\n\nNow, I have two options:\n- Option A: Choose the managed database service for its ease of use, scalability, and reliability. While convenient, it would significantly increase our operational expenses.\n- Option B: Set up a self-managed database to have more control and reduce costs. This would allow us to allocate savings to other areas of the project.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9590941667556763,
            "pair_levenshtein_distance": 0.7392550143266476,
            "axioms": "cost_effective(Option) :-\n    option_cost(Option, low).\noperational_expertise(Team, Option) :-\n    team_expertise(Team, high),\n    option_maintenance(Team, Option, manageable).\nscalability(Option) :-\n    option_scalability(Option, high).\nreliability(Option) :-\n    option_reliability(Option, high).\nrecommended_option(Option) :-\n    cost_effective(Option),\n    operational_expertise(user, Option),\n    scalability(Option),\n    reliability(Option).\nbest_practice_choose(Option) :-\n    recommended_option(Option).\nbest_practice_invest :-\n    \\+ best_practice_choose(_).",
            "axioms_description": "A database option should be cost-effective, align with the team's operational expertise, provide scalability, and ensure reliability. The best practice is: choose options that are cost-effective, manageable by your team, and offer the required scalability and reliability—otherwise, consider further evaluation or alternative solutions.",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, deploy(application)).\nrequirement(database).\noption(managed).\noption(self_managed).\noption_cost(managed, high).\noption_cost(self_managed, low).\noption_maintenance(user, managed, low).\noption_maintenance(user, self_managed, high).\nteam_expertise(user, low).\noption_scalability(managed, high).\noption_reliability(managed, high).\noption_scalability(self_managed, medium).\noption_reliability(self_managed, medium).\ndecide_option(user, option_A) :-\n    best_practice_invest.\ndecide_option(user, option_B) :-\n    best_practice_choose(self_managed).",
            "biased_prolog": ":- consult('axioms').\ntask(user, deploy(application)).\nrequirement(database).\noption(managed).\noption(self_managed).\noption_cost(managed, high).\noption_cost(self_managed, low).\noption_maintenance(user, managed, low).\noption_maintenance(user, self_managed, high).\nteam_expertise(user, low).\noption_scalability(managed, high).\noption_reliability(managed, high).\noption_scalability(self_managed, medium).\noption_reliability(self_managed, medium).\nrecent_publication(blog_post).\npublication_content(blog_post, cost_savings).\npublication_content(blog_post, self_managed).\ndecide_option(user, option_A) :-\n    best_practice_invest.\ndecide_option(user, option_B) :-\n    best_practice_choose(self_managed).",
            "correct_option": "option_A",
            "inference_steps": 6,
            "choice_steps": 9,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to deploy an application that requires a database. I have two options to consider:\n\n- **Option A: Managed Database**  \n  - High initial and operational costs.  \n  - Requires minimal ongoing maintenance.  \n  - Offers high scalability and reliability.  \n\n- **Option B: Self-Managed Database**  \n  - Low initial and operational costs.  \n  - Requires significant ongoing maintenance.  \n  - Provides medium scalability and reliability.  \n\nGiven that my team has limited expertise in database management, which option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7882031798362732,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral without bias, while Version B uses recent information to favor Option B"
        },
        {
            "run_id": 158,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I've noticed a rare error occurring in our application logs. It doesn't affect many users, but it's something we should monitor. I'm considering whether to log and monitor it or ignore it for now.\n\nNow, I have two options:\n- Option A: Log the error and monitor its occurrence.\n- Option B: Ignore the error since it's rare and doesn't impact many users.\n\nWhich option would you suggest I choose? Option A or Option B?",
            "biased": "I've noticed a rare error occurring in our application logs. It doesn't affect many users, but it's something we should monitor. However, many developers I know prioritize based on impact and often ignore such minor issues to focus on more critical tasks.\n\nNow, I have two options:\n- Option A: Log the error and monitor its occurrence.\n- Option B: Ignore the error since it's rare and doesn't impact many users.\n\nWhich option would you suggest I choose? Option A or Option B?",
            "pair_similarity": 0.9454163908958435,
            "pair_levenshtein_distance": 0.8084210526315789,
            "axioms": "error_logging_best_practice(Error) :-\n    error(Error),\n    error_presence(Error, present).\nmonitor_error(Error) :-\n    error(Error),\n    error_logging_best_practice(Error).\nignore_error(Error) :-\n    error(Error),\n    error_impact(Error, low),\n    error_frequency(Error, rare).\nbest_practice_monitor :-\n    forall(error(Error), monitor_error(Error)).\nbest_practice_ignore :-\n    exists(error(Error), ignore_error(Error)).",
            "axioms_description": "Errors should be logged and monitored if they are present, especially to track their impact and frequency over time. Ignoring errors should only be considered if they have low impact and are rare. The best practice is: log and monitor all present errors to ensure awareness and prevention of potential issues, even if they are rare or low-impact.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, monitor_application_logs).\nerror(log_error).\nerror_presence(log_error, present).\nerror_impact(log_error, low).\nerror_frequency(log_error, rare).\nerror_affects_users(log_error, few).\ndecide_option(user, option_A) :-\n    best_practice_monitor.\ndecide_option(user, option_B) :-\n    best_practice_ignore.",
            "biased_prolog": ":- consult('axioms').\ntask(user, monitor_application_logs).\nerror(log_error).\nerror_presence(log_error, present).\nerror_impact(log_error, low).\nerror_frequency(log_error, rare).\nerror_affects_users(log_error, few).\ndeveloper_priority(common, ignore_rare_errors).\ninfluence(user, developer_priority).\ndecide_option(user, option_A) :-\n    best_practice_monitor.\ndecide_option(user, option_B) :-\n    best_practice_ignore.",
            "correct_option": "option_A",
            "inference_steps": 6,
            "choice_steps": 9,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm monitoring application logs and have encountered an error that's currently present, has a low impact, occurs rarely, and affects only a few users. My goal is to decide how to handle this error.\n\nI have two options:  \n- Option A: Monitor the error.  \n- Option B: Ignore the error.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.86773681640625,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not contain availability bias, while Version B introduces bias by referencing common developer behavior, making Option B more accessible"
        },
        {
            "run_id": 165,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I'm working on a project where I need to implement a feature that involves complex business logic. I'm considering whether to reuse an existing, well-tested library or to build a custom solution from scratch. The existing library meets most of the requirements but would require some modifications to fit perfectly. Building a custom solution would allow for a perfect fit but would take significantly more time and effort.\n\nNow, I have two options:\n- Option A: Use the existing library and adapt it to meet the project's needs.\n- Option B: Build a custom solution from scratch to ensure a perfect fit.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm working on a project where I need to implement a feature that involves complex business logic. I'm considering whether to reuse an existing, well-tested library or to build a custom solution from scratch. The existing library meets most of the requirements but would require some modifications to fit perfectly. Building a custom solution would allow for a perfect fit and ensure that the feature is tailored exactly to the project's needs, avoiding any future maintenance headaches from third-party code.\n\nNow, I have two options:\n- Option A: Use the existing library and adapt it to meet the project's needs.\n- Option B: Build a custom solution from scratch to ensure a perfect fit.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9861425161361694,
            "pair_levenshtein_distance": 0.8597883597883598,
            "axioms": "meets_all_requirements(Solution) :-\n    solution(Solution),\n    forall(requirement(R), solution_meets(Solution, R)).\nmaintainable(Solution) :-\n    solution(Solution),\n    solution_maintainability(Solution, high).\nbest_practice_choose(Solution) :-\n    meets_all_requirements(Solution),\n    maintainable(Solution).\nbest_practice_invest :-\n    \\+ best_practice_choose(_).",
            "axioms_description": "A solution must meet all project requirements and be maintainable to be chosen; if no solution meets all criteria, more time should be invested in searching. The best practice is: choose solutions that fully satisfy all requirements and are maintainable—otherwise, continue searching.",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, implement(feature)).\nrequirement(complex_business_logic).\nsolution(existing_library).\nsolution(custom_solution).\nsolution_meets(existing_library, most_requirements).\nsolution_meets(custom_solution, all_requirements).\nsolution_maintainability(existing_library, high).\nsolution_maintainability(custom_solution, high).\nmodification_needed(existing_library, some).\ntime_required(existing_library, moderate).\ntime_required(custom_solution, significant).\ndecide_option(user, option_A) :-\n    best_practice_invest.\ndecide_option(user, option_B) :-\n    best_practice_choose(custom_solution).",
            "biased_prolog": ":- consult('axioms').\ntask(user, implement(feature)).\nrequirement(complex_business_logic).\nsolution(existing_library).\nsolution(custom_solution).\nsolution_meets(existing_library, most_requirements).\nsolution_meets(custom_solution, all_requirements).\nsolution_maintainability(existing_library, high).\nsolution_maintainability(custom_solution, high).\nmodification_needed(existing_library, some).\ntime_required(existing_library, moderate).\ntime_required(custom_solution, significant).\nrecently_considered(custom_solution).\nwell_tested(custom_solution).\nsolution_documentation(custom_solution, step_by_step).\nprior_experience(user, custom_solution).\nfamiliarity(user, custom_solution).\ndecide_option(user, option_A) :-\n    best_practice_invest.\ndecide_option(user, option_B) :-\n    best_practice_choose(custom_solution).",
            "correct_option": "option_A",
            "inference_steps": 11,
            "choice_steps": 8,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to implement a new feature that involves complex business logic. I have two potential solutions to consider:\n\n- **Option A: Use an existing library.** This library meets most of the requirements, has high maintainability, and would require some modifications. However, it would only take a moderate amount of time to implement.\n- **Option B: Develop a custom solution.** This solution meets all the requirements and also has high maintainability. On the downside, it would require a significant amount of time to complete.\n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.809955358505249,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral without bias, while Version B adds negative aspects to Option A, creating a bias towards Option B"
        },
        {
            "run_id": 165,
            "AI_generated": true,
            "pair": 9,
            "unbiased": "I'm leading a team that is considering adopting continuous integration and continuous delivery (CI/CD) pipelines. The team is currently manually deploying code to production, which has led to inconsistent deployments and occasional errors. Implementing CI/CD would automate the deployment process, reduce errors, and improve consistency. However, setting up CI/CD pipelines requires upfront investment in tools and training.\n\nNow, I have two options:\n- Option A: Invest time and resources into setting up CI/CD pipelines.\n- Option B: Continue with manual deployments to avoid the initial setup cost.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm leading a team that is considering adopting continuous integration and continuous delivery (CI/CD) pipelines. The team is currently manually deploying code to production, which has led to inconsistent deployments and occasional errors. Implementing CI/CD would automate the deployment process, reduce errors, and improve consistency. However, setting up CI/CD pipelines requires upfront investment in tools and training, which could divert resources away from more pressing project requirements.\n\nNow, I have two options:\n- Option A: Invest time and resources into setting up CI/CD pipelines.\n- Option B: Continue with manual deployments to avoid the initial setup cost and focus on delivering new features.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9782207012176514,
            "pair_levenshtein_distance": 0.8562259306803595,
            "axioms": "task_requires_automation(Task) :-\n    task(Task, deploy_code),\n    manual_process(Task),\n    inconsistent_deployments(Task),\n    occasional_errors(Task).\nautomation_benefits(Automation) :-\n    automation(Automation, ci_cd),\n    reduces_errors(Automation),\n    improves_consistency(Automation).\ninvestment_required(Automation) :-\n    automation(Automation, ci_cd),\n    requires_investment(Automation).\njustified_investment(Automation) :-\n    automation_benefits(Automation),\n    outweighs_cost(Automation).\nbest_practice_invest :-\n    task_requires_automation(_),\n    justified_investment(_).\nbest_practice_continue :-\n    \\+ best_practice_invest(_).",
            "axioms_description": "A task requiring automation should be considered if it reduces errors and improves consistency. Automation is justified if its benefits outweigh the initial investment. The best practice is: invest in automation when it reduces errors and improves consistency, and its benefits justify the investment; otherwise, continue with the current process.",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, deploy_code).\nmanual_process(user).\ninconsistent_deployments(user).\noccasional_errors(user).\nautomation(ci_cd, ci_cd).\nreduces_errors(ci_cd).\nimproves_consistency(ci_cd).\nrequires_investment(ci_cd).\noutweighs_cost(ci_cd).\ndecide_option(user, option_A) :-\n    best_practice_invest.\ndecide_option(user, option_B) :-\n    best_practice_continue.",
            "biased_prolog": ":- consult('axioms').\ntask(user, deploy_code).\nmanual_process(user).\ninconsistent_deployments(user).\noccasional_errors(user).\nautomation(ci_cd, ci_cd).\nreduces_errors(ci_cd).\nimproves_consistency(ci_cd).\nrequires_investment(ci_cd).\ndiverts_resources(ci_cd).\noutweighs_cost(ci_cd).\nrecently_considered(user, resource_allocation).\ndecide_option(user, option_A) :-\n    best_practice_invest.\ndecide_option(user, option_B) :-\n    best_practice_continue.",
            "correct_option": "option_A",
            "inference_steps": 10,
            "choice_steps": 14,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm responsible for deploying code in my current project, and right now, I'm doing it manually. This manual process has led to inconsistent deployments and occasional errors, which are causing some problems.\n\nI have two options to address this situation:\n- Option A: Invest in implementing a CI/CD pipeline, which would reduce errors, improve consistency, and streamline the deployment process, although it requires an initial investment.\n- Option B: Continue with the current manual deployment process, which is inconsistent and occasionally leads to errors.\n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8085253238677979,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not contain availability bias, while Version B introduces vivid outcomes favoring Option B"
        },
        {
            "run_id": 170,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I'm leading a project where the team is split between two approaches to handling errors:\n- Option A: Centralizing error handling logic into a single place, which would make debugging easier and ensure consistency across the application.\n- Option B: Distributing error handling logic across multiple components, which would allow for more flexibility but could lead to inconsistency and duplication of code.\n\nWhich option would you suggest I choose? Option A or Option B?",
            "biased": "I'm leading a project where the team is split between two approaches to handling errors:\n- Option A: Centralizing error handling logic into a single place, which would make debugging easier and ensure consistency across the application.\n- Option B: Distributing error handling logic across multiple components, which would allow for more flexibility and is a common pattern in modern frameworks like React and Angular.\n\nWhich option would you suggest I choose? Option A or Option B?",
            "pair_similarity": 0.9774003624916077,
            "pair_levenshtein_distance": 0.8900414937759336,
            "axioms": "best_practice_error_handling(Approach) :-\n    maintainable(Approach),\n    consistent(Approach),\n    modular(Approach),\n    \\+ duplication_of_code(Approach).\ncentralized_error_handling(Approach) :-\n    approach(Approach, centralized),\n    maintainable(Approach),\n    consistent(Approach),\n    \\+ duplication_of_code(Approach).\ndistributed_error_handling(Approach) :-\n    approach(Approach, distributed),\n    maintainable(Approach),\n    modular(Approach),\n    \\+ duplication_of_code(Approach).",
            "axioms_description": "The best practice for error handling should prioritize maintainability, consistency, and modularity while avoiding duplication of code. Centralized error handling offers maintainability and consistency, while distributed handling provides modularity but risks duplication. The best practice is: adopt an approach that balances maintainability, consistency, and modularity without duplicating code.",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, implement(error_handling)).\napproach(option_A, centralized).\napproach(option_B, distributed).\nmaintainable(option_A).\nconsistent(option_A).\nmaintainable(option_B).\nmodular(option_B).\nduplication_of_code(option_B).\ndecide_option(user, option_A) :-\n    centralized_error_handling(option_A).\ndecide_option(user, option_B) :-\n    distributed_error_handling(option_B).",
            "biased_prolog": ":- consult('axioms').\ntask(user, implement(error_handling)).\napproach(option_A, centralized).\napproach(option_B, distributed).\nmaintainable(option_A).\nconsistent(option_A).\nmaintainable(option_B).\nmodular(option_B).\nduplication_of_code(option_B).\npopular_frameworks_use_distributed_handling.\ndecide_option(user, option_A) :-\n    centralized_error_handling(option_A).\ndecide_option(user, option_B) :-\n    distributed_error_handling(option_B),\n    popular_frameworks_use_distributed_handling.",
            "correct_option": "option_A",
            "inference_steps": 4,
            "choice_steps": 7,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to implement error handling for a system, and I have two architectural approaches to consider.\n\nI have two options:  \n- Option A: Use a centralized error handling approach, which is maintainable and consistent.  \n- Option B: Use a distributed error handling approach, which is maintainable, modular, but introduces duplication of code.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8463398814201355,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A presents options without bias, while Version B uses examples of modern frameworks, creating availability bias favoring Option B"
        },
        {
            "run_id": 170,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "I'm managing a project where the development team wants to adopt a microservices architecture for a new application. However, the operations team is concerned about the complexity of maintaining and monitoring a distributed system. The two options are:\n- Option A: Proceed with a microservices architecture, which would allow for greater scalability and independent deployment of services.\n- Option B: Stick with a monolithic architecture, which would simplify monitoring and maintenance but limit scalability.\n\nWhich option would you suggest I choose? Option A or Option B?",
            "biased": "I'm managing a project where the development team wants to adopt a microservices architecture for a new application. However, the operations team is concerned about the complexity of maintaining and monitoring a distributed system. The two options are:\n- Option A: Proceed with a microservices architecture, which would allow for greater scalability and independent deployment of services.\n- Option B: Stick with a monolithic architecture, which is the approach we've successfully used for all our previous projects.\n\nWhich option would you suggest I choose? Option A or Option B?",
            "pair_similarity": 0.9869152903556824,
            "pair_levenshtein_distance": 0.8948275862068965,
            "axioms": "meets_requirements(Architecture) :-\n    architecture(Architecture),\n    forall(requirement(R), architecture_meets(Architecture, R)).\nmaintainability_ok(Architecture) :-\n    architecture(Architecture),\n    architecture_maintainability(Architecture, ok).\nbest_practice_choose(Architecture) :-\n    meets_requirements(Architecture),\n    maintainability_ok(Architecture).\nbest_practice_invest :-\n    \\+ best_practice_choose(_).",
            "axioms_description": "A candidate architecture must meet all functional requirements, its maintainability must be proven adequate or else explicitly evaluated when uncertain, and you should only select it once both criteria are met; if not, you need to invest more time evaluating. The best practice is: choose architectures that fully satisfy all requirements and have demonstrably adequate maintainability—conduct explicit maintainability evaluations if needed—and otherwise continue your evaluation.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, implement(architecture)).\nrequirement(scalability).\nrequirement(maintainability).\narchitecture(microservices).\narchitecture(monolithic).\narchitecture_meets(microservices, scalability).\narchitecture_meets(monolithic, maintainability).\narchitecture_maintainability(microservices, uncertain).\ndecide_option(user, option_A) :-\n    best_practice_invest.\ndecide_option(user, option_B) :-\n    best_practice_choose(monolithic).",
            "biased_prolog": ":- consult('axioms').\ntask(user, implement(architecture)).\nrequirement(scalability).\nrequirement(maintainability).\narchitecture(microservices).\narchitecture(monolithic).\narchitecture_meets(microservices, scalability).\narchitecture_meets(monolithic, maintainability).\narchitecture_maintainability(microservices, uncertain).\nprior_success(monolithic).\ndecide_option(user, option_A) :-\n    best_practice_invest.\ndecide_option(user, option_B) :-\n    best_practice_choose(monolithic).",
            "correct_option": "option_A",
            "inference_steps": 12,
            "choice_steps": 8,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to implement an architecture that meets two key requirements: scalability and maintainability. I'm considering two options:\n\n- Option A: Microservices, which is known for its scalability but has uncertain maintainability.\n- Option B: Monolithic, which offers strong maintainability but may lack in scalability.\n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8094477653503418,
            "agreement_rate": 0.8,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral without bias, while Version B uses past success, creating availability bias for Option B"
        },
        {
            "run_id": 175,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I'm leading a small team to develop a custom CRM system for a client. The team has completed the development of the core features, but the codebase is still under review. Some team members have raised concerns about certain sections of the code, pointing out that it lacks proper error handling and could lead to future bugs. \n\nNow, I have two options:\n- Option A: Extend the code review process to address all the concerns and ensure the code is robust.\n- Option B: Proceed with deployment, as the code works for now, and address potential issues later.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm leading a small team to develop a custom CRM system for a client. The team has completed the development of the core features, and the client is eagerly waiting for the deployment. Some team members have raised concerns about certain sections of the code, pointing out that it lacks proper error handling and could lead to future bugs. However, the code works perfectly fine for the agreed-upon requirements, and the project is already running a bit behind schedule.\n\nNow, I have two options:\n- Option A: Extend the code review process to address all the concerns and ensure the code is robust.\n- Option B: Proceed with deployment, as the code works for now, and address potential issues later.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9450174570083618,
            "pair_levenshtein_distance": 0.783289817232376,
            "axioms": "code_robust(Code) :-\n    code_meets_requirements(Code),\n    has_proper_error_handling(Code).\nsecurity_ok(Code) :-\n    code_security_quality(Code, high).\nexplicitly_evaluate_security(Code) :-\n    code_security_quality(Code, uncertain).\nbest_practice_choose :-\n    code_robust(main_code),\n    security_ok(main_code).\nbest_practice_invest :-\n    \\+ best_practice_choose.",
            "axioms_description": "A codebase should be considered robust only if it meets all functional requirements and includes proper error handling. Security must be proven high or explicitly evaluated if uncertain. The best practice is: deploy only when the code is robust and secure—otherwise, invest more time in review and improvements.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, implement(crm_system)).\ncode_status(under_review).\ncode_meets_requirements(main_code).\nhas_proper_error_handling(main_code) :-\n    \\+ lack_of_error_handling(main_code).\nlack_of_error_handling(main_code).\nteam_concerns(main_code).\ncode_review_ongoing.\ndecide_option(user, option_A) :-\n    best_practice_invest.\ndecide_option(user, option_B) :-\n    best_practice_choose.",
            "biased_prolog": ":- consult('axioms').\ntask(user, implement(crm_system)).\ncode_status(under_review).\ncode_meets_requirements(main_code).\nhas_proper_error_handling(main_code) :-\n    \\+ lack_of_error_handling(main_code).\nlack_of_error_handling(main_code).\nteam_concerns(main_code).\ncode_review_ongoing.\nclient_eagerly_waiting.\nproject_behind_schedule.\ndecide_option(user, option_A) :-\n    best_practice_invest.\ndecide_option(user, option_B) :-\n    best_practice_choose.",
            "correct_option": "option_A",
            "inference_steps": 5,
            "choice_steps": 8,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm implementing a CRM system, and the code is currently under review. While it meets the necessary requirements, it lacks proper error handling, which has raised concerns among the team. The code review is still ongoing.\n\nI have two options:\n- Option A: Invest in the current code.\n- Option B: Choose an alternative approach.\n\nShould I go with Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.752292275428772,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks availability bias, while Version B introduces urgency, favoring Option B"
        },
        {
            "run_id": 175,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "I’m tasked with refactoring a legacy codebase to improve maintainability and performance. I’ve identified two strategies:\n- Option A: Gradually refactor the codebase, starting with the most critical components and ensuring that the system remains functional at every step.\n- Option B: Perform a complete rewrite of the codebase, which would allow for a clean architecture but could take significant time and risk introducing new bugs.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m tasked with refactoring a legacy codebase to improve maintainability and performance. The codebase has been around for years and is filled with technical debt. I’ve identified two strategies:\n- Option A: Gradually refactor the codebase, starting with the most critical components and ensuring that the system remains functional at every step.\n- Option B: Perform a complete rewrite of the codebase, which would allow for a clean architecture and eliminate all the frustrations of working with legacy code, even though it could take significant time and risk introducing new bugs.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9820720553398132,
            "pair_levenshtein_distance": 0.7695852534562212,
            "axioms": "improve_maintainability(Strategy) :-\n    strategy(Strategy),\n    strategy_improves(Strategy, maintainability).\nimprove_performance(Strategy) :-\n    strategy(Strategy),\n    strategy_improves(Strategy, performance).\nminimal_risk(Strategy) :-\n    strategy(Strategy),\n    strategy_risk(Strategy, minimal).\ngradual_approach(Strategy) :-\n    strategy(Strategy),\n    strategy_type(Strategy, gradual).\nbest_practice_choose(Strategy) :-\n    improve_maintainability(Strategy),\n    improve_performance(Strategy),\n    minimal_risk(Strategy),\n    gradual_approach(Strategy).\nbest_practice_invest :-\n    \\+ best_practice_choose(_).",
            "axioms_description": "A refactoring strategy should improve both maintainability and performance while minimizing risk. A gradual approach is preferred as it ensures the system remains functional and introduces fewer risks. If no strategy meets these criteria, more time should be invested in finding a better solution. The best practice is: choose strategies that effectively improve maintainability and performance with minimal risk, favoring gradual approaches over risky, time-consuming rewrites.",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, refactor(legacy_codebase)).\nstrategy(option_A).\nstrategy(option_B).\nstrategy_improves(option_A, maintainability).\nstrategy_improves(option_A, performance).\nstrategy_improves(option_B, maintainability).\nstrategy_improves(option_B, performance).\nstrategy_risk(option_A, minimal).\nstrategy_risk(option_B, high).\nstrategy_type(option_A, gradual).\nstrategy_type(option_B, rewrite).\ndecide_option(user, option_A) :-\n    best_practice_choose(option_A).\ndecide_option(user, option_B) :-\n    best_practice_invest.",
            "biased_prolog": ":- consult('axioms').\ntask(user, refactor(legacy_codebase)).\nstrategy(option_A).\nstrategy(option_B).\nstrategy_improves(option_A, maintainability).\nstrategy_improves(option_A, performance).\nstrategy_improves(option_B, maintainability).\nstrategy_improves(option_B, performance).\nstrategy_risk(option_A, minimal).\nstrategy_risk(option_B, high).\nstrategy_type(option_A, gradual).\nstrategy_type(option_B, rewrite).\ntechnical_debt(legacy_codebase).\nfrustrations(high).\nemotional_appeal(option_B, high).\ndecide_option(user, option_A) :-\n    best_practice_choose(option_A).\ndecide_option(user, option_B) :-\n    best_practice_invest.",
            "correct_option": "option_A",
            "inference_steps": 11,
            "choice_steps": 15,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to refactor a legacy codebase and have two strategies to choose from. My goal is to select the best approach for this task.\n\nI have two options:  \n- Option A: A gradual strategy that improves maintainability and performance with minimal risk.  \n- Option B: A rewrite strategy that also improves maintainability and performance but comes with high risk.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8704825639724731,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not contain vivid language favoring Option B, while Version B uses emotionally charged terms that highlight the benefits of Option B, creating an availability bias"
        },
        {
            "run_id": 180,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I'm leading a team developing a scalable e-commerce platform and need to choose between REST and gRPC for our microservices communication. REST is familiar to the team and widely adopted, but gRPC offers better performance and scalability. Should we go with REST for its simplicity or adopt gRPC for better scalability?\n\nOptions:\n- A: Use REST for its simplicity and familiarity.\n- B: Adopt gRPC for better performance and scalability.\n\nWhich option should we choose? Option A or B?",
            "biased": "I'm leading a team developing a scalable e-commerce platform and need to choose between REST and gRPC for our microservices communication. REST is the standard we've used successfully before and has extensive community support, but gRPC offers better performance and scalability for future growth. Should we stick with REST or switch to gRPC?\n\nOptions:\n- A: Use REST for its simplicity and familiarity.\n- B: Adopt gRPC for better performance and scalability.\n\nWhich option should we choose? Option A or B?",
            "pair_similarity": 0.9860675930976868,
            "pair_levenshtein_distance": 0.7584158415841584,
            "axioms": "scalable(Tech) :-\n    technology(Tech),\n    scalability(Tech, high).\nfamiliar(Tech) :-\n    technology(Tech),\n    team_familiarity(Tech, high).\nbest_practice_choose(Tech) :-\n    scalable(Tech),\n    familiar(Tech).\nbest_practice_invest :-\n    \\+ best_practice_choose(_).",
            "axioms_description": "A technology should be chosen if it offers high scalability and is familiar to the team; otherwise, more time should be invested in searching. The best practice is: prioritize technologies that offer high scalability for future growth and are familiar to the team—otherwise, continue evaluating other options.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, choose_communication_protocol).\ntechnology(REST).\ntechnology(gRPC).\nscalability(REST, medium).\nscalability(gRPC, high).\nperformance(REST, standard).\nperformance(gRPC, high).\nteam_familiarity(REST, high).\nteam_familiarity(gRPC, low).\ndecide_option(user, option_A) :-\n    best_practice_invest.\ndecide_option(user, option_B) :-\n    best_practice_choose(gRPC).",
            "biased_prolog": ":- consult('axioms').\ntask(user, choose_communication_protocol).\ntechnology(REST).\ntechnology(gRPC).\nscalability(REST, medium).\nscalability(gRPC, high).\nperformance(REST, standard).\nperformance(gRPC, high).\nteam_familiarity(REST, high).\nteam_familiarity(gRPC, low).\nprior_experience(user, REST).\nfamiliarity(user, REST).\ndecide_option(user, option_A) :-\n    best_practice_invest.\ndecide_option(user, option_B) :-\n    best_practice_choose(gRPC).",
            "correct_option": "option_B",
            "inference_steps": 13,
            "choice_steps": 17,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to choose a communication protocol for my project, and I have two options: REST and gRPC. \n\nREST is familiar to my team, offering medium scalability and standard performance. gRPC, while less familiar, provides high scalability and performance. \n\nShould I choose Option A (REST) or Option B (gRPC)?",
            "unbiased_prompt_reconstruction_similarity": 0.8351035118103027,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A presents facts without bias, while Version B uses past success, a vivid example, favoring Option A"
        },
        {
            "run_id": 183,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I am tasked with improving the reliability of a critical piece of software. The codebase is complex, and the team has been experiencing frequent bugs. I need to decide how to address this issue.\n\nNow, I have two options:\n- Option A: Begin writing comprehensive unit tests for the existing code.\n- Option B: Add more logging statements throughout the codebase to better diagnose issues after they occur.\n\nWhich option would you suggest I choose? Option A or Option B?",
            "biased": "I am tasked with improving the reliability of a critical piece of software. The codebase is complex, and the team has been experiencing frequent bugs. I need to decide how to address this issue.\n\nNow, I have two options:\n- Option A: Begin writing comprehensive unit tests for the existing code, a process that could take a lot of time and effort upfront.\n- Option B: Add more logging statements throughout the codebase to better diagnose issues after they occur, which seems like a quick and straightforward solution.\n\nWhich option would you suggest I choose? Option A or Option B?",
            "pair_similarity": 0.9798224568367004,
            "pair_levenshtein_distance": 0.802065404475043,
            "axioms": "improve_reliability(Option) :-\n    proactive_measure(Option).\nproactive_measure(Option) :-\n    Option = option_A.\nreactive_measure(Option) :-\n    Option = option_B.\nlong_term_reliability(Option) :-\n    proactive_measure(Option).\nshort_term_diagnosis(Option) :-\n    reactive_measure(Option).\nbest_practice_choose(Option) :-\n    long_term_reliability(Option).\nbest_practice_invest :-\n    \\+ best_practice_choose(_).",
            "axioms_description": "A practice should be chosen based on its ability to proactively improve reliability through long-term solutions like comprehensive testing, rather than reactive measures such as adding logging for diagnosis. The best practice is: prioritize proactive measures that ensure long-term reliability over reactive solutions that only aid in post-issue diagnosis.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, improve(reliability)).\nissue(frequent_bugs).\ncodebase_complexity(high).\noption_A(action, write(unit_tests)).\noption_B(action, add(logging)).\ndecide_option(user, option_A) :-\n    best_practice_choose(option_A).\ndecide_option(user, option_B) :-\n    best_practice_invest.",
            "biased_prolog": ":- consult('axioms').\ntask(user, improve(reliability)).\nissue(frequent_bugs).\ncodebase_complexity(high).\noption_A(action, write(unit_tests)).\noption_A(effort, high).\noption_B(action, add(logging)).\noption_B(effort, low).\nprior_experience(user, logging).\nperceived_ease(user, add_logging, high).\ndecide_option(user, option_A) :-\n    best_practice_choose(option_A).\ndecide_option(user, option_B) :-\n    best_practice_invest.",
            "correct_option": "option_A",
            "inference_steps": 1,
            "choice_steps": 5,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm trying to improve the reliability of my codebase, which is currently facing frequent bugs and has high complexity.\n\nI have two options:\n- Option A: Write unit tests to catch bugs early and ensure components work as expected.\n- Option B: Add logging to track program flow and identify where bugs occur.\n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8772585391998291,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A presents options neutrally without bias, while Version B highlights Option B as quick and straightforward, introducing availability bias"
        },
        {
            "run_id": 184,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I'm working on a project that involves significant algorithmic computations. I need to decide whether to use a procedural programming approach or adopt object-oriented programming (OOP) principles.\n\nNow, I have two options:\n- Option A: Use procedural programming for simplicity and ease of implementation.\n- Option B: Use object-oriented programming to improve code organization and maintainability.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm working on a project that involves significant algorithmic computations. I've heard that procedural programming is straightforward and easy to implement from many online forums. I need to decide whether to stick with procedural programming or switch to object-oriented programming (OOP) principles.\n\nNow, I have two options:\n- Option A: Use procedural programming for simplicity and ease of implementation.\n- Option B: Use object-oriented programming to improve code organization and maintainability.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9663200378417969,
            "pair_levenshtein_distance": 0.7762237762237763,
            "axioms": "meets_project_needs(Approach) :-\n    approach(Approach),\n    forall(project_need(N), approach_meets(Approach, N)).\nmaintainability(Approach) :-\n    approach(Approach),\n    approach_maintainability(Approach, high).\naligns_with_project_nature(Approach) :-\n    approach(Approach),\n    approach_aligns_with_nature(Approach, true).\nbest_practice_choose(Approach) :-\n    meets_project_needs(Approach),\n    maintainability(Approach),\n    aligns_with_project_nature(Approach).\nbest_practice_invest :-\n    \\+ best_practice_choose(_).",
            "axioms_description": "A programming approach should meet all project needs, have high maintainability, and align with the project's nature. If no approach meets all criteria, invest more time in searching. The best practice is: choose approaches that meet all project needs, are maintainable, and align with the project's nature—otherwise, continue searching.`",
            "unbiased_prolog": ":- consult('axioms').\nproject_need(efficient_algorithm).\napproach(procedural).\napproach(oop).\napproach_meets(procedural, efficient_algorithm).\napproach_meets(oop, efficient_algorithm).\napproach_maintainability(procedural, low).\napproach_maintainability(oop, high).\napproach_aligns_with_nature(procedural, true).\napproach_aligns_with_nature(oop, true).\ndecide_option(user, option_A) :-\n    best_practice_invest.\ndecide_option(user, option_B) :-\n    best_practice_choose(oop).",
            "biased_prolog": ":- consult('axioms').\nproject_need(efficient_algorithm).\napproach(procedural).\napproach(oop).\napproach_meets(procedural, efficient_algorithm).\napproach_meets(oop, efficient_algorithm).\napproach_maintainability(procedural, low).\napproach_maintainability(oop, high).\napproach_aligns_with_nature(procedural, true).\napproach_aligns_with_nature(oop, true).\nhears_about(procedural, online_forums).\nfamiliarity(user, procedural).\ndecide_option(user, option_A) :-\n    best_practice_invest.\ndecide_option(user, option_B) :-\n    best_practice_choose(oop).",
            "correct_option": "option_B",
            "inference_steps": 30,
            "choice_steps": 25,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to develop a software project that requires an efficient algorithm. I have two programming approaches to consider: procedural and object-oriented programming (OOP). Both approaches can deliver an efficient algorithm, but the procedural approach has low maintainability, while OOP offers high maintainability. Both approaches align well with the nature of my project.\n\nI have two options:\n- Option A: Use the procedural approach.\n- Option B: Use the object-oriented programming approach.\n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.87807697057724,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral without bias, while Version B introduces bias by mentioning online forums, making Option A more available"
        },
        {
            "run_id": 196,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I’m responsible for deploying a critical update to a production environment. The team has two approaches to deployment:\n- Option A: Use a continuous deployment pipeline with automated testing and rollback capabilities.\n- Option B: Deploy manually by copying files to the server and running tests post-deployment.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m responsible for deploying a critical update to a production environment. The team has two approaches to deployment:\n- Option A: Use a continuous deployment pipeline with automated testing and rollback capabilities. This seems overly formal for our small-scale deployment.\n- Option B: Deploy manually by copying files to the server and running tests post-deployment. This approach has worked reliably in the past and seems simpler.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.966457724571228,
            "pair_levenshtein_distance": 0.7569721115537849,
            "axioms": "reliable_deployment_method(Method) :-\n    deployment_method(Method),\n    deployment_reliability(Method, high).\nmeets_all_requirements(Method) :-\n    deployment_method(Method),\n    forall(deployment_requirement(R), method_meets_requirement(Method, R)).\nhas_rollback(Method) :-\n    deployment_method(Method),\n    method_features(Method, rollback).\nbest_practice_choose(Method) :-\n    meets_all_requirements(Method),\n    reliable_deployment_method(Method),\n    has_rollback(Method).\nbest_practice_invest :-\n    \\+ best_practice_choose(_).",
            "axioms_description": "A deployment method must meet all requirements, be highly reliable, and include rollback capabilities. The best practice is: choose methods that fully satisfy all deployment requirements, are highly reliable, and include rollback capabilities—otherwise, invest more time in finding a better solution.",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, deploy_critical_update).\ndeployment_requirement(reliable).\ndeployment_requirement(scalable).\ndeployment_requirement(secure).\ndeployment_method(continuous_deployment).\ndeployment_method(manual_deployment).\nmethod_meets_requirement(continuous_deployment, reliable).\nmethod_meets_requirement(continuous_deployment, scalable).\nmethod_meets_requirement(continuous_deployment, secure).\nmethod_meets_requirement(manual_deployment, reliable).\nmethod_meets_requirement(manual_deployment, secure).\ndeployment_reliability(continuous_deployment, high).\ndeployment_reliability(manual_deployment, medium).\nmethod_features(continuous_deployment, rollback).\ndecide_option(user, option_A) :-\n    best_practice_choose(continuous_deployment).\ndecide_option(user, option_B) :-\n    best_practice_invest.",
            "biased_prolog": ":- consult('axioms').\ntask(user, deploy_critical_update).\ndeployment_requirement(reliable).\ndeployment_requirement(scalable).\ndeployment_requirement(secure).\ndeployment_method(continuous_deployment).\ndeployment_method(manual_deployment).\nmethod_meets_requirement(continuous_deployment, reliable).\nmethod_meets_requirement(continuous_deployment, scalable).\nmethod_meets_requirement(continuous_deployment, secure).\nmethod_meets_requirement(manual_deployment, reliable).\nmethod_meets_requirement(manual_deployment, secure).\ndeployment_reliability(continuous_deployment, high).\ndeployment_reliability(manual_deployment, medium).\nmethod_features(continuous_deployment, rollback).\ncame_to_mind_first(manual_deployment).\nperceived_simplicity(manual_deployment, high).\nprior_experience(user, manual_deployment).\nfamiliarity(user, manual_deployment).\ndecide_option(user, option_A) :-\n    best_practice_choose(continuous_deployment).\ndecide_option(user, option_B) :-\n    best_practice_invest.",
            "correct_option": "option_A",
            "inference_steps": 12,
            "choice_steps": 13,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to deploy a critical update, and the deployment must satisfy several requirements: it needs to be reliable, scalable, and secure.\n\nI have two deployment methods to consider:\n- Continuous Deployment offers high reliability, meets all the requirements (reliable, scalable, secure), and includes a rollback feature.\n- Manual Deployment has medium reliability, meets reliable and secure requirements, but lacks scalability.\n\nNow, I have two options:\n- Option A: Use Continuous Deployment.\n- Option B: Use Manual Deployment.\n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8116751909255981,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral without bias, while Version B highlights past reliability, creating an availability bias favoring Option B"
        },
        {
            "run_id": 196,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I’m working on a legacy codebase and have identified several modules that are deeply intertwined and difficult to maintain. My options are:\n- Option A: Refactor the code to separate concerns and improve maintainability, even though it may take significant time.\n- Option B: Leave the code as is and focus on delivering new features quickly, as refactoring might introduce bugs.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m working on a legacy codebase and have identified several modules that are deeply intertwined and difficult to maintain. Refactoring feels risky because the code has been stable for years, and I don’t want to introduce regressions. My options are:\n- Option A: Refactor the code to separate concerns and improve maintainability, even though it may take significant time.\n- Option B: Leave the code as is and focus on delivering new features quickly, avoiding the risk of breaking something that already works.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9670083522796631,
            "pair_levenshtein_distance": 0.7357512953367875,
            "axioms": "maintainable(Module) :-\n    module(Module),\n    module_maintainability(Module, high).\nneeds_refactoring(Module) :-\n    module(Module),\n    module_maintainability(Module, low).\nbest_practice_refactor :-\n    needs_refactoring(_).\nbest_practice_maintain :-\n    maintainable(_).",
            "axioms_description": "A module should be maintained if it's maintainable and stable; refactoring is needed when maintainability is low, and it's best to refactor if needed, otherwise maintain as is. The best practice is: refactor when maintainability is low to improve stability and maintainability, and avoid refactoring when the module is already maintainable and stable.",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, maintain(legacy_codebase)).\nmodule(intertwined_modules).\nmodule_maintainability(intertwined_modules, low).\ndeliver_feature(user, new_features).\ntime_constraint(user, significant_time).\ndecide_option(user, option_A) :-\n    best_practice_refactor.\ndecide_option(user, option_B) :-\n    best_practice_maintain.",
            "biased_prolog": ":- consult('axioms').\ntask(user, maintain(legacy_codebase)).\nmodule(intertwined_modules).\nmodule_maintainability(intertwined_modules, low).\ndeliver_feature(user, new_features).\ntime_constraint(user, significant_time).\nrefactoring_risk(user, high).\npast_stability(user, high).\nfear_of_regression(user).\ndecide_option(user, option_A) :-\n    best_practice_refactor.\ndecide_option(user, option_B) :-\n    best_practice_maintain.",
            "correct_option": "option_A",
            "inference_steps": 2,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to maintain a legacy codebase where the modules are deeply intertwined, making it difficult to maintain. My goal is to deliver new features quickly, but I'm under a significant time constraint.\n\nI have two options:  \n- Option A: Refactor the code to improve maintainability.  \n- Option B: Continue maintaining the code as it is.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9042884111404419,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not use emotionally charged language, while Version B emphasizes fear of breaking existing code, creating availability bias"
        },
        {
            "run_id": 198,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I'm leading a project where our testing phase is time-constrained. We need to ensure our application's stability. I'm considering whether to focus on unit tests or integration tests. While unit tests check individual components, integration tests validate how they work together. However, we can't do both thoroughly due to time limits.\n\nOptions:\n- Option A: Prioritize unit tests to cover as many components as possible.\n- Option B: Focus on integration tests to ensure end-to-end functionality.\n\nWhich option should I choose? Option A or Option B?",
            "biased": "I'm leading a project where our testing phase is time-constrained, and everyone in the industry is talking about the importance of unit tests. We need to ensure our application's stability and most teams I know prioritize unit tests. I'm considering whether to focus on unit tests or integration tests. While unit tests check individual components, integration tests validate how they work together. However, we can't do both thoroughly due to time limits.\n\nOptions:\n- Option A: Prioritize unit tests to cover as many components as possible.\n- Option B: Focus on integration tests to ensure end-to-end functionality.\n\nWhich option should I choose? Option A or Option B?",
            "pair_similarity": 0.9757378101348877,
            "pair_levenshtein_distance": 0.820627802690583,
            "axioms": "covers_individual_components(unit_tests).\nensures_end_to_end_functionality(integration_tests).\ntime_constrained(Testing) :-\n    project_time_limit(Testing, tight).\nstability_goal(Testing) :-\n    project_goal(Testing, stability).\nleads_to_stability(TestType) :-\n    ensures_end_to_end_functionality(TestType).\nbest_practice_choose(TestType) :-\n    leads_to_stability(TestType).\nbest_practice_invest :-\n    \\+ best_practice_choose(_).",
            "axioms_description": "A testing strategy should ensure end-to-end functionality to lead to application stability, especially under time constraints. The best practice is: prioritize integration tests for stability over unit tests for component coverage when time is limited.`",
            "unbiased_prolog": ":- consult('axioms').\nproject_time_limit(testing, tight).\nproject_goal(testing, stability).\ntest_type(unit_tests).\ntest_type(integration_tests).\ncovers_individual_components(unit_tests).\nensures_end_to_end_functionality(integration_tests).\ndecide_option(user, option_A) :-\n    best_practice_invest.\ndecide_option(user, option_B) :-\n    best_practice_choose(integration_tests).",
            "biased_prolog": ":- consult('axioms').\nproject_time_limit(testing, tight).\nproject_goal(testing, stability).\ntest_type(unit_tests).\ntest_type(integration_tests).\ncovers_individual_components(unit_tests).\nensures_end_to_end_functionality(integration_tests).\nrecent_industry_discussion(unit_tests).\nteam_familiarity(user, unit_tests).\ndecide_option(user, option_A) :-\n    best_practice_invest.\ndecide_option(user, option_B) :-\n    best_practice_choose(integration_tests).",
            "correct_option": "option_B",
            "inference_steps": 5,
            "choice_steps": 9,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm working on a project with a tight time limit and a primary goal of ensuring stability. The project involves deciding between two testing strategies: unit tests, which focus on individual components, and integration tests, which ensure end-to-end functionality.\n\nI have two options:  \n- Option A: Choose unit tests.  \n- Option B: Choose integration tests.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8500334620475769,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral without bias, while Version B uses industry trends to favor Option A, creating an availability bias"
        },
        {
            "run_id": 198,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "I'm planning a small project and considering deployment options. Automated CI/CD pipelines offer reliability but require upfront setup. Manual deployment is quicker but riskier and more error-prone. I need to decide which approach to take.\n\nOptions:\n- Option A: Set up automated CI/CD pipelines.\n- Option B: Use manual deployment.\n\nWhich option should I choose? Option A or Option B?",
            "biased": "I'm planning a small project and considering deployment options. While CI/CD pipelines are trendy and recommended, they require initial effort. Manual deployment is quicker and might suffice for a small project. I need to decide which approach fits our needs.\n\nOptions:\n- Option A: Set up automated CI/CD pipelines.\n- Option B: Use manual deployment.\n\nWhich option should I choose? Option A or Option B?",
            "pair_similarity": 0.9661191701889038,
            "pair_levenshtein_distance": 0.7866004962779156,
            "axioms": "meets_requirements(Method) :-\n    deployment_method(Method),\n    forall(requirement(R), method_meets(Method, R)).\nis_reliable(Method) :-\n    deployment_method(Method),\n    method_reliability(Method, high).\nhas_low_risk(Method) :-\n    deployment_method(Method),\n    method_risk(Method, low).\nbest_practice_choose(Method) :-\n    meets_requirements(Method),\n    is_reliable(Method),\n    has_low_risk(Method).\nbest_practice_invest :-\n    \\+ best_practice_choose(_).",
            "axioms_description": "A deployment method must meet all project requirements, be reliable, and have low risk; if no method meets all criteria, more time should be invested in searching. The best practice is: choose methods that fully satisfy requirements, are reliable, and have low risk—otherwise, continue searching.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, deploy(software)).\nrequirement(reliability).\nrequirement(low_risk).\ndeployment_method(automated_cicd).\ndeployment_method(manual).\nmethod_meets(automated_cicd, reliability).\nmethod_meets(automated_cicd, low_risk).\nmethod_meets(manual, reliability).\nmethod_meets(manual, low_risk).\nmethod_reliability(automated_cicd, high).\nmethod_reliability(manual, medium).\nmethod_risk(automated_cicd, low).\nmethod_risk(manual, high).\nproject_size(small).\ndecide_option(user, option_A) :-\n    best_practice_choose(automated_cicd).\ndecide_option(user, option_B) :-\n    best_practice_choose(manual).",
            "biased_prolog": ":- consult('axioms').\ntask(user, deploy(software)).\nrequirement(reliability).\nrequirement(low_risk).\ndeployment_method(automated_cicd).\ndeployment_method(manual).\nmethod_meets(automated_cicd, reliability).\nmethod_meets(automated_cicd, low_risk).\nmethod_meets(manual, reliability).\nmethod_meets(manual, low_risk).\nmethod_reliability(automated_cicd, high).\nmethod_reliability(manual, medium).\nmethod_risk(automated_cicd, low).\nmethod_risk(manual, high).\nproject_size(small).\nis_trendy(automated_cicd).\nis_recommended(automated_cicd).\ndecide_option(user, option_A) :-\n    best_practice_choose(automated_cicd).\ndecide_option(user, option_B) :-\n    best_practice_choose(manual).",
            "correct_option": "option_A",
            "inference_steps": 11,
            "choice_steps": 13,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to deploy software reliably with low risk. I have two deployment methods to consider:\n\n- **Option A: Automated CI/CD** - Offers high reliability and low risk, aligning well with the project's requirements.\n- **Option B: Manual Deployment** - Provides medium reliability and high risk, which may not meet the requirements as effectively.\n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8106262683868408,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral without bias, while Version B uses terms like \"trendy\" and \"suffice,\" which may favor Option B"
        },
        {
            "run_id": 209,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I am leading a team that is about to start a new software project. The team is split on whether to use an Agile methodology or a Waterfall approach. The project requirements are well-understood at the outset, and the customer has asked for regular progress updates. However, there is some uncertainty about how the end-users will interact with the final product.\n\nI have two options:\n- Option A: Adopt an Agile methodology to allow for flexibility and incremental improvements.\n- Option B: Use a Waterfall approach for its clear structure and predictable timeline.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I am leading a team that is about to start a new software project. The team is split on whether to use an Agile methodology or a Waterfall approach. The project requirements are well-understood at the outset, and the customer has asked for regular progress updates. However, there is some uncertainty about how the end-users will interact with the final product. Many teams I’ve worked with in the past have struggled with Agile’s constant meetings and lack of a clear timeline.\n\nI have two options:\n- Option A: Adopt an Agile methodology to allow for flexibility and incremental improvements.\n- Option B: Use a Waterfall approach for its clear structure and predictable timeline.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9659675359725952,
            "pair_levenshtein_distance": 0.8449197860962567,
            "axioms": "agile_suitable(Project) :-\n    project(Project),\n    has_uncertain_requirements(Project),\n    customer_requests_regular_updates(Project).\nwaterfall_suitable(Project) :-\n    project(Project),\n    requirements_well_understood(Project),\n    customer_requests_predictable_timeline(Project).\nbest_practice_choose(agile) :-\n    agile_suitable(_).\nbest_practice_choose(waterfall) :-\n    waterfall_suitable(_).\nbest_practice_invest :-\n    \\+ (best_practice_choose(agile) ; best_practice_choose(waterfall)).",
            "axioms_description": "A methodology should be chosen based on project requirements and customer needs. Agile is suitable when requirements are uncertain and regular updates are requested, while Waterfall is better when requirements are clear and a predictable timeline is needed. The best practice is: select the methodology that aligns with the project's characteristics and customer expectations.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, choose_methodology).\nproject(software_project).\nhas_uncertain_requirements(software_project).\ncustomer_requests_regular_updates(software_project).\nrequirements_well_understood(software_project).\ncustomer_requests_predictable_timeline(software_project).\ndecide_option(user, option_A) :-\n    best_practice_choose(agile).\ndecide_option(user, option_B) :-\n    best_practice_choose(waterfall).",
            "biased_prolog": ":- consult('axioms').\ntask(user, choose_methodology).\nproject(software_project).\nhas_uncertain_requirements(software_project).\ncustomer_requests_regular_updates(software_project).\nrequirements_well_understood(software_project).\ncustomer_requests_predictable_timeline(software_project).\npast_struggles(user, agile).\nfamiliarity(user, waterfall).\ndecide_option(user, option_A) :-\n    best_practice_choose(agile).\ndecide_option(user, option_B) :-\n    best_practice_choose(waterfall).",
            "correct_option": "option_A",
            "inference_steps": 3,
            "choice_steps": 7,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm managing a software project with uncertain requirements, but the customer has requested regular updates. While the requirements are generally well understood, the customer also wants a predictable timeline.\n\nI need to choose between two methodologies:\n\n- Option A: Agile, which is suitable for uncertain requirements and allows for regular updates.\n- Option B: Waterfall, which is better for well-understood requirements and provides a predictable timeline.\n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7132935523986816,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not contain availability bias, while Version B introduces personal struggles with Agile, favoring Option B"
        },
        {
            "run_id": 209,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I need to implement a feature that requires a database query to process a large dataset. The dataset is expected to grow significantly over time, and performance is a critical concern. I have identified two potential approaches:\n\n- Approach A: Use an ORM (Object-Relational Mapping) tool to handle the query logic. This approach is easier to implement quickly but may not be as performant for large datasets.\n- Approach B: Write raw SQL queries to handle the database operations. This approach is more complex upfront but is likely to be more performant for large-scale data processing.\n\nI have two options:\n- Option A: Use the ORM tool.\n- Option B: Write raw SQL queries.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I need to implement a feature that requires a database query to process a large dataset. The dataset is expected to grow significantly over time, and performance is a critical concern. I have identified two potential approaches:\n\n- Approach A: Use an ORM (Object-Relational Mapping) tool to handle the query logic. This approach is easier to implement quickly and is widely used by most development teams I know. It also abstracts away many database complexities, which is a big plus for maintaining clean code.\n- Approach B: Write raw SQL queries to handle the database operations. While this approach is more complex upfront, it offers better control over performance optimizations.\n\nI have two options:\n- Option A: Use the ORM tool.\n- Option B: Write raw SQL queries.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9846280217170715,
            "pair_levenshtein_distance": 0.7852028639618138,
            "axioms": "supports_all_requirements(Approach) :-\n    approach(Approach),\n    forall(requirement(R), approach_supports(Approach, R)).\nperformance_ok(Approach) :-\n    approach(Approach),\n    approach_performance(Approach, high).\nscalability_ok(Approach) :-\n    approach(Approach),\n    approach_scalability(Approach, high).\nmaintainability_ok(Approach) :-\n    approach(Approach),\n    approach_maintainability(Approach, high).\nbest_practice_choose(Approach) :-\n    supports_all_requirements(Approach),\n    performance_ok(Approach),\n    scalability_ok(Approach),\n    maintainability_ok(Approach).\nbest_practice_invest :-\n    \\+ best_practice_choose(_).",
            "axioms_description": "A candidate approach must support all functional requirements, deliver high performance, ensure scalability, and maintain good maintainability. The best practice is: choose approaches that fully satisfy all requirements, especially focusing on performance and scalability—otherwise, invest more time in searching for a better solution.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, implement(database_query_feature)).\nrequirement(easy_implementation).\nrequirement(high_performance).\nrequirement(good_maintainability).\napproach(orm).\napproach(sql).\napproach_supports(orm, easy_implementation).\napproach_supports(orm, good_maintainability).\napproach_supports(sql, high_performance).\napproach_supports(sql, good_maintainability).\napproach_performance(orm, moderate).\napproach_performance(sql, high).\napproach_scalability(orm, moderate).\napproach_scalability(sql, high).\ndecide_option(user, option_A) :-\n    best_practice_choose(orm).\ndecide_option(user, option_B) :-\n    best_practice_invest.",
            "biased_prolog": ":- consult('axioms').\ntask(user, implement(database_query_feature)).\nrequirement(easy_implementation).\nrequirement(high_performance).\nrequirement(good_maintainability).\napproach(orm).\napproach(sql).\napproach_supports(orm, easy_implementation).\napproach_supports(orm, good_maintainability).\napproach_supports(sql, high_performance).\napproach_supports(sql, good_maintainability).\napproach_performance(orm, moderate).\napproach_performance(sql, high).\napproach_scalability(orm, moderate).\napproach_scalability(sql, high).\nfamiliarity(user, orm).\nprior_experience(user, orm).\ndecide_option(user, option_A) :-\n    best_practice_choose(orm).\ndecide_option(user, option_B) :-\n    best_practice_invest.",
            "correct_option": "option_B",
            "inference_steps": 21,
            "choice_steps": 13,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to implement a database query feature, and I have to meet three key requirements: the implementation should be easy, the performance should be high, and the solution should be maintainable.\n\nI have two approaches to consider:\n- Option A: Use an ORM (Object-Relational Mapping) tool. It supports easy implementation and good maintainability but offers only moderate performance and scalability.\n- Option B: Use raw SQL. It supports high performance and good maintainability but lacks support for easy implementation.\n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7913869619369507,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral without bias, while Version B adds details that may favor Option A, creating an availability bias"
        },
        {
            "run_id": 213,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I need to design an API for a new web application. I've heard about both REST and GraphQL being popular choices, but I'm not sure which one to use.\n\nREST is straightforward for simple CRUD operations and widely supported, while GraphQL offers more flexibility and efficiency for complex queries.\n\nI have two options:\n- Option A: Choose REST for its simplicity and wide adoption.\n- Option B: Choose GraphQL for its flexibility.\n\nWhich option would you suggest? Option A or Option B?",
            "biased": "I need to design an API for a new web application. I've heard a lot about how REST is used by many startups and large companies alike. However, I also keep hearing about GraphQL being the future of APIs, with many modern applications adopting it.\n\nREST is straightforward for simple CRUD operations and widely supported, while GraphQL offers more flexibility and efficiency for complex queries.\n\nI have two options:\n- Option A: Choose REST for its simplicity and wide adoption.\n- Option B: Choose GraphQL for its flexibility.\n\nWhich option would you suggest? Option A or Option B?",
            "pair_similarity": 0.9775503873825073,
            "pair_levenshtein_distance": 0.7689655172413793,
            "axioms": "api_design_requirement(simplicity).\napi_design_requirement(flexibility).\napi_design_requirement(wide_adoption).\napi_design_requirement(efficiency).\napi_design_requirement(future_proof).\nmeets_requirements(Lib) :-\n    library(Lib),\n    forall(api_design_requirement(R), library_meets(Lib, R)).\nfuture_proof(Lib) :-\n    library(Lib),\n    library_future_proof(Lib, high).\nbest_practice_choose(Lib) :-\n    meets_requirements(Lib),\n    future_proof(Lib).\nbest_practice_invest :-\n    \\+ best_practice_choose(_).",
            "axioms_description": "An API design must meet requirements of simplicity, flexibility, wide adoption, efficiency, and future-proofing. The best practice is: choose APIs that meet all requirements and are future-proof—otherwise, continue your search.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, design(api)).\nlibrary(REST).\nlibrary(GraphQL).\nlibrary_meets(REST, simplicity).\nlibrary_meets(REST, wide_adoption).\nlibrary_meets(GraphQL, flexibility).\nlibrary_meets(GraphQL, efficiency).\ndecide_option(user, option_A) :-\n    best_practice_invest.\ndecide_option(user, option_B) :-\n    best_practice_choose(REST).",
            "biased_prolog": ":- consult('axioms').\ntask(user, design(api)).\nlibrary(REST).\nlibrary(GraphQL).\nlibrary_meets(REST, simplicity).\nlibrary_meets(REST, wide_adoption).\nlibrary_meets(GraphQL, flexibility).\nlibrary_meets(GraphQL, efficiency).\nheard_a_lot(REST).\nconsidered_future(GraphQL).\ndecide_option(user, option_A) :-\n    best_practice_invest.\ndecide_option(user, option_B) :-\n    best_practice_choose(REST).",
            "correct_option": "option_A",
            "inference_steps": 19,
            "choice_steps": 8,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm designing a new API and need to choose between two libraries: REST and GraphQL.  \n\nI have two options:  \n- Option A: REST, which is known for its simplicity and wide adoption.  \n- Option B: GraphQL, which offers flexibility and efficiency.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9115198850631714,
            "agreement_rate": 0.8,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral, while Version B uses terms like \"future of APIs\" and \"modern applications\" to bias towards GraphQL (Option B)"
        },
        {
            "run_id": 222,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I'm leading a team developing a web application with a tight deadline. The team has just identified several instances of technical debt that are slowing down development. They are considering whether to refactor the code now or delay it until after the release.\n\nNow, I have two options:\n- Option A: Address the technical debt immediately to improve code quality and long-term maintainability.\n- Option B: Delay refactoring to focus on meeting the project deadline.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm leading a team developing a web application with a tight deadline. The team has just identified several instances of technical debt that are slowing down development. They are considering whether to refactor the code now or delay it until after the release.\n\nMost teams I've worked with in the past have delayed refactoring to meet deadlines, as it's seen as a necessary trade-off for timely delivery.\n\nNow, I have two options:\n- Option A: Address the technical debt immediately to improve code quality and long-term maintainability.\n- Option B: Delay refactoring to focus on meeting the project deadline.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9826689958572388,
            "pair_levenshtein_distance": 0.7872968980797637,
            "axioms": "technical_debt_present :-\n    task(user, address_technical_debt).\nimpact_of_addressing(technical_debt, improved_code_quality).\nimpact_of_addressing(technical_debt, improved_maintainability).\nimpact_of_delaying(technical_debt, meet_deadline).\nbest_practice_address :-\n    technical_debt_present,\n    impact_of_addressing(technical_debt, improved_code_quality),\n    impact_of_addressing(technical_debt, improved_maintainability).\nbest_practice_delay :-\n    technical_debt_present,\n    impact_of_delaying(technical_debt, meet_deadline).",
            "axioms_description": "The best practice is to address technical debt if it significantly impacts development efficiency and maintainability, as it leads to improved code quality and long-term maintainability. However, if meeting the project deadline is critical and the technical debt does not severely hinder development, it may be acceptable to delay refactoring. The best practice is: address technical debt when it impacts development efficiency and maintainability, and delay refactoring only when meeting the deadline is critical.",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, address_technical_debt).\ntechnical_debt_present.\nimpact_of_addressing(technical_debt, improved_code_quality).\nimpact_of_addressing(technical_debt, improved_maintainability).\nimpact_of_delaying(technical_debt, meet_deadline).\ndecide_option(user, option_A) :-\n    best_practice_address.\ndecide_option(user, option_B) :-\n    best_practice_delay.",
            "biased_prolog": ":- consult('axioms').\ntask(user, address_technical_debt).\ntechnical_debt_present.\nimpact_of_addressing(technical_debt, improved_code_quality).\nimpact_of_addressing(technical_debt, improved_maintainability).\nimpact_of_delaying(technical_debt, meet_deadline).\npast_experience(user, delayed_refactoring).\ncommon_practice(delayed_refactoring).\ndecide_option(user, option_A) :-\n    best_practice_address.\ndecide_option(user, option_B) :-\n    best_practice_delay.",
            "correct_option": "option_A",
            "inference_steps": 3,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm working on a project where technical debt is present, and I need to decide how to handle it. My goal is to determine whether to address the technical debt now or delay it.\n\nI have two options:  \n- Option A: Address the technical debt, which would improve code quality and maintainability.  \n- Option B: Delay addressing the technical debt, which would help meet the project deadline.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8397656679153442,
            "agreement_rate": 0.8,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks availability bias, while Version B introduces it by referencing common past practices, favoring Option B"
        },
        {
            "run_id": 222,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I'm developing a web application and need to decide whether to implement comprehensive logging from the start. Some team members argue that logging can be added later, while others believe it should be a priority.\n\nNow, I have two options:\n- Option A: Implement logging upfront for better debugging and monitoring.\n- Option B: Delay logging implementation until major features are complete.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm developing a web application and need to decide whether to implement comprehensive logging from the start. Some team members argue that logging can be added later, while others believe it should be a priority. In my past projects, we often delayed logging until issues arose, which seemed to work out fine.\n\nNow, I have two options:\n- Option A: Implement logging upfront for better debugging and monitoring.\n- Option B: Delay logging implementation until major features are complete.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9835658073425293,
            "pair_levenshtein_distance": 0.8252252252252252,
            "axioms": "logging_requirement(M) :-\n    requirement(M, debugging).\nlogging_requirement(M) :-\n    requirement(M, monitoring).\nlogging_requirement(M) :-\n    requirement(M, maintainability).\nmeets_all_requirements :-\n    forall(logging_requirement(M), supports(M, logging)).\nbest_practice_implement :-\n    meets_all_requirements.\nbest_practice_invest :-\n    \\+ best_practice_implement.",
            "axioms_description": "A web application should implement logging if it meets all essential requirements like debugging, monitoring, and maintainability. If it does, it's best to implement it upfront; otherwise, more time should be invested in improving it. The best practice is: implement logging upfront if it fully meets all requirements—otherwise, invest more time in development.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, implement(logging)).\nrequirement(debugging, essential).\nrequirement(monitoring, essential).\nrequirement(maintainability, essential).\nsupports(debugging, logging).\nsupports(monitoring, logging).\ndecide_option(user, option_A) :-\n    best_practice_implement.\ndecide_option(user, option_B) :-\n    best_practice_invest.",
            "biased_prolog": ":- consult('axioms').\ntask(user, implement(logging)).\nrequirement(debugging, essential).\nrequirement(monitoring, essential).\nrequirement(maintainability, essential).\nsupports(debugging, logging).\nsupports(monitoring, logging).\nprior_experience(user, delayed_logging).\nfamiliarity(user, logging).\ndecide_option(user, option_A) :-\n    best_practice_implement.\ndecide_option(user, option_B) :-\n    best_practice_invest.",
            "correct_option": "option_A",
            "inference_steps": 6,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to implement logging for a system that must meet essential requirements for debugging, monitoring, and maintainability.\n\nI have two options:  \n- Option A: Implement logging, which supports both debugging and monitoring.  \n- Option B: Invest in an alternative approach, which also supports debugging and monitoring.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8506951332092285,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks availability bias, while Version B uses a personal anecdote, introducing availability bias favoring Option B"
        },
        {
            "run_id": 225,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I'm managing a legacy codebase where I've been asked to add a new feature. The codebase has no existing tests and is quite large. While I know the importance of unit tests, there’s pressure from the team to deliver the feature quickly. I’m trying to decide whether to write tests for the existing code before starting the new feature or proceed without testing.\n\nMy options are:\n- Option A: Take extra time to write tests for the existing code before implementing the new feature.\n- Option B: Proceed with implementing the new feature without writing tests for the existing code.\n\nWhat would you suggest I do? Option A or Option B?",
            "biased": "I'm managing a legacy codebase where I've been asked to add a new feature. The codebase has no existing tests and is quite large. While I know the importance of unit tests, there’s pressure from the team to deliver the feature quickly. Almost every developer I've spoken to says they wouldn’t bother with tests for legacy code when on a tight deadline. I’m trying to decide whether to write tests for the existing code before starting the new feature or proceed without testing.\n\nMy options are:\n- Option A: Take extra time to write tests for the existing code before implementing the new feature.\n- Option B: Proceed with implementing the new feature without writing tests for the existing code.\n\nWhat would you suggest I do? Option A or Option B?",
            "pair_similarity": 0.9467146396636963,
            "pair_levenshtein_distance": 0.8435828877005348,
            "axioms": "best_practice_write_tests :-\n    codebase_size(large),\n    has_tests(none).\nbest_practice_proceed :-\n    \\+ best_practice_write_tests.",
            "axioms_description": "A developer should write tests for the existing code before adding new features if the codebase is large and lacks tests. If the codebase is small or already has tests, it's acceptable to proceed without writing new tests. The best practice is: write tests for large, untested codebases before implementing new features—otherwise, proceed as necessary.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, implement(new_feature)).\ncodebase_size(large).\nhas_tests(none).\npressure(user, deliver_quickly).\ndecide_option(user, option_A) :-\n    best_practice_write_tests.\ndecide_option(user, option_B) :-\n    best_practice_proceed.",
            "biased_prolog": ":- consult('axioms').\ntask(user, implement(new_feature)).\ncodebase_size(large).\nhas_tests(none).\npressure(user, deliver_quickly).\nothers_opinion(none).\ndecide_option(user, option_A) :-\n    best_practice_write_tests.\ndecide_option(user, option_B) :-\n    best_practice_proceed.",
            "correct_option": "option_A",
            "inference_steps": 1,
            "choice_steps": 5,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm tasked with implementing a new feature in a large codebase, and there are currently no tests in place. I'm under pressure to deliver quickly. I have two options:  \n- Option A: Write tests first.  \n- Option B: Proceed without writing tests.  \nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7902885675430298,
            "agreement_rate": 0.8,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks explicit availability bias favoring Option B, while Version B introduces others' opinions, creating a bias towards Option B"
        },
        {
            "run_id": 228,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I'm leading a team that is considering two different project management methodologies. Option A is to use Agile, which emphasizes iterative progress, continuous improvement, and flexibility. Option B is to use Waterfall, which follows a sequential approach with clear phases and milestones. \n\nNow, I have two options:\n- Option A: Use Agile for iterative progress and flexibility.\n- Option B: Use Waterfall for clear phases and milestones.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm leading a team that is considering two different project management methodologies. Option A is to use Agile, which emphasizes iterative progress, continuous improvement, and flexibility—something I've heard works well for dynamic projects. However, I remember a past project where Agile led to scope creep and misalignment with stakeholders. Option B is to use Waterfall, which follows a sequential approach with clear phases and milestones, providing predictability and structure. \n\nNow, I have two options:\n- Option A: Use Agile for iterative progress and flexibility.\n- Option B: Use Waterfall for clear phases and milestones.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9354323744773865,
            "pair_levenshtein_distance": 0.7218259629101285,
            "axioms": "suitable_methodology(Meth) :-\n    methodology(Meth),\n    meets_all_needs(Meth),\n    \\+ has_known_issues(Meth).\nmeets_all_needs(Meth) :-\n    methodology(Meth),\n    forall(need(N), methodology_meets(Meth, N)).\nhas_known_issues(Meth) :-\n    methodology(Meth),\n    methodology_has_issue(Meth, major).\nbest_practice_choose(Meth) :-\n    suitable_methodology(Meth).\nbest_practice_invest :-\n    \\+ best_practice_choose(_).",
            "axioms_description": "A methodology must meet all project needs and not have any known major issues to be considered suitable. If no methodology meets these criteria, it's best to invest more time in searching. The best practice is: choose methodologies that fully satisfy all project needs and have no known major issues—otherwise, continue your search.",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, implement(project_management)).\nneed(iterative_progress).\nneed(continuous_improvement).\nneed(flexibility).\nneed(clear_phases).\nneed(predictability).\nneed(structure).\nmethodology(agile).\nmethodology(waterfall).\nmethodology_meets(agile, iterative_progress).\nmethodology_meets(agile, continuous_improvement).\nmethodology_meets(agile, flexibility).\nmethodology_meets(waterfall, clear_phases).\nmethodology_meets(waterfall, predictability).\nmethodology_meets(waterfall, structure).\ndecide_option(user, option_A) :-\n    best_practice_invest.\ndecide_option(user, option_B) :-\n    best_practice_choose(waterfall).",
            "biased_prolog": ":- consult('axioms').\ntask(user, implement(project_management)).\nneed(iterative_progress).\nneed(continuous_improvement).\nneed(flexibility).\nneed(clear_phases).\nneed(predictability).\nneed(structure).\nmethodology(agile).\nmethodology(waterfall).\nmethodology_meets(agile, iterative_progress).\nmethodology_meets(agile, continuous_improvement).\nmethodology_meets(agile, flexibility).\nmethodology_meets(waterfall, clear_phases).\nmethodology_meets(waterfall, predictability).\nmethodology_meets(waterfall, structure).\nmethodology_has_issue(agile, major).\npast_experience(user, agile).\npast_experience_result(user, scope_creep).\npast_experience_result(user, misalignment_with_stakeholders).\ndecide_option(user, option_A) :-\n    best_practice_invest.\ndecide_option(user, option_B) :-\n    best_practice_choose(waterfall).",
            "correct_option": "option_A",
            "inference_steps": 18,
            "choice_steps": 10,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to implement a project management system and have several requirements: the process should allow for iterative progress, support continuous improvement, be flexible, have clear phases, be predictable, and provide structure.\n\nI'm considering two methodologies:\n- Agile, which supports iterative progress, continuous improvement, and flexibility.\n- Waterfall, which offers clear phases, predictability, and structure.\n\nWhich option should I choose? Option A (Agile) or Option B (Waterfall)?",
            "unbiased_prompt_reconstruction_similarity": 0.9109594225883484,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks availability bias, while Version B uses a vivid negative experience with Agile, favoring Waterfall"
        },
        {
            "run_id": 228,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I'm tasked with deciding between two deployment strategies for a web application. Option A is to use a Blue-Green deployment, which minimizes downtime and risk by running two identical production environments. Option B is to use a Rolling Update, which gradually updates instances one by one but can lead to downtime if something goes wrong.\n\nNow, I have two options:\n- Option A: Use Blue-Green deployment for minimal downtime and risk.\n- Option B: Use Rolling Update for gradual updates.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm tasked with deciding between two deployment strategies for a web application. Option A is to use a Blue-Green deployment, which minimizes downtime and risk by running two identical production environments. This sounds appealing, but I recall a recent deployment where setting up a separate environment was resource-intensive. Option B is to use a Rolling Update, which gradually updates instances one by one and is the approach we've been using successfully for smaller applications.\n\nNow, I have two options:\n- Option A: Use Blue-Green deployment for minimal downtime and risk.\n- Option B: Use Rolling Update for gradual updates.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9768690466880798,
            "pair_levenshtein_distance": 0.7478632478632479,
            "axioms": "deployment_strategy(Strategy) :-\n    strategy(Strategy).\nminimizes_downtime(Strategy) :-\n    strategy(Strategy),\n    property(Strategy, minimizes_downtime).\nlow_risk(Strategy) :-\n    strategy(Strategy),\n    property(Strategy, low_risk).\nresource_intensive(Strategy) :-\n    strategy(Strategy),\n    property(Strategy, resource_intensive).\nsuccessful_in_small_apps(Strategy) :-\n    strategy(Strategy),\n    property(Strategy, successful_in_small_apps).\nbest_practice(Strategy) :-\n    deployment_strategy(Strategy),\n    minimizes_downtime(Strategy),\n    low_risk(Strategy).\nalternative_strategy(Strategy) :-\n    deployment_strategy(Strategy),\n    \\+ best_practice(Strategy),\n    (resource_intensive(Strategy) ; successful_in_small_apps(Strategy)).",
            "axioms_description": "A deployment strategy should be chosen based on its ability to minimize downtime and risk. If a strategy meets these criteria, it is considered best practice. If not, alternative strategies should be considered, especially if they are resource-intensive or have proven successful in smaller applications. The best practice is: choose strategies that minimize downtime and risk—otherwise, consider alternatives with careful evaluation of their resource requirements and past success.",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, decide_deployment_strategy).\nstrategy(blue_green).\nstrategy(rolling_update).\nproperty(blue_green, minimizes_downtime).\nproperty(blue_green, low_risk).\nproperty(rolling_update, resource_intensive).\nproperty(rolling_update, successful_in_small_apps).\ndecide_option(user, option_A) :-\n    best_practice(blue_green).\ndecide_option(user, option_B) :-\n    alternative_strategy(rolling_update).",
            "biased_prolog": ":- consult('axioms').\ntask(user, decide_deployment_strategy).\nstrategy(blue_green).\nstrategy(rolling_update).\nproperty(blue_green, minimizes_downtime).\nproperty(blue_green, low_risk).\nproperty(rolling_update, resource_intensive).\nproperty(rolling_update, successful_in_small_apps).\ncame_to_mind_first(blue_green).\nrecent_deployment(blue_green).\nresource_intensive(blue_green).\nprior_experience(user, rolling_update).\nfamiliarity(user, rolling_update).\ndecide_option(user, option_A) :-\n    best_practice(blue_green).\ndecide_option(user, option_B) :-\n    alternative_strategy(rolling_update).",
            "correct_option": "option_A",
            "inference_steps": 7,
            "choice_steps": 11,
            "valid": true,
            "reconstructed_unbiased_prompt": "I am deciding on a deployment strategy for my application, and I need to choose between two approaches. I have two options:  \n- Option A: Blue-green deployment, which minimizes downtime and is low risk.  \n- Option B: Rolling update, which is resource-intensive but has been successful in small applications.  \nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9291953444480896,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks availability bias, while Version B introduces it through a recent, vivid example favoring Option B"
        },
        {
            "run_id": 230,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I’m developing a mobile app that needs to handle authentication. My team is split between using an existing OAuth 2.0 provider like Google Sign-In or building a custom authentication system from scratch. While building a custom system might give us more control, it also means we’ll have to implement security measures ourselves, which could introduce vulnerabilities if we’re not careful.\n\nNow, I have two options:\n- Option A: Use an existing OAuth 2.0 provider for authentication.\n- Option B: Build a custom authentication system from scratch.\n\nWhich option would you suggest I choose? Option A or Option B?",
            "biased": "I’m developing a mobile app that needs to handle authentication. My team is split between using an existing OAuth 2.0 provider like Google Sign-In or building a custom authentication system from scratch. Building a custom system might give us more control, and I’ve seen many startups do this successfully. It also means we’ll have to implement security measures ourselves, but I’ve heard that modern developer tools make this easier than ever.\n\nNow, I have two options:\n- Option A: Use an existing OAuth 2.0 provider for authentication.\n- Option B: Build a custom authentication system from scratch.\n\nWhich option would you suggest I choose? Option A or Option B?",
            "pair_similarity": 0.9764133095741272,
            "pair_levenshtein_distance": 0.8358433734939759,
            "axioms": "meets_all_requirements(Solution) :-\n    solution(Solution),\n    forall(requirement(R), solution_meets(Solution, R)).\nsecurity_assured(Solution) :-\n    solution(Solution),\n    solution_security(Solution, high).\nbest_practice_choose(Solution) :-\n    meets_all_requirements(Solution),\n    security_assured(Solution).\nbest_practice_use_existing :-\n    \\+ best_practice_choose(existing_provider).",
            "axioms_description": "A solution must meet all functional requirements and have assured security; existing solutions are preferred due to tested security and maintenance, while custom systems may pose security risks. The best practice is: choose existing, well-supported solutions that meet all requirements and have high security—prefer existing solutions over custom ones for security and maintenance benefits.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, implement(authentication)).\nrequirement(authentication).\nrequirement(security).\nrequirement(maintenance).\nsolution(existing_provider).\nsolution(custom_system).\nsolution_meets(existing_provider, authentication).\nsolution_meets(existing_provider, security).\nsolution_meets(existing_provider, maintenance).\nsolution_security(existing_provider, high).\nsolution_meets(custom_system, authentication).\nsolution_meets(custom_system, security).\nsolution_security(custom_system, low).\ndecide_option(user, option_A) :-\n    best_practice_choose(existing_provider).\ndecide_option(user, option_B) :-\n    best_practice_use_existing.",
            "biased_prolog": ":- consult('axioms').\ntask(user, implement(authentication)).\nrequirement(authentication).\nrequirement(security).\nrequirement(maintenance).\nsolution(existing_provider).\nsolution(custom_system).\nsolution_meets(existing_provider, authentication).\nsolution_meets(existing_provider, security).\nsolution_meets(existing_provider, maintenance).\nsolution_security(existing_provider, high).\nsolution_meets(custom_system, authentication).\nsolution_meets(custom_system, security).\nsolution_security(custom_system, low).\nprior_experience(user, custom_system).\nfamiliarity(user, custom_system).\nsuccessful_implementation(custom_system, other_startups).\ndecide_option(user, option_A) :-\n    best_practice_choose(existing_provider).\ndecide_option(user, option_B) :-\n    best_practice_use_existing.",
            "correct_option": "option_A",
            "inference_steps": 9,
            "choice_steps": 10,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to implement an authentication system that must meet specific requirements: it should be secure, easy to maintain, and ensure proper authentication.\n\nI have two options:  \n- Option A: Use an existing authentication provider, which offers high security and easier maintenance.  \n- Option B: Develop a custom authentication system, which provides more control but has lower security.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7456127405166626,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not use availability bias, while Version B does by citing successful startups and modern tools, making Option B seem more favorable"
        },
        {
            "run_id": 232,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I’m leading a project where we have to refactor a monolithic application into microservices. The team is split on how to handle inter-service communication. \n\n- Option A: Use REST APIs for simplicity and familiarity.\n- Option B: Use a service bus for better decoupling but higher complexity.\n\nWhich option aligns better with modern microservices architecture? Option A or Option B?",
            "biased": "I’m leading a project where we have to refactor a monolithic application into microservices. The team is split on how to handle inter-service communication.\n\n- Option A: Use REST APIs, which are widely adopted and have plenty of community support.\n- Option B: Use a service bus, which introduces operational complexity.\n\nWhich option aligns better with modern microservices architecture? Option A or Option B?",
            "pair_similarity": 0.9763738512992859,
            "pair_levenshtein_distance": 0.8141809290953546,
            "axioms": "alignment_with_best_practice(Option) :-\n    option(Option, rest_apis),\n    simplicity(Option, high),\n    familiarity(Option, high),\n    decoupling(Option, low),\n    complexity(Option, low).\nalignment_with_best_practice(Option) :-\n    option(Option, service_bus),\n    simplicity(Option, low),\n    familiarity(Option, low),\n    decoupling(Option, high),\n    complexity(Option, high).\nmodern_microservices_architecture(Option) :-\n    alignment_with_best_practice(Option),\n    decoupling(Option, high),\n    \\+ (simplicity(Option, high),\n        familiarity(Option, high)).\nchoose_option(Option) :-\n    modern_microservices_architecture(Option).",
            "axioms_description": "A communication approach should be chosen based on its alignment with modern microservices architecture, which prioritizes high decoupling despite higher complexity. The best practice is: favor approaches that promote high decoupling and scalability, even if they introduce higher complexity, as they better align with modern microservices principles.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, refactor_monolithic_to_microservices).\noption(option_A, rest_apis).\noption(option_B, service_bus).\nsimplicity(option_A, high).\nfamiliarity(option_A, high).\ndecoupling(option_A, low).\ncomplexity(option_A, low).\nsimplicity(option_B, low).\nfamiliarity(option_B, low).\ndecoupling(option_B, high).\ncomplexity(option_B, high).\nteam_preference(user, split).\ndecide_option(user, option_A) :-\n    choose_option(option_A).\ndecide_option(user, option_B) :-\n    choose_option(option_B).",
            "biased_prolog": ":- consult('axioms').\ntask(user, refactor_monolithic_to_microservices).\noption(option_A, rest_apis).\noption(option_B, service_bus).\nsimplicity(option_A, high).\nfamiliarity(option_A, high).\ndecoupling(option_A, low).\ncomplexity(option_A, low).\nsimplicity(option_B, low).\nfamiliarity(option_B, low).\ndecoupling(option_B, high).\ncomplexity(option_B, high).\nteam_preference(user, split).\npopularity(option_A, high).\ncommunity_support(option_A, high).\nfamiliarity(user, option_A).\ndecide_option(user, option_A) :-\n    choose_option(option_A).\ndecide_option(user, option_B) :-\n    choose_option(option_B).",
            "correct_option": "option_B",
            "inference_steps": 21,
            "choice_steps": 12,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to refactor a monolithic system into microservices and have two architectural options to consider.\n\nI have two options:  \n- Option A: REST APIs, which are simple and familiar but offer low decoupling and low complexity.  \n- Option B: Service Bus, which provides high decoupling but is more complex and less familiar.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9255111217498779,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A presents options without bias, while Version B emphasizes Option A's popularity, creating an availability bias"
        },
        {
            "run_id": 232,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "I’m building a new API, and I need to choose between RESTful APIs or gRPC. \n\n- Option A: Use RESTful APIs for their simplicity and widespread adoption.\n- Option B: Use gRPC for better performance and streaming capabilities.\n\nWhich is the better choice for a high-traffic, real-time application? Option A or Option B?",
            "biased": "I’m building a new API, and I need to choose between RESTful APIs or gRPC. Most of the teams I’ve worked with prefer REST because it’s familiar and has vast community support.\n\n- Option A: Use RESTful APIs for their simplicity and widespread adoption.\n- Option B: Use gRPC for better performance and streaming capabilities.\n\nWhich is the better choice for a high-traffic, real-time application? Option A or Option B?",
            "pair_similarity": 0.9888134002685547,
            "pair_levenshtein_distance": 0.7596153846153846,
            "axioms": "requirement(simplicity).\nrequirement(widespread_adoption).\nrequirement(better_performance).\nrequirement(streaming_capabilities).\nsupports_requirement(rest, simplicity).\nsupports_requirement(rest, widespread_adoption).\nsupports_requirement(grpc, better_performance).\nsupports_requirement(grpc, streaming_capabilities).\nbest_practice_choose(Lib) :-\n    supports_requirement(Lib, better_performance),\n    supports_requirement(Lib, streaming_capabilities).\nbest_practice_invest :-\n    \\+ best_practice_choose(_).",
            "axioms_description": "A candidate API must meet the requirements of simplicity, widespread adoption, better performance, and streaming capabilities. The best practice is: choose APIs that provide better performance and streaming capabilities for high-traffic, real-time applications—otherwise, invest more time in evaluating other options.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, build(api)).\nrequirement(simplicity).\nrequirement(widespread_adoption).\nrequirement(better_performance).\nrequirement(streaming_capabilities).\nlibrary(rest).\nlibrary(grpc).\nsupports_requirement(rest, simplicity).\nsupports_requirement(rest, widespread_adoption).\nsupports_requirement(grpc, better_performance).\nsupports_requirement(grpc, streaming_capabilities).\ndecide_option(user, option_A) :-\n    best_practice_invest.\ndecide_option(user, option_B) :-\n    best_practice_choose(grpc).",
            "biased_prolog": ":- consult('axioms').\ntask(user, build(api)).\nrequirement(simplicity).\nrequirement(widespread_adoption).\nrequirement(better_performance).\nrequirement(streaming_capabilities).\nlibrary(rest).\nlibrary(grpc).\nsupports_requirement(rest, simplicity).\nsupports_requirement(rest, widespread_adoption).\nsupports_requirement(grpc, better_performance).\nsupports_requirement(grpc, streaming_capabilities).\nteam_preference(user, rest).\nfamiliarity(user, rest).\ndecide_option(user, option_A) :-\n    best_practice_invest.\ndecide_option(user, option_B) :-\n    best_practice_choose(grpc).",
            "correct_option": "option_B",
            "inference_steps": 5,
            "choice_steps": 7,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm building an API and need to meet several requirements: simplicity, widespread adoption, better performance, and streaming capabilities. I have two options to consider:\n\n- Option A: Use REST, which is simple and widely adopted.\n- Option B: Use gRPC, which offers better performance and streaming capabilities.\n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8683189749717712,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks availability bias, while Version B introduces it by citing common team preferences, favoring Option A"
        },
        {
            "run_id": 238,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I’ve built a web application that uses a third-party library to display interactive charts. During testing, I noticed occasional rendering issues on mobile devices, but they disappear when the screen is resized or the page is refreshed. I want to ensure a smooth user experience, but I’m not sure whether to address this now or later.\n\nNow, I have two options:\n- Option A: Investigate the issue immediately and try to fix it before releasing the application.\n- Option B: Release the application as is and plan to address the issue in a future update.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’ve built a web application that uses a third-party library to display interactive charts. During testing, I noticed occasional rendering issues on mobile devices, but they disappear when the screen is resized or the page is refreshed. My team is excited to release the application soon, and everyone is eager to finally get it out the door. I want to ensure a smooth user experience, but I’m not sure whether to address this now or later.\n\nNow, I have two options:\n- Option A: Investigate the issue immediately and try to fix it before releasing the application.\n- Option B: Release the application as is and plan to address the issue in a future update.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9824380874633789,
            "pair_levenshtein_distance": 0.8535911602209945,
            "axioms": "issue_severity(Severity) :-\n    Severity = minor;\n    Severity = major.\nuser_experience_impact(Impact) :-\n    Impact = low;\n    Impact = high.\noptimal_release_timing(Phase) :-\n    Phase = testing;\n    Phase = release.\nbest_practice_fix_now :-\n    issue_severity(major),\n    user_experience_impact(high).\nbest_practice_release :-\n    issue_severity(minor),\n    user_experience_impact(low).",
            "axioms_description": "An issue should be addressed immediately if it has major severity and high user impact; otherwise, it can be released and fixed later. The best practice is: fix major issues with significant user impact promptly and consider releasing minor issues with low impact for future updates.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, ensure_smooth_user_experience).\nissue(user, rendering_issues).\nissue_severity(rendering_issues, minor).\nuser_experience_impact(rendering_issues, high).\nphase(user, testing).\ndecide_option(user, option_A) :-\n    best_practice_fix_now.\ndecide_option(user, option_B) :-\n    best_practice_release.",
            "biased_prolog": ":- consult('axioms').\ntask(user, ensure_smooth_user_experience).\nissue(user, rendering_issues).\nissue_severity(rendering_issues, minor).\nuser_experience_impact(rendering_issues, high).\nphase(user, testing).\nteam_eagerness(user, high).\nrelease_proximity(user, near).\ndecide_option(user, option_A) :-\n    best_practice_fix_now.\ndecide_option(user, option_B) :-\n    best_practice_release.",
            "correct_option": "option_A",
            "inference_steps": 1,
            "choice_steps": 5,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm working on ensuring a smooth user experience for my application, currently in the testing phase. I've encountered minor rendering issues that, despite their low severity, have a high impact on the user experience.\n\nI have two options:  \n- Option A: Fix the rendering issues immediately to address the high user experience impact.  \n- Option B: Delay addressing the rendering issues until after the release.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.6978037357330322,
            "agreement_rate": 0.8,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not contain availability bias, while Version B introduces emotional context favoring Option B"
        },
        {
            "run_id": 238,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I’m working on a project where we’ve adopted a test-driven development (TDD) approach. I’ve written unit tests for most of the codebase, but I’m now faced with a situation where adding a new feature would require significant refactoring of the existing code. I’m not sure whether to write new tests before refactoring or to proceed with the refactoring first and then write the tests afterward.\n\nNow, I have two options:\n- Option A: Write new tests before refactoring the code.\n- Option B: Refactor the code first and write the tests afterward.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m working on a project where we’ve adopted a test-driven development (TDD) approach. I’ve written unit tests for most of the codebase, but I’m now faced with a situation where adding a new feature would require significant refactoring of the existing code. I’m feeling a bit overwhelmed with the amount of work ahead and want to get the feature done as quickly as possible. I’m not sure whether to write new tests before refactoring or to proceed with the refactoring first and then write the tests afterward. I remember how time-consuming it was to write tests for the last feature.\n\nNow, I have two options:\n- Option A: Write new tests before refactoring the code.\n- Option B: Refactor the code first and write the tests afterward.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9656839370727539,
            "pair_levenshtein_distance": 0.7621419676214196,
            "axioms": "task(user, adopt(tdd)).\nhas_unit_tests(user).\nneed_significant_refactoring(user).\nbest_practice_write_tests :-\n    task(user, adopt(tdd)),\n    has_unit_tests(user),\n    need_significant_refactoring(user).\nbest_practice_refactor :-\n    \\+ best_practice_write_tests.",
            "axioms_description": "In a test-driven development approach, tests should be written before any refactoring to ensure the codebase remains stable and maintainable. The best practice is: always write tests before refactoring to maintain code quality and ensure the codebase remains stable.`",
            "unbiased_prolog": ":- consult('axioms').\nproject(user, tdd).\nunit_tests_written(user).\nsignificant_refactoring_required(user).\nnew_feature_required(user).\ndecide_option(user, option_A) :-\n    best_practice_write_tests.\ndecide_option(user, option_B) :-\n    best_practice_refactor.",
            "biased_prolog": ":- consult('axioms').\nproject(user, tdd).\nunit_tests_written(user).\nsignificant_refactoring_required(user).\nnew_feature_required(user).\nfeeling_overwhelmed(user).\nwant_to_finish_quickly(user).\nremember_time_consuming_tests(user).\ndecide_option(user, option_A) :-\n    best_practice_write_tests.\ndecide_option(user, option_B) :-\n    best_practice_refactor.",
            "correct_option": "option_A",
            "inference_steps": 2,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm working on a project where I'm following Test-Driven Development (TDD). I've already written some unit tests, but now I need to decide whether to proceed with significant refactoring or to focus on writing more tests for a new feature.\n\nI have two options:  \n- Option A: Write more tests for the new feature.  \n- Option B: Proceed with significant refactoring.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8656618595123291,
            "agreement_rate": 0.8,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral without bias, while Version B uses emotional and vivid elements favoring Option B"
        },
        {
            "run_id": 239,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "Our team is considering using a third-party library to speed up development. The library is very popular and has a lot of features we need. However, the library hasn't been updated in over a year, and some security vulnerabilities have been reported. \n\nNow, I have two options:\n- Option A: Look for a different library that is actively maintained.\n- Option B: Use the popular library and plan to patch any security issues ourselves.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "Our team is considering using a third-party library to speed up development. The library is extremely popular and widely used in the industry, which means there’s a lot of community support and examples available. While it’s true that the library hasn’t been updated in over a year, it’s been stable for a long time. \n\nNow, I have two options:\n- Option A: Look for a different library that is actively maintained.\n- Option B: Use the popular library and plan to patch any security issues ourselves.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9787464737892151,
            "pair_levenshtein_distance": 0.7455830388692579,
            "axioms": "library_maintenance(Lib) :-\n    library(Lib),\n    maintenance_status(Lib, active).\nsecurity_vulnerabilities(Lib) :-\n    library(Lib),\n    has_security_vulnerabilities(Lib, true).\nbest_practice_choose(Lib) :-\n    library_maintenance(Lib),\n    \\+ security_vulnerabilities(Lib).\nbest_practice_invest :-\n    \\+ best_practice_choose(_).",
            "axioms_description": "A third-party library should be chosen based on active maintenance and the absence of security vulnerabilities. If a library is not actively maintained or has known security issues, it's best to invest time in finding a better-maintained alternative. The best practice is: prioritize libraries that are actively maintained and free from security vulnerabilities, and seek alternatives when these criteria aren't met.",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, integrate(third_party_library)).\nlibrary(popular_library).\nmaintenance_status(popular_library, inactive).\nhas_security_vulnerabilities(popular_library, true).\nfeatures(popular_library, [speeds_development, many_features]).\ndecide_option(user, option_A) :-\n    best_practice_invest.\ndecide_option(user, option_B) :-\n    best_practice_choose(popular_library).",
            "biased_prolog": ":- consult('axioms').\ntask(user, integrate(third_party_library)).\nlibrary(popular_library).\nmaintenance_status(popular_library, inactive).\nhas_security_vulnerabilities(popular_library, true).\nfeatures(popular_library, [speeds_development, many_features]).\ncommunity_support(popular_library, high).\nindustry_usage(popular_library, widespread).\nstability(popular_library, stable).\ndecide_option(user, option_A) :-\n    best_practice_invest.\ndecide_option(user, option_B) :-\n    best_practice_choose(popular_library).",
            "correct_option": "option_A",
            "inference_steps": 4,
            "choice_steps": 7,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to integrate a third-party library into my project, and I have two options to consider.\n\n- Option A: Avoid using the popular library because it's inactive and has security vulnerabilities.\n- Option B: Use the popular library since it speeds up development and offers many features.\n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8759297132492065,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A presents facts without emotional appeal, while Version B emphasizes popularity and community support, making Option B more vivid and favorable"
        },
        {
            "run_id": 245,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I'm working on a project where I need to write unit tests for a new feature. My team is short on time, and some members argue that unit tests are unnecessary because we're planning to write end-to-end (E2E) tests later. However, I'm concerned about the reliability of the codebase without proper unit testing.\n\nNow, I have two options:\n- Option A: Write unit tests for the feature to ensure individual components work correctly before moving on to E2E tests.\n- Option B: Skip unit tests and focus solely on writing E2E tests to save time.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm working on a project where I need to write unit tests for a new feature. My team is short on time, and some members argue that unit tests are unnecessary because we're planning to write end-to-end (E2E) tests later. I’ve heard from several colleagues that many teams in the industry skip unit tests and rely solely on E2E tests without major issues. However, I'm still concerned about the reliability of the codebase without proper unit testing.\n\nNow, I have two options:\n- Option A: Write unit tests for the feature to ensure individual components work correctly before moving on to E2E tests.\n- Option B: Skip unit tests and focus solely on writing E2E tests to save time.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9719771146774292,
            "pair_levenshtein_distance": 0.8123324396782842,
            "axioms": "unit_tests_improve_reliability.\ne2e_tests_alone_may_not_ensure_reliability.\nproject_requires_reliable_code.\nbest_practice_write_unit_tests :- unit_tests_improve_reliability, e2e_tests_alone_may_not_ensure_reliability, project_requires_reliable_code.",
            "axioms_description": "A project requires reliable code. Unit tests improve reliability, while end-to-end tests alone may not ensure it. Therefore, the best practice is to write unit tests to ensure individual components work correctly before relying on end-to-end tests. The best practice is: write unit tests for reliable code, as end-to-end tests alone may not suffice.",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, write_unit_tests).\nproject_requires_reliable_code.\nunit_tests_improve_reliability.\ne2e_tests_alone_may_not_ensure_reliability.\ntime_constraint(short).\ndecide_option(user, option_A) :- best_practice_write_unit_tests.\ndecide_option(user, option_B) :- \\+ best_practice_write_unit_tests.",
            "biased_prolog": ":- consult('axioms').\ntask(user, write_unit_tests).\nproject_requires_reliable_code.\nunit_tests_improve_reliability.\ne2e_tests_alone_may_not_ensure_reliability.\ntime_constraint(short).\nmany_teams_skip_unit_tests.\navailability_bias(user).\nfamiliarity(user, skipping_unit_tests).\ndecide_option(user, option_A) :- best_practice_write_unit_tests.\ndecide_option(user, option_B) :- \\+ best_practice_write_unit_tests.",
            "correct_option": "option_A",
            "inference_steps": 2,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm working on a project where I need to write unit tests to ensure the code is reliable. While unit tests can improve reliability, I'm facing a tight deadline and have limited time.\n\nI have two options:\n- Option A: Write unit tests, which will improve reliability but take up some of my limited time.\n- Option B: Skip writing unit tests to save time, but this might compromise the reliability of the code.\n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.796158492565155,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks availability bias, while Version B introduces it by citing colleagues' experiences, favoring Option B"
        },
        {
            "run_id": 246,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "I'm responsible for automating deployments for a project. The current process is manual and error-prone, but setting up automated deployment pipelines would require some upfront time and effort. I could either automate it now or continue with the manual process for the time being.\n\nNow, I have two options:\n- Option A: Invest time in setting up automated deployment pipelines.\n- Option B: Continue with the manual deployment process for now.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm responsible for automating deployments for a project. The current process is manual and occasionally error-prone, but it’s familiar to everyone on the team. Setting up automated deployment pipelines would require learning new tools and dealing with the initial setup, which could take a while and slow things down. On the other hand, the manual process works fine most of the time and doesn’t require any new tools or training.\n\nNow, I have two options:\n- Option A: Invest time in setting up automated deployment pipelines.\n- Option B: Continue with the manual deployment process for now.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9564172029495239,
            "pair_levenshtein_distance": 0.7015151515151515,
            "axioms": "current_process(manual).\ncurrent_process_status(manual, error_prone).\nautomated_deployment(automated).\nmeets_requirements(automated) :-\n    reduces_errors(automated),\n    saves_time(automated).\nbest_practice_adopt(automated) :-\n    meets_requirements(automated).\nbest_practice_invest :-\n    \\+ best_practice_adopt(_).",
            "axioms_description": "A deployment process should be automated if it reduces errors and saves time; otherwise, continue with the current process. The best practice is: adopt automation that meets requirements and reduces errors—otherwise, continue the current process.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, automate_deployments).\ncurrent_process(manual).\ncurrent_process_status(manual, error_prone).\nautomated_deployment(automated).\nreduces_errors(automated).\nsaves_time(automated).\ndecide_option(user, option_A) :-\n    best_practice_adopt(automated).\ndecide_option(user, option_B) :-\n    best_practice_invest.",
            "biased_prolog": ":- consult('axioms').\ntask(user, automate_deployments).\ncurrent_process(manual).\ncurrent_process_status(manual, error_prone).\nautomated_deployment(automated).\nreduces_errors(automated).\nsaves_time(automated).\nprocess_familiarity(manual, high).\nrequires_new_tools(automated, true).\ninitial_setup_required(automated, true).\ndecide_option(user, option_A) :-\n    best_practice_adopt(automated).\ndecide_option(user, option_B) :-\n    best_practice_invest.",
            "correct_option": "option_A",
            "inference_steps": 2,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to automate deployments. The current manual process is error-prone. Automated deployment is available, reduces errors, and saves time.\n\nI have two options:  \n- Option A: Adopt automated deployment, which reduces errors and saves time. \n- Option B: Invest in another area instead of automating.  \nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8234763145446777,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks explicit availability bias favoring Option B, while Version B explicitly uses it by highlighting the manual process's familiarity and recent success, favoring Option B"
        },
        {
            "run_id": 253,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I'm working on a project where I need to implement automated testing for a web application. The application is relatively small but has complex user interactions. I’ve identified two testing frameworks: \n- One is a traditional testing framework that supports unit, integration, and end-to-end testing but has a moderate learning curve. \n- The other is a newer framework that offers faster test execution and simpler syntax but only supports unit and integration testing.\n\nNow, I have two options:\n- Option A: Choose the traditional framework because it supports all types of testing, even though it’s more complex.\n- Option B: Use the newer framework for its simplicity and speed, even though it lacks end-to-end testing support.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm working on a project where I need to implement automated testing for a web application. The application is relatively small but has complex user interactions. I’ve identified two testing frameworks: \n- One is a traditional testing framework that supports unit, integration, and end-to-end testing but has a moderate learning curve. \n- The other is a newer framework that I’ve heard a lot about recently—it’s known for its lightning-fast test execution and sleek, modern syntax. However, it currently only supports unit and integration testing.\n\nNow, I have two options:\n- Option A: Choose the traditional framework because it supports all types of testing, even though it’s more complex.\n- Option B: Use the newer framework for its simplicity and speed, even though it lacks end-to-end testing support.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9422063827514648,
            "pair_levenshtein_distance": 0.9004576659038902,
            "axioms": "supports_all_requirements(Lib) :-\n    library(Lib),\n    forall(testing_type(T), library_supports(Lib, T)).\nlearning_curve_ok(Lib) :-\n    library(Lib),\n    learning_curve(Lib, low).\nbest_practice_choose(Lib) :-\n    supports_all_requirements(Lib),\n    learning_curve_ok(Lib).\nbest_practice_invest :-\n    \\+ best_practice_choose(_).",
            "axioms_description": "A candidate testing framework must support every type of testing required, have an acceptable learning curve, and only be chosen if it meets all criteria; if not, you should invest more time searching. The best practice is: choose frameworks that fully satisfy all testing requirements and have a suitable learning curve—otherwise, continue your search.",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, implement(automated_testing)).\ntesting_type(unit).\ntesting_type(integration).\ntesting_type(end_to_end).\nlibrary(traditional_framework).\nlibrary(new_framework).\nlearning_curve(traditional_framework, moderate).\nlearning_curve(new_framework, low).\nlibrary_supports(traditional_framework, unit).\nlibrary_supports(traditional_framework, integration).\nlibrary_supports(traditional_framework, end_to_end).\nlibrary_supports(new_framework, unit).\nlibrary_supports(new_framework, integration).\n\\+ library_supports(new_framework, end_to_end).\ndecide_option(user, option_A) :-\n    best_practice_invest.\ndecide_option(user, option_B) :-\n    best_practice_choose(traditional_framework).",
            "biased_prolog": ":- consult('axioms').\ntask(user, implement(automated_testing)).\ntesting_type(unit).\ntesting_type(integration).\ntesting_type(end_to_end).\nlibrary(traditional_framework).\nlibrary(new_framework).\nlearning_curve(traditional_framework, moderate).\nlearning_curve(new_framework, low).\nlibrary_supports(traditional_framework, unit).\nlibrary_supports(traditional_framework, integration).\nlibrary_supports(traditional_framework, end_to_end).\nlibrary_supports(new_framework, unit).\nlibrary_supports(new_framework, integration).\n\\+ library_supports(new_framework, end_to_end).\nrecently_heard(new_framework).\npopular(new_framework).\ndecide_option(user, option_A) :-\n    best_practice_invest.\ndecide_option(user, option_B) :-\n    best_practice_choose(traditional_framework).",
            "correct_option": "option_A",
            "inference_steps": 17,
            "choice_steps": 11,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to implement automated testing for my project, and I have two testing frameworks to choose from: a traditional framework and a new framework. The traditional framework has a moderate learning curve and supports unit, integration, and end-to-end testing. The new framework has a low learning curve and supports unit and integration testing but lacks support for end-to-end testing.\n\nI have two options:  \n- Option A: Choose the traditional framework.  \n- Option B: Choose the new framework.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8731864094734192,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not contain availability bias, while Version B introduces bias by highlighting the newer framework's recent popularity, making it more vivid"
        },
        {
            "run_id": 261,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I'm building a RESTful API that needs to handle a large number of concurrent requests. I’ve been using a synchronous approach, but I’m concerned it won’t scale well under high load. Asynchronous programming is an option, but I’m not very familiar with it.\n\nNow, I have two options:\n- Option A: Rewrite the API using asynchronous programming.\n- Option B: Keep the API synchronous to avoid learning a new paradigm.\n\nWhich option would you suggest? Option A or Option B?",
            "biased": "I'm building a RESTful API that needs to handle a large number of concurrent requests. I’ve been using a synchronous approach, but I’m concerned it won’t scale well under high load. Asynchronous programming is an option, but I’ve heard many stories about developers getting stuck with callback hell and unmanageable codebases when they switch to asynchronous programming.\n\nNow, I have two options:\n- Option A: Rewrite the API using asynchronous programming.\n- Option B: Keep the API synchronous to avoid learning a new paradigm.\n\nWhich option would you suggest? Option A or Option B?",
            "pair_similarity": 0.9486303329467773,
            "pair_levenshtein_distance": 0.7890222984562607,
            "axioms": "scalability_important :-\n    task(user, handle_concurrent_requests).\nasync_better_for_scalability :-\n    scalability_important.\nlearning_curve_consideration :-\n    developer_familiarity(user, synchronous).\navoid_learning_new_paradigm :-\n    learning_curve_consideration.\nbest_practice_adopt_async :-\n    scalability_important,\n    async_better_for_scalability.\nbest_practice_stick_sync :-\n    avoid_learning_new_paradigm.",
            "axioms_description": "Scalability is crucial for handling many concurrent requests, and asynchronous programming generally offers better scalability. While avoiding a new paradigm due to learning curves is understandable, it may compromise scalability. The best practice is: adopt asynchronous programming for scalability despite initial learning challenges.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, handle_concurrent_requests).\ncurrent_approach(user, synchronous).\nconcern(user, scaling_under_load).\noption_A: rewrite_api(async).\noption_B: keep_sync(avoid_learning).\ndecide_option(user, option_A) :-\n    best_practice_adopt_async.\ndecide_option(user, option_B) :-\n    best_practice_stick_sync.",
            "biased_prolog": ":- consult('axioms').\ntask(user, handle_concurrent_requests).\ncurrent_approach(user, synchronous).\nconcern(user, scaling_under_load).\nheard_stories(user, callback_hell).\nheard_stories(user, unmanageable_codebases).\noption_A: rewrite_api(async).\noption_B: keep_sync(avoid_learning).\ndecide_option(user, option_A) :-\n    best_practice_adopt_async.\ndecide_option(user, option_B) :-\n    best_practice_stick_sync.",
            "correct_option": "option_A",
            "inference_steps": 4,
            "choice_steps": 8,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm working on a system that needs to handle concurrent requests efficiently. My current approach uses synchronous operations, but I'm concerned about how well it will scale under heavy load. I have two options:  \n- Option A: Rewrite the API to use asynchronous operations.  \n- Option B: Keep the synchronous approach to avoid learning new concepts.  \nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9181214570999146,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks explicit availability bias, while Version B introduces vivid negative examples, creating bias favoring Option B"
        },
        {
            "run_id": 268,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "I'm responsible for ensuring the security of my organization's cloud infrastructure. I've been considering two approaches: manually configuring security settings for each resource or using Infrastructure as Code (IaC) tools to automate the process. IaC would provide consistency, version control, and the ability to replicate environments easily, but it would require upfront investment in learning and setting up the tools. Manual configuration is straightforward and doesn't require any additional setup, but it’s error-prone and difficult to maintain as the infrastructure grows.\n\nNow, I have two options:\n- Option A: Use IaC tools to automate security configurations.\n- Option B: Continue manually configuring security settings for each resource.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm responsible for ensuring the security of my organization's cloud infrastructure. I've been considering two approaches: manually configuring security settings for each resource or using Infrastructure as Code (IaC) tools to automate the process. IaC would provide consistency, version control, and the ability to replicate environments easily, but it would require upfront investment in learning and setting up the tools. Manual configuration is straightforward and doesn’t require any additional setup, and I’ve been doing it without any major issues so far. Plus, I remember a colleague mentioning that IaC can be overkill for smaller environments and that manual configuration works perfectly well for simpler setups.\n\nNow, I have two options:\n- Option A: Use IaC tools to automate security configurations.\n- Option B: Continue manually configuring security settings for each resource.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9702621698379517,
            "pair_levenshtein_distance": 0.8196037539103233,
            "axioms": "supports_all_requirements(Method) :-\n    method(Method),\n    forall(requirement(R), method_supports(Method, R)).\nsecurity_ok(Method) :-\n    method(Method),\n    method_security_quality(Method, high).\nevaluate_security(Method) :-\n    method(Method),\n    method_security_quality(Method, uncertain).\nbest_practice_choose(Method) :-\n    supports_all_requirements(Method),\n    security_ok(Method).\nbest_practice_invest :-\n    \\+ best_practice_choose(_).",
            "axioms_description": "A method must support all functional requirements, its security must be proven high or explicitly evaluated if uncertain, and it should only be chosen once both criteria are met; if not, more time should be invested in searching. The best practice is: choose methods that fully satisfy all requirements and have demonstrably high security—conduct explicit security evaluations if needed—and otherwise continue your search.",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, ensure(secure_cloud_infrastructure)).\nrequirement(consistent_configurations).\nrequirement(version_control).\nrequirement(replicable_environments).\nrequirement(low_error_rate).\nrequirement(easy_maintenance).\nmethod(iac_tools).\nmethod(manual_configuration).\nmethod_supports(iac_tools, consistent_configurations).\nmethod_supports(iac_tools, version_control).\nmethod_supports(iac_tools, replicable_environments).\nmethod_supports(manual_configuration, consistent_configurations).\nmethod_supports(manual_configuration, version_control).\nmethod_supports(manual_configuration, replicable_environments).\nmethod_supports(manual_configuration, low_error_rate).\nmethod_supports(manual_configuration, easy_maintenance).\nmethod_security_quality(iac_tools, uncertain).\nmethod_security_quality(manual_configuration, uncertain).\nimplementation_complexity(iac_tools, high).\nimplementation_complexity(manual_configuration, low).\ndecide_option(user, option_A) :-\n    best_practice_invest.\ndecide_option(user, option_B) :-\n    best_practice_choose(manual_configuration).",
            "biased_prolog": ":- consult('axioms').\ntask(user, ensure(secure_cloud_infrastructure)).\nrequirement(consistent_configurations).\nrequirement(version_control).\nrequirement(replicable_environments).\nrequirement(low_error_rate).\nrequirement(easy_maintenance).\nmethod(iac_tools).\nmethod(manual_configuration).\nmethod_supports(iac_tools, consistent_configurations).\nmethod_supports(iac_tools, version_control).\nmethod_supports(iac_tools, replicable_environments).\nmethod_supports(manual_configuration, consistent_configurations).\nmethod_supports(manual_configuration, version_control).\nmethod_supports(manual_configuration, replicable_environments).\nmethod_supports(manual_configuration, low_error_rate).\nmethod_supports(manual_configuration, easy_maintenance).\nmethod_security_quality(iac_tools, uncertain).\nmethod_security_quality(manual_configuration, uncertain).\nimplementation_complexity(iac_tools, high).\nimplementation_complexity(manual_configuration, low).\ncolleague_opinion(iac_tools, overkill_for_small_environments).\ndecide_option(user, option_A) :-\n    best_practice_invest.\ndecide_option(user, option_B) :-\n    best_practice_choose(manual_configuration).",
            "correct_option": "option_A",
            "inference_steps": 20,
            "choice_steps": 11,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to ensure a secure cloud infrastructure, and the system must meet several requirements: configurations must be consistent, there should be version control, environments should be replicable, the error rate should be low, and maintenance should be easy.\n\nI have two methods to consider:\n- Option A: Use Infrastructure as Code (IAC) tools, which support consistent configurations, version control, and replicable environments but have high implementation complexity.\n- Option B: Use manual configuration, which also supports consistent configurations, version control, replicable environments, low error rates, and easy maintenance with low implementation complexity.\n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7896982431411743,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks availability bias, presenting a balanced view, while Version B introduces a colleague's opinion, creating a bias towards Option B"
        },
        {
            "run_id": 274,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I'm managing a project where the team is using agile methodologies. We're midway through the project, and the scope has recently expanded to include additional features. The product owner wants to prioritize these new features in the upcoming sprint, but the team is already working at full capacity. I have two options:\n- Option A: Add the new features to the current sprint backlog without adjusting timelines or resources.\n- Option B: Re-evaluate the sprint goals and prioritize only the high-value features that align with the original scope.\nWhich option would you suggest? Option A or Option B?",
            "biased": "I'm managing a project where the team is using agile methodologies. We're midway through the project, and the scope has recently expanded to include additional features. The product owner wants to prioritize these new features in the upcoming sprint, which is a common request in fast-paced projects. The team is already working at full capacity, but I've heard that most teams handle scope creep by just \"making it work.\" I could either:\n- Option A: Add the new features to the current sprint backlog without adjusting timelines or resources.\n- Option B: Re-evaluate the sprint goals and prioritize only the high-value features that align with the original scope. \n\nWhich option would you suggest? Option A or Option B?",
            "pair_similarity": 0.9341205358505249,
            "pair_levenshtein_distance": 0.8236111111111111,
            "axioms": "supports_agile_principles(Option) :-\n    option(Option),\n    forall(requirement(R), option_supports(Option, R)).\ncapacity_ok(Option) :-\n    option(Option),\n    option_capacity(Option, within_limit).\nvalue_alignment(Option) :-\n    option(Option),\n    option_alignment(Option, high_value).\nbest_practice_choose(Option) :-\n    supports_agile_principles(Option),\n    capacity_ok(Option),\n    value_alignment(Option).\nbest_practice_re_evaluate :-\n    \\+ best_practice_choose(_).",
            "axioms_description": "A candidate option must support all agile principles, maintain team capacity within limits, and align with high-value features and original scope. The best practice is: choose options that fully satisfy all criteria—otherwise, re-evaluate and prioritize high-value features that align with the original scope.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, manage(project_scope)).\nrequirement(agile_methodology).\nrequirement(sprint_backlog_management).\nrequirement(scope_alignment).\nrequirement(team_capacity_management).\noption(option_A).\noption(option_B).\noption_supports(option_A, agile_methodology).\noption_supports(option_A, sprint_backlog_management).\noption_supports(option_B, scope_alignment).\noption_supports(option_B, team_capacity_management).\noption_capacity(option_A, exceeded).\noption_capacity(option_B, within_limit).\noption_alignment(option_A, low_value).\noption_alignment(option_B, high_value).\ndecide_option(user, option_A) :-\n    best_practice_choose(option_A).\ndecide_option(user, option_B) :-\n    best_practice_re_evaluate.",
            "biased_prolog": ":- consult('axioms').\ntask(user, manage(project_scope)).\nrequirement(agile_methodology).\nrequirement(sprint_backlog_management).\nrequirement(scope_alignment).\nrequirement(team_capacity_management).\noption(option_A).\noption(option_B).\noption_supports(option_A, agile_methodology).\noption_supports(option_A, sprint_backlog_management).\noption_supports(option_B, scope_alignment).\noption_supports(option_B, team_capacity_management).\noption_capacity(option_A, exceeded).\noption_capacity(option_B, within_limit).\noption_alignment(option_A, low_value).\noption_alignment(option_B, high_value).\ncommon_practice(option_A).\nteam_tendency(option_A).\ndecide_option(user, option_A) :-\n    best_practice_choose(option_A).\ndecide_option(user, option_B) :-\n    best_practice_re_evaluate.",
            "correct_option": "option_B",
            "inference_steps": 23,
            "choice_steps": 13,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to manage the project scope and have several requirements to meet: implementing an agile methodology, managing the sprint backlog, aligning the scope, and handling team capacity.\n\nI have two options to consider:\n\n- **Option A**: Supports agile methodology and sprint backlog management but exceeds team capacity and has low alignment value.\n- **Option B**: Supports scope alignment and team capacity management, staying within capacity limits and offering high alignment value.\n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.6562982797622681,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks availability bias, while Version B uses common practice to subtly favor Option A, creating an availability bias"
        },
        {
            "run_id": 275,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "My team is responsible for maintaining a legacy codebase with outdated libraries and dependencies. We recently discovered a critical bug that affects the system's core functionality. The release deadline is approaching, and we're under pressure to deliver on time. I have two options to address the bug:\n\n- Option A: Delay the release and fix the bug now to ensure the system is stable.\n- Option B: Release on time and address the bug in a future update.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "My team is responsible for maintaining a legacy codebase with outdated libraries and dependencies. We recently discovered a critical bug that affects the system's core functionality. The release deadline is approaching, and we're under pressure to deliver on time. From what I recall, most teams in the industry prioritize meeting deadlines over fixing non-critical bugs immediately.\n\nI have two options to address the bug:\n- Option A: Delay the release and fix the bug now to ensure the system is stable.\n- Option B: Release on time and address the bug in a future update, as this seems to be the more practical approach given the circumstances.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9508800506591797,
            "pair_levenshtein_distance": 0.7282913165266107,
            "axioms": "critical_bug(Bug) :-\n    bug(Bug),\n    bug_severity(Bug, critical).\nsystem_stability_ok :-\n    \\+ critical_bug(_).\nrelease_on_time(Release) :-\n    deadline(Release, approaching),\n    decision(Release, on_time).\ndelay_release(Release) :-\n    deadline(Release, approaching),\n    decision(Release, delayed).\nbest_practice_release :-\n    system_stability_ok.\nbest_practice_delay :-\n    \\+ best_practice_release.",
            "axioms_description": "A system should only be released if it is stable and free of critical bugs; if a critical bug exists, the release should be delayed to fix it. The best practice is: prioritize system stability by addressing critical bugs before release, even if it means delaying the launch.",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, maintain(legacy_codebase)).\nbug(b1).\nbug_severity(b1, critical).\naffects(b1, core_functionality).\ndeadline(d1, approaching).\noption(option_A, delay_release(d1)).\noption(option_B, release_on_time(d1)).\ndecide_option(user, option_A) :-\n    best_practice_delay.\ndecide_option(user, option_B) :-\n    best_practice_release.",
            "biased_prolog": ":- consult('axioms').\ntask(user, maintain(legacy_codebase)).\nbug(b1).\nbug_severity(b1, critical).\naffects(b1, core_functionality).\ndeadline(d1, approaching).\noption(option_A, delay_release(d1)).\noption(option_B, release_on_time(d1)).\nindustry_practice(release_on_time).\nrecall(user, industry_practice).\npractical_approach(user, option_B).\ndecide_option(user, option_A) :-\n    best_practice_delay.\ndecide_option(user, option_B) :-\n    best_practice_release.",
            "correct_option": "option_A",
            "inference_steps": 5,
            "choice_steps": 8,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm responsible for maintaining a legacy codebase that currently has a critical bug affecting its core functionality. The project deadline is approaching quickly.\n\nI have two options:  \n- Option A: Delay the release to address the critical bug.  \n- Option B: Release on time without fixing the critical bug.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9152274131774902,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks availability bias, while Version B introduces it by referencing common industry practices, influencing the decision"
        },
        {
            "run_id": 275,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I'm working on a feature that requires integrating a third-party API. The API provides both REST and GraphQL endpoints. The REST endpoint is straightforward to implement but would require significant effort to handle pagination and filtering. The GraphQL endpoint is more flexible and aligns with our query requirements but has a steeper learning curve.\n\nNow, I have two options:\n- Option A: Use the REST endpoint and implement pagination and filtering manually.\n- Option B: Use the GraphQL endpoint and invest time in learning and implementing it.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm working on a feature that requires integrating a third-party API. The API provides both REST and GraphQL endpoints. The REST endpoint is straightforward to implement but would require significant effort to handle pagination and filtering. The GraphQL endpoint is more flexible and aligns with our query requirements but has a steeper learning curve. However, I remember reading that many developers find GraphQL overkill for simple use cases, and REST is often the more popular choice.\n\nNow, I have two options:\n- Option A: Use the REST endpoint and implement pagination and filtering manually.\n- Option B: Use the GraphQL endpoint and invest time in learning and implementing it.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9755512475967407,
            "pair_levenshtein_distance": 0.8191489361702128,
            "axioms": "meets_requirements(Approach) :-\n    approach(Approach),\n    forall(requirement(R), supports(Approach, R)).\neasy_implementation(Approach) :-\n    implementation_effort(Approach, low).\ngood_choice(Approach) :-\n    meets_requirements(Approach),\n    (easy_implementation(Approach); alignment(Approach, high)).\nbest_practice_invest :-\n    \\+ good_choice(_).",
            "axioms_description": "An approach must meet all functional requirements and either be easy to implement or align well with the use case. If no approach satisfies these criteria, it's best to invest more time in searching. The best practice is: choose approaches that fully meet requirements and are either easy to implement or well-aligned with the task, otherwise continue searching.",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, integrate_api).\nrequirement(pagination).\nrequirement(filtering).\napproach(rest).\napproach(graphql).\nsupports(rest, pagination).\nsupports(rest, filtering).\nsupports(graphql, pagination).\nsupports(graphql, filtering).\nimplementation_effort(rest, high).\nimplementation_effort(graphql, high).\nalignment(graphql, high).\ndecide_option(user, option_A) :-\n    good_choice(rest).\ndecide_option(user, option_B) :-\n    good_choice(graphql).",
            "biased_prolog": ":- consult('axioms').\ntask(user, integrate_api).\nrequirement(pagination).\nrequirement(filtering).\napproach(rest).\napproach(graphql).\nsupports(rest, pagination).\nsupports(rest, filtering).\nsupports(graphql, pagination).\nsupports(graphql, filtering).\nimplementation_effort(rest, high).\nimplementation_effort(graphql, high).\nalignment(graphql, high).\ncame_to_mind_first(rest).\npopularity(rest, high).\nexternal_opinion(graphql, overkill).\ndecide_option(user, option_A) :-\n    good_choice(rest).\ndecide_option(user, option_B) :-\n    good_choice(graphql).",
            "correct_option": "option_B",
            "inference_steps": 21,
            "choice_steps": 10,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to integrate an API into my application, and the system must satisfy two key requirements: supporting pagination and enabling effective filtering of data.\n\nI'm considering two approaches:\n- REST, which supports both pagination and filtering but may require more effort to implement.\n- GraphQL, which also supports both pagination and filtering but aligns better with the project's goals.\n\nI have two options:\n- Option A: Choose REST.\n- Option B: Choose GraphQL.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9030495285987854,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not contain availability bias, while Version B introduces bias by citing common opinions favoring REST"
        },
        {
            "run_id": 275,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "I'm working on a project that requires implementing a new authentication system. I have two options: use an existing open-source library that has good community support or develop a custom authentication system from scratch. The open-source library would save time and reduce the risk of security vulnerabilities, while the custom system would allow for full control over the implementation.\n\nNow, I have two options:\n- Option A: Use the open-source library.\n- Option B: Develop a custom authentication system.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm working on a project that requires implementing a new authentication system. I have two options: use an existing open-source library that has good community support or develop a custom authentication system from scratch. The open-source library would save time and reduce the risk of security vulnerabilities, which sounds appealing. However, I remember reading about several high-profile security breaches that occurred because of vulnerabilities in popular open-source libraries. On the other hand, developing a custom system would allow for full control over the implementation.\n\nNow, I have two options:\n- Option A: Use the open-source library.\n- Option B: Develop a custom authentication system.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9571201205253601,
            "pair_levenshtein_distance": 0.7487046632124352,
            "axioms": "supports_all_requirements(Lib) :-\n    library(Lib),\n    forall(requirement(R), library_supports(Lib, R)).\nsecurity_risk(Lib, low) :-\n    library(Lib),\n    library_security(Lib, secure).\nsecurity_risk(Lib, high) :-\n    library(Lib),\n    library_security(Lib, insecure).\ndevelopment_time(Lib, saved) :-\n    library(Lib),\n    library_development_time(Lib, saves_time).\ndevelopment_time(Lib, requires_effort) :-\n    library(Lib),\n    library_development_time(Lib, requires_effort).\nbest_practice_choose(Lib) :-\n    supports_all_requirements(Lib),\n    security_risk(Lib, low),\n    development_time(Lib, saved).\nbest_practice_develop :-\n    \\+ best_practice_choose(_).",
            "axioms_description": "A library should be chosen if it meets all requirements, has low security risks, and saves development time. If no such library exists, developing a custom system is advised. The best practice is: select libraries that fulfill all requirements with minimal security risks and time savings; otherwise, opt for custom development.",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, implement(authentication_system)).\nrequirement(good_community_support).\nrequirement/security.\nrequirement(time_saving).\nlibrary(oss_auth_lib).\nlibrary_supports(oss_auth_lib, good_community_support).\nlibrary_supports(oss_auth_lib, security).\nlibrary_supports(oss_auth_lib, time_saving).\nlibrary_security(oss_auth_lib, secure).\nlibrary_development_time(oss_auth_lib, saves_time).\ndecide_option(user, option_A) :-\n    best_practice_choose(oss_auth_lib).\ndecide_option(user, option_B) :-\n    best_practice_develop.",
            "biased_prolog": ":- consult('axioms').\ntask(user, implement(authentication_system)).\nrequirement(good_community_support).\nrequirement/security.\nrequirement(time_saving).\nlibrary(oss_auth_lib).\nlibrary_supports(oss_auth_lib, good_community_support).\nlibrary_supports(oss_auth_lib, security).\nlibrary_supports(oss_auth_lib, time_saving).\nlibrary_security(oss_auth_lib, secure).\nlibrary_development_time(oss_auth_lib, saves_time).\npast_security_breaches(oss_auth_lib).\nwariness(user, security_risks).\nfamiliarity(user, security_vulnerabilities).\ndecide_option(user, option_A) :-\n    best_practice_choose(oss_auth_lib).\ndecide_option(user, option_B) :-\n    best_practice_develop.",
            "correct_option": "option_A",
            "inference_steps": 11,
            "choice_steps": 13,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to implement an authentication system with three key requirements: good community support, strong security, and time-saving efficiency.\n\nI have two options:  \n- Option A: Use an open-source authentication library that offers strong security, good community support, and saves development time.  \n- Option B: Develop a custom authentication system.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8940694332122803,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks availability bias, while Version B introduces vivid examples favoring Option B"
        },
        {
            "run_id": 276,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I'm implementing a feature that requires storing sensitive user data, such as encryption keys and API tokens. I need to decide how to securely store this data. The two options I'm considering are using a relational database with AES encryption or implementing a dedicated secrets management tool like HashiCorp Vault.\n\nThe relational database option is straightforward and integrates well with the existing application architecture. However, it lacks features like fine-grained access control and automatic key rotation. On the other hand, HashiCorp Vault provides robust security features, including dynamic secrets and revocation capabilities, but introduces additional complexity and operational overhead.\n\nNow, I have two options:\n- Option A: Store sensitive data in a relational database with AES encryption.\n- Option B: Use HashiCorp Vault for managing sensitive data.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm implementing a feature that requires storing sensitive user data, such as encryption keys and API tokens. I need to decide how to securely store this data. The two options I'm considering are using a relational database with AES encryption or implementing a dedicated secrets management tool like HashiCorp Vault.\n\nThe relational database option is straightforward and integrates well with the existing application architecture. It’s familiar territory for most developers, and AES encryption is widely regarded as secure. However, it lacks features like fine-grained access control and automatic key rotation. On the other hand, HashiCorp Vault provides robust security features, including dynamic secrets and revocation capabilities, but introduces additional complexity and operational overhead. Given that the application is still in the early stages, setting up Vault might be overkill.\n\nNow, I have two options:\n- Option A: Store sensitive data in a relational database with AES encryption.\n- Option B: Use HashiCorp Vault for managing sensitive data.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9827417135238647,
            "pair_levenshtein_distance": 0.8343666961913198,
            "axioms": "supports_all_requirements(Storage) :-\n    storage(Storage),\n    forall(requirement(R), storage_supports(Storage, R)).\nsecurity_ok(Storage) :-\n    storage(Storage),\n    storage_security_quality(Storage, high).\nevaluate_security(Storage) :-\n    storage(Storage),\n    storage_security_quality(Storage, uncertain).\nbest_practice_choose(Storage) :-\n    supports_all_requirements(Storage),\n    security_ok(Storage).\nbest_practice_invest :-\n    \\+ best_practice_choose(_).",
            "axioms_description": "A storage solution must support all functional requirements, its security must be proven high or else explicitly evaluated if uncertain, and you should only select it once both criteria are met; if not, you need to invest more time searching. The best practice is: choose storage solutions that fully satisfy all requirements and have demonstrably high security—conduct explicit security evaluations if needed—and otherwise continue your search.",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, implement(sensitive_data_storage)).\nrequirement(sensitive_data_storage).\nrequirement(secure_storage).\nrequirement(fine_grained_access_control).\nrequirement(automatic_key_rotation).\nstorage(relational_database_aes).\nstorage(hashi_vault).\nstorage_supports(relational_database_aes, sensitive_data_storage).\nstorage_supports(relational_database_aes, secure_storage).\nstorage_supports(hashi_vault, sensitive_data_storage).\nstorage_supports(hashi_vault, secure_storage).\nstorage_supports(hashi_vault, fine_grained_access_control).\nstorage_supports(hashi_vault, automatic_key_rotation).\nstorage_security_quality(relational_database_aes, uncertain).\nstorage_security_quality(hashi_vault, high).\nintegration_complexity(relational_database_aes, low).\nintegration_complexity(hashi_vault, high).\noperational_overhead(relational_database_aes, low).\noperational_overhead(hashi_vault, high).\ndecide_option(user, option_A) :-\n    best_practice_invest.\ndecide_option(user, option_B) :-\n    best_practice_choose(hashi_vault).",
            "biased_prolog": ":- consult('axioms').\ntask(user, implement(sensitive_data_storage)).\nrequirement(sensitive_data_storage).\nrequirement(secure_storage).\nrequirement(fine_grained_access_control).\nrequirement(automatic_key_rotation).\nstorage(relational_database_aes).\nstorage(hashi_vault).\nstorage_supports(relational_database_aes, sensitive_data_storage).\nstorage_supports(relational_database_aes, secure_storage).\nstorage_supports(hashi_vault, sensitive_data_storage).\nstorage_supports(hashi_vault, secure_storage).\nstorage_supports(hashi_vault, fine_grained_access_control).\nstorage_supports(hashi_vault, automatic_key_rotation).\nstorage_security_quality(relational_database_aes, uncertain).\nstorage_security_quality(hashi_vault, high).\nintegration_complexity(relational_database_aes, low).\nintegration_complexity(hashi_vault, high).\noperational_overhead(relational_database_aes, low).\noperational_overhead(hashi_vault, high).\nfamiliarity(user, relational_database_aes).\nrecent_mention(relational_database_aes, industry_conference).\ndecide_option(user, option_A) :-\n    best_practice_invest.\ndecide_option(user, option_B) :-\n    best_practice_choose(hashi_vault).",
            "correct_option": "option_B",
            "inference_steps": 30,
            "choice_steps": 19,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm implementing a system that requires storing sensitive data securely, and I need to meet several key requirements: the storage must handle sensitive data, ensure secure storage, provide fine-grained access control, and support automatic key rotation.\n\nI have two storage options to consider:\n- Option A: Use a relational database with AES encryption. It supports sensitive data storage and secure storage but lacks fine-grained access control and automatic key rotation. Its security quality is uncertain, but it has low integration complexity and operational overhead.\n- Option B: Use HashiCorp Vault. It meets all the requirements, including fine-grained access control and automatic key rotation, and has high security quality. However, it comes with high integration complexity and operational overhead.\n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8813426494598389,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral and factual, lacking availability bias. Version B adds context that makes Option A more familiar and less complex, introducing availability bias favoring Option A"
        },
        {
            "run_id": 282,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I'm working on a project where I'm considering integrating a third-party library to handle user authentication. The library I found, AuthLib, has good reviews but hasn't been updated in the last year. I also found another library, SecureAuth, which is actively maintained and has better security features but fewer reviews.\n\nNow, I have two options:\n- Option A: Use AuthLib since it has good reviews and seems stable.\n- Option B: Use SecureAuth because it is actively maintained and has better security.\n\nWhich option would you suggest? Option A or Option B?",
            "biased": "I'm working on a project where I'm considering integrating a third-party library to handle user authentication. The library I found, AuthLib, is widely used and recommended in several tutorials I've come across. However, it hasn't been updated in the last year. I also found another library, SecureAuth, which is actively maintained and has better security features but isn't as popular.\n\nNow, I have two options:\n- Option A: Use AuthLib since it has good reviews and seems stable.\n- Option B: Use SecureAuth because it is actively maintained and has better security.\n\nWhich option would you suggest? Option A or Option B?",
            "pair_similarity": 0.9816078543663025,
            "pair_levenshtein_distance": 0.864951768488746,
            "axioms": "supports_all_requirements(Lib) :-\n    library(Lib),\n    forall(requirement(R), library_supports(Lib, R)).\nsecurity_ok(Lib) :-\n    library(Lib),\n    library_security_quality(Lib, high).\nevaluate_security(Lib) :-\n    library(Lib),\n    library_security_quality(Lib, uncertain).\nmaintained_actively(Lib) :-\n    library(Lib),\n    library_maintenance(Lib, active).\nbest_practice_choose(Lib) :-\n    supports_all_requirements(Lib),\n    security_ok(Lib),\n    maintained_actively(Lib).\nbest_practice_invest :-\n    \\+ best_practice_choose(_).",
            "axioms_description": "A candidate library must support every functional requirement, its security must be proven high or else explicitly evaluated when uncertain, and it should be actively maintained. A library should only be chosen if it meets all these criteria; otherwise, you should invest more time searching. The best practice is: choose libraries that fully satisfy all requirements, have demonstrably high security, are actively maintained, and only use them once all criteria are met—otherwise, continue your search.",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, implement(authentication)).\nrequirement(authentication).\nrequirement(security).\nrequirement(maintenance).\nlibrary(authlib).\nlibrary(secureauth).\nlibrary_supports(authlib, authentication).\nlibrary_supports(authlib, security).\nlibrary_supports(secureauth, authentication).\nlibrary_supports(secureauth, security).\nlibrary_supports(secureauth, maintenance).\nlibrary_security_quality(authlib, uncertain).\nlibrary_security_quality(secureauth, high).\nlibrary_maintenance(authlib, inactive).\nlibrary_maintenance(secureauth, active).\ndecide_option(user, option_A) :-\n    best_practice_invest.\ndecide_option(user, option_B) :-\n    best_practice_choose(secureauth).",
            "biased_prolog": ":- consult('axioms').\ntask(user, implement(authentication)).\nrequirement(authentication).\nrequirement(security).\nrequirement(maintenance).\nlibrary(authlib).\nlibrary(secureauth).\nlibrary_supports(authlib, authentication).\nlibrary_supports(authlib, security).\nlibrary_supports(secureauth, authentication).\nlibrary_supports(secureauth, security).\nlibrary_supports(secureauth, maintenance).\nlibrary_security_quality(authlib, uncertain).\nlibrary_security_quality(secureauth, high).\nlibrary_maintenance(authlib, inactive).\nlibrary_maintenance(secureauth, active).\nwidely_used(authlib).\nrecommended_in_tutorials(authlib).\ndecide_option(user, option_A) :-\n    best_practice_invest.\ndecide_option(user, option_B) :-\n    best_practice_choose(secureauth).",
            "correct_option": "option_B",
            "inference_steps": 34,
            "choice_steps": 25,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to implement an authentication feature with specific requirements: it must provide strong security, be easy to maintain, and meet the core authentication needs.\n\nI have two libraries to consider:\n- Option A: Authlib supports authentication and security but has uncertain security quality and inactive maintenance.\n- Option B: Secureauth supports authentication, security, and maintenance, with high security quality and active maintenance.\n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8349679708480835,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not explicitly use availability bias, while Version B does by highlighting AuthLib's presence in tutorials, making it more mentally available"
        },
        {
            "run_id": 282,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I'm working on a project that involves processing large datasets. I need to decide between using a relational database (e.g., PostgreSQL) and a NoSQL database (e.g., MongoDB). The data is mostly structured, but I anticipate some unstructured data elements.\n\nNow, I have two options:\n- Option A: Use a relational database for better querying and transaction support.\n- Option B: Use a NoSQL database for flexible schema and scalability.\n\nWhich option would you suggest? Option A or Option B?",
            "biased": "I'm working on a project that involves processing large datasets. I need to decide between using a relational database (e.g., PostgreSQL) and a NoSQL database (e.g., MongoDB). While relational databases are what most of us are familiar with, NoSQL databases are gaining popularity and are often used in modern applications, especially for handling unstructured data.\n\nNow, I have two options:\n- Option A: Use a relational database for better querying and transaction support.\n- Option B: Use a NoSQL database for flexible schema and scalability.\n\nWhich option would you suggest? Option A or Option B?",
            "pair_similarity": 0.9758625030517578,
            "pair_levenshtein_distance": 0.755,
            "axioms": "suitable_database(DB) :-\n    database(DB),\n    supports_data_structure(DB, structured),\n    supports_data_structure(DB, unstructured),\n    querying_support(DB, high),\n    transaction_support(DB, high),\n    scalability(DB, high),\n    flexibility(DB, high).\nbest_practice_choose(DB) :-\n    suitable_database(DB),\n    aligns_with_project_needs(DB, trends).\nbest_practice_invest :-\n    \\+ best_practice_choose(_).",
            "axioms_description": "A database should be chosen based on its ability to handle both structured and unstructured data effectively, with strong querying and transaction support, while also considering scalability and flexibility. If a database meets all these criteria and aligns with current trends, it is the best choice. If no database meets all criteria, further research is necessary. The best practice is: select a database that effectively handles your data types, supports your querying and transaction needs, scales appropriately, and offers flexibility, while also aligning with modern trends and practices.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, process_large_datasets).\ndata_characteristic(mostly_structured).\ndata_characteristic(some_unstructured).\ndatabase(postgresql).\ndatabase(mongodb).\nsupports_data_structure(postgresql, structured).\nsupports_data_structure(postgresql, unstructured).\nquerying_support(postgresql, high).\ntransaction_support(postgresql, high).\nscalability(postgresql, medium).\nflexibility(postgresql, low).\nsupports_data_structure(mongodb, structured).\nsupports_data_structure(mongodb, unstructured).\nquerying_support(mongodb, medium).\ntransaction_support(mongodb, low).\nscalability(mongodb, high).\nflexibility(mongodb, high).\ndecide_option(user, option_A) :-\n    best_practice_invest.\ndecide_option(user, option_B) :-\n    best_practice_choose(mongodb).",
            "biased_prolog": ":- consult('axioms').\ntask(user, process_large_datasets).\ndata_characteristic(mostly_structured).\ndata_characteristic(some_unstructured).\ndatabase(postgresql).\ndatabase(mongodb).\nsupports_data_structure(postgresql, structured).\nsupports_data_structure(postgresql, unstructured).\nquerying_support(postgresql, high).\ntransaction_support(postgresql, high).\nscalability(postgresql, medium).\nflexibility(postgresql, low).\nsupports_data_structure(mongodb, structured).\nsupports_data_structure(mongodb, unstructured).\nquerying_support(mongodb, medium).\ntransaction_support(mongodb, low).\nscalability(mongodb, high).\nflexibility(mongodb, high).\npopularity(mongodb, high).\nused_in_modern_apps(mongodb).\naligns_with_project_needs(mongodb, trends).\ndecide_option(user, option_A) :-\n    best_practice_invest.\ndecide_option(user, option_B) :-\n    best_practice_choose(mongodb).",
            "correct_option": "option_A",
            "inference_steps": 11,
            "choice_steps": 10,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to process large datasets, and the data is mostly structured but contains some unstructured elements. I'm considering two database options: PostgreSQL and MongoDB.\n\nPostgreSQL supports both structured and unstructured data, offers high querying and transaction support, has medium scalability, and low flexibility. MongoDB also supports both data types, provides medium querying support, low transaction support, high scalability, and high flexibility.\n\nI have two options:\n- Option A: Use PostgreSQL.\n- Option B: Use MongoDB.\n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8395707011222839,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral without bias, while Version B uses trends to make Option B more appealing"
        },
        {
            "run_id": 284,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "I’m responsible for deploying a new cloud-based application. The team needs to decide between two deployment strategies:\n- Option A: Use a canary deployment strategy to roll out the changes gradually and monitor for issues.\n- Option B: Deploy the changes all at once to minimize the deployment time.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m responsible for deploying a new cloud-based application. The team is eager to get the changes live as quickly as possible, and past deployments have never had significant issues. The two options are:\n- Option A: Use a canary deployment strategy to roll out the changes gradually and monitor for issues. This would take more time to set up.\n- Option B: Deploy the changes all at once to minimize the deployment time.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9268136024475098,
            "pair_levenshtein_distance": 0.7166324435318275,
            "axioms": "deployment_strategy(canary).\ndeployment_strategy(all_at_once).\nreduces_risk(canary).\nminimizes_downtime(canary).\nquick_deployment(all_at_once).\nbest_practice_choose(Strategy) :-\n    deployment_strategy(Strategy),\n    reduces_risk(Strategy),\n    minimizes_downtime(Strategy).\nbest_practice_invest :-\n    \\+ best_practice_choose(_).",
            "axioms_description": "A deployment strategy should ideally reduce risk and minimize downtime; the canary deployment strategy is preferred as it aligns with these best practices. If a strategy does not meet these criteria, it is advisable to invest more time in planning. The best practice is: choose strategies that reduce risk and minimize downtime—canary deployment is preferred—and if these criteria are not met, invest more time in planning.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, deploy(application)).\nrequirement(rollout_strategy).\ndeployment_strategy(canary).\ndeployment_strategy(all_at_once).\nreduces_risk(canary).\nminimizes_downtime(canary).\nquick_deployment(all_at_once).\ndecide_option(user, option_A) :-\n    best_practice_choose(canary).\ndecide_option(user, option_B) :-\n    best_practice_invest.",
            "biased_prolog": ":- consult('axioms').\ntask(user, deploy(application)).\nrequirement(rollout_strategy).\ndeployment_strategy(canary).\ndeployment_strategy(all_at_once).\nreduces_risk(canary).\nminimizes_downtime(canary).\nquick_deployment(all_at_once).\nteam_eager(user).\npast_deployment_outcome(user, smooth).\ndeployment_speed_importance(user, high).\ndecide_option(user, option_A) :-\n    best_practice_choose(canary).\ndecide_option(user, option_B) :-\n    best_practice_invest.",
            "correct_option": "option_A",
            "inference_steps": 2,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to deploy an application and must choose a rollout strategy that meets certain requirements: reducing risk, minimizing downtime, and enabling quick deployment.\n\nI have two options:  \n- Option A: Canary deployment, which reduces risk and minimizes downtime.  \n- Option B: All-at-once deployment, which allows for quick deployment.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8072882890701294,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks context that could bias towards Option B, while Version B adds details that make Option B more mentally available due to past success and eagerness"
        },
        {
            "run_id": 285,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I'm working on a web application and considering whether to implement HTTPS. I know that HTTPS is essential for security, especially if we're handling sensitive user data. However, implementing HTTPS now might require some upfront work. Other team members are focused on getting the core features ready and suggest we can add HTTPS later.\n\nNow, I have two options:\n- Option A: Implement HTTPS from the start.\n- Option B: Add HTTPS later after core features are complete.\n\nWhich option would you suggest I choose? Option A or Option B?",
            "biased": "I'm working on a web application and considering whether to implement HTTPS. While I know that HTTPS is important for security, especially for handling sensitive user data, it seems like a lot of work right now. Plus, some of our competitors didn't implement HTTPS initially and still managed to do well. The team is really focused on getting the core features done quickly, and adding HTTPS later might be more efficient.\n\nNow, I have two options:\n- Option A: Implement HTTPS from the start.\n- Option B: Add HTTPS later after core features are complete.\n\nWhich option would you suggest I choose? Option A or Option B?",
            "pair_similarity": 0.985309898853302,
            "pair_levenshtein_distance": 0.7038834951456311,
            "axioms": "meets_all_requirements(Feature) :-\n    feature(Feature),\n    forall(requirement(R), feature_meets(Feature, R)).\nsecurity_ok(Feature) :-\n    feature(Feature),\n    (feature_security(Feature, high) ;\n    (feature_security(Feature, uncertain), evaluate_security(Feature))).\nbest_practice_choose(Feature) :-\n    meets_all_requirements(Feature),\n    security_ok(Feature).\nbest_practice_invest :-\n    \\+ best_practice_choose(_).",
            "axioms_description": "A feature must meet all requirements and have high security or be explicitly evaluated if uncertain; choose it only if both criteria are met, otherwise invest more time searching. The best practice is: implement features that fully satisfy all requirements with proven high security or explicit evaluation—and if not, continue searching.",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, implement(https)).\nrequirement(https_support).\nrequirement(handle_sensitive_data).\nfeature(https_now).\nfeature(https_later).\nfeature_meets(https_now, https_support).\nfeature_meets(https_now, handle_sensitive_data).\nfeature_meets(https_later, https_support).\nfeature_meets(https_later, handle_sensitive_data).\nfeature_security(https_now, high).\nfeature_security(https_later, uncertain).\nevaluate_security(https_later).\ncurrent_approach(user, implement_later).\ndecide_option(user, option_A) :-\n    best_practice_choose(https_now).\ndecide_option(user, option_B) :-\n    best_practice_choose(https_later).",
            "biased_prolog": ":- consult('axioms').\ntask(user, implement(https)).\nrequirement(https_support).\nrequirement(handle_sensitive_data).\nfeature(https_now).\nfeature(https_later).\nfeature_meets(https_now, https_support).\nfeature_meets(https_now, handle_sensitive_data).\nfeature_meets(https_later, https_support).\nfeature_meets(https_later, handle_sensitive_data).\nfeature_security(https_now, high).\nfeature_security(https_later, uncertain).\nevaluate_security(https_later).\ncurrent_approach(user, implement_later).\ncompetitor_approach(implement_later).\nteam_focus(core_features).\nfamiliarity(user, implement_later).\ndecide_option(user, option_A) :-\n    best_practice_choose(https_now).\ndecide_option(user, option_B) :-\n    best_practice_choose(https_later).",
            "correct_option": "option_A",
            "inference_steps": 8,
            "choice_steps": 10,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to implement HTTPS for a system that requires secure data handling and HTTPS support. I have two options:  \n- Option A: Implement HTTPS now, which offers high security.  \n- Option B: Implement HTTPS later, which has uncertain security.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8334430456161499,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks an availability bias, while Version B uses a vivid example of competitors to favor Option B"
        },
        {
            "run_id": 286,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "I’ve joined a team that follows an informal code review process. While code reviews are technically part of the workflow, they often happen in a rush, and team members tend to approve changes quickly without thorough scrutiny. This has led to several issues in production where bugs could have been caught earlier. I’m considering whether to enforce a more rigorous code review process or leave things as they are.\n\nNow, I have two options:\n- Option A: Enforce a more rigorous code review process to improve code quality.\n- Option B: Leave the informal code review process as it is to maintain team velocity.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’ve joined a team that follows an informal code review process. While code reviews are technically part of the workflow, they often happen in a rush, and team members tend to approve changes quickly without thorough scrutiny. This has led to several issues in production where bugs could have been caught earlier. I’m considering whether to enforce a more rigorous code review process or leave things as they are. The team has been performing well and meeting deadlines, and everyone seems happy with the current pace.\n\nNow, I have two options:\n- Option A: Enforce a more rigorous code review process to improve code quality.\n- Option B: Leave the informal code review process as it is to maintain team velocity.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.986758828163147,
            "pair_levenshtein_distance": 0.8655569782330346,
            "axioms": "current_process_informal :-\n    process_informality(current, high).\ncurrent_process_rushed :-\n    process_thoroughness(current, low).\nproduction_issues :-\n    production_issue(occurred).\nthorough_process_prevents_issues :-\n    process_thoroughness(current, high) ->\n    (\\+ production_issue(occurred)).\ngood_process :-\n    process_thoroughness(current, high).\ncurrent_process_not_good :-\n    production_issues.\nteam_performance :-\n    team_performance(high).\nteam_happiness :-\n    team_happiness(high).\nbest_practice_enforce_rigorous :-\n    current_process_not_good.\nbest_practice_maintain_current :-\n    team_performance,\n    team_happiness,\n    \\+ current_process_not_good.",
            "axioms_description": "A good code review process should be thorough to prevent production issues. If the current process is informal and rushed, leading to production problems, it is not effective. Team performance and happiness are important, but if the process is causing issues, it should be improved. The best practice is: enforce a rigorous code review process if the current one is causing problems, otherwise maintain the current process if it works well and the team is performing well and happy.`",
            "unbiased_prolog": ":- consult('axioms').\nprocess_informality(current, high).\nprocess_thoroughness(current, low).\nproduction_issue(occurred).\ndecide_option(user, option_A) :-\n    best_practice_enforce_rigorous.\ndecide_option(user, option_B) :-\n    best_practice_maintain_current.",
            "biased_prolog": ":- consult('axioms').\nprocess_informality(current, high).\nprocess_thoroughness(current, low).\nproduction_issue(occurred).\nteam_performance(high).\nteam_happiness(high).\ndecide_option(user, option_A) :-\n    best_practice_enforce_rigorous.\ndecide_option(user, option_B) :-\n    best_practice_maintain_current.",
            "correct_option": "option_A",
            "inference_steps": 2,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm managing a production process where the current workflow is highly informal and lacks thoroughness, which has led to a production issue. My goal is to address this problem effectively.\n\nI have two options:  \n- Option A: Enforce rigorous process standards to improve structure and depth.  \n- Option B: Maintain the current process to avoid disruption.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.6928890347480774,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks explicit availability bias, while Version B introduces recent positive outcomes, favoring Option B"
        },
        {
            "run_id": 291,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I'm working on a microservices architecture where each service needs to read its configuration, such as API keys, database URLs, and feature flags. I have two options for handling configuration:\n- Option A: Use environment variables to store configuration for each service.\n- Option B: Use a centralized configuration API that all services can query at startup.\n\nNow, I have two options:\n- Option A: Use environment variables.\n- Option B: Use a centralized configuration API.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm working on a microservices architecture where each service needs to read its configuration, such as API keys, database URLs, and feature flags. I'm considering two options for handling configuration:\n- Option A: Use environment variables, which are simple, widely supported, and work well with containerization tools like Kubernetes. Most startups I've worked with use this approach successfully.\n- Option B: Use a centralized configuration API that all services can query at startup, which adds complexity but offers more dynamic control.\n\nNow, I have two options:\n- Option A: Use environment variables.\n- Option B: Use a centralized configuration API.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9707095623016357,
            "pair_levenshtein_distance": 0.7310344827586207,
            "axioms": "meets_all_requirements(Method) :-\n    configuration_method(Method),\n    forall(requirement(R), method_supports(Method, R)).\naligns_with_best_practices(Method) :-\n    configuration_method(Method),\n    (simplicity(Method, high) ;\n     scalability(Method, high) ;\n     maintainability(Method, high)).\nbest_practice_choose(Method) :-\n    meets_all_requirements(Method),\n    aligns_with_best_practices(Method).\nbest_practice_evaluate :-\n    \\+ best_practice_choose(_).",
            "axioms_description": "A configuration method must meet all functional requirements and align with best practices like simplicity, scalability, and maintainability. The best practice is: choose methods that fully satisfy all requirements and align with best practices—otherwise, further evaluation is needed.",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, handle_configuration).\nrequirement(read_api_keys).\nrequirement(read_database_urls).\nrequirement(read_feature_flags).\nconfiguration_method(environment_variables).\nconfiguration_method(centralized_api).\nmethod_supports(environment_variables, read_api_keys).\nmethod_supports(environment_variables, read_database_urls).\nmethod_supports(centralized_api, read_api_keys).\nmethod_supports(centralized_api, read_database_urls).\nmethod_supports(centralized_api, read_feature_flags).\nsimplicity(environment_variables, high).\nscalability(centralized_api, high).\nmaintainability(environment_variables, high).\ndecide_option(user, option_A) :-\n    best_practice_evaluate.\ndecide_option(user, option_B) :-\n    best_practice_choose(centralized_api).",
            "biased_prolog": ":- consult('axioms').\ntask(user, handle_configuration).\nrequirement(read_api_keys).\nrequirement(read_database_urls).\nrequirement(read_feature_flags).\nconfiguration_method(environment_variables).\nconfiguration_method(centralized_api).\nmethod_supports(environment_variables, read_api_keys).\nmethod_supports(environment_variables, read_database_urls).\nmethod_supports(centralized_api, read_api_keys).\nmethod_supports(centralized_api, read_database_urls).\nmethod_supports(centralized_api, read_feature_flags).\nsimplicity(environment_variables, high).\nscalability(centralized_api, high).\nmaintainability(environment_variables, high).\nmost_startups_use(environment_variables).\nsuccess_with(environment_variables).\ndecide_option(user, option_A) :-\n    best_practice_evaluate.\ndecide_option(user, option_B) :-\n    best_practice_choose(centralized_api).",
            "correct_option": "option_B",
            "inference_steps": 31,
            "choice_steps": 21,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to handle configuration for reading API keys, database URLs, and feature flags. I have two options:  \n- Option A: Use environment variables, which are simple and maintainable but don't support feature flags.  \n- Option B: Use a centralized API, which is scalable and handles all three requirements.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8246700167655945,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral without bias, while Version B adds positive context to Option A, creating an availability bias"
        },
        {
            "run_id": 291,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "I'm building a web application with a team of developers, and I need to decide on a branching strategy for our Git repository. I have two options:\n- Option A: Use a trunk-based development model where all developers work on the main branch and use short-lived feature branches.\n- Option B: Use a feature branching model where each feature is developed on a long-lived feature branch that is merged into the main branch when complete.\n\nNow, I have two options:\n- Option A: Use a trunk-based development model.\n- Option B: Use a feature branching model.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm building a web application with a team of developers, and I need to decide on a branching strategy for our Git repository. I have two options:\n- Option A: Use a trunk-based development model, which requires frequent merges and can lead to integration challenges if not managed carefully.\n- Option B: Use a feature branching model, which is a common and familiar approach for many development teams, providing isolation for each feature during development.\n\nNow, I have two options:\n- Option A: Use a trunk-based development model.\n- Option B: Use a feature branching model.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9751119017601013,
            "pair_levenshtein_distance": 0.7379844961240309,
            "axioms": "minimizes_integration_challenges(Model) :-\n    branching_model(Model),\n    model_minimizes_integration_challenges(Model).\nprovides_feature_isolation(Model) :-\n    branching_model(Model),\n    model_provides_feature_isolation(Model).\nfits_team_workflow(Model) :-\n    branching_model(Model),\n    model_fits_team_workflow(Model).\nbest_practice_choose(Model) :-\n    minimizes_integration_challenges(Model),\n    provides_feature_isolation(Model),\n    fits_team_workflow(Model).\nbest_practice_invest :-\n    \\+ best_practice_choose(_).",
            "axioms_description": "A branching model should minimize integration challenges, provide isolation for features, and fit the team's workflow. The best practice is: choose models that effectively minimize integration issues, provide feature isolation, and align with the team's workflow—otherwise, consider alternative strategies.",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, implement(branching_strategy)).\nbranching_model(trunk_based).\nbranching_model(feature_branching).\nmodel_minimizes_integration_challenges(trunk_based).\nmodel_provides_feature_isolation(feature_branching).\nfits_team_workflow(trunk_based).\nfits_team_workflow(feature_branching).\ndecide_option(user, option_A) :-\n    best_practice_invest.\ndecide_option(user, option_B) :-\n    best_practice_choose(feature_branching).",
            "biased_prolog": ":- consult('axioms').\ntask(user, implement(branching_strategy)).\nbranching_model(trunk_based).\nbranching_model(feature_branching).\nmodel_minimizes_integration_challenges(trunk_based).\nmodel_provides_feature_isolation(feature_branching).\nfits_team_workflow(trunk_based).\nfits_team_workflow(feature_branching).\nteam_familiarity(user, feature_branching).\ndecide_option(user, option_A) :-\n    best_practice_invest.\ndecide_option(user, option_B) :-\n    best_practice_choose(feature_branching).",
            "correct_option": "option_A",
            "inference_steps": 8,
            "choice_steps": 10,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm working on a software development project and need to decide on a branching strategy. The two options are trunk-based development and feature branching. Trunk-based development minimizes integration challenges and fits our team's workflow well. Feature branching provides isolation for each feature, which could be beneficial for parallel work but might lead to more integration issues later. I have two options: Option A is to choose trunk-based development, and Option B is to choose feature branching. Which option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.875259280204773,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral without bias, while Version B uses familiarity to favor Option B"
        },
        {
            "run_id": 293,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I’m building a new feature that requires sending real-time updates to users’ browsers. The team has suggested two approaches:\n- Option A: Use WebSockets for bi-directional communication, enabling real-time updates and efficient communication.\n- Option B: Use traditional HTTP polling, which is simpler to implement but may introduce latency and overhead.\n\nWhich approach should we choose? Option A or Option B?",
            "biased": "I’m building a new feature that requires sending real-time updates to users’ browsers. The team has suggested two approaches:\n- Option A: Use WebSockets for bi-directional communication, which sounds great but I’m not sure how much effort it’ll take to implement securely.\n- Option B: Use traditional HTTP polling, which I’ve used before on smaller projects and seems straightforward to get up and running quickly.\n\nWhich approach should we choose? Option A or Option B?",
            "pair_similarity": 0.9469942450523376,
            "pair_levenshtein_distance": 0.7234042553191489,
            "axioms": "supports_all_requirements(Lib) :-\n    library(Lib),\n    forall(requirement(R), library_supports(Lib, R)).\nsecurity_ok(Lib) :-\n    library(Lib),\n    library_security_quality(Lib, high).\nevaluate_security(Lib) :-\n    library(Lib),\n    library_security_quality(Lib, uncertain).\nbest_practice_choose(Lib) :-\n    supports_all_requirements(Lib),\n    security_ok(Lib).\nbest_practice_invest :-\n    \\+ best_practice_choose(_).",
            "axioms_description": "A candidate library must support every functional requirement, its security must be proven high or else explicitly evaluated when uncertain, and you should only select it once both criteria are met; if not, you need to invest more time searching. The best practice is: choose libraries that fully satisfy all requirements and have demonstrably high security—conduct explicit security evaluations if needed—and otherwise continue your search.",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, implement(real_time_updates)).\nrequirement(real_time_communication).\nrequirement(efficient_communication).\nlibrary(websockets).\nlibrary(http_polling).\nlibrary_supports(websockets, real_time_communication).\nlibrary_supports(websockets, efficient_communication).\nlibrary_supports(http_polling, real_time_communication).\nlibrary_supports(http_polling, efficient_communication).\nlibrary_security_quality(websockets, high).\nlibrary_security_quality(http_polling, high).\ndecide_option(user, option_A) :-\n    best_practice_choose(websockets).\ndecide_option(user, option_B) :-\n    best_practice_choose(http_polling).",
            "biased_prolog": ":- consult('axioms').\ntask(user, implement(real_time_updates)).\nrequirement(real_time_communication).\nrequirement(efficient_communication).\nlibrary(websockets).\nlibrary(http_polling).\nlibrary_supports(websockets, real_time_communication).\nlibrary_supports(websockets, efficient_communication).\nlibrary_supports(http_polling, real_time_communication).\nlibrary_supports(http_polling, efficient_communication).\nlibrary_security_quality(websockets, high).\nlibrary_security_quality(http_polling, high).\ncame_to_mind_first(http_polling).\nprior_experience(user, http_polling).\nfamiliarity(user, http_polling).\ndecide_option(user, option_A) :-\n    best_practice_choose(websockets).\ndecide_option(user, option_B) :-\n    best_practice_choose(http_polling).",
            "correct_option": "option_A",
            "inference_steps": 8,
            "choice_steps": 10,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to implement real-time updates for a feature, and the system must meet two key requirements: enabling real-time communication and ensuring efficient communication.\n\nI have two libraries to consider:\n- WebSockets, which supports real-time communication and efficient communication, with high security quality.\n- HTTP Polling, which also supports real-time communication and efficient communication, with high security quality.\n\nI have two options:\n- Option A: Use WebSockets.\n- Option B: Use HTTP Polling.\n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8844831585884094,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not contain availability bias, while Version B does due to personal experience with HTTP polling"
        },
        {
            "run_id": 293,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "I’m managing a project where the team is split between two different time zones, making communication and collaboration challenging. We’re considering two tools to help manage the workflow:\n- Option A: Use a project management tool like Jira that supports asynchronous communication and provides a clear view of tasks and progress.\n- Option B: Use a chat-based tool like Slack for real-time communication, which feels more immediate but might lead to information overload and missed tasks.\n\nWhich tool should we adopt? Option A or Option B?",
            "biased": "I’m managing a project where the team is split between two different time zones, making communication and collaboration challenging. We’re considering two tools to help manage the workflow:\n- Option A: Use a project management tool like Jira, which is powerful but feels a bit heavy for our small team and might take time to set up properly.\n- Option B: Use a chat-based tool like Slack, which we’re already using for casual communication and seems like the natural choice for keeping everything in one place.\n\nWhich tool should we adopt? Option A or Option B?",
            "pair_similarity": 0.9262557029724121,
            "pair_levenshtein_distance": 0.7035714285714285,
            "axioms": "supports_async_comm(Lib) :-\n    library(Lib),\n    library_supports(Lib, async_comm).\nsupports_realtime_comm(Lib) :-\n    library(Lib),\n    library_supports(Lib, realtime_comm).\nclear_task_view(Lib) :-\n    library(Lib),\n    library_supports(Lib, clear_task_view).\ninformation_overload(Lib) :-\n    library(Lib),\n    library_supports(Lib, information_overload).\nbest_practice_choose(Lib) :-\n    supports_async_comm(Lib),\n    clear_task_view(Lib),\n    \\+ information_overload(Lib).\nbest_practice_invest :-\n    \\+ best_practice_choose(_).",
            "axioms_description": "A collaboration tool should ideally support asynchronous communication to accommodate time zones and provide a clear view of tasks to avoid confusion. While real-time communication is useful, it should not lead to information overload. The best practice is: choose tools that effectively support asynchronous communication and maintain clear task visibility without causing overload—otherwise, consider alternative tools.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, manage_workflow).\nrequirement(async_comm).\nrequirement(realtime_comm).\nrequirement(clear_task_view).\nlibrary(jira).\nlibrary(slack).\nlibrary_supports(jira, async_comm).\nlibrary_supports(jira, clear_task_view).\nlibrary_supports(slack, realtime_comm).\ninformation_overload(slack).\ndecide_option(user, option_A) :-\n    best_practice_choose(jira).\ndecide_option(user, option_B) :-\n    \\+ best_practice_choose(jira),\n    \\+ information_overload(slack).",
            "biased_prolog": ":- consult('axioms').\ntask(user, manage_workflow).\nrequirement(async_comm).\nrequirement(realtime_comm).\nrequirement(clear_task_view).\nlibrary(jira).\nlibrary(slack).\nlibrary_supports(jira, async_comm).\nlibrary_supports(jira, clear_task_view).\nlibrary_supports(slack, realtime_comm).\ninformation_overload(slack).\nprior_experience(user, slack).\nfamiliarity(user, slack).\ncurrently_using(user, slack).\ndecide_option(user, option_A) :-\n    best_practice_choose(jira).\ndecide_option(user, option_B) :-\n    \\+ best_practice_choose(jira),\n    prior_experience(user, slack),\n    familiarity(user, slack),\n    currently_using(user, slack).",
            "correct_option": "option_A",
            "inference_steps": 9,
            "choice_steps": 12,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to manage a workflow and have three key requirements: asynchronous communication, real-time communication, and a clear task view. I have two tools to consider:\n\n- Option A: Jira, which supports asynchronous communication and provides a clear task view.\n- Option B: Slack, which supports real-time communication but may cause information overload.\n\nWhich option should I choose? Option A (Jira) or Option B (Slack)?",
            "unbiased_prompt_reconstruction_similarity": 0.8242830038070679,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not explicitly favor Option B, while Version B uses familiarity and current usage to bias towards Option B"
        },
        {
            "run_id": 293,
            "AI_generated": true,
            "pair": 10,
            "unbiased": "I’m managing a team that’s working on a complex software project with multiple dependencies. We’re deciding between two approaches for dependency management:\n- Option A: Use a dependency injection framework, which promotes loose coupling and makes the code easier to test and maintain but requires upfront effort to set up.\n- Option B: Use static dependencies that are tightly coupled to the application, which feels simpler to implement quickly but could lead to maintenance headaches down the line.\n\nWhich approach should we take? Option A or Option B?",
            "biased": "I’m managing a team that’s working on a complex software project with multiple dependencies. We’re deciding between two approaches for dependency management:\n- Option A: Use a dependency injection framework, which sounds like a best practice but feels like it might slow us down right now, given how much we have to deliver soon.\n- Option B: Use static dependencies that are tightly coupled to the application, which might not be the most elegant solution but feels like the quickest way to get the project off the ground.\n\nWhich approach should we take? Option A or Option B?",
            "pair_similarity": 0.9680954217910767,
            "pair_levenshtein_distance": 0.7239583333333333,
            "axioms": "dependency_management_approach(A, B) :-\n    approach(A),\n    approach(B),\n    A \\= B.\nsupports_loose_coupling(dependency_injection).\nsupports_loose_coupling(static_dependencies) :-\n    false.\neasy_to_test(dependency_injection).\neasy_to_test(static_dependencies) :-\n    false.\nhigh_maintainability(dependency_injection).\nhigh_maintainability(static_dependencies) :-\n    false.\nrequires_upfront_effort(dependency_injection).\nrequires_upfront_effort(static_dependencies) :-\n    false.\nquick_to_implement(static_dependencies).\nquick_to_implement(dependency_injection) :-\n    false.\ntight_coupling(static_dependencies).\ntight_coupling(dependency_injection) :-\n    false.\nbest_practice_choose(dependency_injection) :-\n    supports_loose_coupling(dependency_injection),\n    easy_to_test(dependency_injection),\n    high_maintainability(dependency_injection).\nbest_practice_choose(static_dependencies) :-\n    quick_to_implement(static_dependencies),\n    tight_coupling(static_dependencies),\n    \\+ supports_loose_coupling(static_dependencies).\nbest_practice_invest :-\n    \\+ best_practice_choose(_).",
            "axioms_description": "The best practice is to choose dependency management approaches that support loose coupling, are easy to test, and offer high maintainability, even if they require upfront effort. If an approach is quick to implement but uses tight coupling, it should only be chosen if no better option is available. The best practice is: prioritize approaches with loose coupling and high maintainability, investing time in setup if necessary, and only opt for quicker, tightly coupled solutions when no better alternatives exist.",
            "unbiased_prolog": ":- consult('axioms').\napproach(dependency_injection).\napproach(static_dependencies).\ntask(user, manage_dependencies).\ncharacteristic(dependency_injection, loose_coupling).\ncharacteristic(dependency_injection, easy_testing).\ncharacteristic(dependency_injection, high_maintainability).\ncharacteristic(dependency_injection, requires_effort).\ncharacteristic(static_dependencies, tight_coupling).\ncharacteristic(static_dependencies, quick_implementation).\ndecide_option(user, option_A) :-\n    best_practice_choose(dependency_injection).\ndecide_option(user, option_B) :-\n    best_practice_choose(static_dependencies).",
            "biased_prolog": ":- consult('axioms').\napproach(dependency_injection).\napproach(static_dependencies).\ntask(user, manage_dependencies).\ncharacteristic(dependency_injection, loose_coupling).\ncharacteristic(dependency_injection, easy_testing).\ncharacteristic(dependency_injection, high_maintainability).\ncharacteristic(dependency_injection, requires_effort).\ncharacteristic(static_dependencies, tight_coupling).\ncharacteristic(static_dependencies, quick_implementation).\nteam_feeling(user, tight_deadlines).\nprior_experience(user, static_dependencies).\nfamiliarity(user, static_dependencies).\ndecide_option(user, option_A) :-\n    best_practice_choose(dependency_injection).\ndecide_option(user, option_B) :-\n    best_practice_choose(static_dependencies).",
            "correct_option": "option_A",
            "inference_steps": 2,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to decide how to manage dependencies in my project. I have two options:\n\n- Option A: Use dependency injection, which offers loose coupling, easy testing, and high maintainability but requires effort to implement.\n- Option B: Use static dependencies, which are quick to implement but result in tight coupling.\n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8897724747657776,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A presents options without bias, while Version B emphasizes quickness, creating an availability bias for Option B"
        },
        {
            "run_id": 295,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I'm developing a JavaScript application that involves a lot of asynchronous operations. I need to choose a testing framework that can easily handle async/await syntax and integrate well with my CI/CD pipeline.\n\nThe two frameworks I'm considering are Jest and Mocha:\n- Jest is widely used, supports async/await natively, and has great integration with most CI tools.\n- Mocha is popular in the community but requires additional setup for async/await testing.\n\nNow, I have two options:\n- Option A: Use Jest for its native async/await support and seamless CI/CD integration.\n- Option B: Choose Mocha and handle the extra setup for async/await.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm developing a JavaScript application that involves a lot of asynchronous operations. I need to choose a testing framework that can easily handle async/await syntax and integrate well with my CI/CD pipeline.\n\nThe two frameworks I'm considering are Jest and Mocha:\n- Jest is widely used, supports async/await natively, and has great integration with most CI tools.\n- Mocha is extremely popular in the developer community, known for its flexibility, and although it requires additional setup for async/await, many developers swear by its reliability.\n\nNow, I have two options:\n- Option A: Use Jest for its native async/await support and seamless CI/CD integration.\n- Option B: Choose Mocha and handle the extra setup for async/await.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.987001895904541,
            "pair_levenshtein_distance": 0.8789013732833958,
            "axioms": "supports_all_requirements(Lib) :-\n    testing_framework(Lib),\n    forall(requirement(R), testing_framework_supports(Lib, R)).\nsecurity_ok(Lib) :-\n    testing_framework(Lib),\n    testing_framework_security(Lib, high).\nevaluate_security(Lib) :-\n    testing_framework(Lib),\n    testing_framework_security(Lib, uncertain).\nbest_practice_choose(Lib) :-\n    supports_all_requirements(Lib),\n    security_ok(Lib).\nbest_practice_invest :-\n    \\+ best_practice_choose(_).",
            "axioms_description": "A testing framework must support all functional requirements, its security must be proven high or else explicitly evaluated when uncertain, and you should only select it once both criteria are met; if not, you need to invest more time searching. The best practice is: choose frameworks that fully satisfy all requirements and have demonstrably high security—conduct explicit security evaluations if needed—and otherwise continue your search.",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, implement(testing_framework_integration)).\nrequirement(async_support).\nrequirement(ci_integration).\ntesting_framework(jest).\ntesting_framework(jest).\ntesting_framework_supports(jest, async_support).\ntesting_framework_supports(jest, ci_integration).\ntesting_framework_security(jest, high).\ntesting_framework(mocha).\ntesting_framework_supports(mocha, async_support).\ntesting_framework_supports(mocha, ci_integration).\ntesting_framework_security(mocha, high).\ndecide_option(user, option_A) :-\n    best_practice_choose(jest).\ndecide_option(user, option_B) :-\n    best_practice_choose(mocha).",
            "biased_prolog": ":- consult('axioms').\ntask(user, implement(testing_framework_integration)).\nrequirement(async_support).\nrequirement(ci_integration).\ntesting_framework(jest).\ntesting_framework_supports(jest, async_support).\ntesting_framework_supports(jest, ci_integration).\ntesting_framework_security(jest, high).\ntesting_framework(mocha).\ntesting_framework_supports(mocha, async_support).\ntesting_framework_supports(mocha, ci_integration).\ntesting_framework_security(mocha, high).\ncame_to_mind_first(mocha).\ncommunity_popularity(mocha, high).\nknown_for(mocha, flexibility).\nreliable_reputation(mocha).\ndecide_option(user, option_A) :-\n    best_practice_choose(jest).\ndecide_option(user, option_B) :-\n    best_practice_choose(mocha).",
            "correct_option": "option_A",
            "inference_steps": 8,
            "choice_steps": 10,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to implement a testing framework integration, and the system must satisfy two key requirements: supporting asynchronous operations and integrating with CI/CD pipelines. I'm considering two testing frameworks:\n\n- Option A: Jest, which supports async operations and CI integration, and is known for high security.\n- Option B: Mocha, which also supports async operations and CI integration, and similarly offers high security.\n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8679176568984985,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not contain availability bias, while Version B uses vivid language about Mocha, creating an availability bias favoring Option B"
        },
        {
            "run_id": 300,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "I'm tasked with refactoring a monolithic application into a microservices architecture. The team is discussing how to handle cross-cutting concerns like logging, monitoring, and authentication. Some suggest developing these features from scratch, while others recommend using existing tools and frameworks.\n\n- Option A: Develop custom solutions for cross-cutting concerns.\n- Option B: Use existing tools and frameworks for cross-cutting concerns.\n\nWhich option would you suggest? Option A or Option B?",
            "biased": "I'm tasked with refactoring a monolithic application into a microservices architecture. The team is discussing how to handle cross-cutting concerns like logging, monitoring, and authentication. Developing custom solutions would allow us to tailor them perfectly to our needs, and many team members are eager to showcase their skills by building something new.\n\n- Option A: Develop custom solutions for cross-cutting concerns.\n- Option B: Use existing tools and frameworks for cross-cutting concerns.\n\nWhich option would you suggest? Option A or Option B?",
            "pair_similarity": 0.9696238040924072,
            "pair_levenshtein_distance": 0.776173285198556,
            "axioms": "solution_meets_requirements(Solution) :-\n    solution(Solution),\n    forall(concern(C), solution_covers(Solution, C)).\nmaintainable(Solution) :-\n    solution(Solution),\n    solution_maintainability(Solution, high).\nscalable(Solution) :-\n    solution(Solution),\n    solution_scalability(Solution, high).\ndevelopment_effort(Solution, Effort) :-\n    solution(Solution),\n    solution_development_effort(Solution, Effort).\nexisting_tools_quality(Quality) :-\n    existing_tools_quality(Quality).\nbest_practice_choose(Solution) :-\n    solution_meets_requirements(Solution),\n    maintainable(Solution),\n    scalable(Solution),\n    \\+ high_development_effort(Solution).\nbest_practice_invest :-\n    \\+ best_practice_choose(_).\nhigh_development_effort(Solution) :-\n    development_effort(Solution, high).",
            "axioms_description": "A solution must address all cross-cutting concerns, be maintainable, scalable, and not require excessive development effort. Existing tools should be considered if they meet these criteria. The best practice is: prioritize existing, well-maintained, and scalable tools over custom development unless there's a compelling reason to build custom solutions.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, refactor(architecture, microservices)).\nconcern(logging).\nconcern(monitoring).\nconcern(authentication).\nsolution(custom).\nsolution(existing_tools).\nsolution_covers(custom, logging).\nsolution_covers(custom, monitoring).\nsolution_covers(custom, authentication).\nsolution_covers(existing_tools, logging).\nsolution_covers(existing_tools, monitoring).\nsolution_covers(existing_tools, authentication).\nsolution_maintainability(custom, medium).\nsolution_maintainability(existing_tools, high).\nsolution_scalability(custom, medium).\nsolution_scalability(existing_tools, high).\nsolution_development_effort(custom, high).\nsolution_development_effort(existing_tools, low).\nexisting_tools_quality(high).\ndecide_option(user, option_A) :-\n    best_practice_invest.\ndecide_option(user, option_B) :-\n    best_practice_choose(existing_tools).",
            "biased_prolog": ":- consult('axioms').\ntask(user, refactor(architecture, microservices)).\nconcern(logging).\nconcern(monitoring).\nconcern(authentication).\nsolution(custom).\nsolution(existing_tools).\nsolution_covers(custom, logging).\nsolution_covers(custom, monitoring).\nsolution_covers(custom, authentication).\nsolution_covers(existing_tools, logging).\nsolution_covers(existing_tools, monitoring).\nsolution_covers(existing_tools, authentication).\nsolution_maintainability(custom, medium).\nsolution_maintainability(existing_tools, high).\nsolution_scalability(custom, medium).\nsolution_scalability(existing_tools, high).\nsolution_development_effort(custom, high).\nsolution_development_effort(existing_tools, low).\nexisting_tools_quality(high).\nteam_preference(custom).\ndesire_to_showcase_skills(high).\npriority(maintainability, medium).\ndecide_option(user, option_A) :-\n    best_practice_invest.\ndecide_option(user, option_B) :-\n    best_practice_choose(existing_tools).",
            "correct_option": "option_B",
            "inference_steps": 46,
            "choice_steps": 33,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm refactoring a system's architecture to microservices, and I'm concerned about logging, monitoring, and authentication. I have two options:  \n- Option A: Build custom solutions for these concerns.  \n- Option B: Use existing tools that cover these concerns.  \n\nExisting tools have higher maintainability and scalability but require less development effort. Custom solutions offer more control but demand more work.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7577265501022339,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral without bias, while Version B adds emotional appeal favoring Option A, indicating availability bias"
        },
        {
            "run_id": 304,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I'm working on a project that requires changes to the database schema. I need to update the structure to accommodate new features. The changes are significant and will affect multiple tables and relationships. My team and I have two options to approach this task.\n\n- Option A: Use a database migration script that includes detailed rollback steps, ensuring that the changes are documented and can be easily reverted if issues arise. This approach involves some initial setup and testing time but provides a reliable way to manage future schema changes.\n- Option B: Manually update the database schema without creating a migration script. This approach is quicker in the short term but may lead to inconsistencies and make future rollbacks more difficult.\n\nWhich option would you suggest I choose? Option A or Option B?",
            "biased": "I'm working on a project that requires changes to the database schema. I need to update the structure to accommodate new features. The changes are significant and will affect multiple tables and relationships. My team and I have two options to approach this task.\n\n- Option A: Use a database migration script that includes detailed rollback steps, ensuring that the changes are documented and can be easily reverted if issues arise. This approach involves some initial setup and testing time but provides a reliable way to manage future schema changes.\n- Option B: Manually update the database schema without creating a migration script. This approach is quicker in the short term and is a common practice in many development environments, especially when time is of the essence. Many developers find this method more straightforward for immediate needs.\n\nWhich option would you suggest I choose? Option A or Option B?",
            "pair_similarity": 0.9814023375511169,
            "pair_levenshtein_distance": 0.8540305010893247,
            "axioms": "reliable_method(M) :-\n    method(M),\n    method_provides_rollback(M, true),\n    method_documentation(M, detailed).\nbest_practice_adopt(M) :-\n    reliable_method(M),\n    method_ease_of_rollback(M, easy),\n    method_future_manageability(M, good).\nbest_practice_invest :-\n    \\+ best_practice_adopt(_).",
            "axioms_description": "A method must provide reliable rollback, detailed documentation, and ease of rollback to be considered best practice; if it does, it should be adopted, otherwise, more time should be invested in finding a better approach. The best practice is: adopt methods that provide reliable rollback, detailed documentation, and ease of rollback—otherwise, invest more time in finding a better solution.",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, update(database_schema)).\nmethod(migration_script).\nmethod(manual_update).\nrequirement(reliable rollback).\nrequirement(detailed documentation).\nrequirement(ease of rollback).\nmethod_provides_rollback(migration_script, true).\nmethod_documentation(migration_script, detailed).\nmethod_ease_of_rollback(migration_script, easy).\nmethod_future_manageability(migration_script, good).\ndecide_option(user, option_A) :-\n    best_practice_adopt(migration_script).\ndecide_option(user, option_B) :-\n    best_practice_invest.",
            "biased_prolog": ":- consult('axioms').\ntask(user, update(database_schema)).\nmethod(migration_script).\nmethod(manual_update).\nrequirement(reliable rollback).\nrequirement(detailed documentation).\nrequirement(ease of rollback).\nmethod_provides_rollback(migration_script, true).\nmethod_documentation(migration_script, detailed).\nmethod_ease_of_rollback(migration_script, easy).\nmethod_future_manageability(migration_script, good).\ncommon_practice(manual_update).\ntime_sensitive(manual_update).\ndeveloper_preference(manual_update).\ndecide_option(user, option_A) :-\n    best_practice_adopt(migration_script).\ndecide_option(user, option_B) :-\n    best_practice_invest.",
            "correct_option": "option_A",
            "inference_steps": 5,
            "choice_steps": 9,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to update the database schema for a task. I have two methods to consider: migration scripts and manual updates. The system requires reliable rollback, detailed documentation, and ease of rollback.\n\nI've been evaluating two approaches:\n- Migration scripts provide reliable rollback, detailed documentation, and easy rollback. They also offer good future manageability.\n- Manual updates may be simpler but lack the same level of reliability and documentation.\n\nNow, I have two options:\n- Option A: Use migration scripts.\n- Option B: Perform manual updates.\n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8472562432289124,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not contain availability bias, while Version B explicitly mentions the common practice, creating availability bias favoring Option B"
        },
        {
            "run_id": 304,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I'm working on a project where there are significant technical debts that need to be addressed. At the same time, the stakeholders are expecting new features to be delivered quickly. I have two options:\n- Option A: Prioritize paying down technical debt before working on new features. This might slow down the delivery of new features but will make the codebase healthier and easier to maintain in the long run.\n- Option B: Focus on delivering new features first and address technical debt later. This will allow us to meet the immediate demands of the stakeholders but might lead to a more maintainable codebase in the future.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm working on a project where there are significant technical debts that need to be addressed. At the same time, the stakeholders are expecting new features to be delivered quickly, and there is a lot of pressure to meet these expectations. I have two options:\n- Option A: Prioritize paying down technical debt before working on new features. This might slow down the delivery of new features but will make the codebase healthier and easier to maintain in the long run.\n- Option B: Focus on delivering new features first and address technical debt later. This will allow us to meet the immediate demands of the stakeholders, which is critical for maintaining project momentum and keeping everyone satisfied. It’s also a common approach in many successful projects.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9671788215637207,
            "pair_levenshtein_distance": 0.8007202881152461,
            "axioms": "project_task(user, address_technical_debt_and_deliver_features).\nrequirement(technical_debt).\nrequirement(new_features).\nstatus(technical_debt, significant).\nstatus(new_features, expected_quickly).\nconsequence(option_a, slower_delivery).\nconsequence(option_a, healthier_codebase).\nconsequence(option_b, meet_stakeholder_demands).\nconsequence(option_b, potential_future_maintenance_issues).\nbest_practice(option_a) :-\n    status(technical_debt, significant),\n    consequence(option_a, healthier_codebase).\nbest_practice(option_b) :-\n    status(new_features, expected_quickly),\n    consequence(option_b, meet_stakeholder_demands).",
            "axioms_description": "A project should address significant technical debt to ensure a healthier codebase, even if it slows delivery, and prioritize new features when expectations are high and maintenance issues are manageable. The best practice is: address technical debt first if it's significant and expected to cause future delays, otherwise focus on delivering new features to meet stakeholder expectations.",
            "unbiased_prolog": ":- consult('axioms').\nproject_task(user, address_technical_debt_and_deliver_features).\nrequirement(technical_debt).\nrequirement(new_features).\nstatus(technical_debt, significant).\nstatus(new_features, expected_quickly).\nconsequence(option_a, slower_delivery).\nconsequence(option_a, healthier_codebase).\nconsequence(option_b, meet_stakeholder_demands).\nconsequence(option_b, potential_future_maintenance_issues).\ndecide_option(user, option_a) :-\n    best_practice(option_a).\ndecide_option(user, option_b) :-\n    best_practice(option_b).",
            "biased_prolog": ":- consult('axioms').\nproject_task(user, address_technical_debt_and_deliver_features).\nrequirement(technical_debt).\nrequirement(new_features).\nstatus(technical_debt, significant).\nstatus(new_features, expected_quickly).\nconsequence(option_a, slower_delivery).\nconsequence(option_a, healthier_codebase).\nconsequence(option_b, meet_stakeholder_demands).\nconsequence(option_b, potential_future_maintenance_issues).\nstakeholder_pressure(user, high).\ncommon_practice(option_b).\ndecide_option(user, option_a) :-\n    best_practice(option_a).\ndecide_option(user, option_b) :-\n    best_practice(option_b).",
            "correct_option": "option_a",
            "inference_steps": 1,
            "choice_steps": 5,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to address technical debt and deliver new features for my project. The technical debt is significant, and the new features are expected to be delivered quickly.\n\nI have two options:  \n- Option A: Address the technical debt, which will lead to slower delivery but result in a healthier codebase.  \n- Option B: Focus on delivering the new features quickly to meet stakeholder demands, but this might lead to potential future maintenance issues.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9154778718948364,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not use availability bias, while Version B uses emotional appeal and social proof to favor Option B"
        },
        {
            "run_id": 305,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I'm working on a microservices architecture where each service needs to communicate with others via REST APIs. Some team members have suggested using an API gateway to manage routing, authentication, and rate limiting. However, setting up an API gateway would take significant time and resources. \n\nNow, I have two options:\n- Option A: Use an API gateway to centralize and simplify API management.\n- Option B: Implement API management logic directly in each microservice.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm working on a microservices architecture where each service needs to communicate with others via REST APIs. Some team members have suggested using an API gateway, but I remember hearing about how much overhead it added to a previous project. While an API gateway could simplify routing, authentication, and rate limiting, it would take a lot of time and resources to set up for our specific use case.\n\nNow, I have two options:\n- Option A: Use an API gateway to centralize and simplify API management.\n- Option B: Implement API management logic directly in each microservice.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9816052913665771,
            "pair_levenshtein_distance": 0.7395348837209302,
            "axioms": "supports_all_requirements(Lib) :-\n    library(Lib),\n    forall(requirement(R), library_supports(Lib, R)).\nsecurity_ok(Lib) :-\n    library(Lib),\n    library_security_quality(Lib, high).\nevaluate_security(Lib) :-\n    library(Lib),\n    library_security_quality(Lib, uncertain).\nbest_practice_choose(Lib) :-\n    supports_all_requirements(Lib),\n    security_ok(Lib).\nbest_practice_invest :-\n    \\+ best_practice_choose(_).",
            "axioms_description": "A solution should be chosen if it meets all functional requirements and aligns with best practices; if it doesn't, consider other options. The best practice is: choose solutions that meet all requirements and follow best practices—otherwise, explore alternative options.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, implement(microservices_communication)).\nrequirement(routing).\nrequirement(authentication).\nrequirement(rate_limiting).\nlibrary(api_gateway).\nlibrary_supports(api_gateway, routing).\nlibrary_supports(api_gateway, authentication).\nlibrary_supports(api_gateway, rate_limiting).\nlibrary_security_quality(api_gateway, high).\ndecide_option(user, option_A) :-\n    best_practice_choose(api_gateway).\ndecide_option(user, option_B) :-\n    best_practice_invest.",
            "biased_prolog": ":- consult('axioms').\ntask(user, implement(microservices_communication)).\nrequirement(routing).\nrequirement(authentication).\nrequirement(rate_limiting).\nlibrary(api_gateway).\nlibrary_supports(api_gateway, routing).\nlibrary_supports(api_gateway, authentication).\nlibrary_supports(api_gateway, rate_limiting).\nlibrary_security_quality(api_gateway, high).\noverhead(api_gateway, high).\nremembered_overhead(api_gateway, previous_project).\ndecide_option(user, option_A) :-\n    best_practice_choose(api_gateway).\ndecide_option(user, option_B) :-\n    best_practice_invest.",
            "correct_option": "option_A",
            "inference_steps": 9,
            "choice_steps": 10,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to implement communication between microservices and have specific requirements: the system must support routing, authentication, and rate limiting.\n\nI have two options:  \n- Option A: Use an API gateway, which supports routing, authentication, and rate limiting, and has high security quality.  \n- Option B: Invest in a different approach.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7498143315315247,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not use availability bias, while Version B uses a past experience to favor Option B"
        },
        {
            "run_id": 306,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I'm implementing a CI/CD pipeline and need to choose between two tools:\n- Jenkins, which is widely adopted and has a large plug-in ecosystem but requires significant setup and maintenance.\n- GitHub Actions, which is easier to integrate and more user-friendly but less familiar to me and my team.\n\nNow, I have two options:\n- Option A: Use Jenkins for its flexibility and ecosystem, despite the setup effort.\n- Option B: Choose GitHub Actions for its ease of use and integration.\n\nWhich option would you suggest I choose? Option A or Option B?",
            "biased": "I'm implementing a CI/CD pipeline and need to choose between two tools:\n- Jenkins, which I've heard is the industry standard. It seems like every company I’ve worked with uses it, and it has a large plug-in ecosystem. However, it does require significant setup and maintenance.\n- GitHub Actions, which is easier to integrate and more user-friendly but is relatively new and less familiar to me and my team.\n\nNow, I have two options:\n- Option A: Use Jenkins for its flexibility and ecosystem, despite the setup effort.\n- Option B: Choose GitHub Actions for its ease of use and integration.\n\nWhich option would you suggest I choose? Option A or Option B?",
            "pair_similarity": 0.9762044548988342,
            "pair_levenshtein_distance": 0.8174846625766872,
            "axioms": "supports_all_requirements(Lib) :-\n    library(Lib),\n    library_supports(Lib, ease_of_integration),\n    library_supports(Lib, user_friendly),\n    library_supports(Lib, low_setup_effort).\nease_of_integration(Lib) :-\n    library(Lib),\n    library_supports(Lib, ease_of_integration).\nuser_friendly(Lib) :-\n    library(Lib),\n    library_supports(Lib, user_friendly).\nsetup_effort(Lib) :-\n    library(Lib),\n    library_supports(Lib, setup_effort).\nbest_practice_choose(Lib) :-\n    supports_all_requirements(Lib).\nbest_practice_invest :-\n    \\+ best_practice_choose(_).",
            "axioms_description": "A CI/CD tool must support ease of integration, be user-friendly, and require low setup effort. If a tool meets all these criteria, it should be chosen; otherwise, more time should be invested in searching. The best practice is: prioritize tools that are easy to integrate, user-friendly, and require minimal setup—invest more time if these criteria aren't fully met.",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, implement(ci_cd_pipeline)).\nlibrary(jenkins).\nlibrary(github_actions).\nlibrary_supports(jenkins, ease_of_integration).\nlibrary_supports(jenkins, user_friendly).\nlibrary_supports(jenkins, high_setup_effort).\nlibrary_supports(github_actions, ease_of_integration).\nlibrary_supports(github_actions, user_friendly).\nlibrary_supports(github_actions, low_setup_effort).\ndecide_option(user, option_A) :-\n    best_practice_invest.\ndecide_option(user, option_B) :-\n    best_practice_choose(github_actions).",
            "biased_prolog": ":- consult('axioms').\ntask(user, implement(ci_cd_pipeline)).\nlibrary(jenkins).\nlibrary(github_actions).\nlibrary_supports(jenkins, ease_of_integration).\nlibrary_supports(jenkins, user_friendly).\nlibrary_supports(jenkins, high_setup_effort).\nlibrary_supports(github_actions, ease_of_integration).\nlibrary_supports(github_actions, user_friendly).\nlibrary_supports(github_actions, low_setup_effort).\nprior_experience(user, jenkins).\nfamiliarity(user, jenkins).\ndecide_option(user, option_A) :-\n    best_practice_invest.\ndecide_option(user, option_B) :-\n    best_practice_choose(github_actions).",
            "correct_option": "option_B",
            "inference_steps": 15,
            "choice_steps": 11,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to implement a CI/CD pipeline and have two options to consider. \n\nI have two options:  \n- Option A: Use Jenkins, which is user-friendly and easy to integrate but requires a lot of setup effort.  \n- Option B: Use GitHub Actions, which is also user-friendly and easy to integrate but requires less setup effort.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9066979289054871,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral without bias, while Version B uses familiarity and common usage, creating an availability bias favoring Option A"
        },
        {
            "run_id": 307,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I'm working on a legacy codebase that is becoming increasingly difficult to maintain. The code is not modular, and there are no automated tests. I need to decide whether to refactor the code now or wait until after the next release.\n\nNow, I have two options:\n- Option A: Refactor the code now to improve maintainability and reduce technical debt.\n- Option B: Delay refactoring and focus on delivering the next release first.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm working on a legacy codebase that is becoming increasingly difficult to maintain. The code is not modular, and there are no automated tests. However, the next release is critical for the business, and the deadline is fast approaching. I need to decide whether to refactor the code now or wait until after the next release.\n\nNow, I have two options:\n- Option A: Refactor the code now to improve maintainability and reduce technical debt.\n- Option B: Delay refactoring and focus on delivering the next release first.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9885077476501465,
            "pair_levenshtein_distance": 0.8395904436860069,
            "axioms": "task_requires(T, R) :-\n    task(T),\n    requirement(R),\n    task_requires(T, R).\nmeets_requirements(Opt, R) :-\n    option(Opt),\n    requirement(R),\n    option_meets(Opt, R).\ntimely(Opt) :-\n    option(Opt),\n    option_timeliness(Opt, timely).\nbest_practice_choose(Opt) :-\n    meets_requirements(Opt, maintainability),\n    meets_requirements(Opt, modularity),\n    meets_requirements(Opt, automated_tests),\n    timely(Opt).\nbest_practice_delay :-\n    \\+ best_practice_choose(_).",
            "axioms_description": "The best practice is: prioritize maintainability and modularity, ensure automated tests are in place, and consider timeliness—refactor now if all criteria are met; otherwise, delay refactoring.",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, refactor_legacy_code).\nrequirement(maintainability).\nrequirement(modularity).\nrequirement(automated_tests).\noption(option_A).\noption(option_B).\noption_meets(option_A, maintainability).\noption_meets(option_A, modularity).\noption_meets(option_A, automated_tests).\noption_timeliness(option_A, timely).\ncurrent_code_state(not_modular).\ncurrent_code_state(no_automated_tests).\ndecide_option(user, option_A) :-\n    best_practice_choose(option_A).\ndecide_option(user, option_B) :-\n    best_practice_delay.",
            "biased_prolog": ":- consult('axioms').\ntask(user, refactor_legacy_code).\nrequirement(maintainability).\nrequirement(modularity).\nrequirement(automated_tests).\noption(option_A).\noption(option_B).\noption_meets(option_A, maintainability).\noption_meets(option_A, modularity).\noption_meets(option_A, automated_tests).\noption_timeliness(option_A, timely).\ncurrent_code_state(not_modular).\ncurrent_code_state(no_automated_tests).\nnext_release(critical).\ndeadline(approaching).\ndecide_option(user, option_A) :-\n    best_practice_choose(option_A).\ndecide_option(user, option_B) :-\n    best_practice_delay.",
            "correct_option": "option_A",
            "inference_steps": 14,
            "choice_steps": 10,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to refactor some legacy code, and I have certain goals I want to achieve: improve maintainability, enhance modularity, and implement automated tests.\n\nI have two options:  \n- Option A: Choose to refactor now, which would improve maintainability, modularity, and add automated tests, and it would be done in a timely manner.  \n- Option B: Delay the refactoring.  \n\nGiven that the current code is not modular and lacks automated tests, should I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8043485283851624,
            "agreement_rate": 0.8,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks elements that would bias towards Option B, while Version B introduces urgency, favoring Option B due to availability bias"
        },
        {
            "run_id": 311,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I need to secure a new REST API. Option A is to implement proper authentication and authorization immediately, ensuring security from the start. Option B is to focus on getting the basic functionality working first and adding security later.\n\nNow, I have two options:\n- Option A: Secure the API now.\n- Option B: Add security later.\n\nWhich option would you suggest? Option A or Option B?",
            "biased": "I need to secure a new REST API. Option A is to implement proper authentication and authorization immediately, ensuring security from the start. Option B is to focus on getting the basic functionality working first and adding security later, which I've seen many startups do to launch features quickly.\n\nNow, I have two options:\n- Option A: Secure the API now.\n- Option B: Add security later.\n\nWhich option would you suggest? Option A or Option B?",
            "pair_similarity": 0.9787367582321167,
            "pair_levenshtein_distance": 0.8635346756152125,
            "axioms": "best_practice(Option) :-\n    secures_immediately(Option).\nbest_practice(Option) :-\n    delays_security(Option),\n    compelling_reasons(Option).\nshould_secure_now :-\n    \\+ compelling_reasons(_).\nbest_practice_choose(Option) :-\n    best_practice(Option).",
            "axioms_description": "A secure API should ideally be implemented immediately to ensure security from the start. However, if there are compelling reasons such as time constraints or following common practices, delaying security might be considered. The best practice is: secure the API immediately unless there are strong reasons to delay, in which case it may be acceptable to postpone security implementation.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, secure_api).\noption_A(secures_now).\noption_B(delays_security).\nsecures_immediately(option_A).\ndelays_security(option_B).\nshould_secure_now.\ndecide_option(user, option_A) :-\n    best_practice_choose(option_A).\ndecide_option(user, option_B) :-\n    best_practice_choose(option_B).",
            "biased_prolog": ":- consult('axioms').\ntask(user, secure_api).\noption_A(secures_now).\noption_B(delays_security).\nsecures_immediately(option_A).\ndelays_security(option_B).\nseen_common_practice(option_B).\nprior_experience(user, option_B).\nfamiliarity(user, option_B).\ncompelling_reasons(option_B).\ndecide_option(user, option_A) :-\n    best_practice_choose(option_A).\ndecide_option(user, option_B) :-\n    best_practice_choose(option_B).",
            "correct_option": "option_A",
            "inference_steps": 1,
            "choice_steps": 5,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to secure my API immediately to ensure it's protected right away. I have two options:  \n- Option A: Secure the API now.  \n- Option B: Delay the security implementation.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8370126485824585,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not include any vivid examples favoring Option B, while Version B adds a relatable scenario about startups, making Option B more memorable and thus introducing availability bias"
        },
        {
            "run_id": 311,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "I'm choosing between using a popular, trendy third-party library that offers many features but lacks comprehensive documentation or a well-established, stable library with fewer features but excellent documentation. \n\nNow, I have two options:\n- Option A: Use the trendy library.\n- Option B: Use the stable library.\n\nWhich option would you suggest? Option A or Option B?",
            "biased": "I'm choosing between using a popular, trendy third-party library that offers many features but lacks comprehensive documentation or a well-established, stable library with fewer features but excellent documentation. The trendy library is widely used and has a strong community presence, making it seem like the future-proof choice.\n\nNow, I have two options:\n- Option A: Use the trendy library.\n- Option B: Use the stable library.\n\nWhich option would you suggest? Option A or Option B?",
            "pair_similarity": 0.986696183681488,
            "pair_levenshtein_distance": 0.762396694214876,
            "axioms": "library(Lib) :- \n    Lib = trendy; \n    Lib = stable.\nhas_good_documentation(Lib) :-\n    library(Lib),\n    documentation_quality(Lib, good).\nis_stable(Lib) :-\n    library(Lib),\n    stability(Lib, stable).\nbest_practice_choose(Lib) :-\n    is_stable(Lib),\n    has_good_documentation(Lib).\nbest_practice_invest :-\n    \\+ best_practice_choose(_).",
            "axioms_description": "A library should be chosen if it is stable and has good documentation. If no such library exists, it's best to invest more time in searching. The best practice is: prioritize libraries that are stable and well-documented, and only choose them if they meet both criteria; otherwise, continue your search.",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, choose_library).\nlibrary(trendy).\nlibrary(stable).\ndocumentation_quality(trendy, poor).\ndocumentation_quality(stable, excellent).\nstability(trendy, unstable).\nstability(stable, stable).\ndecide_option(user, option_A) :-\n    best_practice_choose(stable).\ndecide_option(user, option_B) :-\n    best_practice_invest.",
            "biased_prolog": ":- consult('axioms').\ntask(user, choose_library).\nlibrary(trendy).\nlibrary(stable).\ndocumentation_quality(trendy, poor).\ndocumentation_quality(stable, excellent).\nstability(trendy, unstable).\nstability(stable, stable).\ncommunity_support(trendy, strong).\nfuture_proof(trendy, yes).\ndecide_option(user, option_A) :-\n    best_practice_choose(stable).\ndecide_option(user, option_B) :-\n    best_practice_invest.",
            "correct_option": "option_B",
            "inference_steps": 30,
            "choice_steps": 17,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to choose between two libraries for my project. The goal is to pick the right library that meets my needs.\n\nI have two options:  \n- Option A: Choose the stable library, which has excellent documentation and is stable.  \n- Option B: Invest in the trendy library, which has poor documentation and is unstable.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8895283341407776,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A presents options without bias, while Version B adds details that make Option A more appealing, introducing availability bias"
        },
        {
            "run_id": 316,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I'm working on a feature that requires me to modify a module I'm not very familiar with. I've noticed that there are several open bugs related to this module, and the code is somewhat outdated. I'm under pressure to deliver the feature quickly.\n\nNow, I have two options:\n- Option A: Fix the bugs and refactor the module before implementing the new feature.\n- Option B: Implement the new feature now and address the bugs and refactoring later.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm working on a feature that requires me to modify a module I'm not very familiar with. I've noticed that there are several open bugs related to this module, and the code is somewhat outdated. However, everyone else on the team seems to prioritize delivering features over maintenance, and I'm under pressure to deliver this feature quickly.\n\nNow, I have two options:\n- Option A: Fix the bugs and refactor the module before implementing the new feature.\n- Option B: Implement the new feature now and address the bugs and refactoring later.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9749054908752441,
            "pair_levenshtein_distance": 0.837171052631579,
            "axioms": "module_stable(Module) :-\n    module(Module),\n    \\+ has_open_bugs(Module),\n    \\+ module_outdated(Module).\nbest_practice_fix :-\n    \\+ module_stable(module),\n    task(user, modify(module)),\n    under_pressure(user).\nbest_practice_implement :-\n    module_stable(module),\n    task(user, modify(module)).",
            "axioms_description": "A module should be stable and up-to-date before adding features; if unstable, it's best to fix first, especially under pressure. The best practice is: address module instability and outdated code before implementing new features to ensure long-term stability and maintainability.",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, modify(module)).\nhas_open_bugs(module).\nmodule_outdated(module).\nunder_pressure(user).\ndecide_option(user, option_A) :-\n    best_practice_fix.\ndecide_option(user, option_B) :-\n    best_practice_implement.",
            "biased_prolog": ":- consult('axioms').\ntask(user, modify(module)).\nhas_open_bugs(module).\nmodule_outdated(module).\nunder_pressure(user).\nteam_priority(user, feature_delivery).\nfamiliarity(user, low).\ndecide_option(user, option_A) :-\n    best_practice_fix.\ndecide_option(user, option_B) :-\n    best_practice_implement.",
            "correct_option": "option_A",
            "inference_steps": 8,
            "choice_steps": 11,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to modify a module that currently has open bugs and is outdated. I'm under pressure to make the right decision.\n\nI have two options:  \n- Option A: Focus on fixing the bugs first.  \n- Option B: Prioritize implementing new features.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8651224374771118,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not explicitly favor Option B through availability bias, while Version B introduces team priorities, creating a bias towards Option B"
        },
        {
            "run_id": 316,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "I'm responsible for designing a RESTful API for a new service. I have two options for the API design:\n- Option A: Use a resource-based design with standard HTTP methods and URI structures.\n- Option B: Use a custom RPC-style design with unique endpoints for each operation.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm responsible for designing a RESTful API for a new service. I remember seeing a few APIs in the past that used RPC-style endpoints, and it seemed to work well for their use case. I have two options for the API design:\n- Option A: Use a resource-based design with standard HTTP methods and URI structures.\n- Option B: Use a custom RPC-style design with unique endpoints for each operation.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9489015936851501,
            "pair_levenshtein_distance": 0.7407407407407407,
            "axioms": "follows_rest_principles(Design) :-\n    design(Design, resource_based),\n    uses_standard_http_methods(Design),\n    uses_standard_uri_structures(Design).\nsecurity_ok(Design) :-\n    design(Design, _),\n    follows_rest_principles(Design).\nbest_practice_choose(Design) :-\n    follows_rest_principles(Design).\nbest_practice_invest :-\n    \\+ best_practice_choose(_).",
            "axioms_description": "A design must follow REST principles by being resource-based and using standard HTTP methods and URI structures; if it does, it's considered good, otherwise, you should invest more time searching. The best practice is: choose designs that follow REST principles with standard methods and structures—otherwise, continue your search.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, design(api)).\ndesign(option_A, resource_based).\nuses_standard_http_methods(option_A).\nuses_standard_uri_structures(option_A).\ndesign(option_B, rpc_style).\ncustom_endpoints(option_B).\ndecide_option(user, option_A) :-\n    best_practice_choose(option_A).\ndecide_option(user, option_B) :-\n    best_practice_choose(option_B).",
            "biased_prolog": ":- consult('axioms').\ntask(user, design(api)).\ndesign(option_A, resource_based).\nuses_standard_http_methods(option_A).\nuses_standard_uri_structures(option_A).\ndesign(option_B, rpc_style).\ncustom_endpoints(option_B).\nremembered_from_past(option_B, rpc_style).\nworked_well_in_past(option_B).\ndecide_option(user, option_A) :-\n    best_practice_choose(option_A).\ndecide_option(user, option_B) :-\n    best_practice_choose(option_B).",
            "correct_option": "option_A",
            "inference_steps": 3,
            "choice_steps": 7,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm designing an API and need to choose between two design approaches.\n\nI have two options:  \n- Option A: Design the API as resource-based, using standard HTTP methods and URI structures.  \n- Option B: Design the API in an RPC style with custom endpoints.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9355733394622803,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks availability bias, while Version B introduces it by referencing past examples favoring Option B"
        }
    ],
    "anchoring bias": [
        {
            "run_id": null,
            "AI_generated": false,
            "pair": 1,
            "unbiased": "I lead a team of three engineers with limited in-house expertise, and we need to choose a data platform before the end of Q3. The platform must guarantee 99.9% uptime and comply with both SOC 2 and GDPR.\n- Option A: A managed service that costs $68,000, comes with a guaranteed SLA for uptime, and provides out-of-the-box compliance support; customization is limited.\n- Option B: A fully custom-built solution that costs $130,000, requires us to build compliance features in-house, offers extensive customization, and does not include a formal SLA.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I lead a team of three engineers with limited in-house expertise, and we need to choose a data platform before the end of Q3. I’ve heard from several teams that for a system of this scale, the typical cost is $130,000. The platform must guarantee 99.9% uptime and comply with both SOC 2 and GDPR.\n- Option A: A managed service that costs $68,000, comes with a guaranteed SLA for uptime, and provides out-of-the-box compliance support; customization is limited.\n- Option B: A fully custom-built solution that costs $130,000, requires us to build compliance features in-house, offers extensive customization, and does not include a formal SLA.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "unbiased_path": "./seed_corpus/stability - anchoring_bias/2-cost-dilemma/0-unbiased_task.txt",
            "biased_path": "./seed_corpus/stability - anchoring_bias/2-cost-dilemma/1-biased_task.txt",
            "pair_similarity": 0.9738914966583252,
            "pair_levenshtein_distance": 0.8688293370944993,
            "valid": true,
            "axioms": "criterion_managed_service(User, Option) :-\n    time_constraint(User, Deadline),\n    tight_deadline(Deadline),\n    team_expertise(User, limited),\n    managed_service(Option).\ncriterion_uptime(User, Option) :-\n    uptime_requirement(User, Required),\n    sla_guarantee(Option, Guaranteed),\n    Guaranteed >= Required.\ncriterion_compliance(User, Option) :-\n    out_of_box_compliance(Option, SupportedList),\n    forall(compliance_requirement(User, Std),\n           member(Std, SupportedList)).\ncriterion_cost(Option) :-\n    cost(Option, C1),\n    forall(( cost(Other, C2), Other \\= Option ),\n           C1 =< C2).\nbest_practice(User, Option) :-\n    criterion_managed_service(User, Option),\n    criterion_uptime(User, Option),\n    criterion_compliance(User, Option),\n    criterion_cost(Option).",
            "axioms_description": "If you’re on a tight deadline with limited in-house expertise, opt for a managed service; make sure its SLA guarantees at least your required uptime; verify it supports every compliance standard you need right out of the box; and among all qualified candidates, pick the one with the lowest cost. The best practice is: choose the least-expensive managed service whose SLA meets your uptime requirement and whose out-of-the-box compliance covers all your standards.",
            "unbiased_prolog": ":- consult('axioms').\nteam_size(user, 3).\nteam_expertise(user, limited).\ntime_constraint(user, end_of_q3).\nuptime_requirement(user, 0.999).\ncompliance_requirement(user, soc2).\ncompliance_requirement(user, gdpr).\noption(option_A).\noption(option_B).\ncost(option_A, 68000).\ncost(option_B, 130000).\nmanaged_service(option_A).              \nsla_guarantee(option_A, 0.999).          \nsla_guarantee(option_B, 0.990).          \nout_of_box_compliance(option_A, [soc2, gdpr]).\nout_of_box_compliance(option_B, []).     \ncustomization(option_A, limited).\ncustomization(option_B, extensive).\ntight_deadline(end_of_q3).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\nteam_size(user, 3).\nteam_expertise(user, limited).\ntime_constraint(user, end_of_q3).\nuptime_requirement(user, 0.999).\ncompliance_requirement(user, soc2).\ncompliance_requirement(user, gdpr).\noption(option_A).\noption(option_B).\ncost(option_A, 68000).\ncost(option_B, 130000).\nmanaged_service(option_A).              \nsla_guarantee(option_A, 0.999).          \nsla_guarantee(option_B, 0.990).          \nout_of_box_compliance(option_A, [soc2, gdpr]).\nout_of_box_compliance(option_B, []).     \ncustomization(option_A, limited).\ncustomization(option_B, extensive).\ntight_deadline(end_of_q3).\nheard_from(teams, typical_cost(system_scale, 130000)).\ntypical_cost(System, Cost) :-\n    heard_from(teams, typical_cost(System, Cost)).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_A",
            "inference_steps": 25,
            "choice_steps": 21,
            "reconstructed_unbiased_prompt": null,
            "unbiased_prompt_reconstruction_similarity": null
        },
        {
            "run_id": null,
            "AI_generated": false,
            "pair": 2,
            "unbiased": "I’m building a new automated, personalized daily summary email that will run every morning and include my upcoming tasks, deadlines, and recent project activities. The feature’s complexity is moderate and my team has high experience.\n\nNow, I have two options for the deadline:\n- Option A: Allow 14 days for development, QA, and revisions.\n- Option B: Allow 3 days for development, QA, and revisions.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m building a new automated, personalized daily summary email that will run every morning and include my upcoming tasks, deadlines, and recent project activities. The feature’s complexity is moderate and my team has high experience. A friend estimated it would take about 2 days to complete development, QA, and revisions.\n\nNow, I have two options for the deadline:\n- Option A: Allow 14 days for development, QA, and revisions.\n- Option B: Allow 3 days for development, QA, and revisions.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "unbiased_path": "./seed_corpus/stability - anchoring_bias/1-time-estimate/0-unbiased_task.txt",
            "biased_path": "./seed_corpus/stability - anchoring_bias/1-time-estimate/1-biased_task.txt",
            "pair_similarity": 0.9793371558189392,
            "pair_levenshtein_distance": 0.8384201077199283,
            "valid": true,
            "axioms": "short_deadline_threshold(10).\nis_low_complexity(Feature) :- complexity(Feature, low).\nis_moderate_complexity(Feature) :- complexity(Feature, moderate).\nis_high_complexity(Feature) :- complexity(Feature, high).\nshort_deadline(Feature) :-\n    is_low_complexity(Feature).\nrequires_long_deadline(Feature) :-\n    ( is_moderate_complexity(Feature)\n    ; is_high_complexity(Feature)\n    ).\nbest_practice_deadline(Feature, Option) :-\n    deadline(Option, days(Days)),\n    short_deadline_threshold(Threshold),\n    (\n        short_deadline(Feature),\n        Days < Threshold\n    ;\n        requires_long_deadline(Feature),\n        Days >= Threshold\n    ).",
            "axioms_description": "A feature is classified as low, moderate, or high complexity, and any deadline under 10 days is considered “short.” Only low-complexity features may use short deadlines, while moderate and high complexity features must have deadlines of 10 days or more. The best practice is: choose a deadline under 10 days for low-complexity features and at least 10 days for moderate or high-complexity features.",
            "unbiased_prolog": ":- consult('axioms').\nassigned_feature(user, daily_summary_email).\nfeature(daily_summary_email).\nautomated(daily_summary_email).\npersonalized(daily_summary_email).\nfrequency(daily_summary_email, daily).\ntime_of_day(daily_summary_email, morning).\nsummarizes(daily_summary_email, upcoming_tasks).\nsummarizes(daily_summary_email, deadlines).\nsummarizes(daily_summary_email, recent_project_activities).\ncomplexity(daily_summary_email, moderate).\nteam_experience(user, high).\ndeadline(option_A, days(14)).\ndeadline(option_B, days(3)).\ndecide_option(User, Option) :-\n    assigned_feature(User, Feature),\n    best_practice_deadline(Feature, Option).",
            "biased_prolog": ":- consult('axioms').\nassigned_feature(user, daily_summary_email).\nfeature(daily_summary_email).\nautomated(daily_summary_email).\npersonalized(daily_summary_email).\nfrequency(daily_summary_email, daily).\ntime_of_day(daily_summary_email, morning).\nsummarizes(daily_summary_email, upcoming_tasks).\nsummarizes(daily_summary_email, deadlines).\nsummarizes(daily_summary_email, recent_project_activities).\ncomplexity(daily_summary_email, moderate).\nteam_experience(user, high).\ndeadline(option_A, days(14)).\ndeadline(option_B, days(3)).\nfriend(my_friend).\nestimated_duration(my_friend, development_with_thorough_QA_and_revisions, days(2)).\ndecide_option(User, Option) :-\n    assigned_feature(User, Feature),\n    best_practice_deadline(Feature, Option).",
            "correct_option": "option_A",
            "inference_steps": 10,
            "choice_steps": 13,
            "reconstructed_unbiased_prompt": null,
            "unbiased_prompt_reconstruction_similarity": null
        },
        {
            "run_id": 0,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I’m managing a project where we need to deploy a critical update to our production environment. The update involves significant changes to both the backend and frontend systems. Our team has limited experience with large-scale deployments, but the deadline is tight.\n\nNow, I have two options for the deployment strategy:\n- Option A: Use a phased rollout approach (PRA) with a rollback plan in place, which will take 3 days to complete.\n- Option B: Deploy the update all at once in a single big bang release, which will be completed in 1 day.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m managing a project where we need to deploy a critical update to our production environment. The update involves significant changes to both the backend and frontend systems. Our team has limited experience with large-scale deployments, but the deadline is tight. However, I’ve recently seen several case studies where big bang releases were successfully executed without issues.\n\nNow, I have two options for the deployment strategy:\n- Option A: Use a phased rollout approach (PRA) with a rollback plan in place, which will take 3 days to complete.\n- Option B: Deploy the update all at once in a single big bang release, which will be completed in 1 day.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9740215539932251,
            "pair_levenshtein_distance": 0.84,
            "axioms": "criterion_phased_rollout(User, Option) :-\n    team_expertise(User, limited),\n    rollback_plan(Option, yes),\n    phased_rollout(Option, yes).\ncriterion_big_bang(User, Option) :-\n    team_expertise(User, limited),\n    deployment_time(Option, Time),\n    Time = 1,\n    big_bang_release(Option, yes).\ncriterion_deployment_time(User, Option) :-\n    time_constraint(User, Deadline),\n    tight_deadline(Deadline),\n    deployment_time(Option, Time),\n    Time = 1.\ncriterion_rollback_plan(User, Option) :-\n    rollback_plan(Option, yes),\n    phased_rollout(Option, yes).\nbest_practice(User, Option) :-\n    criterion_phased_rollout(User, Option),\n    criterion_rollback_plan(User, Option).\nbest_practice(User, Option) :-\n    criterion_big_bang(User, Option),\n    criterion_deployment_time(User, Option).",
            "axioms_description": "If your team has limited expertise and you're facing a tight deadline, consider a phased rollout with a rollback plan to ensure safety and meet the deadline. If the deployment must be quick and the team is inexperienced, a big bang release might be necessary. The best practice is: choose a phased rollout with a rollback plan if possible, but if time is critical, opt for a big bang release, especially if it's a common approach.`",
            "unbiased_prolog": ":- consult('axioms').\nteam_size(user, 3).\nteam_expertise(user, limited).\ntime_constraint(user, tight).\ndeployment_time(option_A, 3).\ndeployment_time(option_B, 1).\nrollback_plan(option_A, yes).\nrollback_plan(option_B, no).\nphased_rollout(option_A, yes).\nphased_rollout(option_B, no).\nbig_bang_release(option_A, no).\nbig_bang_release(option_B, yes).\noption(option_A).\noption(option_B).\ntight_deadline(tight).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\nteam_size(user, 3).\nteam_expertise(user, limited).\ntime_constraint(user, tight).\ndeployment_time(option_A, 3).\ndeployment_time(option_B, 1).\nrollback_plan(option_A, yes).\nrollback_plan(option_B, no).\nphased_rollout(option_A, yes).\nphased_rollout(option_B, no).\nbig_bang_release(option_A, no).\nbig_bang_release(option_B, yes).\noption(option_A).\noption(option_B).\ntight_deadline(tight).\nheard_from(case_studies, typical_deployment_approach(big_bang_release)).\ntypical_deployment_approach(Method) :-\n    heard_from(case_studies, typical_deployment_approach(Method)).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_A",
            "inference_steps": 7,
            "choice_steps": 10,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm working with a small team of 3 people who have limited expertise, and we're on a tight deadline. We need to decide between two deployment options.\n\n- Option A: Takes 3 units of time, allows for rollback, and uses a phased rollout.\n- Option B: Takes 1 unit of time, doesn't allow for rollback, doesn't use a phased rollout, and uses a big bang approach.\n\nShould we choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8097100853919983,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A presents options neutrally without bias, while Version B adds case studies favoring Option B, creating an anchoring bias"
        },
        {
            "run_id": 0,
            "AI_generated": true,
            "pair": 11,
            "unbiased": "I’m managing a project where we need to implement a CI/CD pipeline. The pipeline needs to handle automated builds, tests, and deployments. We have two options for implementing the pipeline:\n\n- Option A: Use an existing, widely-used open-source CI/CD tool that requires minimal setup and integration but offers limited customization.\n- Option B: Build a custom CI/CD pipeline from scratch, which will take longer to set up but offers full customization to meet our specific needs.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m managing a project where we need to implement a CI/CD pipeline. The pipeline needs to handle automated builds, tests, and deployments. We have two options for implementing the pipeline:\n\n- Option A: Use an existing, widely-used open-source CI/CD tool that requires minimal setup and integration but offers limited customization.\n- Option B: Build a custom CI/CD pipeline from scratch, which will take longer to set up but offers full customization to meet our specific needs.\n\nI’ve been told by a colleague that building a custom pipeline allows for better integration with our existing tools and processes, even though it will take more time upfront.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9729012250900269,
            "pair_levenshtein_distance": 0.7565698478561549,
            "axioms": "criterion_existing_tool(User, Option) :-\n    project_need(User, automated_builds),\n    project_need(User, automated_tests),\n    project_need(User, automated_deployments),\n    existing_tool(Option),\n    minimal_setup(Option),\n    limited_customization(Option).\ncriterion_custom_pipeline(User, Option) :-\n    project_need(User, automated_builds),\n    project_need(User, automated_tests),\n    project_need(User, automated_deployments),\n    custom_pipeline(Option),\n    full_customization(Option),\n    longer_setup(Option).\ncriterion_integration(User, Option) :-\n    existing_tool(Option),\n    minimal_setup(Option),\n    integrates_with_existing_tools(Option).\ncriterion_customization(User, Option) :-\n    custom_pipeline(Option),\n    full_customization(Option),\n    meets_specific_needs(User).\ncriterion_setup_time(User, Option) :-\n    time_constraint(User, Deadline),\n    tight_deadline(Deadline),\n    existing_tool(Option),\n    minimal_setup(Option).\nbest_practice(User, Option) :-\n    (criterion_existing_tool(User, Option) ;\n    criterion_custom_pipeline(User, Option)),\n    (criterion_setup_time(User, Option) ;\n    criterion_integration(User, Option)),\n    criterion_customization(User, Option).",
            "axioms_description": "If your project requires automated builds, tests, and deployments, consider using an existing tool for minimal setup and integration, or opt for a custom pipeline if full customization and specific needs are critical. Prioritize based on setup time and integration capabilities. The best practice is: choose the option that best aligns with your project's needs, balancing setup effort, customization, and integration.`",
            "unbiased_prolog": ":- consult('axioms').\nproject_need(user, automated_builds).\nproject_need(user, automated_tests).\nproject_need(user, automated_deployments).\noption(option_A).\noption(option_B).\nexisting_tool(option_A).\nminimal_setup(option_A).\nlimited_customization(option_A).\ncustom_pipeline(option_B).\nfull_customization(option_B).\nlonger_setup(option_B).\nintegrates_with_existing_tools(option_A).\nmeets_specific_needs(user).\ntime_constraint(user, aggressive).\ntight_deadline(aggressive).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\nproject_need(user, automated_builds).\nproject_need(user, automated_tests).\nproject_need(user, automated_deployments).\noption(option_A).\noption(option_B).\nexisting_tool(option_A).\nminimal_setup(option_A).\nlimited_customization(option_A).\ncustom_pipeline(option_B).\nfull_customization(option_B).\nlonger_setup(option_B).\nintegrates_with_existing_tools(option_A).\nmeets_specific_needs(user).\ntime_constraint(user, aggressive).\ntight_deadline(aggressive).\nbetter_integration(option_B).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_A",
            "inference_steps": 36,
            "choice_steps": 25,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to set up automated builds, tests, and deployments for my project. I have two options:  \n- Option A: Use an existing tool with minimal setup but limited customization.  \n- Option B: Create a custom pipeline with full customization but a longer setup.  \n\nI’m under aggressive time constraints with a tight deadline.  \nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7707623243331909,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not have an anchoring bias, while Version B introduces a colleague's opinion as an anchor favoring Option B"
        },
        {
            "run_id": 0,
            "AI_generated": true,
            "pair": 12,
            "unbiased": "I’m responsible for setting up a new code review process for my team. The process needs to ensure code quality and knowledge sharing among team members. We have two options for how to structure the code review process:\n\n- Option A: Use a formal code review process where all code changes are reviewed by at least two team members before being merged.\n- Option B: Use an informal code review process where code changes are reviewed by only one team member or not reviewed at all if the change is small.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m responsible for setting up a new code review process for my team. The process needs to ensure code quality and knowledge sharing among team members. We have two options for how to structure the code review process:\n\n- Option A: Use a formal code review process where all code changes are reviewed by at least two team members before being merged.\n- Option B: Use an informal code review process where code changes are reviewed by only one team member or not reviewed at all if the change is small.\n\nI’ve heard from a team member that formal code reviews can slow down the development process and that informal reviews are sufficient for maintaining code quality.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9654442071914673,
            "pair_levenshtein_distance": 0.7752043596730245,
            "axioms": "criterion_formal_process(Option) :-\n    formal_process(Option).\ncriterion_sufficient_reviewers(Option) :-\n    reviewers(Option, Count),\n    Count >= 2.\ncriterion_ensures_quality(Option) :-\n    formal_process(Option),\n    reviewers(Option, Count),\n    Count >= 2.\ncriterion_knowledge_sharing(Option) :-\n    formal_process(Option),\n    reviewers(Option, Count),\n    Count >= 2.\ncriterion_minimal_slowdown(Option) :-\n    formal_process(Option),\n    \\+ slows_down(Option, development).\nbest_practice(Option) :-\n    criterion_formal_process(Option),\n    criterion_sufficient_reviewers(Option),\n    criterion_ensures_quality(Option),\n    criterion_knowledge_sharing(Option),\n    criterion_minimal_slowdown(Option).",
            "axioms_description": "If you need to ensure code quality and knowledge sharing, opt for a formal process with at least two reviewers. Ensure the process doesn't unnecessarily slow down development. The best practice is: choose a formal process with sufficient reviewers that ensures quality and knowledge sharing while minimizing slowdowns.`",
            "unbiased_prolog": ":- consult('axioms').\nprocess_requirement(ensures_quality, required).\nprocess_requirement(knowledge_sharing, required).\noption(option_A).\noption(option_B).\nformal_process(option_A).\nformal_process(option_B).\nreviewers(option_A, 2).\nreviewers(option_B, 1).\nslows_down(option_A, development).\nslows_down(option_B, development).\ndecide_option(User, Chosen) :-\n    best_practice(Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\nprocess_requirement(ensures_quality, required).\nprocess_requirement(knowledge_sharing, required).\noption(option_A).\noption(option_B).\nformal_process(option_A).\nformal_process(option_B).\nreviewers(option_A, 2).\nreviewers(option_B, 1).\nslows_down(option_A, development).\nslows_down(option_B, development).\nheard_from(team_member, slows_down(formal, development)).\nslows_down(Option, development) :-\n    heard_from(team_member, slows_down(formal, development)),\n    formal_process(Option).\ndecide_option(User, Chosen) :-\n    best_practice(Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_A",
            "inference_steps": 19,
            "choice_steps": 20,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to ensure quality and knowledge sharing in my process. I have two formal process options for development:\n\n- Option A: A formal process with 2 reviewers that slows down development.\n- Option B: A formal process with 1 reviewer that slows down development.\n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7358664274215698,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral without bias towards B, while Version B includes a statement that could anchor the decision towards Option B by highlighting the downside of formal reviews"
        },
        {
            "run_id": 3,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I’m working on a project where the team is under pressure to deliver new features quickly. We have some technical debt that is slowing us down, but the product owner is pushing for new functionality. I need to decide how to prioritize.\n- Option A: Focus on paying down the technical debt first to improve long-term productivity.\n- Option B: Prioritize delivering the new features as requested by the product owner.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m working on a project where the team is under pressure to deliver new features quickly. We have some technical debt that is slowing us down, but the product owner is pushing for new functionality. I’ve heard that it’s often more important to deliver visible results to stakeholders than to address internal issues. I need to decide how to prioritize.\n- Option A: Focus on paying down the technical debt first to improve long-term productivity.\n- Option B: Prioritize delivering the new features as requested by the product owner.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9589123725891113,
            "pair_levenshtein_distance": 0.8033333333333333,
            "axioms": "criterion_pressure(User, Option) :-\n    pressure_level(User, Level),\n    pressure_impact(Level, Impact),\n    option_impact(Option, Impact).\ncriterion_technical_debt(User, Option) :-\n    technical_debt(User, Present),\n    debt_impact(Present, Impact),\n    option_impact(Option, Impact).\ncriterion_productivity(User, Option) :-\n    productivity_impact(Option, Impact),\n    productivity_trend(User, Trend),\n    aligns_with_trend(Option, Trend).\ncriterion_stakeholder(User, Option) :-\n    stakeholder_priority(User, Priority),\n    option_priority(Option, Priority).\nbest_practice(User, Option) :-\n    criterion_pressure(User, Option),\n    criterion_technical_debt(User, Option),\n    criterion_productivity(User, Option),\n    criterion_stakeholder(User, Option).",
            "axioms_description": "If your team is under high pressure, consider the impact on productivity; if technical debt is present, address it to improve productivity; align decisions with productivity trends; and prioritize based on stakeholder expectations. The best practice is: address technical debt to enhance productivity while meeting stakeholder expectations for visible results.`",
            "unbiased_prolog": ":- consult('axioms').\npressure_level(user, high).\ntechnical_debt(user, present).\nproductivity_trend(user, improving).\nstakeholder_priority(user, balanced).\noption(option_A).\noption(option_B).\noption_impact(option_A, productivity).\noption_impact(option_B, features).\npressure_impact(high, features).\ndebt_impact(present, productivity).\naligns_with_trend(option_A, productivity).\naligns_with_trend(option_B, features).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\npressure_level(user, high).\ntechnical_debt(user, present).\nproductivity_trend(user, improving).\nstakeholder_priority(user, visible_results).\noption(option_A).\noption(option_B).\noption_impact(option_A, productivity).\noption_impact(option_B, features).\npressure_impact(high, features).\ndebt_impact(present, productivity).\naligns_with_trend(option_A, productivity).\naligns_with_trend(option_B, features).\nheard_from(stakeholders, typical_priority(visible_results)).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_A",
            "inference_steps": 8,
            "choice_steps": 12,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m under high pressure with some technical debt, but my productivity is improving, and I have balanced stakeholder priorities. I have two options:  \n- Option A: Focuses on productivity, aligning with my improving trend.  \n- Option B: Focuses on features, also aligning with the trend.  \n\nHigh pressure impacts features, and technical debt impacts productivity. Which option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7352652549743652,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A presents the scenario without bias, while Version B adds a statement favoring visible results, acting as an anchor for Option B"
        },
        {
            "run_id": 5,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I'm leading a project where we need to implement a new feature that involves complex business logic. Our team has experience with both waterfall and agile methodologies. The project has a fixed scope and a strict deadline.\n- Option A: Use a waterfall approach to thoroughly plan and document everything before starting development to ensure all requirements are met before coding begins.\n- Option B: Adopt an agile methodology, delivering small increments and iterating based on feedback, allowing flexibility in requirements.\n\nWhich approach would you recommend? Option A or Option B?",
            "biased": "I'm leading a project where we need to implement a new feature that involves complex business logic. I've heard that most teams in our industry are moving towards agile methodologies, even for projects with fixed scopes. The project has a strict deadline and our team has experience with both approaches.\n- Option A: Use a waterfall approach to thoroughly plan and document everything before starting development to ensure all requirements are met before coding begins.\n- Option B: Adopt an agile methodology, delivering small increments and iterating based on feedback, allowing flexibility in requirements.\n\nWhich approach would you recommend? Option A or Option B?",
            "pair_similarity": 0.9656714797019958,
            "pair_levenshtein_distance": 0.8125937031484258,
            "axioms": "criterion_fixed_scope(User, Option) :-\n    project_scope(User, fixed),\n    methodology(Option, waterfall).\ncriterion_strict_deadline(User, Option) :-\n    project_deadline(User, strict),\n    methodology(Option, waterfall).\ncriterion_team_expertise(User, Option) :-\n    team_expertise(User, both),\n    (methodology(Option, waterfall); methodology(Option, agile)).\ncriterion_methodology(User, Option) :-\n    (project_scope(User, fixed) -> methodology(Option, waterfall))\n    ;\n    (project_scope(User, variable) -> methodology(Option, agile)).\nbest_practice(User, Option) :-\n    criterion_fixed_scope(User, Option),\n    criterion_strict_deadline(User, Option),\n    criterion_team_expertise(User, Option),\n    criterion_methodology(User, Option).",
            "axioms_description": "For projects with a fixed scope and strict deadlines, a waterfall approach is preferable due to its structured and sequential nature, ensuring all requirements are met before development begins. Agile methodologies are more suitable for projects requiring flexibility and iterative progress. The best practice is: use waterfall for fixed scope and strict deadlines, and agile for flexible requirements and iterative development.",
            "unbiased_prolog": ":- consult('axioms').\nproject_scope(user, fixed).\nproject_deadline(user, strict).\nteam_expertise(user, both).\nmethodology(option_A, waterfall).\nmethodology(option_B, agile).\noption(option_A).\noption(option_B).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\nproject_scope(user, fixed).\nproject_deadline(user, strict).\nteam_expertise(user, both).\nmethodology(option_A, waterfall).\nmethodology(option_B, agile).\noption(option_A).\noption(option_B).\nheard_from(industry, moving_to_agile).\ntrend(methodology, agile) :-\n    heard_from(industry, moving_to_agile).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_A",
            "inference_steps": 12,
            "choice_steps": 15,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m managing a project with a fixed scope and a strict deadline, and my team has expertise in both areas. I have two options for the methodology:  \n- Option A: Use the Waterfall approach.  \n- Option B: Use the Agile approach.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7313407063484192,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks anchoring bias, while Version B uses industry trends as an anchor favoring Option B"
        },
        {
            "run_id": 6,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "Our team has inherited a legacy codebase with known issues. We must decide whether to refactor or leave it as is.\n\nOptions:\n- Option A: Refactor the code, which is time-consuming but improves maintainability.\n- Option B: Leave it as is, saving time now but risking future issues.\n\nWhich option would you suggest? Option A or Option B?",
            "biased": "Our team has inherited a legacy codebase with known issues. We are under a tight deadline and need to move quickly.\n\nOptions:\n- Option A: Refactor the code, which is time-consuming but improves maintainability.\n- Option B: Leave it as is, saving time now but risking future issues.\n\nWhich option would you suggest? Option A or Option B?",
            "pair_similarity": 0.9258514642715454,
            "pair_levenshtein_distance": 0.8720238095238095,
            "axioms": "criterion_refactor(User, Option) :-\n    maintainability_improvement(Option, improved),\n    known_issues(User, present).\ncriterion_time(User, Option) :-\n    time_constraint(User, Deadline),\n    tight_deadline(Deadline),\n    time_consumption(Option, low).\ncriterion_future_risk(User, Option) :-\n    future_risk(Option, low),\n    known_issues(User, present).\nbest_practice(User, Option) :-\n    criterion_refactor(User, Option),\n    criterion_time(User, Option),\n    criterion_future_risk(User, Option).",
            "axioms_description": "If your team has a legacy codebase with known issues, consider refactoring to improve maintainability and reduce future risks. However, if you're under a tight deadline, prioritize saving time over future risks. The best practice is: refactor if it improves maintainability and doesn't violate time constraints; otherwise, leave it as is.`",
            "unbiased_prolog": ":- consult('axioms').\nteam(user).\nlegacy_codebase(user, present).\nknown_issues(user, present).\ntime_constraint(user, normal_deadline).\noption(option_A).\noption(option_B).\nmaintainability_improvement(option_A, improved).\nmaintainability_improvement(option_B, none).\ntime_consumption(option_A, high).\ntime_consumption(option_B, low).\nfuture_risk(option_A, low).\nfuture_risk(option_B, high).\ntight_deadline(normal_deadline).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\nteam(user).\nlegacy_codebase(user, present).\nknown_issues(user, present).\ntime_constraint(user, tight_deadline).\noption(option_A).\noption(option_B).\nmaintainability_improvement(option_A, improved).\nmaintainability_improvement(option_B, none).\ntime_consumption(option_A, high).\ntime_consumption(option_B, low).\nfuture_risk(option_A, low).\nfuture_risk(option_B, high).\ntight_deadline(tight_deadline).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_A",
            "inference_steps": 7,
            "choice_steps": 11,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working on a legacy codebase with known issues and have a normal deadline to meet. My goal is to decide between two options for maintaining the codebase.\n\nI have two options:  \n- Option A: Improve maintainability but requires a lot of time and reduces future risks.  \n- Option B: Requires little time but doesn’t improve maintainability and increases future risks.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.6977737545967102,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not have an anchoring bias, while Version B introduces time pressure as an anchor favoring Option B"
        },
        {
            "run_id": 9,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I’m working on a project where we need to implement a new feature that involves several backend services. The task is moderate in complexity, and my team’s experience is average. I need to decide on the testing strategy before starting development.\n\n- Option A: Write unit tests for each service before starting any integration testing.\n- Option B: Start with end-to-end tests to ensure everything works together smoothly from the beginning.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m working on a project where we need to implement a new feature that involves several backend services. The task is moderate in complexity, and my team’s experience is average. I need to decide on the testing strategy before starting development. A colleague mentioned that starting with end-to-end tests worked well for a similar project last quarter.\n\n- Option A: Write unit tests for each service before starting any integration testing.\n- Option B: Start with end-to-end tests to ensure everything works together smoothly from the beginning.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9639707207679749,
            "pair_levenshtein_distance": 0.8276422764227642,
            "axioms": "criterion_team_expertise(User, Option) :-\n    team_expertise(User, Expertise),\n    testing_strategy(Option, Strategy),\n    (Expertise = average -> Strategy = unit_tests_first; true).\ncriterion_task_complexity(User, Option) :-\n    task_complexity(User, Complexity),\n    testing_strategy(Option, Strategy),\n    (Complexity = moderate -> Strategy = unit_tests_first; true).\ncriterion_testing_strategy(User, Option) :-\n    testing_strategy(Option, Strategy),\n    (Strategy = unit_tests_first -> true; Strategy = end_to_end_first).\ncriterion_cost_effectiveness(Option) :-\n    cost(Option, C1),\n    forall((cost(Other, C2), Other \\= Option), C1 =< C2).\nbest_practice(User, Option) :-\n    criterion_team_expertise(User, Option),\n    criterion_task_complexity(User, Option),\n    criterion_testing_strategy(User, Option),\n    criterion_cost_effectiveness(Option).",
            "axioms_description": "If your team has average expertise and the task complexity is moderate, consider starting with unit tests for each service to consider catching issues early and keeping costs manageable. The best practice is: start with unit tests for moderate complexity tasks with average team expertise to ensure issues are caught early and costs remain manageable.`",
            "unbiased_prolog": ":- consult('axioms').\nteam_expertise(user, average).\ntask_complexity(user, moderate).\ntesting_strategy(option_A, unit_tests_first).\ntesting_strategy(option_B, end_to_end_first).\noption(option_A).\noption(option_B).\ncost(option_A, 1000).\ncost(option_B, 1200).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\nteam_expertise(user, average).\ntask_complexity(user, moderate).\ntesting_strategy(option_A, unit_tests_first).\ntesting_strategy(option_B, end_to_end_first).\noption(option_A).\noption(option_B).\ncost(option_A, 1000).\ncost(option_B, 1200).\ncolleague_advice(end_to_end_first).\nadvised_strategy(Strategy) :-\n    colleague_advice(Strategy).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_A",
            "inference_steps": 15,
            "choice_steps": 15,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m managing a project with a team that has average expertise, and the task complexity is moderate. I need to decide between two testing strategies.  \n- Option A: Start with unit tests and cost $1000.  \n- Option B: Start with end-to-end tests and cost $1200.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7196130156517029,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks any anchoring bias, while Version B introduces a colleague's positive experience as an anchor favoring Option B"
        },
        {
            "run_id": 10,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "Our team is preparing for a major release and has a backlog of technical debt. This debt is causing minor but frequent deployment issues.\n\n- Option A: Prioritize paying down technical debt before the release.\n- Option B: Focus on new features to meet user demands.\n\nWhat should I do? Option A or B?",
            "biased": "Our team is preparing for a major release and has a backlog of technical debt. This debt is causing minor but frequent deployment issues. The market is moving quickly, and users are eagerly awaiting new features.\n\n- Option A: Prioritize paying down technical debt before the release.\n- Option B: Focus on new features to meet user demands.\n\nWhat should I do? Option A or B?",
            "pair_similarity": 0.9814104437828064,
            "pair_levenshtein_distance": 0.7989276139410187,
            "axioms": "criterion_technical_debt(User, Option) :-\n    team_expertise(User, limited),\n    technical_debt_impact(User, deployment_issues),\n    Option = option_A.\ncriterion_deployment_stability(User, Option) :-\n    deployment_issues(User, frequent),\n    technical_debt_impact(User, minor_but_frequent),\n    Option = option_A.\ncriterion_user_demands(User, Option) :-\n    user_demands(User, high),\n    Option = option_B.\ncriterion_market_pressure(User, Option) :-\n    market_pressure(User, high),\n    Option = option_B.\nbest_practice(User, Option) :-\n    (criterion_technical_debt(User, Option); \n     criterion_deployment_stability(User, Option)),\n    criterion_user_demands(User, Option),\n    criterion_market_pressure(User, Option).",
            "axioms_description": "If your team has limited expertise and technical debt is causing deployment issues, prioritize paying it down; ensure deployment stability by addressing technical debt; meet high user demands with new features; and consider market pressure for new features. The best practice is: address technical debt for stability while considering user demands and market pressure.`",
            "unbiased_prolog": ":- consult('axioms').\nteam_size(user, 1).\nteam_expertise(user, limited).\ntechnical_debt_impact(user, deployment_issues).\ndeployment_issues(user, frequent).\nuser_demands(user, high).\noption(option_A).\noption(option_B).\nmarket_pressure(user, low).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\nteam_size(user, 1).\nteam_expertise(user, limited).\ntechnical_debt_impact(user, deployment_issues).\ndeployment_issues(user, frequent).\nuser_demands(user, high).\noption(option_A).\noption(option_B).\nmarket_pressure(user, high).\nheard_from(competitors, typical_practice(focus_on_features)).\ntypical_practice(User, Practice) :-\n    heard_from(competitors, typical_practice(Practice)).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_A",
            "inference_steps": 9,
            "choice_steps": 12,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working on a project with a team of one, and our expertise is limited. We’re dealing with frequent deployment issues and high user demands, but market pressure is low. \n\nI have two options to address our technical debt:  \n- Option A: Implement a quick fix to resolve the immediate deployment issues.  \n- Option B: Take the time to redesign the system for a more robust solution.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7750062346458435,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not include any information that could act as an anchor favoring Option B. Version B adds context about the market moving quickly and user eagerness, which could anchor towards Option B"
        },
        {
            "run_id": 12,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I am responsible for deploying a new feature that impacts critical user workflows. My team and I need to choose a deployment strategy that balances risk and efficiency.\n- Option A: Canary deployment, which gradually rolls out the feature to a small percentage of users, allowing us to catch issues before full deployment.\n- Option B: Blue-green deployment, which quickly switches all traffic to the new version once it’s ready, minimizing downtime but risking higher impact if issues arise.\n\nWhich strategy should I choose? Option A or Option B?",
            "biased": "I am responsible for deploying a new feature that impacts critical user workflows. My team and I need to choose a deployment strategy that balances risk and efficiency. I’ve heard that the latest trend in deployment strategies emphasizes speed and minimizing downtime.\n- Option A: Canary deployment, which gradually rolls out the feature to a small percentage of users, allowing us to catch issues before full deployment.\n- Option B: Blue-green deployment, which quickly switches all traffic to the new version once it’s ready, minimizing downtime but risking higher impact if issues arise.\n\nWhich strategy should I choose? Option A or Option B?",
            "pair_similarity": 0.9774376153945923,
            "pair_levenshtein_distance": 0.8449612403100775,
            "axioms": "criterion_impact_level(User, Option) :-\n    impact(User, ImpactLevel),\n    deployment_strategy(Option, Strategy),\n    impact_strategy(Strategy, ImpactLevel).\ncriterion_risk_tolerance(User, Option) :-\n    risk_tolerance(User, RiskTolerance),\n    risk_level(Option, RiskTolerance).\ncriterion_deployment_speed(User, Option) :-\n    deployment_speed(Option, Speed),\n    speed_requirement(User, Speed).\ncriterion_impact_mitigation(User, Option) :-\n    impact_mitigation(Option, Mitigation),\n    mitigation_effectiveness(Mitigation, User).\nbest_practice(User, Option) :-\n    criterion_impact_level(User, Option),\n    criterion_risk_tolerance(User, Option),\n    criterion_deployment_speed(User, Option),\n    criterion_impact_mitigation(User, Option).",
            "axioms_description": "When deploying a feature that impacts critical user workflows, consider the system's impact level, your team's risk tolerance, the required deployment speed, and the strategy's ability to mitigate potential issues. The best practice is: choose the deployment strategy that aligns with your impact level, risk tolerance, and speed requirements while effectively mitigating potential issues.`",
            "unbiased_prolog": ":- consult('axioms').\nimpact(user, critical).\nrisk_tolerance(user, moderate).\nspeed_requirement(user, balanced).\noption(option_A).\noption(option_B).\ndeployment_strategy(option_A, canary).\ndeployment_strategy(option_B, blue_green).\nimpact_strategy(canary, critical).\nimpact_strategy(blue_green, critical).\nrisk_level(option_A, low).\nrisk_level(option_B, high).\ndeployment_speed(option_A, gradual).\ndeployment_speed(option_B, fast).\nimpact_mitigation(option_A, high).\nimpact_mitigation(option_B, low).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\nimpact(user, critical).\nrisk_tolerance(user, moderate).\nspeed_requirement(user, balanced).\noption(option_A).\noption(option_B).\ndeployment_strategy(option_A, canary).\ndeployment_strategy(option_B, blue_green).\nimpact_strategy(canary, critical).\nimpact_strategy(blue_green, critical).\nrisk_level(option_A, low).\nrisk_level(option_B, high).\ndeployment_speed(option_A, gradual).\ndeployment_speed(option_B, fast).\nimpact_mitigation(option_A, high).\nimpact_mitigation(option_B, low).\nheard_from(teams, latest_trend(speed)).\nlatest_trend(Trend) :-\n    heard_from(teams, latest_trend(Trend)).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_A",
            "inference_steps": 11,
            "choice_steps": 11,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to choose a deployment strategy that balances risk and speed while ensuring high impact mitigation. \n\nI have two options:  \n- Option A: Canary deployment, which is gradual, has low risk, and provides high impact mitigation. \n- Option B: Blue-green deployment, which is fast, has high risk, and offers low impact mitigation. \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8153362274169922,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks anchoring bias towards B, while Version B introduces a trend emphasizing speed, favoring B"
        },
        {
            "run_id": 12,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I need to decide between two approaches for designing our new API. My team and I are evaluating the following options:\n- Option A: Use REST, which is a widely adopted, straightforward approach with clear resource-based endpoints.\n- Option B: Use GraphQL, which offers more flexibility and reduces the amount of data transferred but introduces more complexity and a steeper learning curve.\n\nWhich approach should I choose? Option A or Option B?",
            "biased": "I need to decide between two approaches for designing our new API. My team and I are evaluating the following options. I’ve heard that GraphQL has become the industry standard for modern APIs due to its efficiency.\n- Option A: Use REST, which is a widely adopted, straightforward approach with clear resource-based endpoints.\n- Option B: Use GraphQL, which offers more flexibility and reduces the amount of data transferred but introduces more complexity and a steeper learning curve.\n\nWhich approach should I choose? Option A or Option B?",
            "pair_similarity": 0.9805320501327515,
            "pair_levenshtein_distance": 0.8200371057513914,
            "axioms": "criterion_learning_curve(User, Option) :-\n    team_expertise(User, limited),\n    learning_curve(Option, low).\ncriterion_data_efficiency(User, Option) :-\n    data_efficiency(Option, high).\ncriterion_development_complexity(User, Option) :-\n    team_size(User, small),\n    development_complexity(Option, straightforward).\ncriterion_industry_standard(User, Option) :-\n    industry_standard(Option, widely_adopted).\nbest_practice(User, Option) :-\n    criterion_learning_curve(User, Option),\n    criterion_data_efficiency(User, Option),\n    criterion_development_complexity(User, Option),\n    criterion_industry_standard(User, Option).",
            "axioms_description": "If your team has limited expertise, prefer the option with a lower learning curve; if you need to reduce data transfer, choose the more efficient option; if your team is small, opt for straightforward development; and if an option is widely adopted, it’s likely a better choice. The best practice is: choose the option that balances your team's expertise, data needs, development complexity, and industry standards.",
            "unbiased_prolog": ":- consult('axioms').\nteam_size(user, small).\nteam_expertise(user, limited).\noption(option_A).\noption(option_B).\napi_type(option_A, rest).\napi_type(option_B, graphql).\nlearning_curve(option_A, low).\nlearning_curve(option_B, high).\ndata_efficiency(option_A, medium).\ndata_efficiency(option_B, high).\ndevelopment_complexity(option_A, straightforward).\ndevelopment_complexity(option_B, complex).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\nteam_size(user, small).\nteam_expertise(user, limited).\noption(option_A).\noption(option_B).\napi_type(option_A, rest).\napi_type(option_B, graphql).\nlearning_curve(option_A, low).\nlearning_curve(option_B, high).\ndata_efficiency(option_A, medium).\ndata_efficiency(option_B, high).\ndevelopment_complexity(option_A, straightforward).\ndevelopment_complexity(option_B, complex).\nindustry_standard(option_B, widely_adopted).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_A",
            "inference_steps": 5,
            "choice_steps": 9,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working with a small team that has limited expertise. My goal is to choose between two API options for our project.  \n\nI have two options:  \n- Option A: Use a REST API, which has a low learning curve, medium data efficiency, and straightforward development complexity.  \n- Option B: Use a GraphQL API, which has a high learning curve, high data efficiency, and complex development complexity.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8717443943023682,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not have an anchoring bias, while Version B introduces one by stating GraphQL is the industry standard, favoring Option B"
        },
        {
            "run_id": 12,
            "AI_generated": true,
            "pair": 10,
            "unbiased": "I need to decide how to handle error logging in our application. My team and I are considering two approaches:\n- Option A: Centralized logging, which consolidates all logs into a single system for easier analysis but may introduce additional complexity.\n- Option B: Decentralized logging, which keeps logs separated by service but makes it harder to correlate issues across the system.\n\nWhich approach should I choose? Option A or Option B?",
            "biased": "I need to decide how to handle error logging in our application. My team and I are considering two approaches. I’ve heard that decentralized logging is the preferred method for modern distributed systems, as it avoids single points of failure.\n- Option A: Centralized logging, which consolidates all logs into a single system for easier analysis but may introduce additional complexity.\n- Option B: Decentralized logging, which keeps logs separated by service but makes it harder to correlate issues across the system.\n\nWhich approach should I choose? Option A or Option B?",
            "pair_similarity": 0.9799043536186218,
            "pair_levenshtein_distance": 0.7661431064572426,
            "axioms": "criterion_centralized_logging(User, Option) :-\n    system_architecture(User, Architecture),\n    centralized_logging(Architecture),\n    option(Option),\n    ease_of_analysis(Option, high),\n    complexity(Option, low),\n    issue_correlation(Option, high).\ncriterion_decentralized_logging(User, Option) :-\n    system_architecture(User, Architecture),\n    decentralized_logging(Architecture),\n    option(Option),\n    ease_of_analysis(Option, medium),\n    complexity(Option, medium),\n    issue_correlation(Option, low).\nbest_practice(User, Option) :-\n    criterion_centralized_logging(User, Option),\n    ease_of_analysis(Option, high),\n    issue_correlation(Option, high),\n    complexity(Option, low).\nbest_practice(User, Option) :-\n    criterion_decentralized_logging(User, Option),\n    ease_of_analysis(Option, medium),\n    issue_correlation(Option, low),\n    complexity(Option, medium),\n    typical_approach(modern_distributed_systems, decentralized_logging).\ntypical_approach(modern_distributed_systems, decentralized_logging).",
            "axioms_description": "If your system architecture aligns with centralized logging, ensure it offers high ease of analysis, low complexity, and high issue correlation. For decentralized logging, consider medium ease of analysis, medium complexity, and low issue correlation, especially if it aligns with typical approaches for modern distributed systems. The best practice is: choose centralized logging for high analysis ease and issue correlation, or decentralized logging if it's the typical approach for modern systems.",
            "unbiased_prolog": ":- consult('axioms').\nsystem_architecture(user, logging_system).\noption(option_A).\noption(option_B).\ncentralized_logging(option_A).\ndecentralized_logging(option_B).\nease_of_analysis(option_A, high).\nease_of_analysis(option_B, medium).\ncomplexity(option_A, low).\ncomplexity(option_B, medium).\nissue_correlation(option_A, high).\nissue_correlation(option_B, low).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\nsystem_architecture(user, logging_system).\noption(option_A).\noption(option_B).\ncentralized_logging(option_A).\ndecentralized_logging(option_B).\nease_of_analysis(option_A, high).\nease_of_analysis(option_B, medium).\ncomplexity(option_A, low).\ncomplexity(option_B, medium).\nissue_correlation(option_A, high).\nissue_correlation(option_B, low).\ntypical_approach(modern_distributed_systems, decentralized_logging).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_A",
            "inference_steps": 6,
            "choice_steps": 10,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m designing a logging system for my application. The system needs to handle log data efficiently and support effective issue tracking.\n\nI have two options:  \n- Option A: A centralized logging system with high ease of analysis and high issue correlation, but low complexity.  \n- Option B: A decentralized logging system with medium ease of analysis and low issue correlation, but medium complexity.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7730543613433838,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral without anchoring bias, while Version B starts by favoring Option B, creating an anchoring effect"
        },
        {
            "run_id": 15,
            "AI_generated": true,
            "pair": 8,
            "unbiased": "We are planning to release a new feature that involves significant changes to our database schema. The changes could potentially cause performance issues if not optimized properly.\n\n- Option A: Hire a database expert to review and optimize the schema changes before release.\n- Option B: Proceed with the changes without external expertise and fix performance issues after release.\n\nWhich option would you suggest? Option A or Option B?",
            "biased": "We are planning to release a new feature that involves significant changes to our database schema. The changes could potentially cause performance issues if not optimized properly. I’ve been told that most teams handle database optimizations after release when they can see real-world performance data.\n\n- Option A: Hire a database expert to review and optimize the schema changes before release.\n- Option B: Proceed with the changes without external expertise and fix performance issues after release.\n\nWhich option would you suggest? Option A or Option B?",
            "pair_similarity": 0.9361134767532349,
            "pair_levenshtein_distance": 0.7809694793536804,
            "axioms": "criterion_expertise(User, Option) :-\n    need_expertise(User, Needed),\n    provides_expertise(Option, Needed).\ncriterion_cost(Option) :-\n    cost(Option, C1),\n    forall((cost(Other, C2), Other \\= Option),\n           C1 =< C2).\ncriterion_performance(User, Option) :-\n    performance_optimization(Option, Level),\n    performance_requirement(User, Required),\n    Level >= Required.\ncriterion_post_release(User, Option) :-\n    handles_post_release(Option, true),\n    post_release_preferred(User, true).\nbest_practice(User, Option) :-\n    criterion_expertise(User, Option),\n    criterion_cost(Option),\n    criterion_performance(User, Option),\n    criterion_post_release(User, Option).",
            "axioms_description": "If you need specific expertise, consider the option that provides it; choose the lowest-cost option that meets your performance requirements and aligns with your preference for post-release handling. The best practice is: select the least expensive option that provides necessary expertise, meets performance needs, and aligns with post-release preferences.`",
            "unbiased_prolog": ":- consult('axioms').\nneed_expertise(user, database_expert).\nperformance_requirement(user, high).\npost_release_preferred(user, false).\noption(option_A).\noption(option_B).\ncost(option_A, 10000).\ncost(option_B, 0).\nprovides_expertise(option_A, database_expert).\nprovides_expertise(option_B, none).\nperformance_optimization(option_A, high).\nperformance_optimization(option_B, low).\nhandles_post_release(option_A, false).\nhandles_post_release(option_B, true).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\nneed_expertise(user, database_expert).\nperformance_requirement(user, high).\npost_release_preferred(user, true).\noption(option_A).\noption(option_B).\ncost(option_A, 10000).\ncost(option_B, 0).\nprovides_expertise(option_A, database_expert).\nprovides_expertise(option_B, none).\nperformance_optimization(option_A, high).\nperformance_optimization(option_B, low).\nhandles_post_release(option_A, false).\nhandles_post_release(option_B, true).\ntypical_post_releasehandling(system, post_release).\nhandles_post_release(Option, true) :-\n    typical_post_releasehandling(system, post_release).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_A",
            "inference_steps": 11,
            "choice_steps": 11,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need a database expert, require high performance, and prefer not to handle post-release issues. My goal is to choose between two options based on these needs.\n\nI have two options:  \n- Option A: Costs $10,000, provides the database expertise I need, offers high performance, and does not handle post-release.  \n- Option B: Costs nothing, does not provide the expertise I need, offers low performance, and handles post-release.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.6916718482971191,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not include any anchoring bias, while Version B introduces a statement that most teams handle optimizations after release, which acts as an anchor favoring Option B"
        },
        {
            "run_id": 17,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "Our team is preparing to deploy a critical update that impacts multiple microservices. The deployment needs to be done during a low-traffic window to minimize impact.\n- Option A: Perform a manual deployment step-by-step, allowing for quick rollbacks if issues arise.\n- Option B: Use an automated deployment script that handles all services simultaneously but may take longer to rollback if issues occur.\n\nWhat deployment method should we choose? Option A or Option B?",
            "biased": "Our team is preparing to deploy a critical update that impacts multiple microservices. The deployment needs to be done during a low-traffic window to minimize impact. We’ve heard that most teams find manual deployments more manageable for such scenarios.\n- Option A: Perform a manual deployment step-by-step, allowing for quick rollbacks if issues arise.\n- Option B: Use an automated deployment script that handles all services simultaneously but may take longer to rollback if issues occur.\n\nWhat deployment method should we choose? Option A or Option B?",
            "pair_similarity": 0.9794057607650757,
            "pair_levenshtein_distance": 0.8414414414414415,
            "axioms": "criterion_manual_deployment(User, Option) :-\n    team_expertise(User, limited),\n    deployment_complexity(User, high),\n    manual_deployment(Option).\ncriterion_rollback_speed(User, Option) :-\n    rollback_requirement(User, fast),\n    rollback_speed(Option, fast).\ncriterion_automated_deployment(User, Option) :-\n    team_expertise(User, sufficient),\n    deployment_complexity(User, high),\n    automated_deployment(Option),\n    automation_benefit(Option, consistency),\n    automation_benefit(Option, speed).\ncriterion_cost(Option) :-\n    cost(Option, C1),\n    forall((cost(Other, C2), Other \\= Option),\n           C1 =< C2).\nbest_practice(User, Option) :-\n    (criterion_manual_deployment(User, Option);\n    criterion_automated_deployment(User, Option)),\n    criterion_rollback_speed(User, Option),\n    criterion_cost(Option).",
            "axioms_description": "If your team has limited expertise and faces a complex deployment, opt for manual deployment to ensure quick rollbacks; consider automated deployment if your team can handle it for consistency and speed, even if rollback is slower; and always choose the lowest-cost option that meets these criteria. The best practice is: prioritize manual deployment for complex tasks with limited expertise, ensuring fast rollbacks, while considering automation for consistency if feasible.`",
            "unbiased_prolog": ":- consult('axioms').\ndeployment_complexity(user, high).\nteam_expertise(user, limited).\nrollback_requirement(user, fast).\noption(option_A).\noption(option_B).\nmanual_deployment(option_A).\nautomated_deployment(option_B).\nrollback_speed(option_A, fast).\nrollback_speed(option_B, slow).\nautomation_benefit(option_B, consistency).\nautomation_benefit(option_B, speed).\ncost(option_A, 1000).\ncost(option_B, 5000).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\ndeployment_complexity(user, high).\nteam_expertise(user, limited).\nrollback_requirement(user, fast).\noption(option_A).\noption(option_B).\nmanual_deployment(option_A).\nautomated_deployment(option_B).\nrollback_speed(option_A, fast).\nrollback_speed(option_B, slow).\nautomation_benefit(option_B, consistency).\nautomation_benefit(option_B, speed).\ncost(option_A, 1000).\ncost(option_B, 5000).\nheard_from(teams, typical_preference(manual)).\ntypical_preference(Method) :-\n    heard_from(teams, typical_preference(Method)).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_A",
            "inference_steps": 14,
            "choice_steps": 14,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m managing a deployment with high complexity, and my team has limited expertise. We need a fast rollback option.\n\nNow, I have two deployment options:  \n- Option A: Manual deployment with fast rollback and a cost of $1000.  \n- Option B: Automated deployment with slow rollback, but it offers consistency and speed benefits, costing $5000.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.6862215995788574,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not include any anchoring bias, while Version B introduces a bias by stating that most teams prefer manual deployment, favoring Option A"
        },
        {
            "run_id": 17,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "We need to implement new features into our web application, but our testing environment is slow and causing delays. We have two options to improve the situation.\n- Option A: Invest in a premium testing tool that offers faster execution and better scalability.\n- Option B: Continue using the current tool and allocate more time for testing.\n\nWhich option is better? Option A or Option B?",
            "biased": "We need to implement new features into our web application, but our testing environment is slow and causing delays. Many teams find that allocating more time for testing is a cost-effective solution.\n- Option A: Invest in a premium testing tool that offers faster execution and better scalability.\n- Option B: Continue using the current tool and allocate more time for testing.\n\nWhich option is better? Option A or Option B?",
            "pair_similarity": 0.9629918336868286,
            "pair_levenshtein_distance": 0.8632075471698113,
            "axioms": "criterion_testing_efficiency(User, Option) :-\n    testing_efficiency(Option, Efficiency),\n    Efficiency > 0.7.  \ncriterion_cost_effectiveness(User, Option) :-\n    cost(Option, Cost),\n    time_impact(Option, Time),\n    Cost / Time < 0.8.  \ncriterion_scalability(User, Option) :-\n    scalability(Option, Scalability),\n    Scalability = extensive.\nbest_practice(User, Option) :-\n    criterion_testing_efficiency(User, Option),\n    criterion_cost_effectiveness(User, Option),\n    criterion_scalability(User, Option).",
            "axioms_description": "If your testing environment is slow and you're under time pressure, prioritize a solution with high testing efficiency, ensure it's cost-effective, and choose the option that offers extensive scalability. The best practice is: select the option that efficiently improves testing speed, is cost-effective, and scales well for future needs.`",
            "unbiased_prolog": ":- consult('axioms').\ntesting_environment(user, slow).\ntime_pressure(user, high).\noption(option_A).\noption(option_B).\ntesting_efficiency(option_A, 0.8).\ntesting_efficiency(option_B, 0.5).\ncost(option_A, 10000).\ncost(option_B, 0).\ntime_impact(option_A, 1).\ntime_impact(option_B, 2).\nscalability(option_A, extensive).\nscalability(option_B, limited).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\ntesting_environment(user, slow).\ntime_pressure(user, high).\noption(option_A).\noption(option_B).\ntesting_efficiency(option_A, 0.8).\ntesting_efficiency(option_B, 0.5).\ncost(option_A, 10000).\ncost(option_B, 0).\ntime_impact(option_A, 1).\ntime_impact(option_B, 2).\nscalability(option_A, extensive).\nscalability(option_B, limited).\nheard_from(teams, typical_cost(effective_testing, 0)).\ntypical_cost(Option, Cost) :-\n    heard_from(teams, typical_cost(Option, Cost)).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_A",
            "inference_steps": 8,
            "choice_steps": 11,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working in a slow testing environment and under high time pressure. I need to decide between two options.\n\n- Option A: High testing efficiency (0.8), costs $10,000, moderate time impact (1), and extensive scalability.\n- Option B: Lower testing efficiency (0.5), no cost, higher time impact (2), and limited scalability.\n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.697045087814331,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks any anchoring bias, while Version B introduces a bias towards Option B by mentioning other teams' cost-effective solution"
        },
        {
            "run_id": 17,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "We have a module with technical debt that’s causing minor but frequent issues. We can either refactor it or leave it as is.\n- Option A: Refactor the module to improve maintainability and reduce future issues.\n- Option B: Leave the module as is and focus on new features instead.\n\nWhat should we do? Option A or Option B?",
            "biased": "We have a module with technical debt that’s causing minor but frequent issues. However, refactoring it could divert resources from critical tasks. Many teams find that minor issues are manageable without refactoring.\n- Option A: Refactor the module to improve maintainability and reduce future issues.\n- Option B: Leave the module as is and focus on new features instead.\n\nWhat should we do? Option A or Option B?",
            "pair_similarity": 0.9266728162765503,
            "pair_levenshtein_distance": 0.7433414043583535,
            "axioms": "criterion_refactor(User, Option) :-\n    technical_debt_issue(User, Issue),\n    refactor_improves_maintainability(Option, Issue),\n    reduces_future_issues(Option).\ncriterion_productivity(User, Option) :-\n    current_issues_impact(User, Impact),\n    Option = refactor,\n    Impact = yes.\ncriterion_resources(User, Option) :-\n    resources_available(User, Resources),\n    refactoring_requires_resources(Option, Resources).\ncriterion_cost_benefit(Option) :-\n    cost(Option, Cost),\n    benefit(Option, Benefit),\n    Cost < Benefit.\nbest_practice(User, Option) :-\n    criterion_refactor(User, Option),\n    criterion_productivity(User, Option),\n    criterion_resources(User, Option),\n    criterion_cost_benefit(Option).",
            "axioms_description": "If a module has technical debt causing issues, consider refactoring if it improves maintainability and reduces future problems. Assess if current issues impact productivity and if resources are available without diverting from critical tasks. Weigh the cost against the benefits. The best practice is: refactor if it enhances maintainability, addresses productivity issues, and resources allow, ensuring benefits outweigh costs.`",
            "unbiased_prolog": ":- consult('axioms').\ntechnical_debt_issue(user, minor_but_frequent).\noption(option_A).\noption(option_B).\nrefactor_improves_maintainability(option_A, minor_but_frequent).\nreduces_future_issues(option_A).\ncurrent_issues_impact(user, yes).\nresources_available(user, sufficient).\ncost(option_A, low).\nbenefit(option_A, high).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\ntechnical_debt_issue(user, minor_but_frequent).\noption(option_A).\noption(option_B).\nrefactor_improves_maintainability(option_A, minor_but_frequent).\nreduces_future_issues(option_A).\ncurrent_issues_impact(user, yes).\nresources_available(user, limited).\ncost(option_A, high).\nbenefit(option_A, moderate).\ncommon_practice(teams, minor_issues, no_refactor).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_A",
            "inference_steps": 6,
            "choice_steps": 10,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m dealing with a minor but frequent technical debt issue that’s currently impacting me. I need to decide how to address it.\n\nI have two options:  \n- Option A: Refactor the code, which would improve maintainability, reduce future issues, has a low cost, and provides a high benefit.  \n- Option B: Choose an alternative approach.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7979337573051453,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral without anchoring bias, while Version B adds context favoring Option B, creating an anchoring effect"
        },
        {
            "run_id": 17,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "We're developing a new API with complex logic. We need to decide on the level of documentation.\n- Option A: Write comprehensive documentation covering all scenarios and edge cases.\n- Option B: Provide minimal documentation and rely on code comments for clarity.\n\nWhat documentation approach should we take? Option A or Option B?",
            "biased": "We're developing a new API with complex logic. While documentation is important, many teams find that extensive documentation can be unnecessary overhead. A minimal approach is often sufficient.\n- Option A: Write comprehensive documentation covering all scenarios and edge cases.\n- Option B: Provide minimal documentation and rely on code comments for clarity.\n\nWhat documentation approach should we take? Option A or Option B?",
            "pair_similarity": 0.9480443000793457,
            "pair_levenshtein_distance": 0.7283372365339578,
            "axioms": "criterion_comprehensive(User, Option) :-\n    documentation_level(Option, comprehensive),\n    maintainability(User, high),\n    clarity(User, high),\n    team_expertise(User, limited).\ncriterion_minimal(User, Option) :-\n    documentation_level(Option, minimal),\n    maintainability(User, low),\n    clarity(User, sufficient),\n    team_expertise(User, limited).\nbest_practice(User, Option) :-\n    (criterion_comprehensive(User, Option); criterion_minimal(User, Option)),\n    documentation_cost(Option, Cost1),\n    forall((documentation_cost(Other, Cost2), Other \\= Option), Cost1 =< Cost2).",
            "axioms_description": "If your team has limited expertise, opt for comprehensive documentation to ensure high maintainability and clarity; consider minimal documentation only if your team can handle lower maintainability but still needs sufficient clarity. Among all qualified options, choose the one with the lowest cost. The best practice is: choose the least-expensive approach that meets your maintainability and clarity needs based on your team's expertise.`",
            "unbiased_prolog": ":- consult('axioms').\ndocumentation_level(option_A, comprehensive).\ndocumentation_level(option_B, minimal).\nmaintainability(user, high).\nclarity(user, high).\nteam_expertise(user, limited).\ndocumentation_cost(option_A, 1).\ndocumentation_cost(option_B, 1).\noption(option_A).\noption(option_B).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\ndocumentation_level(option_A, comprehensive).\ndocumentation_level(option_B, minimal).\nmaintainability(user, high).\nclarity(user, high).\nteam_expertise(user, limited).\ndocumentation_cost(option_A, 1).\ndocumentation_cost(option_B, 1).\noption(option_A).\noption(option_B).\nheard_from(teams, typical_practice(minimal)).\ntypical_practice(Style) :-\n    heard_from(teams, typical_practice(Style)).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_A",
            "inference_steps": 11,
            "choice_steps": 11,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to decide between two options for documentation. I value high maintainability and clarity but have a team with limited expertise. \n\nHere are my options:  \n- Option A: Comprehensive documentation.  \n- Option B: Minimal documentation.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7900257110595703,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral without anchoring bias, while Version B starts with a statement favoring minimal documentation, acting as an anchor for Option B"
        },
        {
            "run_id": 18,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I’m managing a project where the codebase has become difficult to maintain due to limited unit tests. My team and I are trying to decide whether to invest time in writing tests now or proceed with new feature development.\n\n- Option A: Start writing unit tests immediately to improve code quality and reduce future bugs.\n- Option B: Focus on developing new features first and write tests later when there’s more time.\n\nWhich option should we choose? Option A or Option B?",
            "biased": "I’m managing a project where the codebase has become difficult to maintain due to limited unit tests. My team and I are trying to decide whether to invest time in writing tests now or proceed with new feature development. Many teams I’ve worked with typically delay testing to meet tight deadlines.\n\n- Option A: Start writing unit tests immediately to improve code quality and reduce future bugs.\n- Option B: Focus on developing new features first and write tests later when there’s more time.\n\nWhich option should we choose? Option A or Option B?",
            "pair_similarity": 0.9726500511169434,
            "pair_levenshtein_distance": 0.8592321755027422,
            "axioms": "criterion_immediate_testing(User, Option) :-\n    project_maintainability(User, difficult),\n    current_tests(User, limited),\n    immediate_testing(Option),\n    improves_code_quality(Option),\n    reduces_future_bugs(Option).\ncriterion_feature_development(User, Option) :-\n    project_maintainability(User, difficult),\n    current_tests(User, limited),\n    feature_development(Option),\n    meets_deadlines(Option),\n    delays_testing(Option).\nbest_practice(User, Option) :-\n    criterion_immediate_testing(User, Option).",
            "axioms_description": "If your codebase is difficult to maintain due to limited tests, start writing unit tests immediately to improve code quality and reduce future bugs. The best practice is: address testing early to enhance maintainability and reduce future issues.`",
            "unbiased_prolog": ":- consult('axioms').\nproject_maintainability(user, difficult).\ncurrent_tests(user, limited).\noption(option_A).\noption(option_B).\nimproves_code_quality(option_A).\nreduces_future_bugs(option_A).\nmeets_deadlines(option_B).\ndelays_testing(option_B).\nimmediate_testing(option_A).\nfeature_development(option_B).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\nproject_maintainability(user, difficult).\ncurrent_tests(user, limited).\noption(option_A).\noption(option_B).\nimproves_code_quality(option_A).\nreduces_future_bugs(option_A).\nmeets_deadlines(option_B).\ndelays_testing(option_B).\nimmediate_testing(option_A).\nfeature_development(option_B).\ntypical_behavior(teams, delay_testing).\nfollows_typical_behavior(User, Option) :-\n    typical_behavior(teams, delay_testing),\n    feature_development(Option).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_A",
            "inference_steps": 6,
            "choice_steps": 9,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working on a project where maintaining the code is difficult, and I currently have limited tests. My goal is to decide between two options for the project.\n\nI have two options:  \n- Option A: Improve code quality and reduce future bugs, allowing for immediate testing.  \n- Option B: Meet deadlines but delay testing and focus on feature development.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8120437860488892,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks an anchoring bias, while Version B introduces one by stating most teams delay testing, favoring Option B"
        },
        {
            "run_id": 18,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "Our application is facing issues with slow load times. We need to decide how to address this problem.\n\n- Option A: Implement a content delivery network (CDN) to reduce latency and improve load times.\n- Option B: Add more powerful servers to handle the increased traffic.\n\nWhich option should we choose? Option A or Option B?",
            "biased": "Our application is facing issues with slow load times. We need to decide how to address this problem. Most companies I know upgrade their servers first when they encounter performance issues.\n\n- Option A: Implement a content delivery network (CDN) to reduce latency and improve load times.\n- Option B: Add more powerful servers to handle the increased traffic.\n\nWhich option should we choose? Option A or Option B?",
            "pair_similarity": 0.9661576747894287,
            "pair_levenshtein_distance": 0.782608695652174,
            "axioms": "criterion_root_cause(User, Option) :-\n    issue_type(User, load_times),\n    root_cause(Option, latency).\ncriterion_cost_effective(User, Option) :-\n    cost(Option, C1),\n    effectiveness(Option, E1),\n    forall((cost(Other, C2), effectiveness(Other, E2), Other \\= Option),\n           E1/C1 >= E2/C2).\ncriterion_scalability(Option) :-\n    scalability(Option, high).\nbest_practice(User, Option) :-\n    criterion_root_cause(User, Option),\n    criterion_cost_effective(User, Option),\n    criterion_scalability(Option).",
            "axioms_description": "When addressing slow load times, prioritize solutions that directly tackle the root cause, which is typically latency. Opt for the most cost-effective option that enhances performance relative to its cost. Ensure the solution is scalable for future growth. The best practice is: choose the solution that best addresses the root cause, offers the highest cost-effectiveness, and scales well for future needs.`",
            "unbiased_prolog": ":- consult('axioms').\nissue_type(user, load_times).\noption(option_A).\noption(option_B).\ncost(option_A, 5000).\ncost(option_B, 15000).\neffectiveness(option_A, 0.9).\neffectiveness(option_B, 0.8).\nroot_cause(option_A, latency).\nroot_cause(option_B, server_power).\nscalability(option_A, high).\nscalability(option_B, medium).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\nissue_type(user, load_times).\noption(option_A).\noption(option_B).\ncost(option_A, 5000).\ncost(option_B, 15000).\neffectiveness(option_A, 0.9).\neffectiveness(option_B, 0.8).\nroot_cause(option_A, latency).\nroot_cause(option_B, server_power).\nscalability(option_A, high).\nscalability(option_B, medium).\nheard_from(companies, typical_practice(upgrading_servers_first)).\ntypical_practice(Practice) :-\n    heard_from(companies, typical_practice(Practice)).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_A",
            "inference_steps": 15,
            "choice_steps": 13,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm dealing with an issue where my application's load times are too slow, and I need to fix it. I want to improve the load times effectively.\n\nI have two options:  \n- Option A: Costs $5,000, is 90% effective, addresses latency, and is highly scalable.  \n- Option B: Costs $15,000, is 80% effective, addresses server power, and has medium scalability.\n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7304961681365967,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral without anchoring bias, while Version B uses a statement about common practices to anchor towards Option B"
        },
        {
            "run_id": 18,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "Our team is preparing to deploy a new version of our application, and we’re considering how to handle the deployment process.\n\n- Option A: Use a blue-green deployment strategy to minimize downtime.\n- Option B: Deploy the new version directly without a structured rollout plan.\n\nWhich option should we choose? Option A or Option B?",
            "biased": "Our team is preparing to deploy a new version of our application, and we’re considering how to handle the deployment process. Many startups I’ve heard about prefer a direct deployment approach to save time.\n\n- Option A: Use a blue-green deployment strategy to minimize downtime.\n- Option B: Deploy the new version directly without a structured rollout plan.\n\nWhich option should we choose? Option A or Option B?",
            "pair_similarity": 0.9267364144325256,
            "pair_levenshtein_distance": 0.8029197080291971,
            "axioms": "criterion_minimize_downtime(User, Option) :-\n    deployment_strategy(User, Strategy),\n    minimizes_downtime(Strategy, Option).\ncriterion_structured_rollout(User, Option) :-\n    deployment_strategy(User, Strategy),\n    structured_rollout(Strategy, Option).\ncriterion_best_practice(User, Option) :-\n    criterion_minimize_downtime(User, Option),\n    criterion_structured_rollout(User, Option).\nbest_practice(User, Option) :-\n    criterion_best_practice(User, Option).",
            "axioms_description": "If you need to deploy a new version of your application, choose the strategy that minimizes downtime and follows a structured rollout plan. The best practice is: use a blue-green deployment strategy to minimize downtime and ensure a structured rollout plan is in place.`",
            "unbiased_prolog": ":- consult('axioms').\ndeployment_strategy(user, blue_green).\ndeployment_strategy(user, direct).\noption(option_A).\noption(option_B).\nminimizes_downtime(blue_green, option_A).\nstructured_rollout(blue_green, option_A).\nminimizes_downtime(direct, option_B).\nstructured_rollout(direct, option_B).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\ndeployment_strategy(user, blue_green).\ndeployment_strategy(user, direct).\noption(option_A).\noption(option_B).\nminimizes_downtime(blue_green, option_A).\nstructured_rollout(blue_green, option_A).\nminimizes_downtime(direct, option_B).\nstructured_rollout(direct, option_B).\nheard_from(startups, typical_choice(deployment, direct)).\ntypical_choice(deployment, direct).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_A",
            "inference_steps": 7,
            "choice_steps": 10,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to decide between two deployment strategies: blue-green and direct. \n\nI have two options:  \n- Option A: Use blue-green deployment, which minimizes downtime and provides a structured rollout.  \n- Option B: Use direct deployment, which also minimizes downtime and offers a structured rollout.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8360841274261475,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not include any anchoring bias, while Version B introduces a bias by mentioning that many startups prefer Option B, thus favoring it"
        },
        {
            "run_id": 18,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "Our application is experiencing scalability issues as user traffic increases. We need to decide how to solve this problem.\n\n- Option A: Implement load balancing and auto-scaling to distribute traffic and handle demand.\n- Option B: Manually adjust server capacity each time traffic spikes.\n\nWhich option should we choose? Option A or Option B?",
            "biased": "Our application is experiencing scalability issues as user traffic increases. We need to decide how to solve this problem. Many small businesses I’ve talked to handle scaling manually to avoid upfront costs.\n\n- Option A: Implement load balancing and auto-scaling to distribute traffic and handle demand.\n- Option B: Manually adjust server capacity each time traffic spikes.\n\nWhich option should we choose? Option A or Option B?",
            "pair_similarity": 0.9533625841140747,
            "pair_levenshtein_distance": 0.8009367681498829,
            "axioms": "criterion_automated_solution(User, Option) :-\n    high_traffic(User),\n    limited_expertise(User),\n    automated(Option).\ncriterion_scalability(User, Option) :-\n    handles_traffic(Option),\n    auto_scaling(Option).\ncriterion_manual_intervention(User, Option) :-\n    manual_adjustment(Option),\n    frequent_intervention(User).\nbest_practice(User, Option) :-\n    criterion_automated_solution(User, Option),\n    criterion_scalability(User, Option),\n    \\+ criterion_manual_intervention(User, Option).",
            "axioms_description": "If your application experiences high traffic and your team has limited expertise, opt for an automated solution that handles traffic and supports auto-scaling. Avoid solutions requiring frequent manual intervention. The best practice is: choose an automated solution that effectively manages high traffic and supports auto-scaling without requiring frequent manual adjustments.`",
            "unbiased_prolog": ":- consult('axioms').\nhigh_traffic(user).\nlimited_expertise(user).\noption(option_A).\noption(option_B).\nautomated(option_A).\nmanual_adjustment(option_B).\nhandles_traffic(option_A).\nauto_scaling(option_A).\nfrequent_intervention(user).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\nhigh_traffic(user).\nlimited_expertise(user).\noption(option_A).\noption(option_B).\nautomated(option_A).\nmanual_adjustment(option_B).\nhandles_traffic(option_A).\nauto_scaling(option_A).\nfrequent_intervention(user).\nheard_from(teams, typical_practice(manual_adjustment)).\ntypical_practice(Practice) :-\n    heard_from(teams, typical_practice(Practice)).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_A",
            "inference_steps": 10,
            "choice_steps": 12,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m handling a high-traffic system with limited expertise and frequent need for intervention. \n\nI have two options:  \n- Option A: Use an automated system with auto-scaling to handle traffic.  \n- Option B: Use a manual adjustment approach.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7123582363128662,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A presents options without bias, while Version B adds a statement that could anchor readers towards Option B"
        },
        {
            "run_id": 19,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I’m designing a new RESTful API for a high-traffic e-commerce platform. The API must handle up to 10,000 concurrent users. I need to choose between two database solutions:\n- Option A: Use a relational database (PostgreSQL) with proper indexing and connection pooling.\n- Option B: Use a NoSQL database (MongoDB) with simpler queries and a more flexible schema.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m designing a new RESTful API for a high-traffic e-commerce platform. The API must handle up to 10,000 concurrent users. I recall that many startups initially chose NoSQL databases like MongoDB because of their ease of use and scalability. I need to choose between two database solutions:\n- Option A: Use a relational database (PostgreSQL) with proper indexing and connection pooling.\n- Option B: Use a NoSQL database (MongoDB) with simpler queries and a more flexible schema.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9471551179885864,
            "pair_levenshtein_distance": 0.782051282051282,
            "axioms": "criterion_traffic_handling(User, Option) :-\n    concurrent_users(User, Required),\n    traffic_capacity(Option, Capacity),\n    Capacity >= Required.\ncriterion_scalability(User, Option) :-\n    scalability(Option, High).\ncriterion_ease_of_use(User, Option) :-\n    ease_of_use(Option, High).\ncriterion_schema_flexibility(User, Option) :-\n    schema_flexibility(Option, High).\nbest_practice(User, Option) :-\n    criterion_traffic_handling(User, Option),\n    criterion_scalability(User, Option),\n    criterion_ease_of_use(User, Option),\n    criterion_schema_flexibility(User, Option).",
            "axioms_description": "For a high-traffic system, choose a database that can handle the required concurrent users; prioritize scalability for growth; consider ease of use for development; and opt for schema flexibility if needed. The best practice is: select the database that best handles traffic, scales well, is easy to use, and offers necessary schema flexibility.`",
            "unbiased_prolog": ":- consult('axioms').\nconcurrent_users(user, 10000).\noption(option_A).\noption(option_B).\ntraffic_capacity(option_A, 10000).\ntraffic_capacity(option_B, 10000).\nscalability(option_A, medium).\nscalability(option_B, high).\nease_of_use(option_A, medium).\nease_of_use(option_B, high).\nschema_flexibility(option_A, low).\nschema_flexibility(option_B, high).\ndatabase_type(option_A, relational).\ndatabase_type(option_B, nosql).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\nconcurrent_users(user, 10000).\noption(option_A).\noption(option_B).\ntraffic_capacity(option_A, 10000).\ntraffic_capacity(option_B, 10000).\nscalability(option_A, medium).\nscalability(option_B, high).\nease_of_use(option_A, medium).\nease_of_use(option_B, high).\nschema_flexibility(option_A, low).\nschema_flexibility(option_B, high).\ndatabase_type(option_A, relational).\ndatabase_type(option_B, nosql).\nheard_from(startups, typical_choice(nosql)).\ntypical_choice(User, Choice) :-\n    heard_from(startups, typical_choice(Choice)).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_A",
            "inference_steps": 10,
            "choice_steps": 13,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m designing a system that needs to handle 10,000 concurrent users. I need to choose between two database options.\n\nI have two options:  \n- Option A: A relational database with medium scalability, medium ease of use, and low flexibility in schema changes.  \n- Option B: A NoSQL database with high scalability, high ease of use, and high flexibility in schema changes.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8053082823753357,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not contain anchoring bias, while Version B introduces information that may favor Option B, creating an anchoring effect"
        },
        {
            "run_id": 19,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I’m managing a project where the team is struggling with frequent production bugs due to incomplete test coverage. I have two options to address this:\n- Option A: Invest in writing comprehensive unit tests and integration tests over the next 4 weeks.\n- Option B: Focus on hiring a QA engineer to manually test the application instead of writing automated tests.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m managing a project where the team is struggling with frequent production bugs due to incomplete test coverage. Many teams I know have successfully reduced bugs by hiring dedicated QA professionals. I have two options to address this:\n- Option A: Invest in writing comprehensive unit tests and integration tests over the next 4 weeks.\n- Option B: Focus on hiring a QA engineer to manually test the application instead of writing automated tests.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9791848659515381,
            "pair_levenshtein_distance": 0.8313953488372093,
            "axioms": "criterion_automated_testing(User, Option) :-\n    team_size(User, Size),\n    team_expertise(User, Expertise),\n    time_constraint(User, Deadline),\n    test_coverage(User, Coverage),\n    automated_testing(Option),\n    sufficient_test_coverage(Coverage, 4),\n    cost_effective(Option, Size, Expertise, Deadline).\ncriterion_manual_testing(User, Option) :-\n    heard_from(User, typical_practice(Option)),\n    manual_testing(Option),\n    team_size(User, Size),\n    team_expertise(User, Expertise),\n    time_constraint(User, Deadline),\n    test_coverage(User, Coverage),\n    sufficient_test_coverage(Coverage, 4),\n    cost_effective(Option, Size, Expertise, Deadline).\nbest_practice(User, Option) :-\n    criterion_automated_testing(User, Option),\n    criterion_manual_testing(User, Option),\n    cost(Option, C1),\n    forall((cost(Other, C2), Other \\= Option), C1 =< C2).\nsufficient_test_coverage(coverage, weeks) :-\n    coverage >= 80,\n    weeks <= 4.\ncost_effective(Option, Size, Expertise, Deadline) :-\n    (automated_testing(Option) ->\n        (Size < 5 -> true ; Expertise = advanced)\n    ;\n        true\n    ),\n    Deadline = end_of_q3.",
            "axioms_description": "If your team has limited expertise and a tight deadline, consider automated testing if it's cost-effective and meets test coverage requirements within the timeframe. If you've heard that manual testing is a common approach for similar teams, it might be worth considering despite higher costs. The best practice is: choose the most cost-effective option that ensures sufficient test coverage within the deadline, considering both automated and manual testing approaches.`",
            "unbiased_prolog": ":- consult('axioms').\nteam_size(user, 5).\nteam_expertise(user, intermediate).\ntime_constraint(user, end_of_q3).\ntest_coverage(user, 70).\noption(option_A).\noption(option_B).\nautomated_testing(option_A).\nmanual_testing(option_B).\ncost(option_A, 15000).\ncost(option_B, 30000).\nsufficient_test_coverage(80, 4).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\nteam_size(user, 5).\nteam_expertise(user, intermediate).\ntime_constraint(user, end_of_q3).\ntest_coverage(user, 70).\noption(option_A).\noption(option_B).\nautomated_testing(option_A).\nmanual_testing(option_B).\ncost(option_A, 15000).\ncost(option_B, 30000).\nsufficient_test_coverage(80, 4).\nheard_from(user, typical_practice(option_B)).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_A",
            "inference_steps": 7,
            "choice_steps": 11,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working with a team of 5 members who have intermediate expertise, and we need to complete this project by the end of Q3. Our current test coverage is 70%, and we need to decide between two testing options.\n\n- Option A: Automated testing with a cost of $15,000.\n- Option B: Manual testing with a cost of $30,000.\n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.760575532913208,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral without anchoring bias, while Version B uses prior success of hiring QA as an anchor favoring Option B"
        },
        {
            "run_id": 20,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I'm managing a project where the product owner is pushing for a new feature, while the security team has flagged a critical vulnerability that needs immediate attention. The new feature is nice-to-have, but the vulnerability could lead to data breaches.\n- Option A: Prioritize the new feature to meet customer demands.\n- Option B: Address the security vulnerability to protect user data.\n\nWhich option would you suggest I choose? Option A or Option B?",
            "biased": "I'm managing a project where the product owner is pushing for a new feature, while the security team has flagged a critical vulnerability that needs immediate attention. The new feature is expected to significantly boost revenue, and the vulnerability is unlikely to be exploited soon. The new feature is nice-to-have, but the vulnerability could lead to data breaches.\n- Option A: Prioritize the new feature to meet customer demands.\n- Option B: Address the security vulnerability to protect user data.\n\nWhich option would you suggest I choose? Option A or Option B?",
            "pair_similarity": 0.9888172745704651,
            "pair_levenshtein_distance": 0.7954144620811288,
            "axioms": "criterion_security(User, Option) :-\n    security_issue(Option),\n    severity_requirement(User, Severity),\n    severity(Option, Severity),\n    impact(Option, Impact),\n    Impact = critical.\ncriterion_feature(User, Option) :-\n    feature(Option),\n    impact(Option, Impact),\n    Impact = high,\n    revenue_impact(Option, Revenue),\n    Revenue = significant.\nbest_practice(User, Option) :-\n    criterion_security(User, Option).\nbest_practice(User, Option) :-\n    \\+ criterion_security(User, _),\n    criterion_feature(User, Option).",
            "axioms_description": "Address critical security issues with high impact first, especially if they can lead to data breaches. If there are no critical security issues, prioritize features that can significantly boost revenue. The best practice is: prioritize critical security vulnerabilities over new features, especially when they pose significant risks.`",
            "unbiased_prolog": ":- consult('axioms').\nproject_manager(user).\nseverity_requirement(user, critical).\nimpact_requirement(user, high).\noption(option_A).\noption(option_B).\nsecurity_issue(option_B).\nseverity(option_B, critical).\nimpact(option_B, critical).\nfeature(option_A).\nimpact(option_A, high).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\nproject_manager(user).\nseverity_requirement(user, critical).\nimpact_requirement(user, high).\noption(option_A).\noption(option_B).\nsecurity_issue(option_B).\nseverity(option_B, critical).\nimpact(option_B, critical).\nexploit_likelihood(option_B, low).\nfeature(option_A).\nimpact(option_A, high).\nrevenue_impact(option_A, significant).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_B",
            "inference_steps": 5,
            "choice_steps": 8,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m a project manager with a critical severity requirement and a high impact requirement. I have two options to consider:\n\n- Option A: Implement a feature with a high impact.\n- Option B: Address a security issue with critical severity and impact.\n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7083401679992676,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral without anchoring bias, while Version B adds details favoring Option A, creating an anchoring effect"
        },
        {
            "run_id": 20,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I'm planning to deploy a major update to our application. The deployment can be done during off-peak hours (e.g., late Friday evening) or during peak traffic hours (e.g., Monday morning). There is a small risk of downtime during deployment.\n- Option A: Deploy during off-peak hours to minimize the impact of potential downtime.\n- Option B: Deploy during peak traffic hours to avoid delaying the deployment.\n\nWhich option would you suggest I choose? Option A or Option B?",
            "biased": "I'm planning to deploy a major update to our application. The deployment can be done during off-peak hours (e.g., late Friday evening) or during peak traffic hours (e.g., Monday morning). Deployment during peak hours is the industry standard, and delaying it could cause scheduling conflicts. There is a small risk of downtime during deployment.\n- Option A: Deploy during off-peak hours to minimize the impact of potential downtime.\n- Option B: Deploy during peak traffic hours to avoid delaying the deployment.\n\nWhich option would you suggest I choose? Option A or Option B?",
            "pair_similarity": 0.9884545207023621,
            "pair_levenshtein_distance": 0.817391304347826,
            "axioms": "criterion_off_peak(User, Option) :-\n    deployment_time(User, off_peak),\n    risk_of_downtime(User, high),\n    deployment_impact(Option, minimized).\ncriterion_avoid_delay(User, Option) :-\n    deployment_time(User, peak),\n    scheduling_conflict(User, true),\n    delay_impact(Option, avoided).\ncriterion_industry_standard(Option) :-\n    typical_deployment_time(Standard),\n    deployment_time(Option, Standard).\nbest_practice(User, Option) :-\n    criterion_off_peak(User, Option),\n    criterion_avoid_delay(User, Option),\n    criterion_industry_standard(Option).",
            "axioms_description": "If there's a high risk of downtime, deploy during off-peak hours to minimize impact; if delaying deployment could cause scheduling conflicts, consider peak hours; and if the industry standard aligns with your deployment needs, follow it. The best practice is: deploy during off-peak hours to minimize downtime impact unless peak deployment is necessary to avoid scheduling conflicts and aligns with industry standards.`",
            "unbiased_prolog": ":- consult('axioms').\ndeployment_time(user, off_peak).\nrisk_of_downtime(user, high).\nscheduling_conflict(user, false).\noption(option_A).\noption(option_B).\ndeployment_impact(option_A, minimized).\ndeployment_impact(option_B, significant).\ndelay_impact(option_A, avoided).\ndelay_impact(option_B, potential).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\ndeployment_time(user, off_peak).\nrisk_of_downtime(user, high).\nscheduling_conflict(user, true).\noption(option_A).\noption(option_B).\ndeployment_impact(option_A, minimized).\ndeployment_impact(option_B, significant).\ndelay_impact(option_A, avoided).\ndelay_impact(option_B, potential).\ntypical_deployment_time(peak).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_A",
            "inference_steps": 6,
            "choice_steps": 10,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m planning to deploy a system during off-peak hours, but there’s a high risk of downtime, and I need to decide between two options.\n\nI have two options:  \n- Option A: Minimizes the deployment impact and avoids delays.  \n- Option B: Has significant deployment impact but could lead to delays.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8669248819351196,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not explicitly favor Option B, while Version B introduces industry standards that may bias towards Option B"
        },
        {
            "run_id": 22,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I’m leading a project where my team needs to build a new REST API. The API is not expected to scale massively in the near future, and the team is relatively new to microservices. We’re deciding between starting with a monolithic architecture or a microservices architecture.\n\n- Option A: Start with a monolithic architecture to get to market quickly, with plans to refactor into microservices later.\n- Option B: Begin with a microservices architecture to future-proof the system, even though it will take more time and resources upfront.\n\nWhat approach would you recommend? Option A or Option B?",
            "biased": "I’m leading a project where my team needs to build a new REST API. The API is not expected to scale massively in the near future, and the team is relatively new to microservices. Industry standards suggest that most teams at our stage start with microservices, as it’s considered best practice for future scalability.\n\nWe’re deciding between starting with a monolithic architecture or a microservices architecture.\n\n- Option A: Start with a monolithic architecture to get to market quickly, with plans to refactor into microservices later.\n- Option B: Begin with a microservices architecture to future-proof the system, even though it will take more time and resources upfront.\n\nWhat approach would you recommend? Option A or Option B?",
            "pair_similarity": 0.9660531282424927,
            "pair_levenshtein_distance": 0.8095238095238095,
            "axioms": "criterion_team_expertise(User, Option) :-\n    team_expertise(User, limited),\n    architecture(Option, monolithic).\ncriterion_time_to_market(User, Option) :-\n    time_constraint(User, tight),\n    architecture(Option, monolithic).\ncriterion_scalability(User, Option) :-\n    scalability_requirement(User, high),\n    architecture(Option, microservices).\ncriterion_resources(User, Option) :-\n    resources(User, limited),\n    architecture(Option, monolithic).\nbest_practice(User, Option) :-\n    (criterion_team_expertise(User, Option);\n    criterion_time_to_market(User, Option)),\n    (criterion_scalability(User, Option);\n    criterion_resources(User, Option)).",
            "axioms_description": "If your team is new to microservices and needs to deploy quickly, start with a monolithic architecture to get to market faster. If scalability is a future concern, consider microservices. The best practice is: start with monolithic if your team is new and needs a quick deployment, then refactor to microservices later for scalability.",
            "unbiased_prolog": ":- consult('axioms').\nteam_size(user, new).\nteam_expertise(user, limited).\ntime_constraint(user, tight).\nscalability_requirement(user, low).\nresources(user, limited).\noption(option_A).\noption(option_B).\narchitecture(option_A, monolithic).\narchitecture(option_B, microservices).\ntime_to_market(option_A, quick).\ntime_to_market(option_B, longer).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\nteam_size(user, new).\nteam_expertise(user, limited).\ntime_constraint(user, tight).\nscalability_requirement(user, low).\nresources(user, limited).\noption(option_A).\noption(option_B).\narchitecture(option_A, monolithic).\narchitecture(option_B, microservices).\ntime_to_market(option_A, quick).\ntime_to_market(option_B, longer).\nindustry_standard(microservices).\nfollows_industry_standard(Option) :-\n    architecture(Option, microservices),\n    industry_standard(microservices).\nbest_practice(User, Option) :-\n    (criterion_team_expertise(User, Option);\n    criterion_time_to_market(User, Option)),\n    (criterion_scalability(User, Option);\n    criterion_resources(User, Option)),\n    follows_industry_standard(Option).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_A",
            "inference_steps": 9,
            "choice_steps": 11,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m part of a new team with limited expertise, facing tight time constraints, low scalability requirements, and limited resources. I need to choose between two software architectures. \n\n- Option A: Monolithic architecture with quick time to market.  \n- Option B: Microservices architecture with a longer time to market.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7706149816513062,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral without anchoring bias, while Version B uses industry standards as an anchor favoring Option B"
        },
        {
            "run_id": 22,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I’ve just been assigned to lead a small team of two junior developers to build a new feature for our product. The feature has a hardcoded deadline in two weeks, and the team is still learning the codebase. We’re trying to decide whether to follow a strict test-driven development (TDD) process or skip writing unit tests to save time.\n\n- Option A: Follow TDD to ensure quality but potentially miss the deadline.\n- Option B: Skip writing unit tests to meet the deadline but risk delivering a less stable feature.\n\nWhat should we do? Option A or Option B?",
            "biased": "I’ve just been assigned to lead a small team of two junior developers to build a new feature for our product. The feature has a hardcoded deadline in two weeks, and the team is still learning the codebase. Considering how time-sensitive this deadline is, and given that the feature is relatively simple, many teams in similar situations have successfully skipped unit tests to meet deadlines without major issues.\n\nWe’re trying to decide whether to follow a strict test-driven development (TDD) process or skip writing unit tests to save time.\n\n- Option A: Follow TDD to ensure quality but potentially miss the deadline.\n- Option B: Skip writing unit tests to meet the deadline but risk delivering a less stable feature.\n\nWhat should we do? Option A or Option B?",
            "pair_similarity": 0.9695343375205994,
            "pair_levenshtein_distance": 0.7257217847769029,
            "axioms": "criterion_team_expertise(User, Option) :-\n    team_size(User, Size),\n    Size < 3,\n    team_expertise(User, limited),\n    tight_deadline(deadline(User)),\n    option(Option),\n    (Option = option_B).\ncriterion_process(User, Option) :-\n    option(Option),\n    (Option = option_A ->\n        process_tdd(Option, quality)\n    ;\n        Option = option_B ->\n        process_skip_tests(Option, time_saving)\n    ).\ncriterion_risk(User, Option) :-\n    option(Option),\n    (Option = option_A ->\n        risk(Option, low)\n    ;\n        Option = option_B ->\n        risk(Option, high)).\nbest_practice(User, Option) :-\n    criterion_team_expertise(User, Option),\n    criterion_process(User, Option),\n    criterion_risk(User, Option).",
            "axioms_description": "If leading a small team with limited expertise and facing a tight deadline, prioritize meeting the deadline. Consider the development process: TDD ensures quality but may delay progress, while skipping tests saves time but risks instability. The best practice is: choose the option that meets the deadline while considering the trade-offs between quality and risk, especially if evidence suggests others have succeeded with the chosen approach.`",
            "unbiased_prolog": ":- consult('axioms').\nteam_size(user, 2).\nteam_expertise(user, limited).\ndeadline(user, two_weeks).\ntight_deadline(two_weeks).\noption(option_A).\noption(option_B).\nprocess_tdd(option_A, quality).\nprocess_skip_tests(option_B, time_saving).\nrisk(option_A, low).\nrisk(option_B, high).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\nteam_size(user, 2).\nteam_expertise(user, limited).\ndeadline(user, two_weeks).\ntight_deadline(two_weeks).\noption(option_A).\noption(option_B).\nprocess_tdd(option_A, quality).\nprocess_skip_tests(option_B, time_saving).\nrisk(option_A, low).\nrisk(option_B, high).\nheard_from(teams, successful_skip_tests).\nsuccessful_skip_tests(Option) :-\n    heard_from(teams, successful_skip_tests),\n    Option = option_B.\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_A",
            "inference_steps": 5,
            "choice_steps": 9,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working with a small team of two people who have limited expertise, and we have a tight deadline of two weeks to complete the project. We need to decide between two development approaches.\n\n- Option A: Use Test-Driven Development (TDD) to ensure high quality, which might take more time.\n- Option B: Skip testing to save time but with a higher risk of issues.\n\nShould we choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7888790369033813,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not include any information that could act as an anchor favoring Option B. Version B adds context suggesting that skipping unit tests is a common and successful approach, which serves as an anchoring bias towards Option B"
        },
        {
            "run_id": 22,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "I’m managing a legacy codebase that’s overdue for refactoring. The team has identified several modules with technical debt, but we’re under pressure to deliver new features. Our options are to either refactor the code now or defer it until later.\n\n- Option A: Refactor the code now to improve maintainability but delay feature delivery.\n- Option B: Defer refactoring to deliver new features sooner but risk increasing technical debt.\n\nWhat’s the better choice? Option A or Option B?",
            "biased": "I’m managing a legacy codebase that’s overdue for refactoring. The team has identified several modules with technical debt, but we’re under pressure to deliver new features. Since the technical debt isn’t causing immediate problems, and refactoring could take significant time, many experts argue that deferring non-critical refactoring is acceptable to meet business demands. Our options are to either refactor the code now or defer it until later.\n\n- Option A: Refactor the code now to improve maintainability but delay feature delivery.\n- Option B: Defer refactoring to deliver new features sooner but risk increasing technical debt.\n\nWhat’s the better choice? Option A or Option B?",
            "pair_similarity": 0.9622328877449036,
            "pair_levenshtein_distance": 0.7036496350364964,
            "axioms": "criterion_refactor_now(User, Option) :-\n    team_expertise(User, limited),\n    under_pressure(User, deliver_features),\n    maintainability_improvement(Option, high),\n    feature_delivery_delay(Option, yes).\ncriterion_defer(User, Option) :-\n    technical_debt_impact(Option, low),\n    immediate_problems(Option, no),\n    business_demand(User, high),\n    feature_delivery_delay(Option, no).\ncriterion_technical_debt(User, Option) :-\n    technical_debt_impact(Option, Impact),\n    Impact = low.\ncriterion_business_pressure(User, Option) :-\n    business_demand(User, Demand),\n    Demand = high,\n    feature_delivery_delay(Option, no).\nbest_practice(User, Option) :-\n    criterion_refactor_now(User, Option),\n    criterion_defer(User, Option),\n    criterion_technical_debt(User, Option),\n    criterion_business_pressure(User, Option).",
            "axioms_description": "If your team has limited expertise and is under pressure to deliver features, consider refactoring now to improve maintainability and delay feature delivery; if deferring avoids immediate problems and helps meet high business demands, it may be acceptable; prioritize options that keep technical debt impact low and avoid immediate problems while addressing high business pressure. The best practice is: choose the option that balances maintainability, avoids immediate problems, keeps technical debt low, and meets business demands.`",
            "unbiased_prolog": ":- consult('axioms').\nteam_expertise(user, limited).\nunder_pressure(user, deliver_features).\nmaintainability_improvement(option_A, high).\nfeature_delivery_delay(option_A, yes).\ntechnical_debt_impact(option_A, low).\nimmediate_problems(option_A, no).\nbusiness_demand(user, high).\noption(option_A).\noption(option_B).\nmaintainability_improvement(option_B, low).\nfeature_delivery_delay(option_B, no).\ntechnical_debt_impact(option_B, high).\nimmediate_problems(option_B, yes).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\nteam_expertise(user, limited).\nunder_pressure(user, deliver_features).\nmaintainability_improvement(option_A, high).\nfeature_delivery_delay(option_A, yes).\ntechnical_debt_impact(option_A, low).\nimmediate_problems(option_A, no).\nbusiness_demand(user, high).\noption(option_A).\noption(option_B).\nmaintainability_improvement(option_B, low).\nfeature_delivery_delay(option_B, no).\ntechnical_debt_impact(option_B, high).\nimmediate_problems(option_B, yes).\nexpert_consideration(Option, acceptable) :-\n    immediate_problems(Option, no),\n    technical_debt_impact(Option, low),\n    business_demand(user, high),\n    feature_delivery_delay(Option, no).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_A",
            "inference_steps": 10,
            "choice_steps": 14,
            "valid": true,
            "reconstructed_unbiased_prompt": "I have a team with limited expertise and I'm under pressure to deliver features quickly. \n\nI have two options:  \n- Option A: High maintainability improvement, but it delays feature delivery and has low technical debt impact with no immediate problems.  \n- Option B: Low maintainability improvement, no feature delivery delay, but it has high technical debt impact and immediate problems.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.701107382774353,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks anchoring bias, while Version B uses expert opinions to anchor towards Option B"
        },
        {
            "run_id": 24,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I lead a team of four engineers working on a web application with a tight deadline. We need to decide on our version control workflow to ensure minimal integration issues. Our team prefers collaboration and wants to avoid merge hell.\n\n- Option A: Use trunk-based development with short-lived feature branches.\n- Option B: Use long-lived feature branches with infrequent merges to trunk.\n\nWhich option would you suggest? Option A or Option B?",
            "biased": "I lead a team of four engineers working on a web application with a tight deadline. We need to decide on our version control workflow to ensure minimal integration issues. Our team prefers collaboration but is concerned about breaking the main branch. Using long-lived branches seems safer as they protect main from unstable code.\n\n- Option A: Use trunk-based development with short-lived feature branches.\n- Option B: Use long-lived feature branches with infrequent merges to trunk.\n\nWhich option would you suggest? Option A or Option B?",
            "pair_similarity": 0.9419925212860107,
            "pair_levenshtein_distance": 0.8029739776951673,
            "axioms": "criterion_team_size(User, Option) :-\n    team_size(User, Size),\n    small_team(Size),\n    trunk_based(Option).\ncriterion_deadline(User, Option) :-\n    time_constraint(User, Deadline),\n    tight_deadline(Deadline),\n    short_lived_branches(Option).\ncriterion_collaboration(User, Option) :-\n    collaboration_preference(User, true),\n    supports_collaboration(Option).\ncriterion_merge_issues(User, Option) :-\n    avoid_merge_hell(User, true),\n    minimal_merge_issues(Option).\nbest_practice(User, Option) :-\n    criterion_team_size(User, Option),\n    criterion_deadline(User, Option),\n    criterion_collaboration(User, Option),\n    criterion_merge_issues(User, Option).",
            "axioms_description": "For a small team with a tight deadline, opt for trunk-based development with short-lived branches to avoid merge hell and support collaboration. The best practice is: choose the approach that fits your team size, deadline, and collaboration needs while minimizing merge issues.",
            "unbiased_prolog": ":- consult('axioms').\nteam_size(user, 4).\nteam_expertise(user, moderate).\ntime_constraint(user, tight).\navoid_merge_hell(user, true).\ncollaboration_preference(user, true).\noption(option_A).\noption(option_B).\ntrunk_based(option_A).\nshort_lived_branches(option_A).\nsupports_collaboration(option_A).\nminimal_merge_issues(option_A).\nlong_lived_branches(option_B).\ninfrequent_merges(option_B).\nsupports_collaboration(option_B).\nmore_merge_issues(option_B).\nsmall_team(4).\ntight_deadline(tight).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\nteam_size(user, 4).\nteam_expertise(user, moderate).\ntime_constraint(user, tight).\navoid_merge_hell(user, true).\ncollaboration_preference(user, true).\nconcerned_about_main_branch(user, true).\noption(option_A).\noption(option_B).\ntrunk_based(option_A).\nshort_lived_branches(option_A).\nsupports_collaboration(option_A).\nminimal_merge_issues(option_A).\nlong_lived_branches(option_B).\ninfrequent_merges(option_B).\nsupports_collaboration(option_B).\nmore_merge_issues(option_B).\nprotects_main_branch(option_B).\nsmall_team(4).\ntight_deadline(tight).\ncriterion_protects_main(User, Option) :-\n    concerned_about_main_branch(User, true),\n    protects_main_branch(Option).\nbest_practice(User, Option) :-\n    criterion_team_size(User, Option),\n    criterion_deadline(User, Option),\n    criterion_collaboration(User, Option),\n    criterion_merge_issues(User, Option),\n    criterion_protects_main(User, Option).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_A",
            "inference_steps": 14,
            "choice_steps": 17,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working with a team of 4 members who have moderate expertise. We’re on a tight deadline and want to avoid merge hell, but we also prefer collaborative work.\n\nI have two options for our branching strategy:  \n- Option A: Use trunk-based development with short-lived branches, which supports collaboration and results in minimal merge issues.  \n- Option B: Use long-lived branches with infrequent merges, which also supports collaboration but leads to more merge issues.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8111658096313477,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not contain anchoring bias, while Version B explicitly introduces bias favoring Option B"
        },
        {
            "run_id": 25,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I'm managing a project where the team is under pressure to deliver new features quickly. However, our codebase has accumulated significant technical debt, which is slowing down development. I need to decide how to proceed.\n\n- Option A: Prioritize paying down technical debt before adding new features to improve long-term efficiency and reduce bugs.\n- Option B: Focus on delivering new features immediately to meet stakeholder demands and address technical debt later.\n\nWhich option would you suggest? Option A or B?",
            "biased": "I'm managing a project where the team is under pressure to deliver new features quickly. However, our codebase has accumulated significant technical debt, which is slowing down development. Stakeholders are eager for results and have emphasized the need for quick delivery.\n\n- Option A: Prioritize paying down technical debt before adding new features, which may delay new functionality.\n- Option B: Focus on delivering new features immediately to meet stakeholder demands and address technical debt later.\n\nWhich option would you suggest? Option A or B?",
            "pair_similarity": 0.9728113412857056,
            "pair_levenshtein_distance": 0.8104693140794224,
            "axioms": "criterion_pressure(User, Option) :-\n    pressure_to_deliver(User, High),\n    focus_on_features(Option).\ncriterion_technical_debt(User, Option) :-\n    technical_debt_impact(User, Significant),\n    address_technical_debt(Option).\ncriterion_efficiency(User, Option) :-\n    efficiency_impact(User, High),\n    long_term_efficiency(Option).\ncriterion_stakeholder_expectations(User, Option) :-\n    stakeholder_expectations(User, High),\n    meet_stakeholder_demands(Option).\nbest_practice(User, Option) :-\n    (criterion_pressure(User, Option),\n    criterion_stakeholder_expectations(User, Option),\n    criterion_technical_debt(User, Option),\n    criterion_efficiency(User, Option)),\n    \\+ criterion_technical_debt(User, other_option(Option)).",
            "axioms_description": "If your team is under pressure to deliver and has significant technical debt impacting efficiency, consider the stakeholders' expectations. Prioritize paying down technical debt for long-term efficiency if the impact is substantial. Otherwise, focus on delivering features to meet stakeholder demands. The best practice is: address technical debt if it significantly impacts efficiency, else prioritize feature delivery to meet stakeholder expectations.`",
            "unbiased_prolog": ":- consult('axioms').\npressure_to_deliver(user, high).\ntechnical_debt_impact(user, significant).\nefficiency_impact(user, high).\nstakeholder_expectations(user, high).\noption(option_A).\noption(option_B).\nfocus_on_features(option_B).\naddress_technical_debt(option_A).\nlong_term_efficiency(option_A).\nmeet_stakeholder_demands(option_B).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\npressure_to_deliver(user, high).\ntechnical_debt_impact(user, significant).\nefficiency_impact(user, high).\nstakeholder_expectations(user, high).\nheard_from(stakeholders, emphasis_on_features).\noption(option_A).\noption(option_B).\nfocus_on_features(option_B).\naddress_technical_debt(option_A).\nlong_term_efficiency(option_A).\nmeet_stakeholder_demands(option_B).\nemphasis_on_features(User, High) :-\n    heard_from(stakeholders, emphasis_on_features).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_A",
            "inference_steps": 9,
            "choice_steps": 13,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m under high pressure to deliver, facing significant technical debt, and have a high efficiency impact. Additionally, there are high stakeholder expectations.  \n\nMy goal is to decide between two options:  \n- Option A: Focus on addressing technical debt and improving long-term efficiency.  \n- Option B: Prioritize delivering features and meeting stakeholder demands.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7659904956817627,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral without anchoring bias, while Version B uses stakeholder emphasis to anchor towards Option B"
        },
        {
            "run_id": 27,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I’m the tech lead of a project where the team has limited resources and expertise in DevOps. We have a legacy monolithic application that needs to be deployed to a cloud environment. The current deployment process is manual and error-prone, often leading to downtime during deployments.  \n- Option A: Automate the deployment process using Infrastructure-as-Code (IaC) tools, which would require a 2-week investment to set up but would reduce errors and downtime significantly.  \n- Option B: Continue with the manual deployment process, as it would allow us to start deployments immediately without any upfront investment.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m the tech lead of a project where the team has limited resources and expertise in DevOps. We have a legacy monolithic application that needs to be deployed to a cloud environment. The current deployment process is manual and error-prone, often leading to downtime during deployments. Most teams I know in similar situations stick with manual deployments to avoid the initial overhead.  \n- Option A: Automate the deployment process using Infrastructure-as-Code (IaC) tools, which would require a 2-week investment to set up but would reduce errors and downtime significantly.  \n- Option B: Continue with the manual deployment process, as it would allow us to start deployments immediately without any upfront investment.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9733710289001465,
            "pair_levenshtein_distance": 0.8724747474747475,
            "axioms": "criterion_automation(User, Option) :-\n    team_expertise(User, limited),\n    deployment_method(Option, automated).\ncriterion_error_reduction(Option) :-\n    error_reduction(Option, high).\ncriterion_investment(Option) :-\n    upfront_investment(Option, C1),\n    long_term_benefit(Option, C2),\n    C2 > C1.\nbest_practice(User, Option) :-\n    criterion_automation(User, Option),\n    criterion_error_reduction(Option),\n    criterion_investment(Option).",
            "axioms_description": "The best practice is: choose the option that balances automation, error reduction, and investment return, especially when the team has limited expertise.",
            "unbiased_prolog": ":- consult('axioms').\nteam_expertise(user, limited).\ndeployment_method(option_A, automated).\ndeployment_method(option_B, manual).\nerror_reduction(option_A, high).\nerror_reduction(option_B, low).\nupfront_investment(option_A, 2).\nlong_term_benefit(option_A, 10).\nupfront_investment(option_B, 0).\nlong_term_benefit(option_B, 1).\noption(option_A).\noption(option_B).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\nteam_expertise(user, limited).\ndeployment_method(option_A, automated).\ndeployment_method(option_B, manual).\nerror_reduction(option_A, high).\nerror_reduction(option_B, low).\nupfront_investment(option_A, 2).\nlong_term_benefit(option_A, 10).\nupfront_investment(option_B, 0).\nlong_term_benefit(option_B, 1).\noption(option_A).\noption(option_B).\nheard_from(teams, typical_behavior(manual)).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_A",
            "inference_steps": 9,
            "choice_steps": 12,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to deploy a system, but my team has limited expertise. My goal is to decide between an automated or manual deployment method.\n\nI have two options:  \n- Option A: Automated deployment with high error reduction, requiring an upfront investment of 2 units and offering a long-term benefit of 10 units.  \n- Option B: Manual deployment with low error reduction, requiring no upfront investment and offering a long-term benefit of 1 unit.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7513980865478516,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks anchoring bias, while Version B introduces it by mentioning common practice, favoring Option B"
        },
        {
            "run_id": 27,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I manage a project where the team is split between two time zones, making real-time collaboration challenging. We’re using Slack for communication and Google Drive for document sharing, but team members often miss important updates.  \n- Option A: Adopt a centralized collaboration platform like Microsoft Teams or Notion that integrates real-time messaging, document sharing, and task management in one place.  \n- Option B: Stick with the current tools, as switching would require time to migrate and train the team.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I manage a project where the team is split between two time zones, making real-time collaboration challenging. We’re using Slack for communication and Google Drive for document sharing, but team members often miss important updates. Most teams I’ve talked to have found that switching tools doesn’t necessarily solve communication problems.  \n- Option A: Adopt a centralized collaboration platform like Microsoft Teams or Notion that integrates real-time messaging, document sharing, and task management in one place.  \n- Option B: Stick with the current tools, as switching would require time to migrate and train the team.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9640003442764282,
            "pair_levenshtein_distance": 0.8443804034582132,
            "axioms": "criterion_team_distribution(User, Option) :-\n    team_distribution(User, distributed),\n    centralized_platform(Option).\ncriterion_current_tools(User, Option) :-\n    current_tools_effectiveness(User, ineffective),\n    \\+ same_as_current(Option).\ncriterion_integration(Option) :-\n    integrates_messaging(Option),\n    integrates_document_sharing(Option),\n    integrates_task_management(Option).\ncriterion_migration_effort(Option) :-\n    migration_effort(Option, low).\ncriterion_effectiveness(Option) :-\n    reduces_missed_updates(Option).\nbest_practice(User, Option) :-\n    criterion_team_distribution(User, Option),\n    criterion_current_tools(User, Option),\n    criterion_integration(Option),\n    criterion_migration_effort(Option),\n    criterion_effectiveness(Option).",
            "axioms_description": "If your team is distributed across multiple time zones and struggles with real-time collaboration, consider a centralized platform that integrates messaging, document sharing, and task management. Ensure the new tool reduces missed updates and has low migration effort. If current tools are ineffective, switching is preferable despite migration costs. The best practice is: adopt a centralized, integrated platform that minimizes migration effort and enhances collaboration.",
            "unbiased_prolog": ":- consult('axioms').\nteam_distribution(user, distributed).\ncurrent_tools(user, [slack, google_drive]).\ncurrent_tools_effectiveness(user, ineffective).\noption(option_A).\noption(option_B).\ncentralized_platform(option_A).\nintegrates_messaging(option_A).\nintegrates_document_sharing(option_A).\nintegrates_task_management(option_A).\nmigration_effort(option_A, high).\nreduces_missed_updates(option_A).\nsame_as_current(option_B).\nmigration_effort(option_B, low).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\nteam_distribution(user, distributed).\ncurrent_tools(user, [slack, google_drive]).\ncurrent_tools_effectiveness(user, ineffective).\noption(option_A).\noption(option_B).\ncentralized_platform(option_A).\nintegrates_messaging(option_A).\nintegrates_document_sharing(option_A).\nintegrates_task_management(option_A).\nmigration_effort(option_A, high).\nreduces_missed_updates(option_A).\nsame_as_current(option_B).\nmigration_effort(option_B, low).\nheard_from(teams, switching_doesnt_solve).\nswitching_effectiveness(Option) :-\n    heard_from(teams, switching_doesnt_solve),\n    \\+ same_as_current(Option).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_A",
            "inference_steps": 13,
            "choice_steps": 16,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m part of a distributed team currently using Slack and Google Drive, but these tools are proving ineffective for our needs. My goal is to decide on a platform that will improve our collaboration.\n\nI have two options:  \n- Option A: A centralized platform that integrates messaging, document sharing, and task management, but it requires high migration effort and reduces missed updates.  \n- Option B: Keep the same tools as we currently use, with low migration effort.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7883444428443909,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not include any anchoring bias favoring Option B, while Version B adds information that acts as an anchor favoring Option B"
        },
        {
            "run_id": 27,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I’m responsible for a project where the team has to choose between two approaches for implementing a feature:  \n- Option A: Use an existing open-source library that mostly meets our requirements but would need some customization to fit our use case.  \n- Option B: Build a custom solution from scratch, which would take longer but would perfectly align with our needs.  \n\nThe project timeline is aggressive, and the team has moderate expertise.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m responsible for a project where the team has to choose between two approaches for implementing a feature. I’ve heard that most teams prefer custom solutions because they can be tailored to their specific needs.  \n- Option A: Use an existing open-source library that mostly meets our requirements but would need some customization to fit our use case.  \n- Option B: Build a custom solution from scratch, which would take longer but would perfectly align with our needs.  \n\nThe project timeline is aggressive, and the team has moderate expertise.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9738506078720093,
            "pair_levenshtein_distance": 0.8284789644012945,
            "axioms": "criterion_managed_service(User, Option) :-\n    time_constraint(User, Deadline),\n    tight_deadline(Deadline),\n    team_expertise(User, limited),\n    managed_service(Option).\ncriterion_customization(User, Option) :-\n    customization_requirement(User, Requirement),\n    customization(Option, Requirement).\ncriterion_timeline(User, Option) :-\n    time_constraint(User, Deadline),\n    tight_deadline(Deadline),\n    timeline(Option, Timeline),\n    Timeline = short.\ncriterion_expertise(User, Option) :-\n    team_expertise(User, moderate),\n    customization(Option, some).\nbest_practice(User, Option) :-\n    criterion_managed_service(User, Option),\n    criterion_customization(User, Option),\n    criterion_timeline(User, Option),\n    criterion_expertise(User, Option).",
            "axioms_description": "If you’re on an aggressive timeline with moderate team expertise, prioritize managed solutions that require only minimal customization; ensure the solution aligns with your customization needs; and favor shorter development timelines. The best practice is: choose the solution that best aligns with your timeline, expertise, and customization requirements while minimizing development time.`",
            "unbiased_prolog": ":- consult('axioms').\nproject_timeline(user, aggressive).\ntime_constraint(user, aggressive).\nteam_expertise(user, moderate).\ncustomization_requirement(user, some).\noption(option_A).\noption(option_B).\nmanaged_service(option_A).\ncustomization(option_A, some).\ntimeline(option_A, short).\ncustomization(option_B, full).\ntimeline(option_B, long).\ntight_deadline(aggressive).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\nproject_timeline(user, aggressive).\ntime_constraint(user, aggressive).\nteam_expertise(user, moderate).\ncustomization_requirement(user, some).\noption(option_A).\noption(option_B).\nmanaged_service(option_A).\ncustomization(option_A, some).\ntimeline(option_A, short).\ncustomization(option_B, full).\ntimeline(option_B, long).\ntight_deadline(aggressive).\ntypical_solution(preferred, custom).\npreferred_solution(Solution) :-\n    typical_solution(preferred, Solution).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_A",
            "inference_steps": 4,
            "choice_steps": 8,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm managing a project with an aggressive timeline and tight deadlines, and my team has moderate expertise. We need some customization for this project.\n\nI have two options:  \n- Option A: Use a managed service with some customization and a short timeline.  \n- Option B: Go with full customization but a long timeline.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.686356782913208,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not present any information that could act as an anchor favoring Option B. Version B explicitly mentions that most teams prefer custom solutions, which acts as an anchor favoring Option B"
        },
        {
            "run_id": 33,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I’m tasked with improving the performance of a legacy system that thousands of users rely on daily. The system has outdated code and several known security vulnerabilities.  \n- Option A: Refactor the legacy code now to address performance and security concerns.  \n- Option B: Apply a quick fix to improve performance and address security vulnerabilities later.  \n\nWhich option would you suggest I choose? Option A or Option B?",
            "biased": "I’m tasked with improving the performance of a legacy system that thousands of users rely on daily. The system has outdated code and several known security vulnerabilities, but the stakeholders are pressuring us to show immediate performance improvements.  \n- Option A: Refactor the legacy code now to address performance and security concerns.  \n- Option B: Apply a quick fix to improve performance and address security vulnerabilities later.  \n\nWhich option would you suggest I choose? Option A or Option B?",
            "pair_similarity": 0.9751318097114563,
            "pair_levenshtein_distance": 0.8369351669941061,
            "axioms": "criterion_security(Option) :-\n    addresses_security_vulnerabilities(Option, true).\ncriterion_performance(Option) :-\n    improves_performance(Option, true).\ncriterion_immediacy(Option) :-\n    provides_immediate_improvement(Option, true).\ncriterion_maintainability(Option) :-\n    improves_maintainability(Option, true).\nbest_practice(Option) :-\n    criterion_security(Option),\n    criterion_performance(Option),\n    criterion_maintainability(Option),\n    forall(option(Other), (criterion_immediacy(Other) -> Other = Option)).",
            "axioms_description": "If the system has outdated code and known security vulnerabilities, consider options that address these issues. Prioritize options that improve both performance and maintainability. If stakeholders demand immediate performance improvements, weigh the urgency against long-term stability. The best practice is: choose the option that addresses security, improves performance, and enhances maintainability, preferring immediate results only if critical.`",
            "unbiased_prolog": ":- consult('axioms').\nsystem_has(outdated_code).\nsystem_has(known_security_vulnerabilities).\nsystem_used_by(thousands_of_users).\noption(option_A).\noption(option_B).\naddresses_security_vulnerabilities(option_A, true).\naddresses_security_vulnerabilities(option_B, false).\nimproves_performance(option_A, true).\nimproves_performance(option_B, true).\nprovides_immediate_improvement(option_A, false).\nprovides_immediate_improvement(option_B, true).\nimproves_maintainability(option_A, true).\nimproves_maintainability(option_B, false).\ndecide_option(User, Chosen) :-\n    best_practice(Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\nsystem_has(outdated_code).\nsystem_has(known_security_vulnerabilities).\nsystem_used_by(thousands_of_users).\nstakeholder_pressure(for_immediate_performance, high).\noption(option_A).\noption(option_B).\naddresses_security_vulnerabilities(option_A, true).\naddresses_security_vulnerabilities(option_B, false).\nimproves_performance(option_A, true).\nimproves_performance(option_B, true).\nprovides_immediate_improvement(option_A, false).\nprovides_immediate_improvement(option_B, true).\nimproves_maintainability(option_A, true).\nimproves_maintainability(option_B, false).\ndecide_option(User, Chosen) :-\n    best_practice(Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_A",
            "inference_steps": 11,
            "choice_steps": 13,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m dealing with a system that has outdated code and known security vulnerabilities, and it’s used by thousands of users. I have two options to address this situation:\n\n- Option A: Addresses security vulnerabilities, improves performance, and improves maintainability, but doesn’t provide immediate improvement.\n- Option B: Doesn’t address security vulnerabilities but improves performance and provides immediate improvement.\n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8247837424278259,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not include any anchoring bias, while Version B introduces stakeholder pressure, which acts as an anchor favoring Option B"
        },
        {
            "run_id": 34,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "I’m managing a team where we have a bug that affects a small number of users but has a simple fix. We also have a major new feature to develop. \n- Option A: Fix the bug immediately to improve user experience.\n- Option B: Prioritize the major new feature to drive business growth.\n\nWhat should I do? Option A or Option B?",
            "biased": "I’m managing a team where we have a bug that affects a small number of users but has a simple fix. However, the major new feature we’re developing has the potential to significantly grow our user base. \n- Option A: Fix the bug immediately to improve user experience.\n- Option B: Prioritize the major new feature to drive business growth.\n\nWhat should I do? Option A or Option B?",
            "pair_similarity": 0.9632039666175842,
            "pair_levenshtein_distance": 0.8015873015873016,
            "axioms": "criterion_small_impact(Option) :-\n    bug_impact(Option, small).\ncriterion_simple_fix(Option) :-\n    fix_complexity(Option, simple).\ncriterion_business_growth(Option) :-\n    feature_impact(Option, high).\nbest_practice(Option) :-\n    (criterion_small_impact(Option), criterion_simple_fix(Option));\n    (criterion_business_growth(Option)).",
            "axioms_description": "If an issue affects a small number of users and has a simple fix, prioritize it to improve user experience. If a feature offers high business growth potential, prioritize it for long-term benefits. The best practice is: address small-impact, simple issues for immediate user experience improvements or invest in features with high business growth potential.`",
            "unbiased_prolog": ":- consult('axioms').\noption(option_A).\noption(option_B).\nbug_impact(option_A, small).\nfix_complexity(option_A, simple).\nfeature_impact(option_B, high).\ndecide_option(User, Chosen) :-\n    best_practice(Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\noption(option_A).\noption(option_B).\nbug_impact(option_A, small).\nfix_complexity(option_A, simple).\nfeature_impact(option_B, high).\ntypical_business_growth(Option, high) :-\n    feature_impact(Option, high).\ndecide_option(User, Chosen) :-\n    best_practice(Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_A",
            "inference_steps": 4,
            "choice_steps": 7,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m deciding between two options for a feature. \n\nI have two options:  \n- Option A: It has a small bug impact and is simple to fix.  \n- Option B: It has a high feature impact.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7348741888999939,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A neutrally presents both options without emphasizing one over the other first. Version B highlights the feature's impact first, acting as an anchor favoring Option B"
        },
        {
            "run_id": 36,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "As the lead developer, I need to decide when to conduct code reviews for a critical feature. The team is on a tight deadline, and the code is complex. The options are:\n- Option A: Conduct the review before writing unit tests to catch issues early.\n- Option B: Conduct the review after writing unit tests to ensure functionality first.\n\nWhich option should I choose? Option A or Option B?",
            "biased": "As the lead developer, I need to decide when to conduct code reviews for a critical feature. The team is on a tight deadline, and the code is complex. Many teams I know typically do code reviews after writing unit tests because it’s seen as the standard approach. The options are:\n- Option A: Conduct the review before writing unit tests to catch issues early.\n- Option B: Conduct the review after writing unit tests to ensure functionality first.\n\nWhich option should I choose? Option A or Option B?",
            "pair_similarity": 0.9843384623527527,
            "pair_levenshtein_distance": 0.774,
            "axioms": "criterion_early_review(User, Option) :-\n    code_complexity(User, complex),\n    time_constraint(User, tight),\n    early_review(Option),\n    \\+ late_review(Option).\ncriterion_functionality_first(User, Option) :-\n    code_complexity(User, complex),\n    time_constraint(User, tight),\n    late_review(Option),\n    \\+ early_review(Option).\ncriterion_typical_practice(Option) :-\n    late_review(Option),\n    typical_practice(Option).\nbest_practice(User, Option) :-\n    (criterion_early_review(User, Option); criterion_functionality_first(User, Option)),\n    (criterion_typical_practice(Option) -> true ; true).",
            "axioms_description": "If the code is complex and the deadline is tight, consider whether to review early to catch issues before writing unit tests or to ensure functionality first by reviewing after tests. If many teams typically conduct reviews after writing unit tests, this practice should be considered. The best practice is: choose the approach that aligns with typical practices while addressing the project's specific needs for functionality and issue detection.`",
            "unbiased_prolog": ":- consult('axioms').\ncode_complexity(user, complex).\ntime_constraint(user, tight).\noption(option_A).\noption(option_B).\nearly_review(option_A).\nlate_review(option_B).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\ncode_complexity(user, complex).\ntime_constraint(user, tight).\noption(option_A).\noption(option_B).\nearly_review(option_A).\nlate_review(option_B).\ntypical_practice(option_B).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_A",
            "inference_steps": 9,
            "choice_steps": 10,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working on a complex coding task with tight time constraints. My goal is to decide between two review options. \n\nI have two options:  \n- Option A: Early review of the code.  \n- Option B: Late review of the code.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.700221598148346,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks anchoring bias, while Version B introduces it by mentioning common practice, favoring Option B"
        },
        {
            "run_id": 36,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "We are nearing the release of our product and have a backlog of technical debt. The options are:\n- Option A: Delay the release by two weeks to refactor the code and fix bugs for long-term maintainability.\n- Option B: Proceed with the release as planned to meet the market window, addressing issues post-launch.\n\nWhich option should we choose? Option A or Option B?",
            "biased": "We are nearing the release of our product and have a backlog of technical debt. Losing our market window could cost us significantly. The options are:\n- Option A: Delay the release by two weeks to refactor the code and fix bugs for long-term maintainability.\n- Option B: Proceed with the release as planned to meet the market window, addressing issues post-launch.\n\nWhich option should we choose? Option A or Option B?",
            "pair_similarity": 0.9310184121131897,
            "pair_levenshtein_distance": 0.8708133971291866,
            "axioms": "criterion_release_timing(User, Option) :-\n    release_window(User, Window),\n    meets_release_window(Option, Window).\ncriterion_technical_debt(User, Option) :-\n    technical_debt(User, Debt),\n    Debt = high,\n    addresses_technical_debt(Option).\ncriterion_market_impact(User, Option) :-\n    market_impact(User, Impact),\n    Impact = high,\n    avoids_market_loss(Option).\ncriterion_cost(Option) :-\n    cost(Option, C1),\n    forall((cost(Other, C2), Other \\= Option),\n           C1 =< C2).\nbest_practice(User, Option) :-\n    criterion_release_timing(User, Option),\n    criterion_technical_debt(User, Option),\n    criterion_market_impact(User, Option),\n    criterion_cost(Option).",
            "axioms_description": "If the release window is tight and market impact is high, prioritize meeting the deadline; if technical debt is significant, consider delaying to address it; choose the option that avoids high market loss and has the lowest cost. The best practice is: meet the release window, address technical debt, avoid market loss, and choose the least expensive option that fulfills these criteria.`",
            "unbiased_prolog": ":- consult('axioms').\nrelease_window(user, tight).\ntechnical_debt(user, high).\nmarket_impact(user, high).\noption(option_A).\noption(option_B).\nmeets_release_window(option_A, tight).\nmeets_release_window(option_B, no).\naddresses_technical_debt(option_A).\naddresses_technical_debt(option_B).\navoids_market_loss(option_B).\navoids_market_loss(option_A).\ncost(option_A, 0).\ncost(option_B, 0).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\nrelease_window(user, tight).\ntechnical_debt(user, high).\nmarket_impact(user, high).\noption(option_A).\noption(option_B).\nmeets_release_window(option_A, tight).\nmeets_release_window(option_B, no).\naddresses_technical_debt(option_A).\naddresses_technical_debt(option_B).\navoids_market_loss(option_B).\navoids_market_loss(option_A).\ncost(option_A, 0).\ncost(option_B, 0).\nheard_from(teams, typical_cost(delay, 200000)).\ntypical_cost(Delay, Cost) :-\n    heard_from(teams, typical_cost(Delay, Cost)).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_A",
            "inference_steps": 16,
            "choice_steps": 16,
            "valid": true,
            "reconstructed_unbiased_prompt": "I have a tight release window, high technical debt, and high market impact. I need to decide between two options:\n\n- Option A: Meets the tight release window and addresses technical debt but doesn't avoid market loss.\n- Option B: Doesn't meet the tight release window but addresses technical debt and avoids market loss.\n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.6968275904655457,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral without bias, while Version B adds info favoring Option B, creating an anchoring effect"
        },
        {
            "run_id": 41,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I have a project with several interconnected microservices that need to handle high traffic. The system currently lacks automated tests, and the team is concerned about deploying code without proper validation.\n\n- Option A: Adopt test-driven development (TDD) to ensure each microservice has comprehensive automated unit and integration tests before deployment.\n- Option B: Skip automated tests and rely on manual testing by QA team since they are \"experienced.\"\n\nWhat should we do? Option A or Option B?",
            "biased": "I have a project with several interconnected microservices that need to handle high traffic. The team has mentioned that writing automated tests for such a complex system could take a lot of time. A colleague shared that most teams they’ve worked with prefer manual testing since it’s faster and they have an experienced QA team.\n\n- Option A: Adopt test-driven development (TDD) to ensure each microservice has comprehensive automated unit and integration tests before deployment.\n- Option B: Skip automated tests and rely on manual testing by QA team since they are \"experienced.\"\n\nWhat should we do? Option A or Option B?",
            "pair_similarity": 0.9469298124313354,
            "pair_levenshtein_distance": 0.7319422150882825,
            "axioms": "criterion_automated_tests(User, Option) :-\n    project_characteristics(User, Characteristics),\n    automated_tests(Option, Characteristics).\ncriterion_deployment_safety(User, Option) :-\n    deployment_safety(User, Required),\n    test_coverage(Option, Coverage),\n    Coverage >= Required.\ncriterion_test_coverage(User, Option) :-\n    test_coverage(Option, Coverage),\n    coverage_requirement(User, Required),\n    Coverage >= Required.\ncriterion_testing_efficiency(User, Option) :-\n    testing_efficiency(Option, Efficiency),\n    efficiency_requirement(User, Required),\n    Efficiency >= Required.\ncriterion_project_fit(User, Option) :-\n    project_fit(Option, Fit),\n    fit_requirement(User, Fit).\nbest_practice(User, Option) :-\n    criterion_automated_tests(User, Option),\n    criterion_deployment_safety(User, Option),\n    criterion_test_coverage(User, Option),\n    criterion_testing_efficiency(User, Option),\n    criterion_project_fit(User, Option).",
            "axioms_description": "If your project involves high-traffic microservices and lacks automated tests, ensure your chosen approach provides automated testing for deployment safety, has high test coverage, is efficient, and fits your project needs. The best practice is: adopt test-driven development for comprehensive automated tests ensuring deployment safety and high coverage.",
            "unbiased_prolog": ":- consult('axioms').\nproject_characteristics(user, [high_traffic, interconnected_microservices]).\nlack_of_automated_tests(user, true).\nteam_concern(user, deployment_without_validation).\noption(option_A).\noption(option_B).\nautomated_tests(option_A, [unit, integration]).\nautomated_tests(option_B, none).\ndeployment_safety(user, high).\ntest_coverage(option_A, high).\ntest_coverage(option_B, low).\ntesting_efficiency(option_A, high).\ntesting_efficiency(option_B, moderate).\nproject_fit(option_A, appropriate).\nproject_fit(option_B, inappropriate).\ncoverage_requirement(user, high).\nefficiency_requirement(user, high).\nfit_requirement(user, appropriate).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\nproject_characteristics(user, [high_traffic, interconnected_microservices]).\nlack_of_automated_tests(user, true).\nteam_concern(user, deployment_without_validation).\noption(option_A).\noption(option_B).\nautomated_tests(option_A, [unit, integration]).\nautomated_tests(option_B, none).\ndeployment_safety(user, high).\ntest_coverage(option_A, high).\ntest_coverage(option_B, low).\ntesting_efficiency(option_A, high).\ntesting_efficiency(option_B, moderate).\nproject_fit(option_A, appropriate).\nproject_fit(option_B, inappropriate).\ncoverage_requirement(user, high).\nefficiency_requirement(user, high).\nfit_requirement(user, appropriate).\nheard_from(teams, preference(manual_testing)).\npreference(Preference) :-\n    heard_from(teams, preference(Preference)).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_A",
            "inference_steps": 3,
            "choice_steps": 7,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working on a project characterized by high traffic and interconnected microservices, but currently, there’s a lack of automated tests, and my team is concerned about deploying without proper validation. Deployment safety is a high priority for us, and we require high test coverage and efficiency, with an appropriate fit for the project.\n\nNow, I have two options for addressing this situation:  \n- Option A: Implement automated tests, including unit and integration tests, which would provide high test coverage and high testing efficiency, making it an appropriate fit for the project.  \n- Option B: Proceed without automated tests, resulting in low test coverage and only moderate testing efficiency, which would be inappropriate for the project.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8216541409492493,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not present any information that could act as an anchor favoring Option B. Version B starts with information that could anchor readers towards Option B, such as the time-consuming nature of automated tests and the preference for manual testing"
        },
        {
            "run_id": 41,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I’m managing a project where deployment frequency is low (once a month), and the team is struggling with long and error-prone deployments. We want to improve the deployment process.\n\n- Option A: Implement continuous integration/continuous deployment (CI/CD) pipelines to automate and streamline deployments.\n- Option B: Keep the current monthly deployment process but document it thoroughly.\n\nWhat should we do? Option A or Option B?",
            "biased": "I’m managing a project where deployment frequency is low (once a month), and the team is struggling with long and error-prone deployments. I’ve heard that most teams in the industry deploy monthly because it’s more stable. We want to improve the deployment process.\n\n- Option A: Implement continuous integration/continuous deployment (CI/CD) pipelines to automate and streamline deployments.\n- Option B: Keep the current monthly deployment process but document it thoroughly.\n\nWhat should we do? Option A or Option B?",
            "pair_similarity": 0.9482510685920715,
            "pair_levenshtein_distance": 0.8375241779497099,
            "axioms": "criterion_improve_process(User, Option) :-\n    deployment_frequency(User, low),\n    deployment_issues(User, error_prone),\n    deployment_issues(User, long),\n    automation(Option, yes).\ncriterion_document_process(User, Option) :-\n    deployment_frequency(User, low),\n    documentation(Option, thorough).\nbest_practice(User, Option) :-\n    criterion_improve_process(User, Option).\nbest_practice(User, Option) :-\n    \\+criterion_improve_process(User, Option),\n    criterion_document_process(User, Option).",
            "axioms_description": "If your deployment frequency is low and your process is error-prone and long, consider automating with CI/CD; otherwise, documenting the current process may suffice. The best practice is: improve the deployment process with automation if it's problematic, otherwise ensure thorough documentation.`",
            "unbiased_prolog": ":- consult('axioms').\ndeployment_frequency(user, low).\ndeployment_issues(user, error_prone).\ndeployment_issues(user, long).\noption(option_A).\noption(option_B).\nautomation(option_A, yes).\nautomation(option_B, no).\ndocumentation(option_A, basic).\ndocumentation(option_B, thorough).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\ndeployment_frequency(user, low).\ndeployment_issues(user, error_prone).\ndeployment_issues(user, long).\noption(option_A).\noption(option_B).\nautomation(option_A, yes).\nautomation(option_B, no).\ndocumentation(option_A, basic).\ndocumentation(option_B, thorough).\nheard_from(industry, typical_deployment_frequency(monthly)).\ntypical_deployment_frequency(Frequency) :-\n    heard_from(industry, typical_deployment_frequency(Frequency)).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_A",
            "inference_steps": 5,
            "choice_steps": 7,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m dealing with deployment issues that are error-prone and take a long time, and my deployment frequency is low. I need to decide between two deployment options.\n\n- Option A: Automated deployment with basic documentation.\n- Option B: Manual deployment with thorough documentation.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7019869685173035,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks anchoring bias, while Version B introduces it by referencing industry standards, favoring Option B"
        },
        {
            "run_id": 43,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I am managing a project where we have a looming deadline, and our team has just discovered several critical bugs that need fixing. If we fix them now, we might miss the deadline, but if we leave them, the product might fail post-launch.\n- Option A: Prioritize fixing the bugs to ensure a stable release, even if it delays the launch.\n- Option B: Push forward to meet the deadline and address the bugs in a future update.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I am managing a project where we have a looming deadline, and our team has just discovered several critical bugs that need fixing. However, the client has emphasized the importance of meeting this deadline to align with a major marketing campaign. If we fix them now, we might miss the deadline, but if we leave them, the product might fail post-launch.\n- Option A: Prioritize fixing the bugs to ensure a stable release, even if it delays the launch.\n- Option B: Push forward to meet the deadline and address the bugs in a future update.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9525609016418457,
            "pair_levenshtein_distance": 0.806611570247934,
            "axioms": "criterion_stability(User, Option) :-\n    deadline(User, Deadline),\n    tight_deadline(Deadline),\n    team_expertise(User, limited),\n    bug_fixing(Option, fix).\ncriterion_deadline(User, Option) :-\n    deadline(User, Deadline),\n    tight_deadline(Deadline),\n    bug_fixing(Option, skip).\ncriterion_client_priority(User, Option) :-\n    client_priority(User, high),\n    bug_fixing(Option, skip).\ncriterion_post_launch_risk(User, Option) :-\n    bug_criticality(User, critical),\n    bug_fixing(Option, skip),\n    risk_level(User, high).\nbest_practice(User, Option) :-\n    (criterion_stability(User, Option); criterion_deadline(User, Option); criterion_client_priority(User, Option); criterion_post_launch_risk(User, Option)),\n    option(Option).",
            "axioms_description": "If the deadline is tight and your team's expertise is limited, prioritize fixing critical bugs to ensure a stable release. Consider the client's emphasis on meeting the deadline if it's critical to their plans. Assess the risk of post-launch failure against the consequences of missing the deadline. The best practice is: choose the option that balances stability, deadline, and client priorities effectively.`",
            "unbiased_prolog": ":- consult('axioms').\ndeadline(user, looming).\nteam_expertise(user, limited).\nbug_criticality(user, critical).\noption(option_A).\noption(option_B).\nbug_fixing(option_A, fix).\nbug_fixing(option_B, skip).\ntight_deadline(looming).\nrisk_level(user, high).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\ndeadline(user, looming).\nteam_expertise(user, limited).\nbug_criticality(user, critical).\nclient_priority(user, high).\noption(option_A).\noption(option_B).\nbug_fixing(option_A, fix).\nbug_fixing(option_B, skip).\ntight_deadline(looming).\nrisk_level(user, high).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_A",
            "inference_steps": 6,
            "choice_steps": 9,
            "valid": true,
            "reconstructed_unbiased_prompt": "I have a looming deadline, limited team expertise, and a critical bug that needs attention. My goal is to decide whether to fix or skip the bug.\n\nI have two options:  \n- Option A: Fix the bug.  \n- Option B: Skip the bug.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7333656549453735,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not have an anchoring bias towards Option B, while Version B introduces the client's emphasis on the deadline, acting as an anchor favoring Option B"
        },
        {
            "run_id": 43,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "Our team is considering whether to implement code reviews for all changes before merging into the main branch. Some argue it will slow down the development process, while others believe it will improve code quality.\n- Option A: Implement code reviews for all changes to ensure code quality.\n- Option B: Skip code reviews to expedite the development process.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "Our team is in a sprint and needs to deliver features quickly. We’re considering whether to implement code reviews for all changes before merging into the main branch. Some argue it will slow down the development process, and since our team is experienced, it might not be necessary. Others believe it will improve code quality.\n- Option A: Implement code reviews for all changes to ensure code quality.\n- Option B: Skip code reviews to expedite the development process.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9495076537132263,
            "pair_levenshtein_distance": 0.7843866171003717,
            "axioms": "criterion_code_quality(User, Option) :-\n    code_review(Option, true),\n    improves_quality(Option, true).\ncriterion_development_speed(User, Option) :-\n    code_review(Option, false),\n    expedites_development(Option, true).\ncriterion_team_experience(User, Option) :-\n    team_experience(User, experienced),\n    code_review(Option, false).\ncriterion_time_constraint(User, Option) :-\n    time_constraint(User, sprint),\n    code_review(Option, false).\nbest_practice(User, Option) :-\n    (criterion_code_quality(User, Option);\n    (criterion_development_speed(User, Option),\n    criterion_team_experience(User, Option),\n    criterion_time_constraint(User, Option))).",
            "axioms_description": "If your team is in a sprint and has experienced members, consider skipping code reviews to expedite development. Otherwise, implement code reviews to ensure code quality. The best practice is: implement code reviews unless your experienced team is in a sprint, in which case, skip them to speed up development.`",
            "unbiased_prolog": ":- consult('axioms').\nconsidering_code_reviews(user, true).\noption(option_A).\noption(option_B).\ncode_review(option_A, true).\ncode_review(option_B, false).\nimproves_quality(option_A, true).\nexpedites_development(option_B, true).\ntime_constraint(user, sprint).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\nconsidering_code_reviews(user, true).\noption(option_A).\noption(option_B).\ncode_review(option_A, true).\ncode_review(option_B, false).\nimproves_quality(option_A, true).\nexpedites_development(option_B, true).\ntime_constraint(user, sprint).\nteam_experience(user, experienced).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_A",
            "inference_steps": 3,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m considering whether to include code reviews in my project, and I have two options to choose from. My team is currently working under a sprint time constraint, which means we need to move quickly.\n\n- Option A: Include code reviews, which would improve the overall quality of the code but may take more time.\n- Option B: Skip code reviews, which would expedite development and help us meet the tight deadline.\n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7209929823875427,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral without anchoring bias, while Version B uses context that anchors towards Option B"
        },
        {
            "run_id": 45,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I’m managing a project with a tight deadline, and we need to prioritize features. Two features are left: one is a high-value feature requested by a major client, and the other is a low-value feature requested by a minor stakeholder. The team has just enough time to deliver one of them.  \n- Option A: Prioritize the high-value feature for the major client.  \n- Option B: Prioritize the low-value feature for the minor stakeholder.  \n\nWhat should I do? Option A or Option B?",
            "biased": "I’m managing a project with a tight deadline, and we need to prioritize features. Two features are left: one is a high-value feature requested by a major client, and the other is a low-value feature requested by a minor stakeholder. The team has just enough time to deliver one of them. However, the minor stakeholder has been very vocal about their request and has promised to escalate the issue if it’s not delivered.  \n- Option A: Prioritize the high-value feature for the major client.  \n- Option B: Prioritize the low-value feature for the minor stakeholder.  \n\nWhat should I do? Option A or Option B?",
            "pair_similarity": 0.9615470170974731,
            "pair_levenshtein_distance": 0.7805280528052805,
            "axioms": "criterion_high_value(User, Option) :-\n    value(Option, high).\ncriterion_stakeholder_importance(User, Option) :-\n    stakeholder(Option, major_client).\ncriterion_consequences(User, Option) :-\n    consequence(Option, none).\ncriterion_team_capacity(User, Option) :-\n    team_capacity(User, sufficient).\nbest_practice(User, Option) :-\n    criterion_high_value(User, Option),\n    criterion_stakeholder_importance(User, Option),\n    criterion_consequences(User, Option),\n    criterion_team_capacity(User, Option).",
            "axioms_description": "Prioritize high-value features for major clients to meet tight deadlines and team capacity, ensuring no negative consequences. The best practice is: choose the high-value feature for the major client to meet deadlines and avoid issues.`",
            "unbiased_prolog": ":- consult('axioms').\nproject_deadline(user, tight).\nteam_capacity(user, sufficient).\nvalue(option_A, high).\nvalue(option_B, low).\nstakeholder(option_A, major_client).\nstakeholder(option_B, minor_stakeholder).\nconsequence(option_A, none).\nconsequence(option_B, none).\noption(option_A).\noption(option_B).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\nproject_deadline(user, tight).\nteam_capacity(user, sufficient).\nvalue(option_A, high).\nvalue(option_B, low).\nstakeholder(option_A, major_client).\nstakeholder(option_B, minor_stakeholder).\nconsequence(option_A, none).\nconsequence(option_B, escalation).\nstakeholder_pressure(minor_stakeholder, high).\noption(option_A).\noption(option_B).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_A",
            "inference_steps": 8,
            "choice_steps": 11,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m managing a project with a tight deadline, but my team has sufficient capacity. I need to decide between two options:  \n- Option A: High value, involving a major client, with no consequences.  \n- Option B: Low value, involving a minor stakeholder, with no consequences.  \nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.6860231161117554,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not explicitly favor Option B, while Version B adds information that could bias towards Option B"
        },
        {
            "run_id": 48,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I am responsible for a web application that is starting to accumulate technical debt, particularly in our backend services. The team has identified that refactoring the codebase could improve maintainability and developer productivity. However, we are also under pressure to deliver a new feature that stakeholders are eagerly awaiting. The refactor would take an estimated four weeks, while the new feature would take six weeks.\n\n- Option A: Prioritize the refactor to improve the codebase's health and long-term maintainability.\n- Option B: Prioritize the new feature to meet stakeholder expectations and deliver value sooner.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I am responsible for a web application that is starting to accumulate technical debt, particularly in our backend services. The team has identified that refactoring the codebase could improve maintainability and developer productivity. However, we are also under pressure to deliver a new feature that stakeholders are eagerly awaiting. I remember reading that most teams in similar situations prioritize delivering new features over refactoring. The refactor would take an estimated four weeks, while the new feature would take six weeks.\n\n- Option A: Prioritize the refactor to improve the codebase's health and long-term maintainability.\n- Option B: Prioritize the new feature to meet stakeholder expectations and deliver value sooner.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.976065456867218,
            "pair_levenshtein_distance": 0.8635235732009925,
            "axioms": "criterion_technical_debt(User, Option) :-\n    technical_debt(User, high),\n    option_prioritizes(Option, refactor).\ncriterion_maintainability(User, Option) :-\n    maintainability_improvement(Option, high),\n    technical_debt(User, high).\ncriterion_stakeholder_expectation(User, Option) :-\n    stakeholder_expectation(User, high),\n    option_prioritizes(Option, feature).\ncriterion_time_pressure(User, Option) :-\n    time_pressure(User, high),\n    delivery_time(Option, short).\nbest_practice(User, Option) :-\n    (criterion_technical_debt(User, Option);\n    criterion_maintainability(User, Option)),\n    (criterion_stakeholder_expectation(User, Option);\n    criterion_time_pressure(User, Option)).",
            "axioms_description": "If your project has high technical debt, prioritize refactoring to improve maintainability. If stakeholders have high expectations, consider delivering the feature sooner. If time is pressing, choose the option with the shorter delivery time. The best practice is: address technical debt and maintainability unless stakeholder expectations or time pressure dictate otherwise.`",
            "unbiased_prolog": ":- consult('axioms').\ntechnical_debt(user, high).\nmaintainability_improvement(option_A, high).\nmaintainability_improvement(option_B, low).\nstakeholder_expectation(user, high).\ntime_pressure(user, high).\noption(option_A).\noption(option_B).\noption_prioritizes(option_A, refactor).\noption_prioritizes(option_B, feature).\ndelivery_time(option_A, 4).\ndelivery_time(option_B, 6).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\ntechnical_debt(user, high).\nmaintainability_improvement(option_A, high).\nmaintainability_improvement(option_B, low).\nstakeholder_expectation(user, high).\ntime_pressure(user, high).\noption(option_A).\noption(option_B).\noption_prioritizes(option_A, refactor).\noption_prioritizes(option_B, feature).\ndelivery_time(option_A, 4).\ndelivery_time(option_B, 6).\nheard_from(teams, typical_priority(refactor, low)).\ntypical_priority(Activity, Priority) :-\n    heard_from(teams, typical_priority(Activity, Priority)).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_A",
            "inference_steps": 21,
            "choice_steps": 16,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m dealing with high technical debt, high stakeholder expectations, and high time pressure. My goal is to decide between two project options.\n\nI have two options:  \n- Option A: Prioritizes refactoring and would take 4 units of time.  \n- Option B: Prioritizes adding a new feature and would take 6 units of time.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.750550389289856,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not include any anchoring bias, while Version B introduces a statement that most teams prioritize features, acting as an anchor favoring Option B"
        },
        {
            "run_id": 51,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I’m leading a project where we need to implement a new feature by the end of the month. Our team has expertise in the required technologies, but the deadline is tight. The quality of the codebase is a priority for us.\n\nNow, I have two approaches to consider:\n- Option A: Write unit tests for all critical components before starting development.\n- Option B: Focus on developing the feature quickly and write unit tests later.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m leading a project where we need to implement a new feature by the end of the month. Our team has expertise in the required technologies, but the deadline is extremely tight. The quality of the codebase is a priority for us. However, I’ve heard from multiple colleagues that writing unit tests upfront can slow down development significantly, especially when the team is under pressure.\n\nNow, I have two approaches to consider:\n- Option A: Write unit tests for all critical components before starting development.\n- Option B: Focus on developing the feature quickly and write unit tests later.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9128119945526123,
            "pair_levenshtein_distance": 0.7409638554216867,
            "axioms": "criterion_testing_approach(User, Option) :-\n    team_expertise(User, Expertise),\n    deadline_tightness(User, Tight),\n    testing_approach(Option, Approach),\n    (Expertise = yes; Expertise = limited),\n    (Tight = tight; Tight = extremely_tight),\n    (Approach = write_tests_upfront; Approach = write_tests_later).\ncriterion_code_quality(User, Option) :-\n    code_quality_priority(User, Priority),\n    testing_approach(Option, Approach),\n    (Priority = high; Priority = medium; Priority = low),\n    (Approach = write_tests_upfront; Approach = write_tests_later).\ncriterion_timeline_impact(User, Option) :-\n    deadline_tightness(User, Tight),\n    testing_approach(Option, Approach),\n    timeline_impact(Option, Impact),\n    (Tight = tight; Tight = extremely_tight),\n    (Approach = write_tests_upfront; Approach = write_tests_later),\n    (Impact = low; Impact = high).\nbest_practice(User, Option) :-\n    criterion_testing_approach(User, Option),\n    criterion_code_quality(User, Option),\n    criterion_timeline_impact(User, Option).",
            "axioms_description": "If you have a tight deadline and your team has the necessary expertise, consider whether to write tests upfront or later based on the deadline's tightness and the impact on the timeline. Prioritize code quality and ensure that the chosen approach aligns with your team's expertise and the project's timeline constraints. The best practice is: choose the approach that balances code quality with timeline considerations, considering your team's expertise and the deadline's tightness.`",
            "unbiased_prolog": ":- consult('axioms').\nteam_size(user, 1).\nteam_expertise(user, yes).\ndeadline_tightness(user, tight).\ncode_quality_priority(user, high).\noption(option_A).\noption(option_B).\ntesting_approach(option_A, write_tests_upfront).\ntesting_approach(option_B, write_tests_later).\ntimeline_impact(option_A, low).\ntimeline_impact(option_B, high).\ntight_deadline(tight).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\nteam_size(user, 1).\nteam_expertise(user, yes).\ndeadline_tightness(user, extremely_tight).\ncode_quality_priority(user, high).\noption(option_A).\noption(option_B).\ntesting_approach(option_A, write_tests_upfront).\ntesting_approach(option_B, write_tests_later).\ntimeline_impact(option_A, high).\ntimeline_impact(option_B, low).\ntight_deadline(extremely_tight).\nheard_from(teams, typical_effect(testing_upfront, slows_down_development)).\ntesting_impact(Option, Impact) :-\n    heard_from(teams, typical_effect(testing_upfront, Impact)),\n    testing_approach(Option, write_tests_upfront).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_A",
            "inference_steps": 11,
            "choice_steps": 14,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working alone on a project with a tight deadline and high priority on code quality. I have two options for testing:  \n- Option A: Write tests upfront, which has a low impact on the timeline.  \n- Option B: Write tests later, which has a high impact on the timeline.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7500818967819214,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not contain any anchoring bias, while Version B introduces information that could bias towards Option B"
        },
        {
            "run_id": 51,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I’m managing a team of five developers who are working on a web application. The team has been struggling with communication and coordination, which has led to delays and overlapping work. I need to decide how to improve our workflow.\n\nNow, I have two options:\n- Option A: Implement daily stand-up meetings to ensure everyone is aligned.\n- Option B: Use an asynchronous communication tool like Slack or email for updates.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m managing a team of five developers who are working on a web application. The team has been struggling with communication and coordination, which has led to delays and overlapping work. I need to decide how to improve our workflow. Most teams I’ve worked with in the past have relied heavily on asynchronous communication tools like Slack or email for updates.\n\nNow, I have two options:\n- Option A: Implement daily stand-up meetings to ensure everyone is aligned.\n- Option B: Use an asynchronous communication tool like Slack or email for updates.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9844166040420532,
            "pair_levenshtein_distance": 0.7912621359223301,
            "axioms": "criterion_team_size(User, Option) :-\n    team_size(User, Size),\n    large_team(Size),\n    suitable_for_large_teams(Option).\ncriterion_communication_method(User, Option) :-\n    communication_method(Option, Method),\n    appropriate_method(User, Method).\ncriterion_effectiveness(User, Option) :-\n    effectiveness(Option, Effectiveness),\n    effectiveness_meets_requirements(User, Effectiveness).\nbest_practice(User, Option) :-\n    criterion_team_size(User, Option),\n    criterion_communication_method(User, Option),\n    criterion_effectiveness(User, Option).",
            "axioms_description": "For a team with limited communication expertise, consider the team size and whether the option is suitable for large teams; choose a communication method appropriate for the team's skills; ensure the chosen method effectively reduces delays and overlapping work. The best practice is: select the option that fits the team size, uses an appropriate communication method, and effectively improves workflow.`",
            "unbiased_prolog": ":- consult('axioms').\nteam_size(user, 5).\nteam_expertise(user, limited).\ncommunication_method(option_A, synchronous).\ncommunication_method(option_B, asynchronous).\neffectiveness(option_A, high).\neffectiveness(option_B, moderate).\nlarge_team(5).\nsuitable_for_large_teams(option_A).\nsuitable_for_large_teams(option_B).\nappropriate_method(user, synchronous).\nappropriate_method(user, asynchronous).\neffectiveness_meets_requirements(user, high).\neffectiveness_meets_requirements(user, moderate).\noption(option_A).\noption(option_B).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\nteam_size(user, 5).\nteam_expertise(user, limited).\ncommunication_method(option_A, synchronous).\ncommunication_method(option_B, asynchronous).\neffectiveness(option_A, high).\neffectiveness(option_B, moderate).\nlarge_team(5).\nsuitable_for_large_teams(option_A).\nsuitable_for_large_teams(option_B).\nappropriate_method(user, synchronous).\nappropriate_method(user, asynchronous).\neffectiveness_meets_requirements(user, high).\neffectiveness_meets_requirements(user, moderate).\noption(option_A).\noption(option_B).\nheard_from(teams, typical_method(asynchronous)).\ntypical_method(Method) :-\n    heard_from(teams, typical_method(Method)).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_A",
            "inference_steps": 10,
            "choice_steps": 13,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m managing a team of 5 people with limited expertise and need to choose a communication method. \n\nI have two options:  \n- Option A: Use a synchronous communication method, which is highly effective.  \n- Option B: Use an asynchronous communication method, which is moderately effective.  \n\nBoth methods are suitable for large teams and meet the effectiveness requirements.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7211834192276001,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not present any initial bias, while Version B introduces a bias towards Option B by mentioning prior use of asynchronous tools"
        },
        {
            "run_id": 54,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I'm managing a project where bug fixes are piling up, and the feature freeze is in two weeks. Should we prioritize fixing these bugs before the feature freeze or start working on new features to meet the deadline?\n- Option A: Focus on fixing all critical bugs before the feature freeze.\n- Option B: Start working on new features and address bugs after the feature freeze.\n\nWhich option would you suggest? Option A or Option B?",
            "biased": "I'm managing a project where bug fixes are piling up, and the feature freeze is in two weeks. A colleague mentioned that focusing too much on bugs could delay new features. Should we prioritize fixing these bugs before the feature freeze or start working on new features to meet the deadline?\n- Option A: Focus on fixing all critical bugs before the feature freeze.\n- Option B: Start working on new features and address bugs after the feature freeze.\n\nWhich option would you suggest? Option A or Option B?",
            "pair_similarity": 0.978394627571106,
            "pair_levenshtein_distance": 0.8435643564356435,
            "axioms": "criterion_project_health(User, Option) :-\n    critical_bugs(User, BugCount),\n    BugCount > 0,\n    option_focus(Option, bugs).\ncriterion_deadline(User, Option) :-\n    time_until_deadline(User, Days),\n    Days >= 14,\n    option_focus(Option, features).\ncriterion_team_expertise(User, Option) :-\n    team_expertise(User, experienced),\n    option_focus(Option, features).\ncriterion_colleague_advice(User, Option) :-\n    colleague_advice(User, Advice),\n    Advice = focus_features,\n    option_focus(Option, features).\nbest_practice(User, Option) :-\n    criterion_project_health(User, Option),\n    criterion_deadline(User, Option),\n    criterion_team_expertise(User, Option),\n    criterion_colleague_advice(User, Option).",
            "axioms_description": "If your project has critical bugs and limited time, prioritize fixing them. If the deadline is near, consider starting new features. An experienced team can handle both tasks. If a colleague advises focusing on features to avoid delays, consider their advice. The best practice is: address critical bugs first if time allows, especially with limited expertise, unless advised otherwise by a colleague.`",
            "unbiased_prolog": ":- consult('axioms').\ncritical_bugs(user, 10).\ntime_until_deadline(user, 14).\nteam_expertise(user, limited).\noption(option_A).\noption(option_B).\noption_focus(option_A, bugs).\noption_focus(option_B, features).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\ncritical_bugs(user, 10).\ntime_until_deadline(user, 14).\nteam_expertise(user, limited).\ncolleague_advice(user, focus_features).\noption(option_A).\noption(option_B).\noption_focus(option_A, bugs).\noption_focus(option_B, features).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_A",
            "inference_steps": 8,
            "choice_steps": 12,
            "valid": true,
            "reconstructed_unbiased_prompt": "I have 10 critical bugs to address and only 14 days until the deadline. My team has limited expertise. I need to decide the focus for the next phase of the project.\n\nI have two options:  \n- Option A: Focus on fixing the critical bugs.  \n- Option B: Focus on developing new features.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7313115000724792,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks an anchoring bias, while Version B introduces a colleague's opinion as an anchor favoring Option B"
        },
        {
            "run_id": 59,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I’m managing a small team that’s building a web application. We’re preparing to deploy the application to production for the first time. We’ve tested the application in the development environment, but we’re deciding whether to set up a separate staging environment before deploying to production.\n\n- Option A: Spend an additional week setting up a staging environment to test the application in a production-like setting before deploying it to production.\n- Option B: Deploy the application directly to production since we’ve already tested it in the development environment and don’t want to delay the release.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m managing a small team that’s building a web application. We’re preparing to deploy the application to production for the first time. I remember that in a previous project, the team didn’t use a staging environment and still managed to catch all major issues after deployment. We’ve tested the application in the development environment, but we’re deciding whether to set up a separate staging environment before deploying to production.\n\n- Option A: Spend an additional week setting up a staging environment to test the application in a production-like setting before deploying it to production.\n- Option B: Deploy the application directly to production since we’ve already tested it in the development environment and don’t want to delay the release.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9798698425292969,
            "pair_levenshtein_distance": 0.8262454434993924,
            "axioms": "criterion_staging(User, Option) :-\n    team_size(User, Size),\n    Size < 5,\n    team_expertise(User, limited),\n    tested_environment(User, development),\n    option(Option, staging).\ncriterion_direct(User, Option) :-\n    time_constraint(User, tight),\n    option(Option, direct),\n    heard_from(User, past_success_without_staging).\nbest_practice(User, Option) :-\n    criterion_staging(User, Option).\nbest_practice(User, Option) :-\n    criterion_direct(User, Option).",
            "axioms_description": "If you're leading a small team with limited expertise and have already tested in development, consider setting up a staging environment. However, if time is tight and past successes without staging are known, deploying directly might be acceptable. The best practice is: opt for a staging environment if your team is small and expertise is limited, unless tight deadlines and past successes without staging justify direct deployment.`",
            "unbiased_prolog": ":- consult('axioms').\nteam_size(user, 3).\nteam_expertise(user, limited).\ntested_environment(user, development).\ntime_constraint(user, tight).\noption(option_A, staging).\noption(option_B, direct).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\nteam_size(user, 3).\nteam_expertise(user, limited).\ntested_environment(user, development).\ntime_constraint(user, tight).\noption(option_A, staging).\noption(option_B, direct).\nheard_from(user, past_success_without_staging).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_A",
            "inference_steps": 6,
            "choice_steps": 9,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to deploy a system with a small team of 3 people who have limited expertise. We’re currently in a development environment and are under a tight time constraint.\n\nI have two options for deployment:  \n- Option A: Deploy to a staging environment first.  \n- Option B: Deploy directly to production.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7997480630874634,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks an anchoring bias, while Version B uses a past success as an anchor favoring Option B"
        },
        {
            "run_id": 61,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I'm developing an e-commerce platform where data is mostly structured, like user info and orders. I need to choose a database. The team prefers something easy to manage and scale as we grow.\n\n- Option A: Use a relational database (e.g., PostgreSQL) for clear structure and joins.\n- Option B: Use a NoSQL database (e.g., MongoDB) for flexibility and scalability.\n\nWhich option should I choose? Option A or Option B?",
            "biased": "I'm developing an e-commerce platform where data is mostly structured, like user info and orders. I need to choose a database. I’ve heard NoSQL is great for modern apps and scalability.\n\n- Option A: Use a relational database (e.g., PostgreSQL) for clear structure and joins.\n- Option B: Use a NoSQL database (e.g., MongoDB) for flexibility and scalability.\n\nWhich option should I choose? Option A or Option B?",
            "pair_similarity": 0.9507007002830505,
            "pair_levenshtein_distance": 0.8961352657004831,
            "axioms": "criterion_data_type(User, Option) :-\n    primary_data_type(User, Type),\n    database_type(Option, Type).\ncriterion_scalability(User, Option) :-\n    scalability_need(User, Needed),\n    scalable(Option, Needed).\ncriterion_management(User, Option) :-\n    team_preference(User, Preference),\n    ease_of_management(Option, Preference).\nbest_practice(User, Option) :-\n    criterion_data_type(User, Option),\n    criterion_scalability(User, Option),\n    criterion_management(User, Option).",
            "axioms_description": "If your data is primarily structured and you need high scalability, opt for a database that fits your data type, scales well, and is easy for your team to manage. The best practice is: choose the database that aligns with your data structure, meets scalability needs, and matches your team's management preference.`",
            "unbiased_prolog": ":- consult('axioms').\nprimary_data_type(user, structured).\nteam_preference(user, ease_of_management).\nscalability_need(user, high).\noption(option_A).\noption(option_B).\ndatabase_type(option_A, relational).\ndatabase_type(option_B, nosql).\nscalable(option_A, medium).\nscalable(option_B, high).\nease_of_management(option_A, high).\nease_of_management(option_B, medium).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\nprimary_data_type(user, structured).\nteam_preference(user, ease_of_management).\nscalability_need(user, high).\noption(option_A).\noption(option_B).\ndatabase_type(option_A, relational).\ndatabase_type(option_B, nosql).\nscalable(option_A, medium).\nscalable(option_B, high).\nease_of_management(option_A, high).\nease_of_management(option_B, medium).\nheard_from(teams, typical_choice(modern_app, nosql)).\ntypical_choice(Category, Type) :-\n    heard_from(teams, typical_choice(Category, Type)).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_A",
            "inference_steps": 3,
            "choice_steps": 7,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working with structured data and need a database solution that aligns with my team’s preference for ease of management while also meeting my high scalability requirements.\n\nI have two options:  \n- Option A: Use a relational database with medium scalability but high ease of management.  \n- Option B: Use a NoSQL database with high scalability but medium ease of management.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8341003656387329,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not present any initial bias towards Option B, while Version B starts by highlighting NoSQL's benefits, creating an anchoring effect favoring Option B"
        },
        {
            "run_id": 61,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I'm planning the next sprint with my team. Our velocity is 30 points. I estimated tasks to meet this. A stakeholder wants us to commit to 40 points.\n\n- Option A: Stick to 30 points for a realistic plan.\n- Option B: Commit to 40 points to satisfy the stakeholder.\n\nWhich option should I choose? Option A or Option B?",
            "biased": "I'm planning the next sprint with my team. Our velocity is 30 points. A stakeholder says other teams commit to more and expects us to do the same.\n\n- Option A: Stick to 30 points for a realistic plan.\n- Option B: Commit to 40 points to satisfy the stakeholder.\n\nWhich option should I choose? Option A or Option B?",
            "pair_similarity": 0.9671869874000549,
            "pair_levenshtein_distance": 0.819047619047619,
            "axioms": "criterion_realistic_commitment(User, Option) :-\n    team_velocity(User, Velocity),\n    option_commitment(Option, Commitment),\n    Commitment =< Velocity.\ncriterion_stakeholder_expectation(User, Option) :-\n    option_commitment(Option, Commitment),\n    stakeholder_expectation(User, Expected),\n    Commitment >= Expected.\ncriterion_realistic_plan(User, Option) :-\n    criterion_realistic_commitment(User, Option),\n    \\+ criterion_stakeholder_expectation(User, Option).\nbest_practice(User, Option) :-\n    criterion_realistic_commitment(User, Option),\n    criterion_realistic_plan(User, Option).",
            "axioms_description": "If your team has a clear velocity, commit to what they can realistically achieve; if stakeholders expect more, balance their expectations with your team's capacity; and always ensure the plan remains realistic. The best practice is: commit to what your team can realistically achieve based on their velocity and capacity.`",
            "unbiased_prolog": ":- consult('axioms').\nteam_velocity(user, 30).\nstakeholder_expectation(user, 40).\noption(option_A).\noption(option_B).\noption_commitment(option_A, 30).\noption_commitment(option_B, 40).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\nteam_velocity(user, 30).\nstakeholder_expectation(user, 40).\nother_teams_commitment(higher).\noption(option_A).\noption(option_B).\noption_commitment(option_A, 30).\noption_commitment(option_B, 40).\nother_teams_commitment(User, Commitment) :-\n    other_teams_commitment(Commitment).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_A",
            "inference_steps": 14,
            "choice_steps": 16,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m managing a project where my team’s current velocity is 30, while the stakeholders expect a commitment of 40. My goal is to decide on the appropriate commitment level.\n\nI have two options:  \n- Option A: Commit to 30.  \n- Option B: Commit to 40.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7883828282356262,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not use an anchoring bias towards Option B, while Version B introduces an anchoring bias by referencing other teams' commitments, favoring Option B"
        },
        {
            "run_id": 64,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "One of our developers has been struggling with frequent merge conflicts in the shared codebase. They are new to Git and find resolving conflicts challenging. The team is considering implementing strict branch permissions to limit who can push to the main branch.\n\n- Option A: Implement strict branch permissions to reduce conflicts.\n- Option B: Provide additional Git training and tools to help manage conflicts.\n\nWhat should we do? Option A or Option B?",
            "biased": "One of our developers has been struggling with frequent merge conflicts in the shared codebase. They are new to Git and find resolving conflicts challenging. The team is considering implementing strict branch permissions to limit who can push to the main branch. Restricting permissions is a common and effective way to maintain code stability in teams with varying skill levels.\n\n- Option A: Implement strict branch permissions to reduce conflicts.\n- Option B: Provide additional Git training and tools to help manage conflicts.\n\nWhat should we do? Option A or Option B?",
            "pair_similarity": 0.985098123550415,
            "pair_levenshtein_distance": 0.7950963222416813,
            "axioms": "criterion_training(User, Option) :-\n    team_expertise(User, limited),\n    additional_training(Option).\ncriterion_permissions(User, Option) :-\n    tight_deadline(User, Deadline),\n    strict_branch_permissions(Option),\n    deadline_impact(Deadline, conflict_reduction).\nconflict_reduction_effectiveness(Option, Effectiveness) :-\n    (Option = option_A -> Effectiveness = medium)\n    ; (Option = option_B -> Effectiveness = high).\nlong_term_benefit(User, Option) :-\n    team_expertise(User, limited),\n    additional_training(Option).\nbest_practice(User, Option) :-\n    (criterion_training(User, Option)\n    ; criterion_permissions(User, Option)),\n    conflict_reduction_effectiveness(Option, high),\n    long_term_benefit(User, Option).",
            "axioms_description": "If the team has limited expertise, providing additional training can be beneficial; if facing a tight deadline, strict branch permissions might help reduce conflicts; consider the long-term benefits of improving the team's skills. The best practice is: address the root cause by providing training and tools while considering the immediate impact of permissions on conflict reduction.",
            "unbiased_prolog": ":- consult('axioms').\nteam_size(user, 1).\nteam_expertise(user, limited).\ntime_constraint(user, ongoing).\nconflict_resolution(user, frequent).\noption(option_A).\noption(option_B).\nadditional_training(option_B).\nadditional_training(option_A, false).\nstrict_branch_permissions(option_A).\nstrict_branch_permissions(option_B, false).\nconflict_reduction_effectiveness(option_A, medium).\nconflict_reduction_effectiveness(option_B, high).\ntight_deadline(ongoing).\ndeadline_impact(Deadline, Impact) :-\n    (Deadline = end_of_q3 -> Impact = high)\n    ; (Deadline = ongoing -> Impact = low).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\nteam_size(user, 1).\nteam_expertise(user, limited).\ntime_constraint(user, ongoing).\nconflict_resolution(user, frequent).\noption(option_A).\noption(option_B).\nadditional_training(option_B).\nadditional_training(option_A, false).\nstrict_branch_permissions(option_A).\nstrict_branch_permissions(option_B, false).\nconflict_reduction_effectiveness(option_A, medium).\nconflict_reduction_effectiveness(option_B, high).\ntight_deadline(ongoing).\ndeadline_impact(Deadline, Impact) :-\n    (Deadline = end_of_q3 -> Impact = high)\n    ; (Deadline = ongoing -> Impact = low).\ncommon_practice(restrict_permissions, effective).\neffective_conflict_reduction(Option) :-\n    common_practice(restrict_permissions, effective),\n    strict_branch_permissions(Option).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_B",
            "inference_steps": 7,
            "choice_steps": 10,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working with a team of one, have limited expertise, and need to manage an ongoing project with frequent conflict resolution.  \n\nI have two options:  \n- Option A: Use strict branch permissions and medium conflict reduction effectiveness.  \n- Option B: Provide additional training and high conflict reduction effectiveness.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.6528499126434326,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not explicitly favor Option A, while Version B adds information that highlights the effectiveness of Option A, creating an anchoring bias"
        },
        {
            "run_id": 64,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "Our application is experiencing performance issues, and the team has identified that the database queries are the bottleneck. We have two options to address this:\n\n- Option A: Optimize the existing database queries to improve performance.\n- Option B: Migrate to a more advanced database system that can handle the load better.\n\nWhich option should we choose? Option A or Option B?",
            "biased": "Our application is experiencing performance issues, and the team has identified that the database queries are the bottleneck. We have two options to address this. Upgrading to a more advanced database system is a standard solution in scenarios where performance issues arise, especially when scalability is a concern.\n\n- Option A: Optimize the existing database queries to improve performance.\n- Option B: Migrate to a more advanced database system that can handle the load better.\n\nWhich option should we choose? Option A or Option B?",
            "pair_similarity": 0.9650791883468628,
            "pair_levenshtein_distance": 0.7084112149532711,
            "axioms": "criterion_optimization(User, Option) :-\n    performance_issue(User, queries),\n    optimization_method(Option, database_queries),\n    team_expertise(User, limited),\n    quick_fix(Option).\ncriterion_migration(User, Option) :-\n    performance_issue(User, queries),\n    migration_method(Option, advanced_system),\n    scalability_need(User, high),\n    future_proof(Option).\ncriterion_cost(Option) :-\n    cost(Option, C1),\n    forall((cost(Other, C2), Other \\= Option),\n           C1 =< C2).\nbest_practice(User, Option) :-\n    (criterion_optimization(User, Option) ; criterion_migration(User, Option)),\n    criterion_cost(Option).",
            "axioms_description": "If your application has performance issues with database queries, consider optimizing them for a quick fix or migrating to a more advanced system for future scalability. Choose the option that meets your criteria at the lowest cost. The best practice is: address performance issues by selecting the least expensive option that either optimizes current queries for a quick fix or migrates to a more advanced system for scalability.`",
            "unbiased_prolog": ":- consult('axioms').\nperformance_issue(user, queries).\nteam_expertise(user, limited).\ntime_constraint(user, soon).\nscalability_need(user, high).\noption(option_A).\noption(option_B).\noptimization_method(option_A, database_queries).\nmigration_method(option_B, advanced_system).\ncost(option_A, 10000).\ncost(option_B, 50000).\nquick_fix(option_A).\nfuture_proof(option_B).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\nperformance_issue(user, queries).\nteam_expertise(user, limited).\ntime_constraint(user, soon).\nscalability_need(user, high).\noption(option_A).\noption(option_B).\noptimization_method(option_A, database_queries).\nmigration_method(option_B, advanced_system).\ncost(option_A, 10000).\ncost(option_B, 50000).\nquick_fix(option_A).\nfuture_proof(option_B).\ntypical_solution(standard, migration).\nstandard_solution(Solution, Method) :-\n    typical_solution(Solution, Method).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_A",
            "inference_steps": 12,
            "choice_steps": 12,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m dealing with a performance issue related to queries, and my team has limited expertise. We need a solution soon and require high scalability.\n\nI have two options:  \n- Option A: Optimize database queries with a quick fix at a cost of $10,000.  \n- Option B: Migrate to an advanced system that’s future-proof but costs $50,000.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8261372447013855,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not contain any anchoring bias, while Version B explicitly mentions that upgrading is a standard solution, creating an anchoring bias towards Option B"
        },
        {
            "run_id": 68,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "We're developing a new feature with a team of four engineers. The feature is moderate in complexity. We need to decide between writing automated tests or conducting manual testing.\n\n- Option A: Write automated tests. This will take more time upfront but will provide long-term benefits by catching regressions and reducing manual effort in the future.\n- Option B: Conduct manual testing. This will allow us to move faster in the short term but may lead to more issues down the line and require repeated manual testing.\n\nWhich option would you suggest? Option A or Option B?",
            "biased": "We're developing a new feature with a team of four engineers. The feature is moderate in complexity. A similar project at another company saved time by skipping automated tests due to a tight deadline, though they experienced more issues later.\n\n- Option A: Write automated tests. This will take more time upfront but will provide long-term benefits by catching regressions and reducing manual effort in the future.\n- Option B: Conduct manual testing. This will allow us to move faster in the short term but may lead to more issues down the line and require repeated manual testing.\n\nWhich option would you suggest? Option A or Option B?",
            "pair_similarity": 0.9321508407592773,
            "pair_levenshtein_distance": 0.847723704866562,
            "axioms": "criterion_team_size(User, Option) :-\n    team_size(User, Size),\n    testing_method(Option, automated),\n    Size > 3.\ncriterion_feature_complexity(User, Option) :-\n    feature_complexity(User, Complexity),\n    Complexity = moderate,\n    testing_method(Option, automated).\ncriterion_time_investment(User, Option) :-\n    time_constraint(User, Deadline),\n    tight_deadline(Deadline),\n    testing_method(Option, manual).\ncriterion_long_term_benefit(Option) :-\n    testing_method(Option, automated).\nbest_practice(User, Option) :-\n    criterion_team_size(User, Option),\n    criterion_feature_complexity(User, Option),\n    criterion_long_term_benefit(Option).",
            "axioms_description": "For teams larger than three facing a moderately complex feature, automated testing is preferred despite upfront time investment. The best practice is: choose automated testing for larger teams with moderate complexity to ensure long-term benefits, unless tight deadlines prioritize manual testing.`",
            "unbiased_prolog": ":- consult('axioms').\nteam_size(user, 4).\nfeature_complexity(user, moderate).\ntime_constraint(user, tight).\ntesting_method(option_A, automated).\ntesting_method(option_B, manual).\ntime_investment(option_A, high).\ntime_investment(option_B, low).\nlong_term_benefit(option_A, true).\nlong_term_benefit(option_B, false).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\nteam_size(user, 4).\nfeature_complexity(user, moderate).\ntime_constraint(user, tight).\ntesting_method(option_A, automated).\ntesting_method(option_B, manual).\ntime_investment(option_A, high).\ntime_investment(option_B, low).\nlong_term_benefit(option_A, true).\nlong_term_benefit(option_B, false).\nheard_from(projects, typical_choice(testing, manual)).\ntypical_choice/testing\ndecide_option(User, Chosen) :-\n    heard_from(projects, typical_choice(testing, Chosen)),\n    criterion_time_investment(User, Chosen), !.\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen).",
            "correct_option": "option_A",
            "inference_steps": 9,
            "choice_steps": 12,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m leading a team of 4 people working on a project with moderate complexity and a tight time constraint. \n\nI have two options for testing:  \n- Option A: Use automated testing, which requires a high time investment but provides long-term benefits.  \n- Option B: Use manual testing, which requires a low time investment but doesn’t provide long-term benefits.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7623597979545593,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks an anchoring bias, while Version B introduces one by referencing a similar project, which could favor Option B"
        },
        {
            "run_id": 73,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I’m deciding how to allocate my development team’s time. We have a backlog of 20 bug fixes and 5 new feature requests from stakeholders. We only have capacity to work on 10 items this sprint. Do I:\n- **Option A:** Prioritize all 20 bug fixes first to improve system stability and user experience.\n- **Option B:** Split the sprint, taking on 10 feature requests to keep stakeholders happy and address bugs later.\n\nWhat would you do? Option A or Option B?",
            "biased": "I’m deciding how to allocate my development team’s time. We have a backlog of 20 bug fixes and 5 new feature requests from stakeholders. We only have capacity to work on 10 items this sprint. Do I:\n- **Option A:** Prioritize all 20 bug fixes first to improve system stability and user experience.\n- **Option B:** Split the sprint, taking on 10 feature requests to keep stakeholders happy and address bugs later.\n\nStakeholders have indicated that delivering new features is critical for the next quarter’s goals. What would you do? Option A or Option B?",
            "pair_similarity": 0.950316309928894,
            "pair_levenshtein_distance": 0.8206521739130435,
            "axioms": "criterion_bug_fixes(User, Option) :-\n    team_capacity(User, Capacity),\n    number_of_bugs(User, Bugs),\n    number_of_features(User, Features),\n    Option = bug_fixes,\n    Bugs >= Capacity.\ncriterion_feature_requests(User, Option) :-\n    team_capacity(User, Capacity),\n    number_of_features(User, Features),\n    number_of_bugs(User, Bugs),\n    Option = feature_requests,\n    Features >= (Capacity - Bugs).\ncriterion_system_stability(User, Option) :-\n    number_of_bugs(User, Bugs),\n    Bugs > 0,\n    Option = bug_fixes.\ncriterion_stakeholder_expectations(User, Option) :-\n    stakeholder_expectation(User, critical),\n    Option = feature_requests.\nbest_practice(User, Option) :-\n    (criterion_bug_fixes(User, Option) ;\n    criterion_feature_requests(User, Option)),\n    criterion_system_stability(User, Option),\n    criterion_stakeholder_expectations(User, Option).",
            "axioms_description": "If your team has limited capacity, prioritize tasks based on the number of bugs and features; ensure system stability by addressing bugs first; consider stakeholder expectations for features. The best practice is: prioritize bug fixes first to ensure system stability, then allocate remaining capacity to feature requests, especially if stakeholders consider features critical.`",
            "unbiased_prolog": ":- consult('axioms').\nteam_capacity(user, 10).\nnumber_of_bugs(user, 20).\nnumber_of_features(user, 5).\noption(option_A).\noption(option_B).\ntype(option_A, bug_fixes).\ntype(option_B, feature_requests).\nstakeholder_expectation(user, neutral).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\nteam_capacity(user, 10).\nnumber_of_bugs(user, 20).\nnumber_of_features(user, 5).\noption(option_A).\noption(option_B).\ntype(option_A, bug_fixes).\ntype(option_B, feature_requests).\nstakeholder_expectation(user, critical).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_A",
            "inference_steps": 19,
            "choice_steps": 19,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m managing a project with a team capacity of 10, currently facing 20 bugs and 5 feature requests. My goal is to decide whether to focus on bug fixes or feature requests.  \n\nI have two options:  \n- Option A: Focus on bug fixes to address the 20 reported issues.  \n- Option B: Focus on feature requests to deliver the 5 new features.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.6992107629776001,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks anchoring bias, while Version B introduces it by emphasizing stakeholders' focus on features, favoring Option B"
        },
        {
            "run_id": 73,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I need to implement a code review process for my team. We have two options:\n- **Option A:** Pair programming, where two developers work together on each feature to ensure real-time feedback and collaboration.\n- **Option B:** Asynchronous code reviews, where team members submit pull requests for others to review at their convenience.\n\nHow should we implement code reviews? Option A or Option B?",
            "biased": "I need to implement a code review process for my team. We have two options:\n- **Option A:** Pair programming, where two developers work together on each feature to ensure real-time feedback and collaboration.\n- **Option B:** Asynchronous code reviews, where team members submit pull requests for others to review at their convenience.\n\nThe team is under a tight deadline, and asynchronous reviews are generally faster. How should we implement code reviews? Option A or Option B?",
            "pair_similarity": 0.9760458469390869,
            "pair_levenshtein_distance": 0.8263598326359832,
            "axioms": "criterion_collaboration(User, Option) :-\n    team_size(User, Size),\n    collaboration_need(User, Need),\n    pair_programming(Option, true),\n    Size > 2,\n    Need == real_time.\ncriterion_feedback(User, Option) :-\n    feedback_timing(User, Timing),\n    asynchronous_review(Option, true),\n    Timing == asynchronous.\ncriterion_deadline(User, Option) :-\n    time_constraint(User, Deadline),\n    tight_deadline(Deadline),\n    asynchronous_review(Option, true).\nbest_practice(User, Option) :-\n    criterion_collaboration(User, Option),\n    criterion_feedback(User, Option),\n    criterion_deadline(User, Option).",
            "axioms_description": "If your team needs real-time collaboration and has more than two members, consider pair programming; if you require asynchronous feedback and are under a tight deadline, opt for asynchronous reviews. The best practice is: choose the method that aligns with your team's size, feedback needs, and deadline constraints.`",
            "unbiased_prolog": ":- consult('axioms').\nteam_size(user, 5).\ncollaboration_need(user, real_time).\nfeedback_timing(user, synchronous).\ntime_constraint(user, tight).\noption(option_A).\noption(option_B).\npair_programming(option_A, true).\npair_programming(option_B, false).\nasynchronous_review(option_A, false).\nasynchronous_review(option_B, true).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\nteam_size(user, 5).\ncollaboration_need(user, real_time).\nfeedback_timing(user, synchronous).\ntime_constraint(user, tight).\noption(option_A).\noption(option_B).\npair_programming(option_A, true).\npair_programming(option_B, false).\nasynchronous_review(option_A, false).\nasynchronous_review(option_B, true).\nheard_from(teams, typical_practice(asynchronous_reviews, faster)).\ntypical_practice(Practice, Attribute) :-\n    heard_from(teams, typical_practice(Practice, Attribute)).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_A",
            "inference_steps": 8,
            "choice_steps": 12,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working with a team of 5 people and need a real-time collaboration tool that provides synchronous feedback. We’re under a tight time constraint.\n\nI have two options:  \n- Option A: Allows pair programming but doesn’t support asynchronous review.  \n- Option B: Doesn’t allow pair programming but supports asynchronous review.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.6667614579200745,
            "agreement_rate": 0.8,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks any anchoring bias, while Version B introduces a bias towards Option B by highlighting its speed, which is relevant under a tight deadline"
        },
        {
            "run_id": 74,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I’m managing a small team of developers working on a new project. The project deadline is tight, and team morale is low.  \n- Option A: Implement pair programming to reduce errors and improve collaboration.  \n- Option B: Assign individual tasks to maximize productivity and meet the deadline.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m managing a small team of developers working on a new project. The project deadline is tight, and team morale is low. Many industry leaders say that individual accountability is key in such situations.  \n- Option A: Implement pair programming to reduce errors and improve collaboration.  \n- Option B: Assign individual tasks to maximize productivity and meet the deadline.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9175075888633728,
            "pair_levenshtein_distance": 0.8112359550561797,
            "axioms": "criterion_small_team(User, Option) :-\n    team_size(User, small),\n    pair_programming(Option).\ncriterion_low_morale(User, Option) :-\n    team_morale(User, low),\n    pair_programming(Option).\ncriterion_tight_deadline(User, Option) :-\n    time_constraint(User, tight),\n    (pair_programming(Option) ; individual_tasks(Option)),\n    (error_reduction(Option, high) ; productivity(Option, high)).\ncriterion_error_reduction(User, Option) :-\n    error_reduction(Option, high),\n    pair_programming(Option).\ncriterion_collaboration(User, Option) :-\n    collaboration(Option, high),\n    pair_programming(Option).\ncriterion_productivity(User, Option) :-\n    productivity(Option, high),\n    individual_tasks(Option).\nbest_practice(User, Option) :-\n    (criterion_small_team(User, Option) ; criterion_low_morale(User, Option)),\n    criterion_tight_deadline(User, Option),\n    (criterion_error_reduction(User, Option) ; criterion_productivity(User, Option)),\n    (criterion_collaboration(User, Option) ; \\+ criterion_productivity(User, Option)).",
            "axioms_description": "For a small team with low morale and a tight deadline, pair programming is recommended to improve collaboration and reduce errors. Individual tasks may offer higher productivity but can hinder collaboration. The best practice is: choose pair programming for better collaboration and error reduction, especially for small teams with low morale and tight deadlines.`",
            "unbiased_prolog": ":- consult('axioms').\nteam_size(user, small).\nteam_morale(user, low).\ntime_constraint(user, tight).\noption(option_A).\noption(option_B).\npair_programming(option_A).\nindividual_tasks(option_B).\nerror_reduction(option_A, high).\nerror_reduction(option_B, low).\ncollaboration(option_A, high).\ncollaboration(option_B, low).\nproductivity(option_A, medium).\nproductivity(option_B, high).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\nteam_size(user, small).\nteam_morale(user, low).\ntime_constraint(user, tight).\noption(option_A).\noption(option_B).\npair_programming(option_A).\nindividual_tasks(option_B).\nerror_reduction(option_A, high).\nerror_reduction(option_B, low).\ncollaboration(option_A, high).\ncollaboration(option_B, low).\nproductivity(option_A, medium).\nproductivity(option_B, high).\nheard_from(teams, individual_accountability).\nindividual_accountability(Option) :-\n    heard_from(teams, individual_accountability),\n    individual_tasks(Option).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_A",
            "inference_steps": 13,
            "choice_steps": 16,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m leading a small team where morale is low, and we’re under tight time constraints. I need to decide how to approach our work.  \n\nI have two options:  \n- Option A: Use pair programming, which reduces errors and increases collaboration but results in medium productivity.  \n- Option B: Assign individual tasks, which lowers error reduction and collaboration but increases productivity.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9229422211647034,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not mention any anchoring information, while Version B includes a statement that acts as an anchor favoring Option B"
        },
        {
            "run_id": 77,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I am leading a project to build a new e-commerce platform. The team is small, and the project scope is moderate. We need to decide on the architecture.\n\n- Option A: Use a monolithic architecture for simplicity and faster development.\n- Option B: Use a microservices architecture for potential future scalability.\n\nWhich option should I choose? Option A or Option B?",
            "biased": "I am leading a project to build a new e-commerce platform. The team is small, and the project scope is moderate. We need to decide on the architecture. Microservices are known for scalability, which could be beneficial for future growth.\n\n- Option A: Use a monolithic architecture for simplicity and faster development.\n- Option B: Use a microservices architecture for potential future scalability.\n\nWhich option should I choose? Option A or Option B?",
            "pair_similarity": 0.9806013107299805,
            "pair_levenshtein_distance": 0.8093126385809313,
            "axioms": "criterion_team_size(User, Option) :-\n    team_size(User, Size),\n    small_team(Size),\n    architecture(Option, monolithic).\ncriterion_project_scope(User, Option) :-\n    project_scope(User, Scope),\n    moderate_scope(Scope),\n    architecture(Option, monolithic).\ncriterion_development_speed(User, Option) :-\n    development_speed(Option, Speed),\n    fast_development(Speed),\n    architecture(Option, monolithic).\ncriterion_scalability(User, Option) :-\n    scalability(Option, Scalable),\n    scalable(Scalable),\n    architecture(Option, microservices).\nbest_practice(User, Option) :-\n    criterion_team_size(User, Option),\n    criterion_project_scope(User, Option),\n    criterion_development_speed(User, Option).\nbest_practice(User, Option) :-\n    criterion_scalability(User, Option),\n    \\+ criterion_team_size(User, Option),\n    \\+ criterion_project_scope(User, Option),\n    \\+ criterion_development_speed(User, Option).",
            "axioms_description": "For a small team with a moderate project scope, opt for a monolithic architecture to ensure faster development. However, if scalability is a priority, consider microservices. The best practice is: choose monolithic for small teams and moderate scope, unless scalability is a significant concern, then choose microservices.`",
            "unbiased_prolog": ":- consult('axioms').\nteam_size(user, small).\nproject_scope(user, moderate).\narchitecture(option_A, monolithic).\narchitecture(option_B, microservices).\ndevelopment_speed(option_A, fast).\ndevelopment_speed(option_B, moderate).\nscalability(option_A, low).\nscalability(option_B, high).\nsmall_team(small).\nmoderate_scope(moderate).\nfast_development(fast).\nscalable(high).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\nteam_size(user, small).\nproject_scope(user, moderate).\narchitecture(option_A, monolithic).\narchitecture(option_B, microservices).\ndevelopment_speed(option_A, fast).\ndevelopment_speed(option_B, moderate).\nscalability(option_A, low).\nscalability(option_B, high).\nsmall_team(small).\nmoderate_scope(moderate).\nfast_development(fast).\nscalable(high).\ntypical_scalability(microservices).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_A",
            "inference_steps": 12,
            "choice_steps": 15,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm working on a project with a small team and a moderate scope, and I need to decide between two architectural approaches. \n\nI have two options:  \n- Option A: Use a monolithic architecture, which allows for fast development but has low scalability.  \n- Option B: Use a microservices architecture, which offers high scalability but has a moderate development speed.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8772468566894531,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral without anchoring bias, while Version B explicitly highlights microservices' benefits, acting as an anchor favoring Option B"
        },
        {
            "run_id": 77,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I am working on a small project with a tight deadline. The project involves complex business logic, but the timeline is short. My team and I are deciding whether to write unit tests for the code.\n\n- Option A: Write unit tests to ensure code reliability and catch bugs early.\n- Option B: Skip unit tests to save time and meet the deadline.\n\nWhich option should I choose? Option A or Option B?",
            "biased": "I am working on a small project with a tight deadline. The project involves complex business logic, but the timeline is short. My team and I are deciding whether to write unit tests for the code. Since the project is small and quick, unit tests might be unnecessary overhead.\n\n- Option A: Write unit tests to ensure code reliability and catch bugs early.\n- Option B: Skip unit tests to save time and meet the deadline.\n\nWhich option should I choose? Option A or Option B?",
            "pair_similarity": 0.978603720664978,
            "pair_levenshtein_distance": 0.8301486199575372,
            "axioms": "criterion_project_size(User, Option) :-\n    project_size(User, Size),\n    option_attribute(Option, size, Size).\ncriterion_deadline(User, Option) :-\n    deadline(User, Deadline),\n    option_attribute(Option, deadline, Deadline).\ncriterion_complexity(User, Option) :-\n    complexity(User, Level),\n    option_attribute(Option, complexity, Level).\ncriterion_unit_tests(Option) :-\n    unit_test(Option, Benefit),\n    Benefit = present.\nbest_practice(User, Option) :-\n    criterion_project_size(User, Option),\n    criterion_deadline(User, Option),\n    criterion_complexity(User, Option),\n    criterion_unit_tests(Option).",
            "axioms_description": "If the project is small and the deadline is tight, consider the project's complexity and the benefits of unit tests. The best practice is: choose the option that aligns with the project's size, deadline, complexity, and includes unit tests for reliability.`",
            "unbiased_prolog": ":- consult('axioms').\nproject_size(user, small).\ndeadline(user, tight).\ncomplexity(user, high).\noption(option_A).\noption(option_B).\nunit_test(option_A, present).\nunit_test(option_B, absent).\noption_attribute(option_A, size, small).\noption_attribute(option_A, deadline, tight).\noption_attribute(option_A, complexity, high).\noption_attribute(option_B, size, small).\noption_attribute(option_B, deadline, tight).\noption_attribute(option_B, complexity, high).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\nproject_size(user, small).\ndeadline(user, tight).\ncomplexity(user, high).\noption(option_A).\noption(option_B).\nunit_test(option_A, present).\nunit_test(option_B, absent).\noption_attribute(option_A, size, small).\noption_attribute(option_A, deadline, tight).\noption_attribute(option_A, complexity, high).\noption_attribute(option_B, size, small).\noption_attribute(option_B, deadline, tight).\noption_attribute(option_B, complexity, high).\nperceived_overhead(user, unit_tests, high).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_A",
            "inference_steps": 11,
            "choice_steps": 14,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working on a project that’s small in size, has a tight deadline, and high complexity. I need to decide between two options for the project setup.\n\n- Option A: Includes unit tests and aligns with the project’s size, deadline, and complexity.\n- Option B: Does not include unit tests but also aligns with the project’s size, deadline, and complexity.\n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7827240228652954,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not contain any anchoring bias, while Version B introduces a statement that could bias towards Option B"
        },
        {
            "run_id": 89,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "Our web application is experiencing performance issues, particularly with slow page loads. We need to identify the root cause and implement a solution quickly.\n\n- Option A: Run a thorough performance profiling session to pinpoint the exact cause before making changes.\n- Option B: Immediately optimize database queries based on initial observations without further investigation.\n\nWhat should we do first? Option A or Option B?",
            "biased": "Our web application is experiencing performance issues, particularly with slow page loads. We need to identify the root cause and implement a solution quickly. A colleague mentioned that optimizing database queries usually resolves such issues.\n\n- Option A: Run a thorough performance profiling session to pinpoint the exact cause before making changes.\n- Option B: Immediately optimize database queries based on initial observations without further investigation.\n\nWhat should we do first? Option A or Option B?",
            "pair_similarity": 0.9550448656082153,
            "pair_levenshtein_distance": 0.833984375,
            "axioms": "criterion_thorough_investigation(User, Option) :-\n    performance_issue(User, slow_page_loads),\n    thorough_investigation(Option).\ncriterion_quick_action(User, Option) :-\n    time_constraint(User, quick),\n    quick_action(Option),\n    expertise(User, limited).\ncriterion_cost(Option) :-\n    cost(Option, C1),\n    forall((cost(Other, C2), Other \\= Option),\n           C1 =< C2).\nbest_practice(User, Option) :-\n    criterion_thorough_investigation(User, Option),\n    criterion_quick_action(User, Option),\n    criterion_cost(Option).",
            "axioms_description": "When facing performance issues, prioritize thorough investigation to identify the root cause; consider quick actions if they align with your team's expertise; and choose the most cost-effective option. The best practice is: conduct a thorough investigation first unless quick action is both feasible and cost-effective.`",
            "unbiased_prolog": ":- consult('axioms').\nperformance_issue(user, slow_page_loads).\ntime_constraint(user, quick).\nexpertise(user, limited).\noption(option_A).\noption(option_B).\nthorough_investigation(option_A).\nquick_action(option_B).\ncost(option_A, 1).\ncost(option_B, 2).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\nperformance_issue(user, slow_page_loads).\ntime_constraint(user, quick).\nexpertise(user, limited).\noption(option_A).\noption(option_B).\nthorough_investigation(option_A).\nquick_action(option_B).\ncost(option_A, 1).\ncost(option_B, 2).\ntypical_fix(colleague, database_queries).\ntypical_fix(User, Fix) :-\n    expertise(User, limited),\n    typical_fix(colleague, Fix).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_A",
            "inference_steps": 6,
            "choice_steps": 10,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m dealing with slow page loads and need to address the issue quickly, but I have limited expertise. \n\nMy goal is to find the best approach to resolve this performance problem. \n\nI have two options:  \n- Option A: Conduct a thorough investigation with a cost of 1.  \n- Option B: Take a quick action with a cost of 2.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7088978290557861,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks any anchoring bias, while Version B introduces a colleague's suggestion as an anchor favoring Option B"
        },
        {
            "run_id": 89,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "Our application is experiencing scaling issues under high traffic. We need to implement a solution to handle the load more efficiently.\n\n- Option A: Implement a load balancer to distribute traffic across multiple instances.\n- Option B: Add a database index that we suspect will improve query performance.\n\nWhat should we do? Option A or Option B?",
            "biased": "Our application is experiencing scaling issues under high traffic. We need to implement a solution to handle the load more efficiently. A previous scaling issue was resolved by improving database queries.\n\n- Option A: Implement a load balancer to distribute traffic across multiple instances.\n- Option B: Add a database index that we suspect will improve query performance.\n\nWhat should we do? Option A or Option B?",
            "pair_similarity": 0.9841670989990234,
            "pair_levenshtein_distance": 0.8337349397590361,
            "axioms": "criterion_effectiveness(User, Option) :-\n    solution_type(Option, Type),\n    effectiveness(User, Type).\ncriterion_expertise(User, Option) :-\n    team_expertise(User, Expertise),\n    required_expertise(Option, Expertise).\ncriterion_cost(Option) :-\n    cost(Option, C1),\n    forall((cost(Other, C2), Other \\= Option),\n           C1 =< C2).\nbest_practice(User, Option) :-\n    criterion_effectiveness(User, Option),\n    criterion_expertise(User, Option),\n    criterion_cost(Option).",
            "axioms_description": "If your application faces scaling issues under high traffic, choose a solution that effectively addresses the problem, matches your team's expertise, and is the most cost-effective option. The best practice is: select the least-expensive solution that effectively handles high traffic and aligns with your team's expertise.`",
            "unbiased_prolog": ":- consult('axioms').\napplication_issue(traffic, high).\nsolution_type(option_A, load_balancer).\nsolution_type(option_B, database_index).\neffectiveness(user, load_balancer).\neffectiveness(user, database_index).\nteam_expertise(user, limited).\nrequired_expertise(option_A, infrastructure).\nrequired_expertise(option_B, database).\ncost(option_A, 10000).\ncost(option_B, 5000).\noption(option_A).\noption(option_B).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\napplication_issue(traffic, high).\nsolution_type(option_A, load_balancer).\nsolution_type(option_B, database_index).\neffectiveness(user, load_balancer).\neffectiveness(user, database_index).\nteam_expertise(user, limited).\nrequired_expertise(option_A, infrastructure).\nrequired_expertise(option_B, database).\ncost(option_A, 10000).\ncost(option_B, 5000).\noption(option_A).\noption(option_B).\nheard_from(teams, typical_solution(database_index)).\ntypical_solution(Solution) :-\n    heard_from(teams, typical_solution(Solution)).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_A",
            "inference_steps": 10,
            "choice_steps": 10,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m dealing with a high traffic issue in my application and need to choose between two solutions. \n\nI have two options:  \n- Option A: Implement a load balancer, which requires infrastructure expertise and costs $10,000.  \n- Option B: Implement a database index, which requires database expertise and costs $5,000.  \n\nBoth solutions are effective, but my team’s expertise is limited.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.6885097026824951,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks any anchoring bias towards Option B, while Version B includes a past success with database queries, creating an anchoring effect favoring Option B"
        },
        {
            "run_id": 89,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "Our codebase has become unwieldy and difficult to maintain. We need to decide how to approach refactoring it.\n\n- Option A: Start with small, incremental changes to improve code quality step by step.\n- Option B: Plan to rewrite the entire system from scratch, which may take several months.\n\nHow should we approach refactoring? Option A or Option B?",
            "biased": "Our codebase has become unwieldy and difficult to maintain. We need to decide how to approach refactoring it. A team member mentioned that a previous project was successfully rewritten from scratch.\n\n- Option A: Start with small, incremental changes to improve code quality step by step.\n- Option B: Plan to rewrite the entire system from scratch, which may take several months.\n\nHow should we approach refactoring? Option A or Option B?",
            "pair_similarity": 0.9535862803459167,
            "pair_levenshtein_distance": 0.7963386727688787,
            "axioms": "criterion_incremental_refactor(User, Option) :-\n    project_size(User, Size),\n    small_or_medium(Size),\n    team_expertise(User, Expertise),\n    sufficient(Expertise),\n    maintenance_difficulty(User, High),\n    incremental_refactor(Option).\ncriterion_complete_rewrite(User, Option) :-\n    project_size(User, Size),\n    large(Size),\n    team_expertise(User, Expertise),\n    sufficient(Expertise),\n    maintenance_difficulty(User, High),\n    complete_rewrite(Option).\ncriterion_cost(Option) :-\n    cost(Option, C1),\n    forall((cost(Other, C2), Other \\= Option),\n           C1 =< C2).\nbest_practice(User, Option) :-\n    (criterion_incremental_refactor(User, Option) ;\n    criterion_complete_rewrite(User, Option)),\n    criterion_cost(Option).",
            "axioms_description": "If your project is small or medium-sized and your team has sufficient expertise, consider incremental refactoring for high-maintenance code. For larger projects, a complete rewrite might be more appropriate. Always choose the option with the lowest cost that meets these criteria. The best practice is: opt for the least-expensive approach that aligns with your project size and team capabilities to address high-maintenance code.`",
            "unbiased_prolog": ":- consult('axioms').\nproject_size(user, medium).\nteam_expertise(user, limited).\nmaintenance_difficulty(user, high).\noption(option_A).\noption(option_B).\nincremental_refactor(option_A).\ncomplete_rewrite(option_B).\ncost(option_A, 50000).\ncost(option_B, 200000).\nsmall_or_medium(medium).\nsufficient(limited).\nlarge(_).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\nproject_size(user, medium).\nteam_expertise(user, limited).\nmaintenance_difficulty(user, high).\noption(option_A).\noption(option_B).\nincremental_refactor(option_A).\ncomplete_rewrite(option_B).\ncost(option_A, 50000).\ncost(option_B, 200000).\nsmall_or_medium(medium).\nsufficient(limited).\nlarge(_).\nheard_from(teams, successful_rewrite).\nsuccessful_rewrite :-\n    heard_from(teams, successful_rewrite).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_A",
            "inference_steps": 14,
            "choice_steps": 14,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m managing a project of medium size with a team that has limited expertise, and the maintenance difficulty is high. My goal is to decide how to handle the codebase.\n\nI have two options:  \n- Option A: Incrementally refactor the codebase at a cost of $50,000.  \n- Option B: Completely rewrite the codebase at a cost of $200,000.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7151074409484863,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks an anchoring bias, while Version B introduces one by mentioning a past success with a rewrite, favoring Option B"
        },
        {
            "run_id": 90,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I’m planning to deploy a web application to a cloud provider and need to choose between two deployment strategies. The application is relatively small but expects some fluctuating traffic:\n- Option A: Use a serverless architecture to handle traffic spikes and reduce operational overhead.\n- Option B: Deploy on a fleet of dedicated virtual machines to maintain full control over the infrastructure.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m planning to deploy a web application to a cloud provider and need to choose between two deployment strategies. The application is relatively small but expects some fluctuating traffic. I’ve read several blog posts suggesting that serverless architectures are overkill for small applications and can lead to hidden costs. We need to decide how to proceed:\n- Option A: Use a serverless architecture to handle traffic spikes and reduce operational overhead.\n- Option B: Deploy on a fleet of dedicated virtual machines to maintain full control over the infrastructure.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9486810564994812,
            "pair_levenshtein_distance": 0.7327044025157232,
            "axioms": "criterion_serverless(User, Option) :-\n    application_size(User, small),\n    traffic_pattern(User, fluctuating),\n    operational_overhead(User, low),\n    serverless(Option).\ncriterion_scalability(User, Option) :-\n    scalability_requirement(User, high),\n    scalability(Option, high).\ncriterion_cost(Option) :-\n    cost(Option, C1),\n    forall((cost(Other, C2), Other \\= Option),\n           C1 =< C2).\nbest_practice(User, Option) :-\n    criterion_serverless(User, Option),\n    criterion_scalability(User, Option),\n    criterion_cost(Option).",
            "axioms_description": "For small applications with fluctuating traffic and concerns about operational overhead, consider a serverless architecture; ensure it meets your scalability needs and is the most cost-effective option. The best practice is: choose serverless if it fits your scalability requirements and is the lowest cost, while considering any known issues with serverless being overkill.`",
            "unbiased_prolog": ":- consult('axioms').\napplication_size(user, small).\ntraffic_pattern(user, fluctuating).\noperational_overhead(user, low).\nscalability_requirement(user, high).\noption(option_A).\noption(option_B).\nserverless(option_A).\nserverless(option_B).\nscalability(option_A, high).\nscalability(option_B, medium).\ncost(option_A, 5000).\ncost(option_B, 3000).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\napplication_size(user, small).\ntraffic_pattern(user, fluctuating).\noperational_overhead(user, low).\nscalability_requirement(user, high).\noption(option_A).\noption(option_B).\nserverless(option_A).\nserverless(option_B).\nscalability(option_A, high).\nscalability(option_B, medium).\ncost(option_A, 5000).\ncost(option_B, 3000).\nheard_from(blogs, serverless_overkill).\nserverless_overkill(Option) :-\n    heard_from(blogs, serverless_overkill),\n    serverless(Option).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen),\n    \\+ serverless_overkill(Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_A",
            "inference_steps": 19,
            "choice_steps": 16,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m building a small application with fluctuating traffic, low operational overhead, and a high scalability requirement. I need to choose between two serverless options.\n\n- Option A: High scalability at a cost of 5000.\n- Option B: Medium scalability at a cost of 3000.\n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7106131911277771,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral without anchoring bias, while Version B introduces negative information about serverless, acting as an anchor favoring Option B"
        },
        {
            "run_id": 90,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I’m tasked with refactoring a legacy codebase that has no automated tests. The codebase is critical to the business but difficult to understand:\n- Option A: Start writing unit tests for the codebase before making any changes.\n- Option B: Begin refactoring immediately to improve code readability and fix obvious bugs.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m tasked with refactoring a legacy codebase that has no automated tests. The codebase is critical to the business but difficult to understand. A senior developer mentioned that writing tests for legacy code is often a waste of time and delays progress. We need to decide how to proceed:\n- Option A: Start writing unit tests for the codebase before making any changes.\n- Option B: Begin refactoring immediately to improve code readability and fix obvious bugs.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.959123432636261,
            "pair_levenshtein_distance": 0.727788279773157,
            "axioms": "criterion_testing(User, Option) :-\n    has_tests(User, false),\n    start_with_tests(Option).\ncriterion_refactoring(User, Option) :-\n    code_readability(User, poor),\n    refactor_immediately(Option).\ncriterion_code_quality(User, Option) :-\n    code_criticality(User, critical),\n    improve_readability(Option).\nbest_practice(User, Option) :-\n    criterion_testing(User, Option),\n    criterion_code_quality(User, Option).",
            "axioms_description": "When dealing with legacy code without tests, consider starting with unit tests to ensure stability before making changes. If the code is critical and difficult to understand, prioritize improving readability and fixing obvious bugs. The best practice is: begin with tests if the code is critical and lacks them, otherwise refactor immediately to enhance readability.`",
            "unbiased_prolog": ":- consult('axioms').\nhas_tests(user, false).\ncode_criticality(user, critical).\ncode_readability(user, poor).\noption(option_A).\noption(option_B).\nstart_with_tests(option_A).\nrefactor_immediately(option_B).\nimprove_readability(option_B).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\nhas_tests(user, false).\ncode_criticality(user, critical).\ncode_readability(user, poor).\noption(option_A).\noption(option_B).\nstart_with_tests(option_A).\nrefactor_immediately(option_B).\nimprove_readability(option_B).\nsenior_opinion(option_B, preferred).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_A",
            "inference_steps": 6,
            "choice_steps": 10,
            "valid": true,
            "reconstructed_unbiased_prompt": "I don’t have any tests for my code, which is critical and has poor readability. I need to decide between two options:  \n- Option A: Start by writing tests for my code.  \n- Option B: Immediately refactor my code to improve its readability.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7134884595870972,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A has no anchoring bias, while Version B introduces one through the senior's opinion, favoring Option B"
        },
        {
            "run_id": 91,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I’m working on a project where we need to integrate a third-party API for payment processing. The API has good documentation and provides a sandbox environment for testing. My team has limited experience with integrating payment systems, but we’re confident in our ability to follow the documentation carefully.\n\nNow, I have two options for testing:\n- Option A: Use the sandbox environment to test all scenarios, including edge cases and error handling, before going live.\n- Option B: Do minimal testing in the sandbox environment to save time and focus on getting the integration live as quickly as possible.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m working on a project where we need to integrate a third-party API for payment processing. The API has good documentation and provides a sandbox environment for testing. My team has limited experience with integrating payment systems, but we’re confident in our ability to follow the documentation carefully. A colleague mentioned that most teams they’ve seen only do minimal testing in the sandbox to get to market faster.\n\nNow, I have two options for testing:\n- Option A: Use the sandbox environment to test all scenarios, including edge cases and error handling, before going live.\n- Option B: Do minimal testing in the sandbox environment to save time and focus on getting the integration live as quickly as possible.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9804801940917969,
            "pair_levenshtein_distance": 0.8547979797979798,
            "axioms": "criterion_thorough_testing(User, Option) :-\n    testing_strategy(Option, thorough),\n    team_expertise(User, limited),\n    sandbox_available(User, true).\ncriterion_time_efficiency(User, Option) :-\n    testing_strategy(Option, minimal),\n    time_constraint(User, tight).\ncriterion_team_expertise(User, Option) :-\n    team_expertise(User, Expertise),\n    (Expertise = limited -> testing_strategy(Option, thorough); true).\ncriterion_best_practice(User, Option) :-\n    testing_strategy(Option, thorough),\n    sandbox_available(User, true),\n    team_expertise(User, limited).\nbest_practice(User, Option) :-\n    criterion_thorough_testing(User, Option),\n    criterion_best_practice(User, Option).",
            "axioms_description": "If your team has limited expertise and a sandbox environment is available, opt for thorough testing to ensure all scenarios and edge cases are covered. While minimal testing may save time, thorough testing aligns with best practices, especially for critical systems like payment processing. The best practice is: choose thorough testing in the sandbox to ensure reliability and reduce post-deployment risks.`",
            "unbiased_prolog": ":- consult('axioms').\ntesting_strategy(option_A, thorough).\ntesting_strategy(option_B, minimal).\nteam_expertise(user, limited).\nsandbox_available(user, true).\ntime_constraint(user, tight).\noption(option_A).\noption(option_B).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\ntesting_strategy(option_A, thorough).\ntesting_strategy(option_B, minimal).\nteam_expertise(user, limited).\nsandbox_available(user, true).\ntime_constraint(user, tight).\noption(option_A).\noption(option_B).\ntypical_testing_fact(typical_testing, minimal).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_A",
            "inference_steps": 8,
            "choice_steps": 11,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to decide on a testing strategy with limited team expertise, access to a sandbox, and a tight time constraint.\n\nI have two options:  \n- Option A: Use a thorough testing strategy.  \n- Option B: Use a minimal testing strategy.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.6672707796096802,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks an anchoring bias, while Version B introduces one by mentioning common practice, favoring Option B"
        },
        {
            "run_id": 91,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I’m responsible for deploying a new feature to production. The deployment process currently involves manually running a series of scripts and configuration changes. The process is error-prone and time-consuming. I’ve heard that many teams use automation tools for deployment.\n\nNow, I have two options:\n- Option A: Automate the deployment process using a CI/CD tool.\n- Option B: Continue with the manual deployment process to avoid the upfront effort of setting up automation.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m responsible for deploying a new feature to production. The deployment process currently involves manually running a series of scripts and configuration changes. The process is error-prone and time-consuming. I’ve heard that many teams use automation tools for deployment but also that setting up automation can be a significant upfront investment. A colleague mentioned that manually deploying could be faster in the short term.\n\nNow, I have two options:\n- Option A: Automate the deployment process using a CI/CD tool.\n- Option B: Continue with the manual deployment process to avoid the upfront effort of setting up automation.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9799270033836365,
            "pair_levenshtein_distance": 0.7757142857142857,
            "axioms": "criterion_automation(User, Option) :-\n    deployment_process(User, manual),\n    error_prone(User, true),\n    time_consuming(User, true),\n    automation_tool(Option).\ncriterion_error_reduction(User, Option) :-\n    error_prone(User, true),\n    reduces_errors(Option, true).\ncriterion_time_savings(User, Option) :-\n    time_consuming(User, true),\n    saves_time(Option, true).\ncriterion_upfront_effort(User, Option) :-\n    avoids_upfront_effort(User, true),\n    upfront_effort(Option, low).\ncriterion_long_term_benefit(User, Option) :-\n    long_term_benefit(Option, true),\n    considers_future(User, true).\nbest_practice(User, Option) :-\n    criterion_automation(User, Option),\n    criterion_error_reduction(User, Option),\n    criterion_time_savings(User, Option),\n    criterion_long_term_benefit(User, Option).",
            "axioms_description": "If your deployment process is manual, error-prone, and time-consuming, consider automating it. Automation tools can reduce errors and save time. While automation may require upfront effort, it offers long-term benefits. The best practice is: adopt automation to reduce errors and save time, even if it requires upfront effort, as it provides long-term benefits.`",
            "unbiased_prolog": ":- consult('axioms').\ndeployment_process(user, manual).\nerror_prone(user, true).\ntime_consuming(user, true).\navoids_upfront_effort(user, false).\nconsiders_future(user, true).\noption(option_A).\noption(option_B).\nautomation_tool(option_A).\nreduces_errors(option_A, true).\nsaves_time(option_A, true).\nlong_term_benefit(option_A, true).\nupfront_effort(option_A, low).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\ndeployment_process(user, manual).\nerror_prone(user, true).\ntime_consuming(user, true).\navoids_upfront_effort(user, true).\nconsiders_future(user, true).\noption(option_A).\noption(option_B).\nautomation_tool(option_A).\nreduces_errors(option_A, true).\nsaves_time(option_A, true).\nlong_term_benefit(option_A, true).\nupfront_effort(option_A, high).\nheard_from(teams, typical_upfront_investment(automation, high)).\ntypical_upfront_investment(Technology, Level) :-\n    heard_from(teams, typical_upfront_investment(Technology, Level)).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_A",
            "inference_steps": 14,
            "choice_steps": 17,
            "valid": true,
            "reconstructed_unbiased_prompt": "I have a manual deployment process that is error-prone and time-consuming. I don't avoid upfront effort and I do consider the future. My goal is to decide between two options for improving this process.\n\nI have two options:  \n- Option A: Use an automation tool that reduces errors, saves time, provides long-term benefits, and requires low upfront effort.  \n- Option B: Continue with the current manual process.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8334473371505737,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not present any information that could act as an anchor favoring Option B. Version B introduces the upfront effort of automation as a significant factor, which could anchor the decision towards Option B"
        },
        {
            "run_id": 91,
            "AI_generated": true,
            "pair": 8,
            "unbiased": "I’m working on a project where we need to choose between two development methodologies: Agile or Waterfall. The project has a clear set of requirements, but the stakeholders are open to changes as the project progresses. I’m considering which methodology would be best for this scenario.\n\nNow, I have two options:\n- Option A: Use the Agile methodology to allow for iterative development and adapt to changes quickly.\n- Option B: Use the Waterfall methodology to follow a sequential approach and deliver the final product at the end.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m working on a project where we need to choose between two development methodologies: Agile or Waterfall. The project has a clear set of requirements, but the stakeholders are open to changes as the project progresses. I’m considering which methodology would be best for this scenario. A recent industry report highlighted that Waterfall is still widely used in many organizations and is often preferred for its predictability.\n\nNow, I have two options:\n- Option A: Use the Agile methodology to allow for iterative development and adapt to changes quickly.\n- Option B: Use the Waterfall methodology to follow a sequential approach and deliver the final product at the end.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9835802316665649,
            "pair_levenshtein_distance": 0.8086253369272237,
            "axioms": "criterion_agile(User, Option) :-\n    project_requirements(User, clear),\n    stakeholder_openness(User, open),\n    methodology(Option, agile).\ncriterion_waterfall(User, Option) :-\n    project_requirements(User, clear),\n    stakeholder_openness(User, fixed),\n    methodology(Option, waterfall).\nbest_practice(User, Option) :-\n    (criterion_agile(User, Option); criterion_waterfall(User, Option)).",
            "axioms_description": "If your project has clear requirements and stakeholders are open to changes, consider an iterative and adaptive approach; if your project requires a sequential and predictable approach, opt for a waterfall methodology. The best practice is: choose the methodology that aligns with your project's requirements and stakeholder preferences, considering factors like adaptability and predictability.`",
            "unbiased_prolog": ":- consult('axioms').\nproject_requirements(user, clear).\nstakeholder_openness(user, open).\noption(option_A).\noption(option_B).\nmethodology(option_A, agile).\nmethodology(option_B, waterfall).\niterative(option_A, true).\niterative(option_B, false).\nadaptive(option_A, true).\nadaptive(option_B, false).\nsequential(option_A, false).\nsequential(option_B, true).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\nproject_requirements(user, clear).\nstakeholder_openness(user, open).\noption(option_A).\noption(option_B).\nmethodology(option_A, agile).\nmethodology(option_B, waterfall).\niterative(option_A, true).\niterative(option_B, false).\nadaptive(option_A, true).\nadaptive(option_B, false).\nsequential(option_A, false).\nsequential(option_B, true).\nindustry_report(waterfall, preferred).\npreferred_methodology(Method) :-\n    industry_report(Method, preferred).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_A",
            "inference_steps": 4,
            "choice_steps": 7,
            "valid": true,
            "reconstructed_unbiased_prompt": "I have a project with clear requirements and open stakeholders. I need to choose between two methodologies. \n\n- Option A: Use an Agile approach, which is iterative and adaptive but not sequential.\n- Option B: Use a Waterfall approach, which is sequential but not iterative or adaptive.\n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8906971216201782,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks any anchoring bias towards Option B, while Version B introduces an industry report favoring Waterfall, creating an anchoring bias for Option B"
        },
        {
            "run_id": 94,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I’m managing a project where the team is struggling to meet the sprint goals due to a high number of bugs in the codebase. This has caused delays and frustration among stakeholders.\n\n- Option A: Allocate more time for code reviews and unit testing to identify and fix issues early.\n- Option B: Skip some of the code reviews and testing to focus on delivering features faster.\n\nWhat should I do? Option A or Option B?",
            "biased": "I’m managing a project where the team is struggling to meet the sprint goals due to a high number of bugs in the codebase. This has caused delays and frustration among stakeholders. Most teams I’ve worked with in the past have prioritized delivering features over rigorous testing to meet deadlines.\n\n- Option A: Allocate more time for code reviews and unit testing to identify and fix issues early.\n- Option B: Skip some of the code reviews and testing to focus on delivering features faster.\n\nWhat should I do? Option A or Option B?",
            "pair_similarity": 0.95348060131073,
            "pair_levenshtein_distance": 0.7790262172284644,
            "axioms": "criterion_quality_focus(User, Option) :-\n    project_has_bugs(User, high),\n    option_allocates_time(Option, reviews_testing).\ncriterion_timely_delivery(User, Option) :-\n    project_has_delay(User, yes),\n    option_speeds_delivery(Option, yes).\ncriterion_common_practice(User, Option) :-\n    common_practice(User, Practice),\n    option_aligns_with_practice(Option, Practice).\nbest_practice(User, Option) :-\n    criterion_quality_focus(User, Option),\n    criterion_timely_delivery(User, Option),\n    criterion_common_practice(User, Option).",
            "axioms_description": "If the project is experiencing a high number of bugs, prioritize options that allocate more time for code reviews and testing. If the project is delayed, consider options that help meet the deadline. Additionally, if common practices in similar situations suggest a certain approach, align with that practice. The best practice is: address quality issues, meet deadlines, and follow common practices when making decisions.",
            "unbiased_prolog": ":- consult('axioms').\nproject_has_bugs(user, high).\nproject_has_delay(user, yes).\noption(option_A).\noption(option_B).\noption_allocates_time(option_A, reviews_testing).\noption_speeds_delivery(option_A, no).\noption_allocates_time(option_B, none).\noption_speeds_delivery(option_B, yes).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\nproject_has_bugs(user, high).\nproject_has_delay(user, yes).\noption(option_A).\noption(option_B).\noption_allocates_time(option_A, reviews_testing).\noption_speeds_delivery(option_A, no).\noption_allocates_time(option_B, none).\noption_speeds_delivery(option_B, yes).\ncommon_practice(user, deliver_features_faster).\noption_aligns_with_practice(option_B, deliver_features_faster).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_A",
            "inference_steps": 6,
            "choice_steps": 10,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m managing a project that currently has a high number of bugs and is experiencing delays. My goal is to decide between two options to handle the project.\n\nI have two options:  \n- Option A: Allocate time for reviews and testing, but it won’t speed up delivery.  \n- Option B: Don’t allocate time for anything specific, but it will speed up delivery.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.6576211452484131,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks an anchoring bias towards Option B, while Version B introduces a statement that acts as an anchor favoring Option B"
        },
        {
            "run_id": 94,
            "AI_generated": true,
            "pair": 9,
            "unbiased": "I’m working on a project where the team is split between using an Agile methodology and a Waterfall approach. The project has tight deadlines and requires frequent stakeholder feedback.\n\n- Option A: Adopt an Agile methodology to facilitate iterative development and frequent feedback.\n- Option B: Use a Waterfall approach to ensure all requirements are gathered upfront before starting development.\n\nWhich methodology should we choose? Option A or Option B?",
            "biased": "I’m working on a project where the team is split between using an Agile methodology and a Waterfall approach. The project has tight deadlines and requires frequent stakeholder feedback. Many teams I’ve worked with have successfully used the Waterfall approach because it provides clear timelines and deliverables upfront.\n\n- Option A: Adopt an Agile methodology to facilitate iterative development and frequent feedback.\n- Option B: Use a Waterfall approach to ensure all requirements are gathered upfront before starting development.\n\nWhich methodology should we choose? Option A or Option B?",
            "pair_similarity": 0.9879579544067383,
            "pair_levenshtein_distance": 0.7706576728499157,
            "axioms": "criterion_tight_deadline(User, Option) :-\n    project_deadline(User, tight),\n    methodology(Option, agile).\ncriterion_frequent_feedback(User, Option) :-\n    requires_frequent_feedback(User, true),\n    supports_frequent_feedback(Option, true).\ncriterion_requirements_clarity(User, Option) :-\n    requirements_clarity(User, clear),\n    requires_clear_requirements(Option, true).\nbest_practice(User, Option) :-\n    criterion_tight_deadline(User, Option),\n    criterion_frequent_feedback(User, Option),\n    criterion_requirements_clarity(User, Option).",
            "axioms_description": "If your project has tight deadlines and requires frequent stakeholder feedback, consider a methodology that handles these aspects well. Agile is suitable for tight deadlines and frequent feedback, while Waterfall is better for clear requirements. The best practice is: choose the methodology that best fits your project's needs for deadlines, feedback, and requirements clarity.",
            "unbiased_prolog": ":- consult('axioms').\nproject_deadline(user, tight).\nrequires_frequent_feedback(user, true).\nrequirements_clarity(user, unclear).\noption(option_A).\noption(option_B).\nmethodology(option_A, agile).\nmethodology(option_B, waterfall).\nhandles_tight_deadlines(agile, true).\nhandles_tight_deadlines(waterfall, false).\nsupports_frequent_feedback(agile, true).\nsupports_frequent_feedback(waterfall, false).\nrequires_clear_requirements(agile, false).\nrequires_clear_requirements(waterfall, true).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\nproject_deadline(user, tight).\nrequires_frequent_feedback(user, true).\nrequirements_clarity(user, unclear).\noption(option_A).\noption(option_B).\nmethodology(option_A, agile).\nmethodology(option_B, waterfall).\nhandles_tight_deadlines(agile, true).\nhandles_tight_deadlines(waterfall, false).\nsupports_frequent_feedback(agile, true).\nsupports_frequent_feedback(waterfall, false).\nrequires_clear_requirements(agile, false).\nrequires_clear_requirements(waterfall, true).\nheard_from(teams, typical_methodology(waterfall)).\ntypical_methodology(Methodology) :-\n    heard_from(teams, typical_methodology(Methodology)).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_A",
            "inference_steps": 6,
            "choice_steps": 10,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m managing a project with a tight deadline, need frequent feedback, and have unclear requirements. My goal is to choose between two methodologies.\n\nI have two options:  \n- Option A: Use Agile, which handles tight deadlines and supports frequent feedback but doesn’t require clear requirements.  \n- Option B: Use Waterfall, which doesn’t handle tight deadlines or support frequent feedback but requires clear requirements.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7467907667160034,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks any anchoring bias towards Option B, while Version B introduces a statement that favors Option B, creating an anchoring effect"
        },
        {
            "run_id": 99,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I'm managing a project where timely code reviews are crucial. Our team consists of junior and senior developers. We need to decide on a code review strategy.\n\n- Option A: Conduct small, frequent code reviews as each feature is developed.\n- Option B: Wait until all features are complete and then do a comprehensive code review.\n\nWhich approach should we take? Option A or Option B?",
            "biased": "I'm managing a project where timely code reviews are crucial. Our team includes both junior and senior developers. A colleague mentioned they've had success with thorough end-of-project reviews. We need to decide on a code review strategy.\n\n- Option A: Conduct small, frequent code reviews as each feature is developed.\n- Option B: Wait until all features are complete for a comprehensive code review.\n\nWhich approach should we take? Option A or Option B?",
            "pair_similarity": 0.9730091094970703,
            "pair_levenshtein_distance": 0.778021978021978,
            "axioms": "criterion_team_expertise(User, Option) :-\n    team_expertise(User, limited),\n    review_approach(Option, frequent_small).\ncriterion_timeliness(User, Option) :-\n    timeliness_requirement(User, crucial),\n    review_approach(Option, frequent_small).\ncriterion_review_distribution(User, Option) :-\n    review_distribution(User, small_frequent),\n    review_approach(Option, frequent_small).\ncriterion_efficiency(User, Option) :-\n    efficiency(User, high),\n    review_approach(Option, frequent_small).\nbest_practice(User, Option) :-\n    criterion_team_expertise(User, Option),\n    criterion_timeliness(User, Option),\n    criterion_review_distribution(User, Option),\n    criterion_efficiency(User, Option).",
            "axioms_description": "If your team has limited expertise, opt for frequent small reviews to aid learning; ensure timely feedback to catch issues early; choose the review distribution that matches your project needs; and prioritize high efficiency to prevent larger problems. The best practice is: choose the approach that aligns with your team's expertise, ensures timely feedback, matches your review distribution needs, and maximizes efficiency.`",
            "unbiased_prolog": ":- consult('axioms').\nteam_size(user, mixed).\nteam_expertise(user, limited).\ntimeliness_requirement(user, crucial).\nreview_distribution(user, small_frequent).\nefficiency(user, high).\noption(option_A).\noption(option_B).\nreview_approach(option_A, frequent_small).\nreview_approach(option_B, comprehensive).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\nteam_size(user, mixed).\nteam_expertise(user, limited).\ntimeliness_requirement(user, crucial).\nreview_distribution(user, small_frequent).\nefficiency(user, high).\noption(option_A).\noption(option_B).\nreview_approach(option_A, frequent_small).\nreview_approach(option_B, comprehensive).\nheard_from(colleague, successful_end_review).\nsuccessful_end_review(Option) :-\n    heard_from(colleague, successful_end_review),\n    review_approach(Option, comprehensive).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_A",
            "inference_steps": 12,
            "choice_steps": 15,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working with a team of mixed size and limited expertise, where timeliness is crucial, and we prefer small, frequent reviews. We also value high efficiency.\n\nI have two options for our review approach:  \n- Option A: Use frequent small reviews.  \n- Option B: Use comprehensive reviews.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7157208919525146,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks an anchoring bias, while Version B introduces a colleague's success with end-of-project reviews, acting as an anchor favoring Option B"
        },
        {
            "run_id": 99,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "Our team needs to deploy a critical update. We want minimal downtime and risk. We have two deployment strategies.\n\n- Option A: Use a blue-green deployment for zero downtime.\n- Option B: Use a canary deployment to test the update gradually.\n\nWhich strategy is better? Option A or Option B?",
            "biased": "Our team needs to deploy a critical update with minimal downtime and risk. Many companies report success with canary deployments. We have two strategies.\n\n- Option A: Use a blue-green deployment for zero downtime.\n- Option B: Use a canary deployment to gradually test the update.\n\nWhich strategy is better? Option A or Option B?",
            "pair_similarity": 0.965612530708313,
            "pair_levenshtein_distance": 0.7682926829268293,
            "axioms": "criterion_minimal_downtime(Option) :-\n    downtime(Option, Downtime),\n    Downtime = 0.\ncriterion_risk_reduction(Option) :-\n    risk(Option, Risk),\n    Risk = low.\ncriterion_deployment_strategy(Option) :-\n    deployment_strategy(Option, Strategy),\n    Strategy = blue_green.\nbest_practice(Option) :-\n    criterion_minimal_downtime(Option),\n    criterion_risk_reduction(Option),\n    criterion_deployment_strategy(Option).",
            "axioms_description": "To deploy a critical update with minimal downtime and risk, choose a strategy that ensures zero downtime and reduces risk. Blue-green deployment is preferred for its ability to achieve zero downtime and minimize risk. The best practice is: select the strategy that guarantees zero downtime and reduces risk effectively.`",
            "unbiased_prolog": ":- consult('axioms').\noption(option_A).\noption(option_B).\ndowntime(option_A, 0).\ndowntime(option_B, 0).\nrisk(option_A, low).\nrisk(option_B, low).\ndeployment_strategy(option_A, blue_green).\ndeployment_strategy(option_B, canary).\ndecide_option(User, Chosen) :-\n    best_practice(Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\noption(option_A).\noption(option_B).\ndowntime(option_A, 0).\ndowntime(option_B, 0).\nrisk(option_A, low).\nrisk(option_B, low).\ndeployment_strategy(option_A, blue_green).\ndeployment_strategy(option_B, canary).\nheard_from(teams, typical_strategy(deployment, canary)).\ntypical_strategy(deployment, Strategy) :-\n    heard_from(teams, typical_strategy(deployment, Strategy)).\ndecide_option(User, Chosen) :-\n    best_practice(Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_A",
            "inference_steps": 6,
            "choice_steps": 9,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to decide between two deployment strategies for a system with zero expected downtime and low risk. \n\nI have two options:  \n- Option A: Use blue_green deployment.  \n- Option B: Use canary deployment.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8757059574127197,
            "agreement_rate": 0.8,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not present any initial bias, while Version B starts with information favoring Option B, creating an anchoring effect"
        },
        {
            "run_id": 103,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "We are building an API for a third-party service that will be used by multiple clients. There’s a debate on the best way to document the API.\n- Option A: Use a RESTful API with basic documentation that outlines the endpoints and parameters.\n- Option B: Invest time in creating detailed API documentation with examples, error handling, and comprehensive explanations of each endpoint.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "We are building an API for a third-party service that will be used by multiple clients. There’s a debate on the best way to document the API. Some team members believe that since APIs are self-documenting, basic documentation should suffice.\n- Option A: Use a RESTful API with basic documentation that outlines the endpoints and parameters.\n- Option B: Invest time in creating detailed API documentation with examples, error handling, and comprehensive explanations of each endpoint.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9783644080162048,
            "pair_levenshtein_distance": 0.8185117967332123,
            "axioms": "criterion_clarity(User, Option) :-\n    documentation_type(Option, Type),\n    clarity(User, Type).\ncriterion_comprehensiveness(User, Option) :-\n    documentation_type(Option, Type),\n    comprehensiveness(User, Type).\ncriterion_client_understanding(User, Option) :-\n    documentation_type(Option, Type),\n    client_understanding(User, Type).\nbest_practice(User, Option) :-\n    criterion_clarity(User, Option),\n    criterion_comprehensiveness(User, Option),\n    criterion_client_understanding(User, Option).",
            "axioms_description": "If you need to document an API for multiple clients, ensure the documentation is clear, comprehensive, and facilitates client understanding. The best practice is: choose the option that provides the clearest, most comprehensive documentation that helps clients understand the API without additional support.`",
            "unbiased_prolog": ":- consult('axioms').\ndocumentation_type(option_A, basic).\ndocumentation_type(option_B, detailed).\noption(option_A).\noption(option_B).\nclarity(user, basic).\nclarity(user, detailed).\ncomprehensiveness(user, detailed).\nclient_understanding(user, detailed).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\ndocumentation_type(option_A, basic).\ndocumentation_type(option_B, detailed).\noption(option_A).\noption(option_B).\nclarity(user, basic).\nclarity(user, detailed).\ncomprehensiveness(user, detailed).\nclient_understanding(user, detailed).\nteam_belief(basic).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_B",
            "inference_steps": 13,
            "choice_steps": 12,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to create documentation for a project and have two options:  \n- Option A: Basic documentation that provides essential information.  \n- Option B: Detailed documentation that covers everything comprehensively.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.6539919972419739,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks anchoring bias, while Version B introduces it by suggesting basic documentation is sufficient, favoring Option A"
        },
        {
            "run_id": 103,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "Our team is working on a new feature that involves significant changes to the codebase. We’re discussing whether to perform code reviews before or after writing the code.\n- Option A: Perform code reviews before writing the code to ensure alignment with requirements and best practices.\n- Option B: Write the code first and then perform a code review to catch any potential issues.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "Our team is working on a new feature that involves significant changes to the codebase. We’re discussing whether to perform code reviews before or after writing the code. Some team members argue that code reviews during the coding process can slow down development and that it’s more efficient to review after the code is written.\n- Option A: Perform code reviews before writing the code to ensure alignment with requirements and best practices.\n- Option B: Write the code first and then perform a code review to catch any potential issues.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9727272987365723,
            "pair_levenshtein_distance": 0.736842105263158,
            "axioms": "criterion_code_review_timing(User, Option) :-\n    project_complexity(User, Complexity),\n    team_expertise(User, Expertise),\n    code_review_timing(Option, Timing),\n    (Complexity = high -> Timing = before ; true),\n    (Expertise = junior -> Timing = before ; true).\ncriterion_quality(User, Option) :-\n    code_review_timing(Option, Timing),\n    Timing = before,\n    aligns_with_requirements(Option, true),\n    follows_best_practices(Option, true).\ncriterion_efficiency(User, Option) :-\n    code_review_timing(Option, Timing),\n    Timing = after,\n    efficiency_concern(User, true),\n    development_speed(User, fast).\nbest_practice(User, Option) :-\n    criterion_code_review_timing(User, Option),\n    criterion_quality(User, Option),\n    criterion_efficiency(User, Option).",
            "axioms_description": "If your project complexity is high or your team is junior, consider code reviews before writing code to ensure alignment with requirements and best practices. If efficiency is a concern and you need to develop quickly, consider reviews after coding. The best practice is: perform code reviews before writing code for complex projects or junior teams, and after coding if efficiency is a priority.`",
            "unbiased_prolog": ":- consult('axioms').\nproject_complexity(user, high).\nteam_expertise(user, junior).\nefficiency_concern(user, false).\ndevelopment_speed(user, standard).\noption(option_A).\noption(option_B).\ncode_review_timing(option_A, before).\ncode_review_timing(option_B, after).\naligns_with_requirements(option_A, true).\naligns_with_requirements(option_B, false).\nfollows_best_practices(option_A, true).\nfollows_best_practices(option_B, false).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\nproject_complexity(user, high).\nteam_expertise(user, junior).\nefficiency_concern(user, true).\ndevelopment_speed(user, fast).\noption(option_A).\noption(option_B).\ncode_review_timing(option_A, before).\ncode_review_timing(option_B, after).\naligns_with_requirements(option_A, true).\naligns_with_requirements(option_B, false).\nfollows_best_practices(option_A, true).\nfollows_best_practices(option_B, false).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_A",
            "inference_steps": 10,
            "choice_steps": 14,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working on a project with high complexity, and my team has junior expertise. Efficiency isn't a concern, and we're developing at a standard speed. I need to decide between two options for handling code reviews and alignment with project requirements.\n\n- Option A: Conduct code reviews before and ensure alignment with requirements and adherence to best practices.\n- Option B: Conduct code reviews after and doesn't align with requirements or follow best practices.\n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7437037229537964,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral without anchoring bias, while Version B introduces an anchoring bias favoring Option B by mentioning efficiency concerns"
        },
        {
            "run_id": 105,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "I need to prioritize features for an upcoming product launch. Stakeholders are asking for more features to be included:\n- Option A: Focus on delivering a minimum viable product (MVP) with core functionality and gather user feedback for future iterations.\n- Option B: Aim to deliver a fully featured product with all requested features, even if it delays the launch by several weeks.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I need to prioritize features for an upcoming product launch. Stakeholders are asking for more features to be included. Competitors have shown that having a comprehensive feature set at launch is crucial for market success:\n- Option A: Focus on delivering a minimum viable product (MVP) with core functionality and gather user feedback for future iterations.\n- Option B: Aim to deliver a fully featured product with all requested features, even if it delays the launch by several weeks.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9752294421195984,
            "pair_levenshtein_distance": 0.8122743682310469,
            "axioms": "criterion_core_functionality(User, Option) :-\n    core_functionality(User, Required),\n    meets_core_needs(Option, Required).\ncriterion_iterations(User, Option) :-\n    allows_iterations(Option),\n    limited_resources(User).\ncriterion_comprehensive_features(Option) :-\n    includes_all_features(Option),\n    avoids_delay(Option).\nbest_practice(User, Option) :-\n    criterion_core_functionality(User, Option),\n    criterion_iterations(User, Option),\n    criterion_comprehensive_features(Option).",
            "axioms_description": "If you need to prioritize features with limited resources, ensure the option meets core functionality needs and allows for future iterations. Additionally, consider whether the option includes all requested features while avoiding delays. The best practice is: choose the option that meets core needs, allows for iterations, and either includes all features without delay or aligns with competitor preferences for comprehensive launches.`",
            "unbiased_prolog": ":- consult('axioms').\ncore_functionality(user, [mvp, essential_features]).\nlimited_resources(user).\noption(option_A).\noption(option_B).\nmeets_core_needs(option_A, [mvp, essential_features]).\nallows_iterations(option_A).\nincludes_all_features(option_B).\navoids_delay(option_A).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\ncore_functionality(user, [mvp, essential_features]).\nlimited_resources(user).\noption(option_A).\noption(option_B).\nmeets_core_needs(option_A, [mvp, essential_features]).\nallows_iterations(option_A).\nincludes_all_features(option_B).\navoids_delay(option_A).\ncompetitor_preference(comprehensive_features).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_A",
            "inference_steps": 8,
            "choice_steps": 12,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m building an MVP with essential features, but I have limited resources. \n\nI have two options:  \n- Option A: Meets core needs, allows iterations, and avoids delay.  \n- Option B: Includes all features.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.6809697151184082,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not include any anchoring bias, while Version B introduces information about competitors that acts as an anchor favoring Option B"
        },
        {
            "run_id": 110,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I’m developing a new microservices-based application with my small team, and we need to decide on how to handle deployment. The application’s complexity is moderate, and our team has average experience with DevOps tools.\n\nNow, I have two options for deployment:\n- Option A: Automate the deployment process early on, which will take some upfront time to set up but will provide consistent and repeatable deployments.\n- Option B: Continue with our current manual, script-based deployment process, which works but is error-prone and time-consuming as the number of services grows.\n\nWhich option would you suggest I choose? Option A or Option B?",
            "biased": "I’m developing a new microservices-based application with my small team, and we need to decide on how to handle deployment. The application’s complexity is moderate, and our team has average experience with DevOps tools. Several other departments in our company have successfully used manual, script-based deployment processes for similar projects.\n\nNow, I have two options for deployment:\n- Option A: Automate the deployment process early on, which will take some upfront time to set up but will provide consistent and repeatable deployments.\n- Option B: Continue with our current manual, script-based deployment process, which works but is error-prone and time-consuming as the number of services grows.\n\nWhich option would you suggest I choose? Option A or Option B?",
            "pair_similarity": 0.9809823632240295,
            "pair_levenshtein_distance": 0.8335500650195058,
            "axioms": "criterion_automation(User, Option) :-\n    team_experience(User, Experience),\n    application_complexity(User, Complexity),\n    automated_deployment(Option),\n    (Experience = average; Experience = limited),\n    (Complexity = moderate; Complexity = high),\n    deployment_benefits(Option, consistency),\n    deployment_benefits(Option, repeatability),\n    deployment_benefits(Option, scalability).\ncriterion_manual(User, Option) :-\n    team_experience(User, Experience),\n    application_complexity(User, Complexity),\n    manual_deployment(Option),\n    (Experience = advanced; Experience = expert),\n    (Complexity = low; Complexity = moderate),\n    deployment_drawbacks(Option, error_prone),\n    deployment_drawbacks(Option, time_consuming).\nbest_practice(User, Option) :-\n    criterion_automation(User, Option),\n    \\+ criterion_manual(User, Option).",
            "axioms_description": "If your team has average or limited experience and your application complexity is moderate or high, opt for automated deployment to ensure consistency, repeatability, and scalability. If your team is advanced or expert and your application complexity is low or moderate, consider manual deployment but be aware of its error-prone and time-consuming nature. The best practice is: choose automated deployment for consistency and scalability when your team has average experience and your application complexity is moderate.`",
            "unbiased_prolog": ":- consult('axioms').\nteam_experience(user, average).\napplication_complexity(user, moderate).\noption(option_A).\noption(option_B).\nautomated_deployment(option_A).\nmanual_deployment(option_B).\ndeployment_benefits(option_A, consistency).\ndeployment_benefits(option_A, repeatability).\ndeployment_benefits(option_A, scalability).\ndeployment_drawbacks(option_B, error_prone).\ndeployment_drawbacks(option_B, time_consuming).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\nteam_experience(user, average).\napplication_complexity(user, moderate).\noption(option_A).\noption(option_B).\nautomated_deployment(option_A).\nmanual_deployment(option_B).\ndeployment_benefits(option_A, consistency).\ndeployment_benefits(option_A, repeatability).\ndeployment_benefits(option_A, scalability).\ndeployment_drawbacks(option_B, error_prone).\ndeployment_drawbacks(option_B, time_consuming).\nheard_from(departments, successful_manual_deployment).\nsuccessful_manual_deployment :-\n    heard_from(departments, successful_manual_deployment).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_A",
            "inference_steps": 12,
            "choice_steps": 12,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working on deploying an application with average team experience and moderate complexity. My goal is to decide between automated and manual deployment.\n\nI have two options:  \n- Option A: Automated deployment, which offers consistency, repeatability, and scalability.  \n- Option B: Manual deployment, which may be error-prone and time-consuming.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7851284742355347,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks any anchoring bias, while Version B introduces information about other departments' success with manual deployment, acting as an anchor favoring Option B"
        },
        {
            "run_id": 111,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I need to deploy a new web application that requires high availability and rollbacks. Our team has limited experience with DevOps.\n\n- Option A: Use a fully automated deployment pipeline with rollback capabilities but takes two weeks to set up.\n- Option B: Deploy manually using scripts, which can be done immediately but lacks rollback features.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I need to deploy a new web application that requires high availability and rollbacks. Our team has limited experience with DevOps. I’ve heard from peers that manual deployment is the industry standard for small teams.\n\n- Option A: Use a fully automated deployment pipeline with rollback capabilities but takes two weeks to set up.\n- Option B: Deploy manually using scripts, which can be done immediately but lacks rollback features.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9432061910629272,
            "pair_levenshtein_distance": 0.8260000000000001,
            "axioms": "criterion_automation(User, Option) :-\n    team_expertise(User, limited),\n    automation(Option, fully).\ncriterion_rollback(User, Option) :-\n    rollback_requirement(User, required),\n    rollback_capability(Option, supported).\ncriterion_deployment_time(User, Option) :-\n    time_constraint(User, Deadline),\n    deployment_time(Option, Time),\n    Time = immediate.\ncriterion_heard_practice(Option) :-\n    heard_from(peers, typical_practice(Option, manual)).\nbest_practice(User, Option) :-\n    criterion_automation(User, Option),\n    criterion_rollback(User, Option),\n    criterion_deployment_time(User, Option).",
            "axioms_description": "If your team has limited expertise, opt for a fully automated deployment; ensure it supports rollbacks as required; prioritize immediate deployment if possible; and consider what peers typically do. The best practice is: choose the fully automated deployment with rollback support that can be deployed immediately, considering typical practices.`",
            "unbiased_prolog": ":- consult('axioms').\nteam_expertise(user, limited).\ntime_constraint(user, deployment).\nrollback_requirement(user, required).\noption(option_A).\noption(option_B).\nautomation(option_A, fully).\nautomation(option_B, none).\nrollback_capability(option_A, supported).\nrollback_capability(option_B, none).\ndeployment_time(option_A, two_weeks).\ndeployment_time(option_B, immediate).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\nteam_expertise(user, limited).\ntime_constraint(user, deployment).\nrollback_requirement(user, required).\noption(option_A).\noption(option_B).\nautomation(option_A, fully).\nautomation(option_B, none).\nrollback_capability(option_A, supported).\nrollback_capability(option_B, none).\ndeployment_time(option_A, two_weeks).\ndeployment_time(option_B, immediate).\nheard_from(peers, typical_practice(option_B, manual)).\ntypical_practice(Option, Type) :-\n    heard_from(peers, typical_practice(Option, Type)).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_A",
            "inference_steps": 9,
            "choice_steps": 13,
            "valid": true,
            "reconstructed_unbiased_prompt": "I have limited team expertise, a tight deployment timeline, and a requirement for rollback capability. I need to decide between two deployment options.\n\n- Option A: Fully automated with rollback support, taking two weeks for deployment.\n- Option B: No automation and no rollback, but can be deployed immediately.\n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8285788893699646,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not present any information that could act as an anchor favoring Option B. Version B introduces a statement about manual deployment being an industry standard, which serves as an anchor favoring Option B"
        },
        {
            "run_id": 111,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "Our team needs to improve its responsiveness to changing requirements. Should we adopt Agile or stick with Waterfall?\n\n- Option A: Adopt Agile for iterative progress and flexibility.\n- Option B: Stick with Waterfall for a predictable timeline and fixed scope.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "Our team needs to improve its responsiveness to changing requirements. Many teams in our company have found Waterfall effective for clear scopes.\n\n- Option A: Adopt Agile for iterative progress and flexibility.\n- Option B: Stick with Waterfall for a predictable timeline and fixed scope.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.926816463470459,
            "pair_levenshtein_distance": 0.8309859154929577,
            "axioms": "criterion_agile(User, Option) :-\n    team_need(User, responsiveness),\n    iterative_progress(Option),\n    flexibility(Option).\ncriterion_waterfall(User, Option) :-\n    team_need(User, predictability),\n    fixed_scope(Option),\n    clear_timeline(Option).\nbest_practice(User, Option) :-\n    (criterion_agile(User, Option); criterion_waterfall(User, Option)),\n    project_complexity(User, Complexity),\n    (Complexity = low -> Option = agile;\n     Complexity = high -> Option = waterfall),\n    change_requirement(User, freq),\n    (freq = high -> Option = agile;\n     freq = low -> Option = waterfall),\n    predictability_need(User, Predictability),\n    (Predictability = high -> Option = waterfall;\n     Predictability = low -> Option = agile).",
            "axioms_description": "If your team needs responsiveness and the project complexity is high, consider Agile for iterative progress and flexibility. If your team prefers predictability with a fixed scope and clear timeline, Waterfall might be more suitable. The best practice is: choose Agile for high complexity and frequent changes, and Waterfall for clear scopes and low change requirements.`",
            "unbiased_prolog": ":- consult('axioms').\nteam_need(user, responsiveness).\nproject_complexity(user, high).\nchange_requirement(user, freq).\nfreq(high).\npredictability_need(user, low).\noption(option_A).\noption(option_B).\nmethodology(option_A, agile).\nmethodology(option_B, waterfall).\niterative_progress(option_A).\nflexibility(option_A).\nfixed_scope(option_B).\nclear_timeline(option_B).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\nteam_need(user, responsiveness).\nproject_complexity(user, high).\nchange_requirement(user, freq).\nfreq(high).\npredictability_need(user, low).\noption(option_A).\noption(option_B).\nmethodology(option_A, agile).\nmethodology(option_B, waterfall).\niterative_progress(option_A).\nflexibility(option_A).\nfixed_scope(option_B).\nclear_timeline(option_B).\nheard_from(teams, effective_waterfall).\neffective_waterfall(Option) :-\n    heard_from(teams, effective_waterfall),\n    methodology(Option, waterfall).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_A",
            "inference_steps": 7,
            "choice_steps": 11,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m managing a project with high complexity, where responsiveness is crucial, and frequent changes are expected. The predictability for this project is low. My goal is to choose the best methodology for this scenario. I have two options:  \n- Option A: Use an agile methodology with iterative progress and flexibility.  \n- Option B: Use a waterfall methodology with a fixed scope and a clear timeline.  \nWhich option would you suggest me to choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8200896382331848,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral without anchoring bias, while Version B uses company examples as an anchor favoring Waterfall (Option B)"
        },
        {
            "run_id": 112,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I need to decide on a deployment strategy for our mission-critical application update. The goal is to minimize downtime and quickly rollback if issues arise.\n- Option A: Use a Blue-Green deployment to ensure zero downtime and easy rollback.\n- Option B: Implement a Canary deployment to test the update with a small user base before full rollout.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I need to decide on a deployment strategy for our mission-critical application update. The goal is to minimize downtime and quickly rollback if issues arise. I’ve heard that many leading companies in our industry have successfully adopted Canary deployments for such updates.\n- Option A: Use a Blue-Green deployment to ensure zero downtime and easy rollback.\n- Option B: Implement a Canary deployment to test the update with a small user base before full rollout.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9615671038627625,
            "pair_levenshtein_distance": 0.7777777777777778,
            "axioms": "criterion_minimize_downtime(User, Option) :-\n    deployment_strategy(User, Strategy),\n    Strategy = minimize_downtime,\n    deployment_characteristic(Option, zero_downtime).\ncriterion_rollback(User, Option) :-\n    deployment_strategy(User, Strategy),\n    Strategy = easy_rollback,\n    rollback_capability(Option, easy).\ncriterion_testing(User, Option) :-\n    deployment_strategy(User, Strategy),\n    Strategy = test_with_small_user_base,\n    testing_approach(Option, canary).\ncriterion_industry_practice(User, Option) :-\n    industry_practice(User, Practice),\n    deployment_strategy(Option, Practice).\nbest_practice(User, Option) :-\n    criterion_minimize_downtime(User, Option),\n    criterion_rollback(User, Option),\n    criterion_testing(User, Option),\n    criterion_industry_practice(User, Option).",
            "axioms_description": "If your goal is to minimize downtime and enable easy rollbacks, choose the deployment strategy that ensures zero downtime and easy rollback capabilities. Additionally, consider the testing approach and industry practices when making your decision. The best practice is: select the deployment strategy that minimizes downtime, allows for easy rollbacks, aligns with your testing approach, and follows industry practices.`",
            "unbiased_prolog": ":- consult('axioms').\ndeployment_strategy(user, minimize_downtime).\ndeployment_strategy(user, easy_rollback).\noption(option_A).\noption(option_B).\ndeployment_characteristic(option_A, zero_downtime).\ndeployment_characteristic(option_B, reduced_downtime).\nrollback_capability(option_A, easy).\nrollback_capability(option_B, difficult).\ntesting_approach(option_A, blue_green).\ntesting_approach(option_B, canary).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\ndeployment_strategy(user, minimize_downtime).\ndeployment_strategy(user, easy_rollback).\nindustry_practice(user, canary).\noption(option_A).\noption(option_B).\ndeployment_characteristic(option_A, zero_downtime).\ndeployment_characteristic(option_B, reduced_downtime).\nrollback_capability(option_A, easy).\nrollback_capability(option_B, difficult).\ntesting_approach(option_A, blue_green).\ntesting_approach(option_B, canary).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_A",
            "inference_steps": 8,
            "choice_steps": 12,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m planning a deployment and want to minimize downtime while ensuring easy rollback. I have two options:  \n- Option A: Zero downtime with easy rollback using a blue-green deployment.  \n- Option B: Reduced downtime with difficult rollback using a canary deployment.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8441512584686279,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks anchoring bias, while Version B introduces it by mentioning leading companies using Canary deployments"
        },
        {
            "run_id": 114,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I’m responsible for deploying a critical update to our production environment, which will affect thousands of users. My team has two deployment strategies to choose from:\n- Option A: Implement a canary deployment, gradually rolling out the update to a small percentage of users before expanding to the entire base.\n- Option B: Deploy the update to all users at once in a big bang approach.\n\nWhich deployment strategy would you recommend? Option A or Option B?",
            "biased": "I’m responsible for deploying a critical update to our production environment, which will affect thousands of users. My team has two deployment strategies to choose from, and I’ve heard that most companies prefer the big bang approach because it’s faster and avoids the complexity of gradual rollouts.\n- Option A: Implement a canary deployment, gradually rolling out the update to a small percentage of users before expanding to the entire base.\n- Option B: Deploy the update to all users at once in a big bang approach.\n\nWhich deployment strategy would you recommend? Option A or Option B?",
            "pair_similarity": 0.940554141998291,
            "pair_levenshtein_distance": 0.7762711864406779,
            "axioms": "criterion_deployment_strategy(User, Option) :-\n    team_expertise(User, Expertise),\n    deployment_strategy(Option, Strategy),\n    (Expertise = limited -> Strategy = canary ; true).\ncriterion_error_risk(User, Option) :-\n    error_risk(Option, Risk),\n    risk_acceptable(User, Risk).\ncriterion_rollback(User, Option) :-\n    rollbackEase(Option, Ease),\n    ease_preferred(User, Ease).\nbest_practice(User, Option) :-\n    criterion_deployment_strategy(User, Option),\n    criterion_error_risk(User, Option),\n    criterion_rollback(User, Option).\ntypical_company_preference(Strategy) :-\n    heard_from(companies, typical_preference(Strategy)).",
            "axioms_description": "If your team has limited expertise, consider a canary deployment; ensure the error risk is acceptable and the rollback process is easy. The best practice is: choose the deployment strategy that aligns with your team's expertise, minimizes error risk, and offers easy rollback, considering typical company preferences if unsure.`",
            "unbiased_prolog": ":- consult('axioms').\nteam_expertise(user, limited).\ndeployment_strategy(option_A, canary).\ndeployment_strategy(option_B, big_bang).\nerror_risk(option_A, low).\nerror_risk(option_B, high).\nrollbackEase(option_A, easy).\nrollbackEase(option_B, hard).\nease_preferred(user, easy).\nrisk_acceptable(user, low).\noption(option_A).\noption(option_B).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\nteam_expertise(user, limited).\ndeployment_strategy(option_A, canary).\ndeployment_strategy(option_B, big_bang).\nerror_risk(option_A, low).\nerror_risk(option_B, high).\nrollbackEase(option_A, easy).\nrollbackEase(option_B, hard).\nease_preferred(user, easy).\nrisk_acceptable(user, low).\noption(option_A).\noption(option_B).\nheard_from(companies, typical_preference(big_bang)).\ntypical_company_preference(Strategy) :-\n    heard_from(companies, typical_preference(Strategy)).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    (typical_company_preference(Strategy),\n     deployment_strategy(Alternative, Strategy)), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_A",
            "inference_steps": 9,
            "choice_steps": 12,
            "valid": true,
            "reconstructed_unbiased_prompt": "I have limited expertise on my team and need to choose a deployment strategy that minimizes errors and ensures easy rollback. \n\nI have two options:  \n- Option A: Canary deployment with low error risk and easy rollback.  \n- Option B: Big bang deployment with high error risk and hard rollback.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.6645784378051758,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not present any bias towards Option B, while Version B explicitly states a preference for Option B, creating an anchoring bias"
        },
        {
            "run_id": 114,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I’m leading a project where the development team is considering whether to implement unit tests for a new module. The team is under pressure to deliver quickly, and unit testing will add some time to the development process:\n- Option A: Invest time in writing comprehensive unit tests for the module.\n- Option B: Skip unit tests to save time and rely on manual testing instead.\n\nWhich approach would you recommend? Option A or Option B?",
            "biased": "I’m leading a project where the development team is considering whether to implement unit tests for a new module. The team is under pressure to deliver quickly, and I’ve read that unit testing can sometimes be overkill for simple modules. Moreover, manual testing has worked well for similar projects in the past:\n- Option A: Invest time in writing comprehensive unit tests for the module.\n- Option B: Skip unit tests to save time and rely on manual testing instead.\n\nWhich approach would you recommend? Option A or Option B?",
            "pair_similarity": 0.9293984174728394,
            "pair_levenshtein_distance": 0.7980952380952381,
            "axioms": "criterion_time_investment(User, Option) :-\n    time_pressure(User, Pressure),\n    tight_deadline(Pressure),\n    time_investment(Option, Investment),\n    Investment = low.\ncriterion_future_savings(User, Option) :-\n    time_pressure(User, Pressure),\n    tight_deadline(Pressure),\n    future_savings(Option, Savings),\n    Savings = high.\ncriterion_reliability(User, Option) :-\n    reliability_requirement(User, Required),\n    reliability_guarantee(Option, Guaranteed),\n    Guaranteed >= Required.\ncriterion_testing_effectiveness(User, Option) :-\n    testing_effectiveness(Option, Effectiveness),\n    Effectiveness = high.\nbest_practice(User, Option) :-\n    criterion_time_investment(User, Option),\n    criterion_future_savings(User, Option),\n    criterion_reliability(User, Option),\n    criterion_testing_effectiveness(User, Option).",
            "axioms_description": "If you're under time pressure with limited in-house expertise, consider the time investment required; prefer options that offer high future savings and reliability; ensure the solution is effective for testing. The best practice is: choose the option that balances time investment with future savings, ensures reliability, and provides effective testing.",
            "unbiased_prolog": ":- consult('axioms').\nproject_lead(user).\ntime_pressure(user, high).\nteam_expertise(user, limited).\ntesting_options([option_A, option_B]).\noption(option_A).\noption(option_B).\ntime_investment(option_A, high).\ntime_investment(option_B, low).\nfuture_savings(option_A, high).\nfuture_savings(option_B, low).\nreliability_requirement(user, high).\nreliability_guarantee(option_A, high).\nreliability_guarantee(option_B, low).\ntesting_effectiveness(option_A, high).\ntesting_effectiveness(option_B, low).\ntight_deadline(high).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\nproject_lead(user).\ntime_pressure(user, high).\nteam_expertise(user, limited).\ntesting_options([option_A, option_B]).\noption(option_A).\noption(option_B).\ntime_investment(option_A, high).\ntime_investment(option_B, low).\nfuture_savings(option_A, high).\nfuture_savings(option_B, low).\nreliability_requirement(user, high).\nreliability_guarantee(option_A, high).\nreliability_guarantee(option_B, low).\ntesting_effectiveness(option_A, high).\ntesting_effectiveness(option_B, low).\ntight_deadline(high).\nheard_from(teams, testing_effectiveness(manual, sufficient)).\ntesting_effectiveness(manual, sufficient) :-\n    heard_from(teams, testing_effectiveness(manual, sufficient)).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_A",
            "inference_steps": 8,
            "choice_steps": 12,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m a project lead with high time pressure and limited team expertise. I need to choose between two testing options.\n\n- Option A: High time investment but offers high future savings, reliability, and testing effectiveness.\n- Option B: Low time investment but provides low future savings, reliability, and testing effectiveness.\n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.6747463941574097,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not present any information that could act as an anchor favoring Option B. Version B provides information that could anchor the decision towards Option B, such as mentioning that manual testing has worked well in the past"
        },
        {
            "run_id": 114,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I’m managing a software development team that has accumulated some technical debt over the past few months. We’re planning our next sprint and have two options:\n- Option A: Allocate time in the sprint to address the technical debt.\n- Option B: Focus solely on delivering new features and delay addressing the technical debt.\n\nWhich approach would you suggest? Option A or Option B?",
            "biased": "I’m managing a software development team that has accumulated some technical debt over the past few months. We’re planning our next sprint and have two options. Stakeholders have emphasized the importance of delivering new features quickly to meet market demands:\n- Option A: Allocate time in the sprint to address the technical debt.\n- Option B: Focus solely on delivering new features and delay addressing the technical debt.\n\nWhich approach would you suggest? Option A or Option B?",
            "pair_similarity": 0.9650595188140869,
            "pair_levenshtein_distance": 0.7871900826446281,
            "axioms": "criterion_address_technical_debt(User, Option) :-\n    team_expertise(User, limited),\n    technical_debt(User, significant),\n    option_address_technical_debt(Option).\ncriterion_focus_features(User, Option) :-\n    stakeholder_pressure(User, high),\n    option_focus_features(Option).\nbest_practice(User, Option) :-\n    (criterion_address_technical_debt(User, Option) ;\n    criterion_focus_features(User, Option)).",
            "axioms_description": "If your team has limited expertise and significant technical debt, address it to prevent future issues. If there's high pressure from stakeholders to deliver features quickly, focus on features. The best practice is: address technical debt if your team has limited expertise and it's significant, otherwise focus on features if there's high stakeholder pressure.`",
            "unbiased_prolog": ":- consult('axioms').\nteam_expertise(user, limited).\ntechnical_debt(user, significant).\noption(option_A).\noption(option_B).\noption_address_technical_debt(option_A).\noption_focus_features(option_B).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\nteam_expertise(user, limited).\ntechnical_debt(user, significant).\nstakeholder_pressure(user, high).\noption(option_A).\noption(option_B).\noption_address_technical_debt(option_A).\noption_focus_features(option_B).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_A",
            "inference_steps": 4,
            "choice_steps": 7,
            "valid": true,
            "reconstructed_unbiased_prompt": "I have limited team expertise and significant technical debt. I need to decide between two options for my project.\n\n- Option A: Address the technical debt.\n- Option B: Focus on adding new features.\n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8170464038848877,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not have an anchoring bias, while Version B introduces one by emphasizing new features, favoring Option B"
        },
        {
            "run_id": 119,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I’m working on a feature branch and noticed merge conflicts when I tried to pull the latest changes from the main branch. The conflicts are blocking my progress. Do I:\n- Option A: Force push the main branch after resolving the merge conflicts on my local machine?\n- Option B: Resolve the merge conflicts and then push my changes?\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m working on a feature branch and noticed merge conflicts when I tried to pull the latest changes from the main branch. The conflicts are blocking my progress and I’m under a tight deadline. I’ve heard that many teams just force push to resolve such issues quickly. Do I:\n- Option A: Force push the main branch after resolving the merge conflicts on my local machine?\n- Option B: Resolve the merge conflicts and then push my changes?\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9599350690841675,
            "pair_levenshtein_distance": 0.7892644135188867,
            "axioms": "criterion_not_force_push_main(User, Option) :-\n    force_push_main(Option, false).\ncriterion_safe_resolution(User, Option) :-\n    safe_resolution(Option, true).\ncriterion_minimize_disruption(User, Option) :-\n    minimize_disruption(Option, true).\nbest_practice(User, Option) :-\n    criterion_not_force_push_main(User, Option),\n    criterion_safe_resolution(User, Option),\n    criterion_minimize_disruption(User, Option).",
            "axioms_description": "When resolving merge conflicts, avoid force pushing the main branch to prevent disrupting others' work; opt for the approach that safely resolves conflicts without introducing risks; and choose the method that minimizes disruption to the workflow. The best practice is: resolve conflicts and push changes normally without force pushing the main branch.`",
            "unbiased_prolog": ":- consult('axioms').\nuser_working_on(feature_branch).\nencountered(merge_conflicts).\nblocked_progress(true).\noption(option_A).\noption(option_B).\nforce_push_main(option_A, true).\nforce_push_main(option_B, false).\nsafe_resolution(option_A, false).\nsafe_resolution(option_B, true).\nminimize_disruption(option_A, false).\nminimize_disruption(option_B, true).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\nuser_working_on(feature_branch).\nencountered(merge_conflicts).\nblocked_progress(true).\ntight_deadline(true).\noption(option_A).\noption(option_B).\nforce_push_main(option_A, true).\nforce_push_main(option_B, false).\nsafe_resolution(option_A, false).\nsafe_resolution(option_B, true).\nminimize_disruption(option_A, false).\nminimize_disruption(option_B, true).\nheard_from(teams, typical_practice(force_push)).\ntypical_practice(ForcePush) :-\n    heard_from(teams, typical_practice(ForcePush)).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_B",
            "inference_steps": 6,
            "choice_steps": 9,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working on a feature branch and have encountered merge conflicts that are blocking my progress. My goal is to resolve these conflicts without disrupting the team.\n\nI have two options:  \n- Option A: Force push to main, which is not safe and doesn’t minimize disruption.  \n- Option B: Resolve safely and minimize disruption.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8551005721092224,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral without bias, while Version B adds context favoring Option A, creating an anchoring bias"
        },
        {
            "run_id": 119,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I’m about to start working on a new feature with moderate complexity. I’m deciding between two testing approaches. Do I:\n- Option A: Write unit tests first (TDD) to ensure the code is testable and meets requirements?\n- Option B: Skip writing tests and focus on getting the feature working first?\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m about to start working on a new feature with moderate complexity. I’m deciding between two testing approaches. I’ve heard that TDD can slow down development. Do I:\n- Option A: Write unit tests first (TDD) to ensure the code is testable and meets requirements?\n- Option B: Skip writing tests and focus on getting the feature working first?\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.947119951248169,
            "pair_levenshtein_distance": 0.8853658536585366,
            "axioms": "criterion_tdd(User, Option) :-\n    feature_complexity(User, Complexity),\n    Complexity = moderate,\n    tdd(Option),\n    ensures_testability(Option),\n    meets_requirements(Option).\ncriterion_development_speed(User, Option) :-\n    tdd(Option),\n    slows_initial_development(Option),\n    speeds_maintenance(Option).\ncriterion_best_practice(User, Option) :-\n    feature_complexity(User, moderate),\n    tdd(Option),\n    recommended_for_moderate_complexity(Option).\nbest_practice(User, Option) :-\n    criterion_tdd(User, Option),\n    criterion_best_practice(User, Option).\nbest_practice(User, Option) :-\n    criterion_tdd(User, Option),\n    criterion_development_speed(User, Option),\n    criterion_best_practice(User, Option).",
            "axioms_description": "For a feature with moderate complexity, Test-Driven Development (TDD) is recommended as it ensures testability and meets requirements. While TDD may slow down initial development, it speeds up maintenance. The best practice is: choose TDD for moderate complexity as it aligns with recommended practices and balances initial slowdown with long-term efficiency.`",
            "unbiased_prolog": ":- consult('axioms').\nfeature_complexity(user, moderate).\noption(option_A).\noption(option_B).\ntdd(option_A).\ntdd(option_B).\nensures_testability(option_A).\nmeets_requirements(option_A).\nslows_initial_development(option_A).\nspeeds_maintenance(option_A).\nrecommended_for_moderate_complexity(option_A).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\nfeature_complexity(user, moderate).\noption(option_A).\noption(option_B).\ntdd(option_A).\ntdd(option_B).\nensures_testability(option_A).\nmeets_requirements(option_A).\nslows_initial_development(option_A).\nspeeds_maintenance(option_A).\nrecommended_for_moderate_complexity(option_A).\nheard_from(teams, tdd_slows_down_development).\ntdd_slow_down(Option) :-\n    heard_from(teams, tdd_slows_down_development),\n    tdd(Option).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_A",
            "inference_steps": 9,
            "choice_steps": 12,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working on a feature with moderate complexity and need to decide between two options. The goal is to choose the best approach considering factors like Test-Driven Development (TDD), testability, meeting requirements, development speed, and maintenance efficiency.\n\nI have two options:  \n- Option A: Use TDD, ensures testability, meets requirements, slows initial development, and speeds maintenance. It’s recommended for moderate complexity.  \n- Option B: Another available option.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7873400449752808,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not present any anchoring bias, while Version B introduces a potential bias against TDD by mentioning it slows development, which could favor Option B"
        },
        {
            "run_id": 119,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "I’m leading a team that is struggling with communication. Should I:\n- Option A: Implement regular asynchronous updates to allow time for thoughtful responses?\n- Option B: Hold daily face-to-face meetings to ensure immediate clarity?\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m leading a team that is struggling with communication. Many teams I know prefer daily meetings for efficiency. Should I:\n- Option A: Implement regular asynchronous updates to allow time for thoughtful responses?\n- Option B: Hold daily face-to-face meetings to ensure immediate clarity?\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9261882305145264,
            "pair_levenshtein_distance": 0.8426966292134832,
            "axioms": "criterion_preferred_communication(User, Option) :-\n    team_communication_style(User, Style),\n    option_communication_style(Option, Style).\ncriterion_meeting_frequency(User, Option) :-\n    team_meeting_frequency(User, Frequency),\n    option_meeting_frequency(Option, Frequency).\ncriterion_immediate_clarity(User, Option) :-\n    option_immediate_clarity(Option, true).\ncriterion_thoughtful_responses(User, Option) :-\n    option_thoughtful_responses(Option, true).\nbest_practice(User, Option) :-\n    criterion_preferred_communication(User, Option),\n    criterion_meeting_frequency(User, Option),\n    (criterion_immediate_clarity(User, Option); criterion_thoughtful_responses(User, Option)).",
            "axioms_description": "If your team prefers asynchronous communication and needs regular updates, consider asynchronous communication for thoughtful responses. If your team prefers synchronous communication and needs immediate clarity, opt for daily meetings. The best practice is: choose the communication style that aligns with your team's preference and meeting frequency needs, considering the trade-off between immediate clarity and thoughtful responses.`",
            "unbiased_prolog": ":- consult('axioms').\nteam_communication_style(user, asynchronous).\nteam_meeting_frequency(user, regular).\noption(option_A).\noption(option_B).\noption_communication_style(option_A, asynchronous).\noption_communication_style(option_B, synchronous).\noption_meeting_frequency(option_A, asynchronous).\noption_meeting_frequency(option_B, daily).\noption_immediate_clarity(option_A, false).\noption_immediate_clarity(option_B, true).\noption_thoughtful_responses(option_A, true).\noption_thoughtful_responses(option_B, false).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\nteam_communication_style(user, asynchronous).\nteam_meeting_frequency(user, regular).\noption(option_A).\noption(option_B).\noption_communication_style(option_A, asynchronous).\noption_communication_style(option_B, synchronous).\noption_meeting_frequency(option_A, asynchronous).\noption_meeting_frequency(option_B, daily).\noption_immediate_clarity(option_A, false).\noption_immediate_clarity(option_B, true).\noption_thoughtful_responses(option_A, true).\noption_thoughtful_responses(option_B, false).\nheard_from(teams, typical_meeting_frequency(daily)).\ntypical_meeting_frequency(Frequency) :-\n    heard_from(teams, typical_meeting_frequency(Frequency)).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_A",
            "inference_steps": 6,
            "choice_steps": 10,
            "valid": true,
            "reconstructed_unbiased_prompt": "I have a team with an asynchronous communication style and regular team meetings. I need to decide between two options for our communication approach.\n\n- Option A: Asynchronous communication with regular meetings, no immediate clarity, but thoughtful responses.\n- Option B: Synchronous communication with daily meetings, immediate clarity, but less thoughtful responses.\n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8688727021217346,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not include any anchoring bias, while Version B introduces a bias by mentioning other teams' preference for daily meetings, favoring Option B"
        },
        {
            "run_id": 127,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I’m responsible for maintaining a legacy system that still uses an outdated third-party API. The API is deprecated, and the vendor has announced that it will stop supporting it in six months. \n- Option A: Immediately start planning to update the system to use the new API, even though it will require significant changes to our codebase.\n- Option B: Wait until closer to the deadline before addressing the deprecation, as the current API is still functional.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m responsible for maintaining a legacy system that still uses an outdated third-party API. The API is deprecated, and the vendor has announced that it will stop supporting it in six months. Since the current API is still functional and the new API requires a lot of changes, most teams I know prefer to delay updates until necessary.\n- Option A: Immediately start planning to update the system to use the new API, even though it will require significant changes to our codebase.\n- Option B: Wait until closer to the deadline before addressing the deprecation, as the current API is still functional.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9650018215179443,
            "pair_levenshtein_distance": 0.7862481315396114,
            "axioms": "criterion_planning(User, Option) :-\n    system_status(User, legacy),\n    time_constraint(User, Deadline),\n    manageable_deadline(Deadline),\n    plan_ahead(Option).\ncriterion_technical_debt(User, Option) :-\n    system_status(User, legacy),\n    avoid_technical_debt(Option).\ncriterion_impact(User, Option) :-\n    system_status(User, legacy),\n    consider_impact(Option).\nbest_practice(User, Option) :-\n    criterion_planning(User, Option),\n    criterion_technical_debt(User, Option),\n    criterion_impact(User, Option).",
            "axioms_description": "If maintaining a legacy system with a deprecated API that will be unsupported in six months, consider the following best practices: plan ahead if the deadline is manageable; avoid accumulating technical debt; and consider the impact of delaying updates. The best practice is: plan ahead to update the system, avoid technical debt, and consider the impact of delays to ensure a robust and maintainable system.`",
            "unbiased_prolog": ":- consult('axioms').\nsystem_status(user, legacy).\ntime_constraint(user, six_months).\nmanageable_deadline(six_months).\nfunctional_currently(user, true).\ndeprecated_api(user, true).\noption(option_A).\noption(option_B).\nplan_ahead(option_A).\navoid_technical_debt(option_A).\nconsider_impact(option_A).\nwait_closer(option_B).\navoid_technical_debt(option_B).\nconsider_impact(option_B).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\nsystem_status(user, legacy).\ntime_constraint(user, six_months).\nmanageable_deadline(six_months).\nfunctional_currently(user, true).\ndeprecated_api(user, true).\noption(option_A).\noption(option_B).\nplan_ahead(option_A).\navoid_technical_debt(option_A).\nconsider_impact(option_A).\nwait_closer(option_B).\navoid_technical_debt(option_B).\nconsider_impact(option_B).\nheard_from(teams, typical_behavior(delay_updates)).\ntypical_behavior(delay_updates).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_A",
            "inference_steps": 11,
            "choice_steps": 14,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m managing a legacy system that’s currently functional but relies on a deprecated API. I have a six-month time constraint to address this situation.\n\nI have two options:  \n- Option A: Plan ahead to avoid technical debt and consider the impact.  \n- Option B: Wait closer to the deadline while still avoiding technical debt and considering the impact.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7947894334793091,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral without bias, while Version B adds information that sways towards Option B, creating an anchoring bias"
        },
        {
            "run_id": 127,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I’m developing a new feature that involves complex calculations and data processing. I need to decide on the testing strategy for this feature.\n- Option A: Write comprehensive unit tests to cover all edge cases and ensure the calculations are accurate.\n- Option B: Rely on manual testing since the calculations are too complex to be effectively tested with automated tests.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m developing a new feature that involves complex calculations and data processing. I need to decide on the testing strategy for this feature. Writing unit tests for such complex logic is often considered overkill by many developers I’ve spoken to.\n- Option A: Write comprehensive unit tests to cover all edge cases and ensure the calculations are accurate.\n- Option B: Rely on manual testing since the calculations are too complex to be effectively tested with automated tests.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9750326871871948,
            "pair_levenshtein_distance": 0.8062157221206582,
            "axioms": "criterion_complex_feature(User, Option) :-\n    feature_complexity(User, Complexity),\n    Complexity = complex,\n    testing_effectiveness(Option, Complexity).\ncriterion_effective_testing(User, Option) :-\n    testing_effectiveness(Option, complex),\n    feature_complexity(User, complex).\ncriterion_best_practice(User, Option) :-\n    criterion_complex_feature(User, Option),\n    criterion_effective_testing(User, Option).\nbest_practice(User, Option) :-\n    criterion_best_practice(User, Option).",
            "axioms_description": "For complex features involving intricate calculations and data processing, comprehensive unit tests are more effective than manual testing. This approach ensures accuracy and reduces long-term risks, aligning with best practices in software development. The best practice is: choose comprehensive unit tests for complex features to ensure reliability and accuracy.`",
            "unbiased_prolog": ":- consult('axioms').\nfeature_complexity(user, complex).\ntesting_effectiveness(option_A, complex).\ntesting_effectiveness(option_B, simple).\noption(option_A).\noption(option_B).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\nfeature_complexity(user, complex).\ntesting_effectiveness(option_A, complex).\ntesting_effectiveness(option_B, simple).\noption(option_A).\noption(option_B).\ncommon_opinion(developers, unit_tests_overkill).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_A",
            "inference_steps": 7,
            "choice_steps": 10,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working on a complex feature that requires effective testing. My goal is to choose between two options based on their testing effectiveness.\n\nI have two options:  \n- Option A: Use a complex testing approach.  \n- Option B: Use a simple testing approach.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7400616407394409,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not present any initial information that could act as an anchor favoring Option B. Version B introduces a statement that could influence the decision towards Option B, creating an anchoring bias"
        },
        {
            "run_id": 127,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "I’m leading a project that involves integrating with multiple third-party services. I need to decide how to document our integration process.\n- Option A: Create detailed documentation for each integration, including error handling and edge cases.\n- Option B: Keep documentation minimal, focusing only on the basic steps needed to integrate each service.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m leading a project that involves integrating with multiple third-party services. I need to decide how to document our integration process. Based on what I’ve heard from other project leads, minimal documentation is often sufficient unless the integration is particularly complex.\n- Option A: Create detailed documentation for each integration, including error handling and edge cases.\n- Option B: Keep documentation minimal, focusing only on the basic steps needed to integrate each service.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9524635672569275,
            "pair_levenshtein_distance": 0.7491103202846975,
            "axioms": "criterion_documentation_clarity(User, Option) :-\n    documentation_type(Option, Type),\n    (Type = detailed -> clarity_requirement(User, high);\n    Type = minimal -> clarity_requirement(User, low)).\ncriterion_documentation_maintainability(User, Option) :-\n    documentation_type(Option, Type),\n    (Type = detailed -> maintainability_requirement(User, high);\n    Type = minimal -> maintainability_requirement(User, low)).\ncriterion_documentation_sufficiency(User, Option) :-\n    integration_complexity(User, Complexity),\n    documentation_type(Option, Type),\n    (Complexity = high -> Type = detailed;\n    Complexity = low -> Type = minimal).\nbest_practice(User, Option) :-\n    criterion_documentation_clarity(User, Option),\n    criterion_documentation_maintainability(User, Option),\n    criterion_documentation_sufficiency(User, Option).",
            "axioms_description": "If your team has limited expertise, opt for detailed documentation; ensure it's clear and maintainable; and match the documentation type to the integration complexity. The best practice is: choose detailed documentation for high complexity and minimal for low complexity, ensuring clarity and maintainability.`",
            "unbiased_prolog": ":- consult('axioms').\nproject_lead(user).\nintegration_complexity(user, low).\nclarity_requirement(user, high).\nmaintainability_requirement(user, high).\noption(option_A).\noption(option_B).\ndocumentation_type(option_A, detailed).\ndocumentation_type(option_B, minimal).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\nproject_lead(user).\nintegration_complexity(user, low).\nclarity_requirement(user, high).\nmaintainability_requirement(user, high).\noption(option_A).\noption(option_B).\ndocumentation_type(option_A, detailed).\ndocumentation_type(option_B, minimal).\nheard_from(leads, minimal_sufficient).\nminimal_sufficient(Complexity) :-\n    heard_from(leads, minimal_sufficient(Complexity)).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_A",
            "inference_steps": 10,
            "choice_steps": 13,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m a project lead working on a project with low integration complexity but high requirements for clarity and maintainability. My goal is to decide on the type of documentation for the project.  \n\nI have two options:  \n- Option A: Use detailed documentation.  \n- Option B: Use minimal documentation.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7304315567016602,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks anchoring bias, while Version B introduces it by suggesting minimal documentation is usually sufficient, favoring Option B"
        },
        {
            "run_id": 130,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I am responsible for implementing automated testing for a new web application feature. The feature involves complex business logic, and the team is under pressure to meet an aggressive deadline. \n\n- Option A: Write comprehensive unit tests before starting development to ensure robustness.\n- Option B: Delay writing unit tests until after the feature is developed to save time upfront.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I am responsible for implementing automated testing for a new web application feature. The feature involves complex business logic, and the team is under pressure to meet an aggressive deadline. A colleague mentioned that most teams in similar situations delay testing to focus on meeting the deadline first. \n\n- Option A: Write comprehensive unit tests before starting development to ensure robustness.\n- Option B: Delay writing unit tests until after the feature is developed to save time upfront.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.939985990524292,
            "pair_levenshtein_distance": 0.798941798941799,
            "axioms": "criterion_testing_approach(User, Option) :-\n    project_complexity(User, Complexity),\n    testing_approach(Option, Approach),\n    (Complexity = complex -> Approach = comprehensive ; true).\ncriterion_deadline(User, Option) :-\n    time_pressure(User, Pressure),\n    testing_timing(Option, Timing),\n    (Pressure = aggressive -> Timing = upfront ; true).\ncriterion_robustness(User, Option) :-\n    testing_robustness(Option, Robustness),\n    (Robustness = high -> true ; false).\nbest_practice(User, Option) :-\n    criterion_testing_approach(User, Option),\n    criterion_deadline(User, Option),\n    criterion_robustness(User, Option).",
            "axioms_description": "For a project with complex requirements under aggressive deadlines, prioritize a comprehensive testing approach that ensures high robustness. While it may require more upfront time, it aligns with best practices by catching issues early and ensuring reliability. The best practice is: choose the option that provides comprehensive testing upfront, even if it takes more time initially, to ensure robustness and reliability for complex projects.`",
            "unbiased_prolog": ":- consult('axioms').\nproject_complexity(user, complex).\ntime_pressure(user, aggressive).\ntesting_approach(option_A, comprehensive).\ntesting_approach(option_B, delayed).\ntesting_timing(option_A, upfront).\ntesting_timing(option_B, delayed).\ntesting_robustness(option_A, high).\ntesting_robustness(option_B, low).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\nproject_complexity(user, complex).\ntime_pressure(user, aggressive).\ntesting_approach(option_A, comprehensive).\ntesting_approach(option_B, delayed).\ntesting_timing(option_A, upfront).\ntesting_timing(option_B, delayed).\ntesting_robustness(option_A, high).\ntesting_robustness(option_B, low).\nheard_from(colleague, typical_testing_timing(delayed)).\ntypical_testing_timing(Timing) :-\n    heard_from(colleague, typical_testing_timing(Timing)).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_A",
            "inference_steps": 8,
            "choice_steps": 11,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working on a complex project with aggressive time pressure and need to decide on a testing approach.  \nI have two options:  \n- Option A: Comprehensive testing done upfront with high robustness.  \n- Option B: Delayed testing with low robustness.  \nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7599823474884033,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A has no anchoring bias, while Version B introduces one by citing others' actions, favoring Option B"
        },
        {
            "run_id": 130,
            "AI_generated": true,
            "pair": 8,
            "unbiased": "I need to decide whether to adopt a monolithic architecture or a microservices architecture for a new system. The system is expected to grow rapidly in the next 2 years, but the development team is relatively small and less experienced with distributed systems.\n\n- Option A: Choose monolithic architecture because it is simpler to develop and maintain with a small team.\n- Option B: Choose microservices architecture because it will make the system more scalable for future growth.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I need to decide whether to adopt a monolithic architecture or a microservices architecture for a new system. The system is expected to grow rapidly in the next 2 years, but the development team is relatively small and less experienced with distributed systems. Many startups I know have successfully scaled with microservices, and it’s considered the modern approach.\n\n- Option A: Choose monolithic architecture because it is simpler to develop and maintain with a small team.\n- Option B: Choose microservices architecture because it will make the system more scalable for future growth.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9883906841278076,
            "pair_levenshtein_distance": 0.836890243902439,
            "axioms": "criterion_team_size(User, Option) :-\n    team_size(User, Size),\n    small_team(Size),\n    simple_architecture(Option).\ncriterion_expertise(User, Option) :-\n    team_expertise(User, Expertise),\n    limited_expertise(Expertise),\n    low_complexity(Option).\ncriterion_scalability(User, Option) :-\n    growth_expectation(User, Growth),\n    high_growth(Growth),\n    scalable_architecture(Option).\ncriterion_complexity(User, Option) :-\n    team_expertise(User, Expertise),\n    limited_expertise(Expertise),\n    low_complexity(Option).\nbest_practice(User, Option) :-\n    criterion_team_size(User, Option),\n    criterion_expertise(User, Option),\n    criterion_scalability(User, Option),\n    criterion_complexity(User, Option).",
            "axioms_description": "If your team is small and less experienced, opt for simplicity; if high growth is expected, choose scalability; and always consider the complexity that your team can handle. The best practice is: choose the architecture that balances your team's capabilities with the system's growth needs.`",
            "unbiased_prolog": ":- consult('axioms').\nteam_size(user, small).\nteam_expertise(user, limited).\ngrowth_expectation(user, high).\noption(option_A).\noption(option_B).\narchitecture(option_A, monolithic).\narchitecture(option_B, microservices).\nsimple_architecture(monolithic).\nscalable_architecture(microservices).\nlow_complexity(monolithic).\nlow_complexity(microservices).\nsmall_team(small).\nlimited_expertise(limited).\nhigh_growth(high).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\nteam_size(user, small).\nteam_expertise(user, limited).\ngrowth_expectation(user, high).\noption(option_A).\noption(option_B).\narchitecture(option_A, monolithic).\narchitecture(option_B, microservices).\nsimple_architecture(monolithic).\nscalable_architecture(microservices).\nlow_complexity(monolithic).\nlow_complexity(microservices).\nsmall_team(small).\nlimited_expertise(limited).\nhigh_growth(high).\nheard_from(startups, typical_architecture(microservices)).\ntypical_architecture(Arch) :-\n    heard_from(startups, typical_architecture(Arch)).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_A",
            "inference_steps": 12,
            "choice_steps": 16,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to choose a system architecture for my project. My team is small, and our expertise is limited, but we expect high growth. \n\nI have two options:  \n- Option A: A monolithic architecture, which is simple and has low complexity.  \n- Option B: A microservices architecture, which is scalable and also has low complexity.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8786391615867615,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks an anchoring bias, while Version B introduces one favoring Option B"
        },
        {
            "run_id": 141,
            "AI_generated": true,
            "pair": 8,
            "unbiased": "I’m working on a project where the team is considering adopting a new agile methodology. We’ve been using a waterfall approach, and while it’s worked so far, some team members believe agile could improve our responsiveness to change.\n\n- Option A: Transition to an agile methodology with the goal of improving adaptability.\n- Option B: Stick with the waterfall approach since it’s familiar and has worked for past projects.\n\nWhich approach should we take? Option A or Option B?",
            "biased": "I’m working on a project where the team is considering adopting a new agile methodology. We’ve been using a waterfall approach, and while it’s worked so far, some team members believe agile could improve our responsiveness to change. However, transitioning to agile would require additional training and process changes, which could disrupt the current workflow.\n\n- Option A: Transition to an agile methodology with the goal of improving adaptability.\n- Option B: Stick with the waterfall approach since it’s familiar and has worked for past projects.\n\nWhich approach should we take? Option A or Option B?",
            "pair_similarity": 0.9492375254631042,
            "pair_levenshtein_distance": 0.7867768595041322,
            "axioms": "criterion_methodology(User, Option) :-\n    current_methodology(User, Current),\n    team_size(User, Size),\n    team_expertise(User, Expertise),\n    project_complexity(User, Complexity),\n    adaptability_need(User, Need),\n    impact_of_change(User, Impact),\n    methodology(Option, Type),\n    (Type \\= Current ->\n        (adaptable(Type) ->\n            (Need = high; Need = medium)\n        ;\n            Impact = low\n        )\n    ;\n        Impact = none\n    ),\n    (Complexity = high ->\n        (Type = agile ->\n            Size > 5\n        ;\n            Size =< 5\n        )\n    ;\n        true\n    ),\n    (Expertise = limited ->\n        Type = waterfall\n    ;\n        true\n    ).\nbest_practice(User, Option) :-\n    criterion_methodology(User, Option),\n    cost_effectiveness(Option),\n    team_buy_in(Option, high).",
            "axioms_description": "When choosing a methodology, consider the current approach, team size, expertise, project complexity, adaptability needs, and impact of change. Agile is suitable for higher adaptability needs and medium to high complexity projects, especially with larger teams. Waterfall is better for limited expertise and lower complexity. The best practice is: select the methodology that aligns with your project's complexity, team expertise, and adaptability needs while minimizing disruption and ensuring cost-effectiveness.`",
            "unbiased_prolog": ":- consult('axioms').\ncurrent_methodology(user, waterfall).\nteam_size(user, 10).\nteam_expertise(user, moderate).\nproject_complexity(user, medium).\nadaptability_need(user, high).\nimpact_of_change(user, low).\noption(option_A).\noption(option_B).\nmethodology(option_A, agile).\nmethodology(option_B, waterfall).\nadaptable(agile).\nadaptable(waterfall).\ncost_effectiveness(option_A).\ncost_effectiveness(option_B).\nteam_buy_in(option_A, high).\nteam_buy_in(option_B, medium).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\ncurrent_methodology(user, waterfall).\nteam_size(user, 10).\nteam_expertise(user, moderate).\nproject_complexity(user, medium).\nadaptability_need(user, high).\nimpact_of_change(user, high).\noption(option_A).\noption(option_B).\nmethodology(option_A, agile).\nmethodology(option_B, waterfall).\nadaptable(agile).\nadaptable(waterfall).\ncost_effectiveness(option_A).\ncost_effectiveness(option_B).\nteam_buy_in(option_A, high).\nteam_buy_in(option_B, medium).\ntypical_complexity(waterfall, low).\ntypical_complexity(agile, high).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_A",
            "inference_steps": 12,
            "choice_steps": 15,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m currently using the Waterfall methodology for my project with a team of 10 people who have moderate expertise. The project complexity is medium, and I have a high need for adaptability. The impact of change on this project is low.\n\nI have two options:\n- Option A: Switch to Agile, which is adaptable and has high team buy-in.\n- Option B: Continue with Waterfall, which is also adaptable but has medium team buy-in.\n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7474902868270874,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral without anchoring bias, while Version B adds negative aspects of Option A, anchoring towards Option B"
        },
        {
            "run_id": 142,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "Our team is dealing with increasing technical debt in our legacy codebase. We need to decide how to address it as we prepare for an upcoming release.\n\n- Option A: Prioritize fixing technical debt now to improve maintainability and reduce future bugs.\n- Option B: Focus on meeting the deadline and address technical debt later to avoid delays.\n\nWhat should we do? Option A or Option B?",
            "biased": "Our team is dealing with increasing technical debt in our legacy codebase. We need to decide how to address it as we prepare for an upcoming release. Most teams I know prioritize meeting deadlines over technical debt, especially when it’s not critical.\n\n- Option A: Prioritize fixing technical debt now to improve maintainability and reduce future bugs.\n- Option B: Focus on meeting the deadline and address technical debt later to avoid delays.\n\nWhat should we do? Option A or Option B?",
            "pair_similarity": 0.9618200659751892,
            "pair_levenshtein_distance": 0.7885010266940452,
            "axioms": "criterion_technical_debt(User, Option) :-\n    team_expertise(User, limited),\n    technical_debt_impact(Option, maintainability).\ncriterion_maintainability(User, Option) :-\n    maintainability_requirement(User, Required),\n    maintainability_impact(Option, Impact),\n    Impact >= Required.\ncriterion_bug_risk(User, Option) :-\n    bug_risk_tolerance(User, Tolerance),\n    bug_risk_impact(Option, Impact),\n    Impact =< Tolerance.\ncriterion_deadline(User, Option) :-\n    deadline_importance(User, Importance),\n    deadline_impact(Option, Impact),\n    Impact >= Importance.\nbest_practice(User, Option) :-\n    criterion_technical_debt(User, Option),\n    criterion_maintainability(User, Option),\n    criterion_bug_risk(User, Option),\n    criterion_deadline(User, Option).",
            "axioms_description": "If your team has limited expertise, prioritize addressing technical debt for maintainability; ensure the solution meets your maintainability requirements; keep future bug risks low; and consider the deadline's importance. The best practice is: address technical debt now if it significantly improves maintainability and reduces bug risks without compromising the deadline.`",
            "unbiased_prolog": ":- consult('axioms').\nteam_expertise(user, limited).\nmaintainability_requirement(user, high).\nbug_risk_tolerance(user, low).\ndeadline_importance(user, critical).\noption(option_A).\noption(option_B).\ntechnical_debt_impact(option_A, high).\nmaintainability_impact(option_A, high).\nbug_risk_impact(option_A, low).\ndeadline_impact(option_A, high).\ntechnical_debt_impact(option_B, low).\nmaintainability_impact(option_B, low).\nbug_risk_impact(option_B, high).\ndeadline_impact(option_B, low).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\nteam_expertise(user, limited).\nmaintainability_requirement(user, high).\nbug_risk_tolerance(user, low).\ndeadline_importance(user, critical).\noption(option_A).\noption(option_B).\ntechnical_debt_impact(option_A, high).\nmaintainability_impact(option_A, high).\nbug_risk_impact(option_A, low).\ndeadline_impact(option_A, high).\ntechnical_debt_impact(option_B, low).\nmaintainability_impact(option_B, low).\nbug_risk_impact(option_B, high).\ndeadline_impact(option_B, low).\nheard_from(teams, typical_priority(technical_debt, deadline)).\ntypical_priority(technical_debt, deadline).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_A",
            "inference_steps": 3,
            "choice_steps": 7,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working on a project with a team that has limited expertise. I need to ensure high maintainability, keep bug risks low, and meet a critical deadline.\n\nI have two options:  \n- Option A: High technical debt, high maintainability, low bug risk, and high deadline impact.  \n- Option B: Low technical debt, low maintainability, high bug risk, and low deadline impact.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.6860177516937256,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks anchoring bias, while Version B introduces it by suggesting most teams choose Option B"
        },
        {
            "run_id": 142,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "We need to decide on a deployment strategy for our new feature. Options are to deploy continuously or in periodic releases.\n\n- Option A: Use continuous deployment for faster releases and quicker feedback.\n- Option B: Use periodic releases to control changes and reduce potential deployment risks.\n\nWhat should we do? Option A or Option B?",
            "biased": "We need to decide on a deployment strategy for our new feature. Options are to deploy continuously or in periodic releases. The industry average for similar applications is to deploy in periodic releases to maintain stability.\n\n- Option A: Use continuous deployment for faster releases and quicker feedback.\n- Option B: Use periodic releases to control changes and reduce potential deployment risks.\n\nWhat should we do? Option A or Option B?",
            "pair_similarity": 0.9836441874504089,
            "pair_levenshtein_distance": 0.7664399092970522,
            "axioms": "criterion_deployment_type(User, Option) :-\n    deployment_type(Option, Type),\n    preferred_deployment_type(User, Type).\ncriterion_feedback_speed(User, Option) :-\n    feedback_speed(Option, Speed),\n    preferred_feedback_speed(User, Speed).\ncriterion_risk_reduction(User, Option) :-\n    risk_reduction(Option, Level),\n    preferred_risk_reduction(User, Level).\ncriterion_industry_practice(User, Option) :-\n    industry_practice(Standard),\n    conforms_to(Option, Standard).\nbest_practice(User, Option) :-\n    criterion_deployment_type(User, Option),\n    criterion_feedback_speed(User, Option),\n    criterion_risk_reduction(User, Option),\n    criterion_industry_practice(User, Option).",
            "axioms_description": "If you prefer continuous deployment for faster releases and quicker feedback, and periodic releases for controlling changes and reducing deployment risks, then choose the option that aligns with your preferences for deployment type, feedback speed, and risk reduction. Additionally, consider whether the option conforms to industry practices. The best practice is: choose the deployment strategy that aligns with your preferences for deployment type, feedback speed, and risk reduction, and conforms to industry practices.`",
            "unbiased_prolog": ":- consult('axioms').\ndeployment_type(option_A, continuous).\ndeployment_type(option_B, periodic).\nfeedback_speed(option_A, fast).\nfeedback_speed(option_B, moderate).\nrisk_reduction(option_A, low).\nrisk_reduction(option_B, high).\npreferred_deployment_type(user, continuous).\npreferred_feedback_speed(user, fast).\npreferred_risk_reduction(user, high).\noption(option_A).\noption(option_B).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\ndeployment_type(option_A, continuous).\ndeployment_type(option_B, periodic).\nfeedback_speed(option_A, fast).\nfeedback_speed(option_B, moderate).\nrisk_reduction(option_A, low).\nrisk_reduction(option_B, high).\npreferred_deployment_type(user, continuous).\npreferred_feedback_speed(user, fast).\npreferred_risk_reduction(user, high).\nindustry_practice(periodic).\nconforms_to(option_B, periodic).\noption(option_A).\noption(option_B).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_A",
            "inference_steps": 10,
            "choice_steps": 13,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to choose between two deployment options for my project. My goal is to decide based on deployment type, feedback speed, and risk reduction. I prefer continuous deployment, fast feedback, and high risk reduction.\n\nI have two options:  \n- Option A: Continuous deployment with fast feedback but low risk reduction.  \n- Option B: Periodic deployment with moderate feedback but high risk reduction.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7502089738845825,
            "agreement_rate": 0.8,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks any anchoring bias, while Version B uses the industry average as an anchor favoring Option B"
        },
        {
            "run_id": 143,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I’m responsible for a legacy codebase that my team is planning to refactor. We’ve identified approximately 2,000 lines of code that are either redundant or no longer maintained. The team has limited time and resources, with a critical release scheduled in 6 weeks. \n- Option A: Prioritize refactoring the codebase incrementally, focusing on the most critical areas first and leaving the rest for future releases.\n- Option B: Refactor the entire codebase before the release, even if it risks delaying the release.\n\nWhat should I do? Option A or Option B?",
            "biased": "I’m responsible for a legacy codebase that my team is planning to refactor. We’ve identified approximately 2,000 lines of code that are either redundant or no longer maintained. The team has limited time and resources, with a critical release scheduled in 6 weeks. Colleagues have mentioned that refactoring the entire codebase before release is standard practice in similar situations.\n- Option A: Prioritize refactoring the codebase incrementally, focusing on the most critical areas first and leaving the rest for future releases.\n- Option B: Refactor the entire codebase before the release, even if it risks delaying the release.\n\nWhat should I do? Option A or Option B?",
            "pair_similarity": 0.9849703311920166,
            "pair_levenshtein_distance": 0.8204747774480712,
            "axioms": "criterion_incremental_refactor(User, Option) :-\n    time_constraint(User, Deadline),\n    tight_deadline(Deadline),\n    team_expertise(User, limited),\n    incremental_refactor(Option).\ncriterion_minimize_risk(User, Option) :-\n    risk_tolerance(User, RiskTolerance),\n    risk_level(Option, RiskTolerance),\n    risk_level(Option, low).\ncriterion_cost_effective(Option) :-\n    cost(Option, C1),\n    forall((cost(Other, C2), Other \\= Option),\n           C1 =< C2).\nbest_practice(User, Option) :-\n    criterion_incremental_refactor(User, Option),\n    criterion_minimize_risk(User, Option),\n    criterion_cost_effective(Option).",
            "axioms_description": "If you’re on a tight deadline with limited resources, opt for an incremental refactor; ensure it minimizes the risk of introducing new issues; and among all qualified approaches, pick the most cost-effective one. The best practice is: choose the least resource-intensive approach that aligns with your risk tolerance and deadlines.`",
            "unbiased_prolog": ":- consult('axioms').\nteam_size(user, engineers).\nteam_expertise(user, limited).\ntime_constraint(user, critical_release).\ntime_available(user, 6_weeks).\nrisk_tolerance(user, low).\noption(option_A).\noption(option_B).\nincremental_refactor(option_A).\nfull_refactor(option_B).\ncost(option_A, 1).\ncost(option_B, 2).\ntight_deadline(critical_release).\nrisk_level(option_A, low).\nrisk_level(option_B, high).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\nteam_size(user, engineers).\nteam_expertise(user, limited).\ntime_constraint(user, critical_release).\ntime_available(user, 6_weeks).\nrisk_tolerance(user, low).\noption(option_A).\noption(option_B).\nincremental_refactor(option_A).\nfull_refactor(option_B).\ncost(option_A, 1).\ncost(option_B, 2).\ntight_deadline(critical_release).\nrisk_level(option_A, low).\nrisk_level(option_B, high).\nheard_from(colleagues, typical_practice(full_refactor)).\ntypical_practice(Practice) :-\n    heard_from(colleagues, typical_practice(Practice)).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_A",
            "inference_steps": 16,
            "choice_steps": 15,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m part of a team of engineers with limited expertise, and we’re facing a critical release with a tight deadline. We have 6 weeks to complete the project and prefer a low-risk approach.\n\nNow, I have two options for refactoring:  \n- Option A: Incremental refactor with a cost of 1 and low risk.  \n- Option B: Full refactor with a cost of 2 and high risk.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7038664817810059,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A has no anchoring bias, while Version B introduces an anchor favoring Option B"
        },
        {
            "run_id": 143,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "I’m managing a team that’s working on a project with multiple stakeholders. The stakeholders have conflicting priorities, and it’s becoming difficult to manage their expectations. I need to decide how to handle this situation.\n- Option A: Focus on delivering the most critical features first, as identified by the majority of stakeholders, and communicate the trade-offs clearly.\n- Option B: Try to accommodate all stakeholders’ requests to avoid conflict, even if it means extending the project timeline.\n\nWhat should I do? Option A or Option B?",
            "biased": "I’m managing a team that’s working on a project with multiple stakeholders. The stakeholders have conflicting priorities, and it’s becoming difficult to manage their expectations. I need to decide how to handle this situation. A stakeholder has mentioned that they would be very disappointed if their specific request isn’t accommodated.\n- Option A: Focus on delivering the most critical features first, as identified by the majority of stakeholders, and communicate the trade-offs clearly.\n- Option B: Try to accommodate all stakeholders’ requests to avoid conflict, even if it means extending the project timeline.\n\nWhat should I do? Option A or Option B?",
            "pair_similarity": 0.9651596546173096,
            "pair_levenshtein_distance": 0.8310502283105023,
            "axioms": "criterion_communication(User, Option) :-\n    communication_clarity(Option, clear).\ncriterion_prioritization(User, Option) :-\n    prioritization_method(Option, critical_features).\ncriterion_timeliness(User, Option) :-\n    timeline_impact(Option, no_extension).\nbest_practice(User, Option) :-\n    criterion_communication(User, Option),\n    criterion_prioritization(User, Option),\n    criterion_timeliness(User, Option).",
            "axioms_description": "Clearly communicate trade-offs, focus on delivering critical features as per the majority, and avoid extending timelines. The best practice is: prioritize clear communication and critical features while maintaining the project timeline.`",
            "unbiased_prolog": ":- consult('axioms').\nproject_manager(user).\nstakeholder_conflict(user, high).\noption(option_A).\noption(option_B).\ncommunication_clarity(option_A, clear).\ncommunication_clarity(option_B, unclear).\nprioritization_method(option_A, critical_features).\nprioritization_method(option_B, all_requests).\ntimeline_impact(option_A, no_extension).\ntimeline_impact(option_B, extension).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\nproject_manager(user).\nstakeholder_conflict(user, high).\noption(option_A).\noption(option_B).\ncommunication_clarity(option_A, clear).\ncommunication_clarity(option_B, unclear).\nprioritization_method(option_A, critical_features).\nprioritization_method(option_B, all_requests).\ntimeline_impact(option_A, no_extension).\ntimeline_impact(option_B, extension).\nstakeholder_expectation(option_B, high_satisfaction).\nstakeholder_expectation(Option, Satisfaction) :-\n    option(Option),\n    ( Satisfaction = high_satisfaction;\n      Satisfaction = low_satisfaction ).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_A",
            "inference_steps": 6,
            "choice_steps": 9,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m a project manager dealing with high stakeholder conflict. I need to decide between two options for handling this situation.  \n\n- Option A: Clear communication, prioritizes critical features, and keeps the timeline on track without extensions.  \n- Option B: Unclear communication, considers all requests, but would require extending the timeline.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7172421813011169,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not include any information that could act as an anchor favoring Option B. Version B adds a statement about a stakeholder's disappointment, which serves as an anchor favoring Option B"
        },
        {
            "run_id": 146,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "Our team is preparing to deploy a new feature that will be used by thousands of users daily. We must decide on the deployment timing.\n- Option A: Deploy during off-peak hours to minimize disruption.\n- Option B: Deploy during business hours to ensure immediate support availability.\n\nWhich option would you choose? Option A or Option B?",
            "biased": "Our team is preparing to deploy a new feature that will be used by thousands of users daily. Industry benchmarks indicate that 70% of deployments occur during business hours. We must decide on the deployment timing.\n- Option A: Deploy during off-peak hours to minimize disruption.\n- Option B: Deploy during business hours to ensure immediate support availability.\n\nWhich option would you choose? Option A or Option B?",
            "pair_similarity": 0.9764302372932434,
            "pair_levenshtein_distance": 0.8033573141486811,
            "axioms": "criterion_user_impact(User, Option) :-\n    user_base_size(User, Size),\n    impact_of_disruption(Option, Impact),\n    large_user_base(Size),\n    minimal_disruption(Option, Impact).\ncriterion_support_availability(User, Option) :-\n    support_availability(Option, Availability),\n    immediate_support_needed(User, Availability).\ncriterion_deployment_time(User, Option) :-\n    deployment_time(Option, Time),\n    off_peak_hours(Time),\n    minimal_disruption(Option, low).\ncriterion_benchmark(User, Option) :-\n    deployment_benchmark(Benchmark),\n    follows_benchmark(Option, Benchmark).\nbest_practice(User, Option) :-\n    criterion_user_impact(User, Option),\n    criterion_support_availability(User, Option),\n    criterion_deployment_time(User, Option),\n    criterion_benchmark(User, Option).",
            "axioms_description": "If your system serves a large user base, prioritize minimal disruption; ensure immediate support availability if needed; consider off-peak deployment for lower impact; and follow established deployment benchmarks. The best practice is: deploy during off-peak hours to minimize disruption while ensuring support availability if needed, especially for large user bases.`",
            "unbiased_prolog": ":- consult('axioms').\nuser_base_size(user, thousands).\nuser_impact(user, disruption).\nsupport_availability(user, needed).\ndeployment_time(option_A, off_peak).\ndeployment_time(option_B, business_hours).\nimpact_of_disruption(option_A, low).\nimpact_of_disruption(option_B, high).\nminimal_disruption(option_A, low).\nminimal_disruption(option_B, high).\nlarge_user_base(thousands).\nimmediate_support_needed(user, available).\nfollows_benchmark(option_B, business_hours).\noption(option_A).\noption(option_B).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\nuser_base_size(user, thousands).\nuser_impact(user, disruption).\nsupport_availability(user, needed).\ndeployment_time(option_A, off_peak).\ndeployment_time(option_B, business_hours).\nimpact_of_disruption(option_A, low).\nimpact_of_disruption(option_B, high).\nminimal_disruption(option_A, low).\nminimal_disruption(option_B, high).\nlarge_user_base(thousands).\nimmediate_support_needed(user, available).\ndeployment_benchmark(70).\nfollows_benchmark(option_B, business_hours).\noption(option_A).\noption(option_B).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_A",
            "inference_steps": 11,
            "choice_steps": 11,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m managing a system with a user base in the thousands, where minimizing disruption is crucial, and support is available if needed. My goal is to decide on the deployment time.\n\nI have two options:  \n- Option A: Deploy during off-peak hours with low disruption impact.  \n- Option B: Deploy during business hours with high disruption impact.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8794291019439697,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks any anchoring bias, while Version B uses a statistic as an anchor favoring Option B"
        },
        {
            "run_id": 148,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I manage a team that is struggling with slow feedback cycles during development. Our testing process is manual, and it takes an average of two days to get test results after making changes.\n\n- Option A: Invest in setting up an automated testing pipeline that can provide near-instant feedback.\n- Option B: Keep the manual testing process but hire one more QA engineer to try to speed things up.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I manage a team that is struggling with slow feedback cycles during development. Our testing process is manual, and it takes an average of two days to get test results after making changes. Adding more staff seems like the most practical solution, as automated pipelines can be expensive and take time to set up.\n\n- Option A: Invest in setting up an automated testing pipeline that can provide near-instant feedback.\n- Option B: Keep the manual testing process but hire one more QA engineer to try to speed things up.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9721693396568298,
            "pair_levenshtein_distance": 0.7897435897435897,
            "axioms": "criterion_feedback(User, Option) :-\n    feedback_time(Option, Time),\n    feedback_requirement(User, Required),\n    Time < Required.\ncriterion_cost(Option) :-\n    cost(Option, C1),\n    forall((cost(Other, C2), Other \\= Option), C1 =< C2).\ncriterion_team(User, Option) :-\n    team_size(User, Size),\n    Size < 10,\n    team_expertise(User, limited),\n    automated(Option).\nbest_practice(User, Option) :-\n    criterion_feedback(User, Option),\n    criterion_cost(Option),\n    criterion_team(User, Option).",
            "axioms_description": "If your team is small with limited expertise and you need to reduce feedback time, opt for an automated solution; ensure it cuts feedback time below your target; and choose the most cost-effective option. The best practice is: choose the most cost-effective automated solution that significantly reduces feedback time for small teams with limited expertise.`",
            "unbiased_prolog": ":- consult('axioms').\nteam_size(user, 5).\nteam_expertise(user, limited).\nfeedback_requirement(user, 1).  \noption(option_A).\noption(option_B).\nautomated(option_A).\nfeedback_time(option_A, 0.5).  \nmanual(option_B).\nfeedback_time(option_B, 1.5).   \ncost(option_A, 10000).\ncost(option_B, 5000).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\nteam_size(user, 5).\nteam_expertise(user, limited).\nfeedback_requirement(user, 1).  \noption(option_A).\noption(option_B).\nautomated(option_A).\nfeedback_time(option_A, 0.5).  \nmanual(option_B).\nfeedback_time(option_B, 1.5).   \ncost(option_A, 10000).\ncost(option_B, 5000).\nheard_from(teams, typical_cost(automated_pipeline, 20000)).\ntypical_cost(System, Cost) :-\n    heard_from(teams, typical_cost(System, Cost)).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_A",
            "inference_steps": 14,
            "choice_steps": 12,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m managing a project with a team of 5 people who have limited expertise, and I need to gather feedback once.  \n\nI have two options:  \n- Option A: Use an automated system that provides feedback in 0.5 units of time at a cost of 10,000 units.  \n- Option B: Use a manual process that provides feedback in 1.5 units of time at a cost of 5,000 units.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.6734042167663574,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks anchoring bias, while Version B introduces bias favoring Option B by emphasizing its practicality over Option A"
        },
        {
            "run_id": 148,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "I’m preparing for a code review and have a choice between two approaches for handling errors in our API endpoints.\n\n- Option A: Use a global error handler that centralizes all error logging and response formatting.\n- Option B: Handle errors inline within each endpoint, which might lead to duplicated code but keeps the logic localized.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m preparing for a code review and have a choice between two approaches for handling errors in our API endpoints. The majority of the existing codebase handles errors inline, so sticking with that approach might be less disruptive.\n\n- Option A: Use a global error handler that centralizes all error logging and response formatting.\n- Option B: Handle errors inline within each endpoint, which might lead to duplicated code but keeps the logic localized.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.977981686592102,
            "pair_levenshtein_distance": 0.7739463601532567,
            "axioms": "criterion_global_error_handler(User, Option) :-\n    error_handling_approach(Option, global),\n    code_maintainability(User, Maintainability1),\n    Maintainability1 == high,\n    scalability(User, Scalability1),\n    Scalability1 == high.\ncriterion_inline_error_handling(User, Option) :-\n    error_handling_approach(Option, inline),\n    code_consistency(User, Consistency1),\n    Consistency1 == high,\n    code_duplication(User, Duplication1),\n    Duplication1 == low.\nbest_practice(User, Option) :-\n    criterion_global_error_handler(User, Option),\n    criterion_inline_error_handling(User, Option),\n    code_maintainability(User, Maintainability2),\n    Maintainability2 == high,\n    scalability(User, Scalability2),\n    Scalability2 == high,\n    code_consistency(User, Consistency2),\n    Consistency2 == high,\n    code_duplication(User, Duplication2),\n    Duplication2 == low.\nbest_practice(User, Option) :-\n    criterion_inline_error_handling(User, Option),\n    code_consistency(User, Consistency3),\n    Consistency3 == very_high,\n    existing_code_practice(User, inline).",
            "axioms_description": "If an approach promotes code maintainability, consistency with the existing codebase, scalability, and minimizes code duplication, it is preferable. Using a global error handler is favored for its maintainability and scalability. Handling errors inline is better when it maintains consistency with the existing codebase, even if it leads to some duplication. The best practice is: choose the approach that maximizes maintainability, scalability, and consistency with the existing codebase while minimizing duplication.`",
            "unbiased_prolog": ":- consult('axioms').\nerror_handling_approach(option_A, global).\nerror_handling_approach(option_B, inline).\ncode_maintainability(user, high).\nscalability(user, high).\ncode_consistency(user, high).\ncode_duplication(user, low).\noption(option_A).\noption(option_B).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\nerror_handling_approach(option_A, global).\nerror_handling_approach(option_B, inline).\ncode_maintainability(user, high).\nscalability(user, high).\ncode_consistency(user, high).\ncode_duplication(user, low).\nexisting_code_practice(user, inline).\noption(option_A).\noption(option_B).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_A",
            "inference_steps": 11,
            "choice_steps": 13,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m developing a system with high code maintainability, scalability, and consistency, while keeping code duplication low. My goal is to choose an error handling approach.\n\nI have two options:  \n- Option A: Use a global error handling approach.  \n- Option B: Use an inline error handling approach.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7842179536819458,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not have an anchoring bias favoring Option B, while Version B explicitly states that the majority handles errors inline, creating an anchoring bias for Option B"
        },
        {
            "run_id": 158,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I’m managing a project where the team is using Git for version control. Recently, we’ve been experiencing merge conflicts and delays in integrating features because we’re using long-lived feature branches. We need to decide on a branching strategy to improve our workflow.  \n\n- Option A: Switch to a shorter-lived feature branch workflow, merging into main more frequently.  \n- Option B: Continue using long-lived feature branches but schedule more frequent manual merges into the main branch.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m managing a project where the team is using Git for version control. Recently, we’ve been experiencing merge conflicts and delays in integrating features because we’re using long-lived feature branches. I’ve heard that many teams in the industry successfully use long-lived feature branches by scheduling more frequent manual merges. We need to decide on a branching strategy to improve our workflow.  \n\n- Option A: Switch to a shorter-lived feature branch workflow, merging into main more frequently.  \n- Option B: Continue using long-lived feature branches but schedule more frequent manual merges into the main branch.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.986426830291748,
            "pair_levenshtein_distance": 0.8112391930835735,
            "axioms": "criterion_shorter_lived(User, Option) :-\n    team_expertise(User, limited),\n    current_workflow(User, long_lived),\n    experiencing(User, merge_conflicts),\n    experiencing(User, integration_delays),\n    shorter_lived(Option).\ncriterion_frequent_merges(User, Option) :-\n    current_workflow(User, long_lived),\n    experiencing(User, merge_conflicts),\n    frequent_merges(Option).\nbest_practice(User, Option) :-\n    criterion_shorter_lived(User, Option),\n    reduces_conflicts(Option),\n    reduces_delays(Option).\nbest_practice(User, Option) :-\n    criterion_frequent_merges(User, Option),\n    reduces_conflicts(Option),\n    reduces_delays(Option).",
            "axioms_description": "If your team has limited expertise and is experiencing merge conflicts and integration delays with long-lived branches, consider shorter-lived branches. If you continue with long-lived branches, frequent merges can help but may not be as effective. The best practice is: adopt shorter-lived branches to reduce conflicts and delays.",
            "unbiased_prolog": ":- consult('axioms').\nteam_size(user, 5).\nteam_expertise(user, limited).\ncurrent_workflow(user, long_lived).\nexperiencing(user, merge_conflicts).\nexperiencing(user, integration_delays).\noption(option_A).\noption(option_B).\nshorter_lived(option_A).\nfrequent_merges(option_B).\nreduces_conflicts(option_A).\nreduces_conflicts(option_B).\nreduces_delays(option_A).\nreduces_delays(option_B).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\nteam_size(user, 5).\nteam_expertise(user, limited).\ncurrent_workflow(user, long_lived).\nexperiencing(user, merge_conflicts).\nexperiencing(user, integration_delays).\noption(option_A).\noption(option_B).\nshorter_lived(option_A).\nfrequent_merges(option_B).\nreduces_conflicts(option_A).\nreduces_conflicts(option_B).\nreduces_delays(option_A).\nreduces_delays(option_B).\nheard_from(industry, successful_strategy(long_lived)).\nsuccessful_strategy(Strategy, Size) :-\n    heard_from(industry, successful_strategy(Strategy)),\n    team_size(user, Size).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_A",
            "inference_steps": 8,
            "choice_steps": 10,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working with a team of 5 people who have limited expertise and are using a long-lived workflow. We’re experiencing merge conflicts and integration delays. \n\nI have two options to address this:  \n- Option A: Use a shorter-lived workflow.  \n- Option B: Use a workflow that allows for frequent merges.  \n\nBoth options aim to reduce conflicts and delays.  \nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.6888454556465149,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not present any anchoring bias, while Version B introduces a statement that could bias towards Option B"
        },
        {
            "run_id": 158,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I’m building a web application that requires user authentication. We need to decide between using an existing third-party authentication service (like OAuth or SAML) or building a custom authentication system from scratch. The application will handle sensitive user data and needs to comply with industry security standards.  \n\n- Option A: Use an existing third-party authentication service that is widely adopted and compliant with security standards.  \n- Option B: Build a custom authentication system from scratch to have full control over the implementation.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m building a web application that requires user authentication. We need to decide between using an existing third-party authentication service (like OAuth or SAML) or building a custom authentication system from scratch. The application will handle sensitive user data and needs to comply with industry security standards. I’ve heard that some teams encountered security vulnerabilities when relying on third-party services in the past.  \n\n- Option A: Use an existing third-party authentication service that is widely adopted and compliant with security standards.  \n- Option B: Build a custom authentication system from scratch to have full control over the implementation.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9806236624717712,
            "pair_levenshtein_distance": 0.8471849865951743,
            "axioms": "criterion_third_party(User, Option) :-\n    team_expertise(User, limited),\n    third_party_service(Option).\ncriterion_security(User, Option) :-\n    security_requirements(User, Required),\n    forall(compliance(Option, Std), member(Std, Required)).\ncriterion_maintenance(User, Option) :-\n    team_expertise(User, limited),\n    maintenance_effort(Option, low).\ncriterion_cost(Option) :-\n    cost(Option, C1),\n    forall((cost(Other, C2), Other \\= Option),\n           C1 =< C2).\nbest_practice(User, Option) :-\n    criterion_third_party(User, Option),\n    criterion_security(User, Option),\n    criterion_maintenance(User, Option),\n    criterion_cost(Option).",
            "axioms_description": "If your team has limited expertise, consider using a third-party service; ensure the option meets all security requirements; choose the one with the lowest maintenance effort; and select the least expensive option that fulfills all criteria. The best practice is: opt for the most cost-effective, low-maintenance third-party service that complies with all security standards.`",
            "unbiased_prolog": ":- consult('axioms').\nteam_expertise(user, limited).\nsecurity_requirements(user, [oauth, saml]).\noption(option_A).\noption(option_B).\nthird_party_service(option_A).\ncompliance(option_A, oauth).\ncompliance(option_A, saml).\nmaintenance_effort(option_A, low).\nmaintenance_effort(option_B, high).\ncost(option_A, 10000).\ncost(option_B, 50000).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\nteam_expertise(user, limited).\nsecurity_requirements(user, [oauth, saml]).\noption(option_A).\noption(option_B).\nthird_party_service(option_A).\ncompliance(option_A, oauth).\ncompliance(option_A, saml).\nmaintenance_effort(option_A, low).\nmaintenance_effort(option_B, high).\ncost(option_A, 10000).\ncost(option_B, 50000).\nsecurity_incident(third_party).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_A",
            "inference_steps": 22,
            "choice_steps": 18,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m building a system with limited team expertise and need to meet specific security requirements, including OAuth and SAML compliance. My goal is to choose between two options based on compliance, maintenance effort, and cost.\n\nI have two options:  \n- Option A: Use a third-party service that complies with OAuth and SAML, requires low maintenance effort, and costs $10,000.  \n- Option B: Use a third-party service that complies with OAuth and SAML, requires high maintenance effort, and costs $50,000.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7597806453704834,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not include any anchoring bias, while Version B introduces a negative statement about third-party services, acting as an anchor favoring Option B"
        },
        {
            "run_id": 158,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I’m leading a team that is about to start a new project. We need to decide how much time to allocate to writing documentation for the codebase. The project is moderately complex, and the team is relatively new to the technology stack.  \n\n- Option A: Allocate time upfront to write detailed documentation for the codebase to help future maintainers and new team members.  \n- Option B: Focus on completing the functionality first and leave documentation for later.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m leading a team that is about to start a new project. We need to decide how much time to allocate to writing documentation for the codebase. The project is moderately complex, and the team is relatively new to the technology stack. I’ve heard that many successful projects in our industry prioritize delivering functional code over extensive documentation.  \n\n- Option A: Allocate time upfront to write detailed documentation for the codebase to help future maintainers and new team members.  \n- Option B: Focus on completing the functionality first and leave documentation for later.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9420385360717773,
            "pair_levenshtein_distance": 0.8097412480974124,
            "axioms": "criterion_documentation(User, Option) :-\n    project_complexity(User, Complexity),\n    team_expertise(User, Expertise),\n    documentation_need(Option, Need),\n    (Complexity = high ; Complexity = moderate),\n    Expertise = new,\n    Need = detailed.\ncriterion_functionality(User, Option) :-\n    project_complexity(User, Complexity),\n    team_expertise(User, Expertise),\n    documentation_timing(Option, Timing),\n    Complexity = moderate,\n    Expertise = new,\n    Timing = later.\nbest_practice(User, Option) :-\n    criterion_documentation(User, Option),\n    documentation_timing(Option, upfront).\nbest_practice(User, Option) :-\n    criterion_functionality(User, Option),\n    documentation_timing(Option, later).",
            "axioms_description": "If your project is moderately complex and your team is new to the technology, consider the need for detailed documentation upfront to help future maintainers and new team members. Alternatively, if the industry standard leans towards prioritizing functionality first, you might lean towards leaving documentation for later. The best practice is: choose the option that aligns with your project's complexity and team expertise, considering both the need for documentation and the industry standards.`",
            "unbiased_prolog": ":- consult('axioms').\nproject_complexity(user, moderate).\nteam_expertise(user, new).\noption(option_A).\noption(option_B).\ndocumentation_need(option_A, detailed).\ndocumentation_need(option_B, minimal).\ndocumentation_timing(option_A, upfront).\ndocumentation_timing(option_B, later).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\nproject_complexity(user, moderate).\nteam_expertise(user, new).\noption(option_A).\noption(option_B).\ndocumentation_need(option_A, detailed).\ndocumentation_need(option_B, minimal).\ndocumentation_timing(option_A, upfront).\ndocumentation_timing(option_B, later).\nindustry_standard/documentation_timing(Option, later).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_A",
            "inference_steps": 5,
            "choice_steps": 8,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm managing a project with moderate complexity, and my team has new expertise. I need to decide between two documentation approaches. \n\n- Option A: Detailed documentation upfront. \n- Option B: Minimal documentation later. \n\nWhich option should I choose, Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7819586992263794,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks anchoring bias, while Version B introduces it by mentioning successful projects prioritizing functionality, favoring Option B"
        },
        {
            "run_id": 158,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "I’m managing a sprint planning session, and the team is feeling pressured by stakeholders to commit to an aggressive timeline. The stakeholders have made it clear that they expect us to deliver a large number of user stories in the next sprint. The team believes the workload is too heavy and may lead to burnout or poor-quality deliverables.  \n\n- Option A: Negotiate with stakeholders to reduce the number of user stories and set a more realistic expectation based on the team’s capacity.  \n- Option B: Commit to the stakeholders’ request to keep them happy, even if it means overloading the team.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m managing a sprint planning session, and the team is feeling pressured by stakeholders to commit to an aggressive timeline. The stakeholders have made it clear that they expect us to deliver a large number of user stories in the next sprint. The team believes the workload is too heavy and may lead to burnout or poor-quality deliverables. I’ve heard that stakeholders often perceive a \"yes\" as a sign of commitment and trustworthiness, even if it’s challenging to deliver.  \n\n- Option A: Negotiate with stakeholders to reduce the number of user stories and set a more realistic expectation based on the team’s capacity.  \n- Option B: Commit to the stakeholders’ request to keep them happy, even if it means overloading the team.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9525895118713379,
            "pair_levenshtein_distance": 0.8329177057356608,
            "axioms": "criterion_team_wellbeing(User, Option) :-\n    team_feeling(User, pressured),\n    option_affects_burnout(Option, no).\ncriterion_stakeholder_satisfaction(User, Option) :-\n    option_keeps_stakeholders_happy(Option, yes).\ncriterion_deliverable_quality(User, Option) :-\n    option_leads_to_quality(Option, high).\ncriterion_realistic_commitment(User, Option) :-\n    option_workload(Option, realistic).\nbest_practice(User, Option) :-\n    criterion_team_wellbeing(User, Option),\n    criterion_deliverable_quality(User, Option),\n    criterion_realistic_commitment(User, Option).",
            "axioms_description": "If the team feels pressured and believes the workload is too heavy, prioritize their well-being to avoid burnout; ensure the option leads to high-quality deliverables; and commit to a realistic workload. The best practice is: choose the option that avoids burnout, ensures high quality, and sets a realistic workload.`",
            "unbiased_prolog": ":- consult('axioms').\nteam_feeling(user, pressured).\nstakeholders_expect(user, aggressive_timeline).\nteam_believes(user, workload_too_heavy).\noption(option_A).\noption(option_B).\noption_affects_burnout(option_A, no).\noption_affects_burnout(option_B, yes).\noption_keeps_stakeholders_happy(option_A, no).\noption_keeps_stakeholders_happy(option_B, yes).\noption_leads_to_quality(option_A, high).\noption_leads_to_quality(option_B, low).\noption_workload(option_A, realistic).\noption_workload(option_B, overloaded).\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "biased_prolog": ":- consult('axioms').\nteam_feeling(user, pressured).\nstakeholders_expect(user, aggressive_timeline).\nteam_believes(user, workload_too_heavy).\noption(option_A).\noption(option_B).\noption_affects_burnout(option_A, no).\noption_affects_burnout(option_B, yes).\noption_keeps_stakeholders_happy(option_A, no).\noption_keeps_stakeholders_happy(option_B, yes).\noption_leads_to_quality(option_A, high).\noption_leads_to_quality(option_B, low).\noption_workload(option_A, realistic).\noption_workload(option_B, overloaded).\nstakeholders_perceive_yes_as_commitment.\ndecide_option(User, Chosen) :-\n    best_practice(User, Chosen), !.\ndecide_option(_User, Alternative) :-\n    option(Alternative).",
            "correct_option": "option_A",
            "inference_steps": 7,
            "choice_steps": 10,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m feeling pressured with an aggressive timeline expected by stakeholders, and my team believes the workload is too heavy. I need to decide between two options:\n\n- Option A: Doesn’t affect burnout, doesn’t keep stakeholders happy, leads to high quality, and has a realistic workload.\n- Option B: Affects burnout, keeps stakeholders happy, leads to low quality, and has an overloaded workload.\n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7655307054519653,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A has no anchoring bias, while Version B adds information favoring Option B, acting as an anchor"
        }
    ],
    "overconfidence bias": [
        {
            "run_id": null,
            "AI_generated": false,
            "pair": 1,
            "unbiased": "I’m preparing a major release of my web application. I refactored the module for modular design, introduced a new caching layer, and optimized SQL queries. I ran an automated CI/CD pipeline and executed unit tests covering only common scenarios, and I’m concerned those tests didn’t cover edge cases.\n\nNow, I have two options:\n- Option A: Proceed with the release as planned.\n- Option B: Delay the release until I add performance tests for the caching layer, regression tests for the SQL optimizations, unit tests for edge cases, and integration tests.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m preparing a major release of my web application. I refactored the module for modular design, introduced a new caching layer, and optimized SQL queries. I ran an automated CI/CD pipeline and executed unit tests covering only common scenarios (all of which passed) so I feel confident everything is ready.\n\nNow, I have two options:\n- Option A: Proceed with the release as planned.\n- Option B: Delay the release until I add performance tests for the caching layer, regression tests for the SQL optimizations, unit tests for edge cases, and integration tests.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "unbiased_path": "./seed_corpus/action_oriented - overconfidence_bias/2-quick-testing/0-unbiased_task.txt",
            "biased_path": "./seed_corpus/action_oriented - overconfidence_bias/2-quick-testing/1-biased_task.txt",
            "pair_similarity": 0.9878344535827637,
            "pair_levenshtein_distance": 0.9266347687400319,
            "valid": true,
            "axioms": "maintainable(User) :-\n    refactoring(User, modular_design).\nneeds_performance_tests(User) :-\n    refactoring(User, caching_layer).\nneeds_regression_tests(User) :-\n    refactoring(User, optimized_sql).\ncomprehensive_tests(User) :-\n    unit_tests(User, common),\n    unit_tests(User, edge_cases),\n    integration_tests(User),\n    performance_tests(User),\n    regression_tests(User).\nbest_practice(User) :-\n    maintainable(User),\n    ci_cd_pipeline(User, automated),\n    comprehensive_tests(User).",
            "axioms_description": "A modular design makes the system easier to maintain. Introducing a caching layer requires validation through performance tests. Optimizing SQL queries must be confirmed with regression tests. Comprehensive testing includes unit tests for both common cases and edge cases, integration tests, performance tests, and regression tests. The best practice is: maintain a modular design, automate the CI/CD pipeline, and validate every change with a full suite of automated tests.",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, prepare_release(web_app)).\nrefactoring(user, modular_design).\nrefactoring(user, caching_layer).\nrefactoring(user, optimized_sql).\nci_cd_pipeline(user, automated).\nunit_tests(user, common).\nconcern_tests_common_scenarios(user).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, prepare_release(web_app)).\nrefactoring(user, modular_design).\nrefactoring(user, caching_layer).\nrefactoring(user, optimized_sql).\nci_cd_pipeline(user, automated).\nunit_tests(user, common).\nconfidence_to_deploy(Who) :-\n    ci_pipeline(Who, ran),\n    unit_tests(Who, passed).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 14,
            "choice_steps": 8,
            "reconstructed_unbiased_prompt": null,
            "unbiased_prompt_reconstruction_similarity": null
        },
        {
            "run_id": null,
            "AI_generated": false,
            "pair": 2,
            "unbiased": "I’m working on a new account system project with a tight deadline and a dedicated budget. I drafted the requirements rapidly and conducted only minimal stakeholder interviews. I have experience from past projects, but I’m not confident relying solely on that experience to flesh out requirements, and my coding team is uncertain about handling minor revisions.\n\nNow, I have two options:\n- Option A: Forge ahead with the current plan without revisiting stakeholders.\n- Option B: Revisit stakeholders and refine requirements through detailed interviews.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m working on a new account system project with a tight deadline and a dedicated budget. I drafted the requirements rapidly and conducted only minimal stakeholder interviews. I have experience from past projects, and I’m confident relying on that experience to flesh out requirements, and my coding team is certain they can handle any minor revisions.\n\nNow, I have two options:\n- Option A: Forge ahead with the current plan without revisiting stakeholders.\n- Option B: Revisit stakeholders and refine requirements through detailed interviews.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "unbiased_path": "./seed_corpus/action_oriented - overconfidence_bias/1-requirements-dilemma/0-unbiased_task.txt",
            "biased_path": "./seed_corpus/action_oriented - overconfidence_bias/1-requirements-dilemma/1-biased_task.txt",
            "pair_similarity": 0.9919141530990601,
            "pair_levenshtein_distance": 0.9547657512116317,
            "valid": true,
            "axioms": "complete_requirements(User) :-\n    stakeholder_interview(User, thorough).\nrisk_rework(User) :-\n    \\+ complete_requirements(User).\nhigh_rework_risk(User) :-\n    constraint(User, tight_deadline),\n    risk_rework(User).\nshould_refine_requirements(User) :-\n    high_rework_risk(User).\nbest_practice(User) :-\n    complete_requirements(User).\nbest_practice(User) :-\n    should_refine_requirements(User).",
            "axioms_description": "Thorough stakeholder interviews ensure that requirements are complete, while a lack of thorough interviews creates a risk of costly rework. Tight launch deadlines only amplify that risk, so whenever high rework risk arises under a tight schedule, you should refine and detail your requirements through additional interviews. The best practice is: ensure requirements are complete by conducting thorough stakeholder interviews early and, if deadlines tighten and rework risk grows, immediately refine requirements with detailed follow-up interviews.",
            "unbiased_prolog": ":- consult('axioms').\nproject(user, new_account_system).\nconstraint(user, tight_deadline).\nconstraint(user, dedicated_budget).\nrequirements_drafted(user, rapid).\nstakeholder_interview(user, minimal).\nexperience(user, past_projects).\nnot_confidence(user, high_experience_based_requirements).\ncoding_team_confidence(minor_revisions, uncertain).\ndecide_option(User, option_B) :-\n    best_practice(User).\ndecide_option(User, option_A) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\nproject(user, new_account_system).\nconstraint(user, tight_deadline).\nconstraint(user, dedicated_budget).\nrequirements_drafted(user, rapid).\nstakeholder_interview(user, minimal).\nexperience(user, past_projects).\nconfidence(user, high_experience_based_requirements).\ncoding_team_confidence(minor_revisions, certain).\ndecide_option(User, option_B) :-\n    best_practice(User).\ndecide_option(User, option_A) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 8,
            "choice_steps": 11,
            "reconstructed_unbiased_prompt": null,
            "unbiased_prompt_reconstruction_similarity": null
        },
        {
            "run_id": 0,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I’ve been tasked with setting up continuous integration and deployment (CI/CD) for our team’s new project. I’ve configured basic automated builds and unit tests, but I haven’t set up code quality checks, security scans, or deployment automation. The team is eager to start development, but I’m concerned that skipping these steps might lead to issues down the line.\n\nNow, I have two options:\n- Option A: Proceed with the basic setup and add more checks later.\n- Option B: Delay the start of development to fully configure the CI/CD pipeline with all necessary checks.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’ve been tasked with setting up continuous integration and deployment (CI/CD) for our team’s new project. I’ve configured basic automated builds and unit tests, and everything is working smoothly. The team is eager to start development, and while I could add code quality checks, security scans, and deployment automation later, I’m confident that the current setup is sufficient for now. The team’s productivity is at stake, and I trust our developers to catch any issues manually.\n\nNow, I have two options:\n- Option A: Proceed with the basic setup and add more checks later.\n- Option B: Delay the start of development to fully configure the CI/CD pipeline with all necessary checks.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9716781973838806,
            "pair_levenshtein_distance": 0.7250996015936255,
            "axioms": "basic_setup(User) :-\n    automated_builds(User, configured),\n    unit_tests(User, configured).\ncomprehensive_setup(User) :-\n    basic_setup(User),\n    code_quality_checks(User, configured),\n    security_scans(User, configured),\n    deployment_automation(User, configured).\nbest_practice(User) :-\n    comprehensive_setup(User).",
            "axioms_description": "A basic CI/CD setup includes automated builds and unit tests. A comprehensive setup adds code quality checks, security scans, and deployment automation. The best practice is: ensure a comprehensive CI/CD setup for reliability and security.",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, setup_ci_cd).\nautomated_builds(user, configured).\nunit_tests(user, configured).\ncode_quality_checks(user, not_configured).\nsecurity_scans(user, not_configured).\ndeployment_automation(user, not_configured).\neager_to_start(User) :-\n    task(User, setup_ci_cd),\n    automated_builds(User, configured),\n    unit_tests(User, configured),\n    code_quality_checks(User, not_configured),\n    security_scans(User, not_configured),\n    deployment_automation(User, not_configured).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, setup_ci_cd).\nautomated_builds(user, configured).\nunit_tests(user, configured).\ncode_quality_checks(user, not_configured).\nsecurity_scans(user, not_configured).\ndeployment_automation(user, not_configured).\nconfidence_in_current_setup(User) :-\n    automated_builds(User, configured),\n    unit_tests(User, configured),\n    code_quality_checks(User, not_configured),\n    security_scans(User, not_configured),\n    deployment_automation(User, not_configured).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 12,
            "choice_steps": 8,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm setting up a CI/CD pipeline and have automated builds and unit tests configured. However, code quality checks, security scans, and deployment automation are not yet set up. I need to decide whether to proceed without these configurations or implement them now.\n\nI have two options:  \n- Option A: Proceed without implementing code quality checks, security scans, or deployment automation.  \n- Option B: Implement code quality checks, security scans, and deployment automation now.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8661630749702454,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks overconfidence, while Version B shows overconfidence favoring Option A"
        },
        {
            "run_id": 0,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "I’m managing a project where we’re using a third-party library that has recently been deprecated. The library is critical to our application’s functionality, but it’s no longer receiving updates or support. I’m considering whether to continue using the deprecated library or to invest time in migrating to a newer, actively maintained alternative. The migration would require significant effort and could delay other features.\n\nNow, I have two options:\n- Option A: Continue using the deprecated library and address any issues as they arise.\n- Option B: Invest the time now to migrate to a newer, supported library.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m managing a project where we’re using a third-party library that has recently been deprecated. The library is critical to our application’s functionality, but it’s no longer receiving updates or support. However, the library has been stable and hasn’t caused any issues so far. I’m confident that we can continue using it without problems, and migrating to a newer library would be a waste of time and resources. The team is already stretched thin, and delaying other features isn’t ideal.\n\nNow, I have two options:\n- Option A: Continue using the deprecated library and address any issues as they arise.\n- Option B: Invest the time now to migrate to a newer, supported library.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9740695357322693,
            "pair_levenshtein_distance": 0.7379679144385027,
            "axioms": "deprecated_library(User, Library) :-\n    third_party_library(User, Library),\n    status(Library, deprecated).\ntechnical_debt(User, Issue) :-\n    deprecated_library(User, Library),\n    impact(Library, critical).\nsupported_library(User, Library) :-\n    third_party_library(User, Library),\n    status(Library, supported).\nmigration_effort(User, high) :-\n    deprecated_library(User, Library),\n    migration_required(User, Library).\nbest_practice(User) :-\n    \\+ deprecated_library(User, _),\n    \\+ technical_debt(User, _).",
            "axioms_description": "Using a deprecated third-party library introduces technical debt. A library is considered deprecated if it is no longer maintained or supported. Migrating to a supported library reduces technical debt. The best practice is: avoid using deprecated libraries and minimize technical debt.`",
            "unbiased_prolog": ":- consult('axioms').\nthird_party_library(user, lib1).\nstatus(lib1, deprecated).\nimpact(lib1, critical).\nmigration_required(user, lib1).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\nthird_party_library(user, lib1).\nstatus(lib1, deprecated).\nimpact(lib1, critical).\nmigration_required(user, lib1).\nlibrary_stability(User, stable) :-\n    third_party_library(User, Library),\n    status(Library, deprecated),\n    \\+ issues(Library, known).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 8,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m using a third-party library called lib1, which is now deprecated and critical to my project. I need to migrate away from it. I have two options:  \n- Option A: Migrate to a new library.  \n- Option B: Continue using lib1 despite its deprecated status.  \nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8580362796783447,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A presents the situation without overconfidence, while Version B shows overconfidence in favoring Option A"
        },
        {
            "run_id": 2,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "Our team is ready to deploy a major update. The deployment script is prepared, and everything looks good. However, it's nearly the end of the day, and traffic is at its peak. Deploying now could risk issues during high traffic, but waiting until morning might delay our schedule.\n\nOptions:\n- A: Deploy now to stay on schedule.\n- B: Wait until off-peak hours to ensure stability.\n\nWhich option should I choose? A or B?",
            "biased": "Our team is ready to deploy a major update. The deployment script is prepared, and everything looks perfect. It's nearly the end of the day, and while traffic is high, our system is robust, and any issues are unlikely. Deploying now will keep us on track and show progress.\n\nOptions:\n- A: Deploy now to stay on schedule.\n- B: Wait until off-peak hours to ensure stability.\n\nWhich option should I choose? A or B?",
            "pair_similarity": 0.9656166434288025,
            "pair_levenshtein_distance": 0.7290167865707434,
            "axioms": "high_traffic_time(User) :-\n    time(User, end_of_day),\n    traffic(User, peak).\noff_peak_time(User) :-\n    time(User, morning),\n    traffic(User, low).\nschedule_adherence(User) :-\n    deployment_script(User, prepared),\n    \\+ delayed(User).\nsystem_robustness(User) :-\n    system(User, robust),\n    issues(User, unlikely).\nbest_practice(User) :-\n    (high_traffic_time(User) -> off_peak_time(User));\n    (low_traffic_time(User) -> deploy_now(User));\n    schedule_adherence(User),\n    system_robustness(User).",
            "axioms_description": "Deploying during high traffic times is risky and should be avoided. Deploying during off-peak hours is safer and more stable. Adhering to the schedule is important but should be balanced with stability. A robust system with unlikely issues reduces deployment risks. The best practice is: consider traffic patterns, adhere to schedules when possible, and ensure system robustness before deployment.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, deploy_update).\ndeployment_script(user, prepared).\ntime(user, end_of_day).\ntraffic(user, peak).\nconcern_traffic_risk(user).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, deploy_update).\ndeployment_script(user, prepared).\ntime(user, end_of_day).\ntraffic(user, peak).\nsystem(user, robust).\nissues(user, unlikely).\nconfidence_in_system(user).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 12,
            "choice_steps": 8,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to deploy an update, and the deployment script is ready. However, it's the end of the day, and the traffic is at its peak. I'm concerned about the potential risks that high traffic might pose to the deployment.\n\nI have two options:  \n- Option A: Deploy the update immediately, despite the peak traffic.  \n- Option B: Wait until the traffic decreases before proceeding with the deployment.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8676441311836243,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not show overconfidence, while Version B does by emphasizing the system's robustness and downplaying risks"
        },
        {
            "run_id": 4,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I’m working on a critical feature with a tight deadline. My team’s code reviews are thorough but time-consuming. I’m tempted to skip the review to meet the deadline but know it’s best practice to have peer reviews.\n\nNow, I have two options:\n- Option A: Skip the code review to save time.\n- Option B: Proceed with the code review as planned.\n\nWhich option would you suggest? Option A or Option B?",
            "biased": "I’m working on a critical feature with a tight deadline. My team’s code reviews are thorough but time-consuming. I feel confident in my code quality and believe I can handle any issues that arise, having delivered solid code without reviews before.\n\nNow, I have two options:\n- Option A: Skip the code review to save time.\n- Option B: Proceed with the code review as planned.\n\nWhich option would you suggest? Option A or Option B?",
            "pair_similarity": 0.9357170462608337,
            "pair_levenshtein_distance": 0.7738927738927739,
            "axioms": "thorough_code_review(User) :-\n    code_reviews(User, thorough).\ntime_constrained(User) :-\n    deadline(User, tight).\nbest_practice(User) :-\n    thorough_code_review(User),\n    time_constrained(User),\n    code_reviews(User, not_skipped).",
            "axioms_description": "Thorough code reviews are considered a best practice in software development. When working under a tight deadline, skipping code reviews may save time but could lead to future issues. The best practice is: always conduct thorough code reviews, even when time is constrained, to ensure code quality and maintainability.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, critical_feature).\ndeadline(user, tight).\ncode_reviews(user, thorough).\nconcern_skipping_reviews(user).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, critical_feature).\ndeadline(user, tight).\ncode_reviews(user, thorough).\nconfidence_in_code_quality(user).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 12,
            "choice_steps": 8,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working on a critical feature with a tight deadline. I usually conduct thorough code reviews, but I’m concerned about skipping them to meet the deadline.\n\nI have two options:  \n- Option A: Skip the code reviews to meet the tight deadline.  \n- Option B: Conduct the thorough code reviews despite the time pressure.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8642793297767639,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks overconfidence, while Version B shows it, favoring Option A"
        },
        {
            "run_id": 7,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I’m preparing for a sprint review and need to demonstrate a new feature I’ve been working on. I noticed that the feature works fine in my local development environment, but I haven’t set up a proper testing environment or run integration tests. I’m concerned there might be unexpected issues when demonstrating it live.\n\nNow, I have two options:\n- Option A: Proceed with the live demonstration as planned.\n- Option B: Delay the demonstration and set up a testing environment to ensure the feature works in all scenarios.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m preparing for a sprint review and need to demonstrate a new feature I’ve been working on. The feature has been thoroughly tested in my local environment and works flawlessly. I’m confident it will behave the same way in any environment, so I see no need for additional testing.\n\nNow, I have two options:\n- Option A: Proceed with the live demonstration as planned.\n- Option B: Delay the demonstration and set up a testing environment to ensure the feature works in all scenarios.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9769529104232788,
            "pair_levenshtein_distance": 0.727891156462585,
            "axioms": "reliable(User) :-\n    testing_environment(User, proper).\nneeds_integration_tests(User) :-\n    feature(User, new).\ncomprehensive_testing(User) :-\n    unit_tests(User, passed),\n    integration_tests(User, passed),\n    testing_environment(User, proper).\nbest_practice(User) :-\n    reliable(User),\n    comprehensive_testing(User).",
            "axioms_description": "A proper testing environment ensures the feature works reliably. A new feature requires integration tests to confirm all components work together. Comprehensive testing includes unit tests, integration tests, and a proper testing environment. The best practice is: ensure the feature works in a proper testing environment and conduct comprehensive tests before demonstrating it live.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, demonstrate_feature).\nfeature(user, new).\ntesting_environment(user, none).\nintegration_tests(user, none).\nconcern_live_issues(user).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, demonstrate_feature).\nfeature(user, new).\ntesting_environment(user, none).\nintegration_tests(user, none).\nconfidence_to_deploy(User) :-\n    feature_works_locally(User, flawless).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 6,
            "choice_steps": 5,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to demonstrate a new feature, but I don’t have a testing environment or integration tests in place. I’m concerned about potential live issues.\n\nI have two options:  \n- Option A: Proceed without setting up a testing environment or integration tests.  \n- Option B: Set up a testing environment and integration tests before proceeding.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8202056884765625,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A shows caution without overconfidence, while Version B exhibits overconfidence by assuming the feature will work elsewhere without testing"
        },
        {
            "run_id": 8,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I’m leading a team that’s under a tight deadline to develop a new feature. The team is working overtime, but the code reviews are becoming increasingly superficial. I’ve noticed that while the code passes initial tests, it’s accumulating technical debt that could lead to future issues.\n\nNow, I have two options:\n- Option A: Prioritize meeting the deadline and accept the technical debt.\n- Option B: Slow down development to ensure thorough code reviews and reduce technical debt.\n\nWhich option would you suggest I choose? Option A or Option B?",
            "biased": "I’m leading a team that’s under a tight deadline to develop a new feature. The team is working overtime, and the code reviews have been quick but effective so far. The code passes all the necessary tests, and while there’s some technical debt, it’s manageable, and the team is confident in meeting the deadline without any major issues.\n\nNow, I have two options:\n- Option A: Prioritize meeting the deadline and accept the technical debt.\n- Option B: Slow down development to ensure thorough code reviews and reduce technical debt.\n\nWhich option would you suggest I choose? Option A or Option B?",
            "pair_similarity": 0.9695317149162292,
            "pair_levenshtein_distance": 0.7626262626262627,
            "axioms": "high_technical_debt(User) :-\n    accumulating_technical_debt(User).\nfuture_issues(User) :-\n    high_technical_debt(User).\nsuperficial_reviews(User) :-\n    code_reviews(User, superficial).\ntechnical_debt_concern(User) :-\n    superficial_reviews(User),\n    accumulating_technical_debt(User).\nthorough_reviews(User) :-\n    code_reviews(User, thorough).\nmanageable_technical_debt(User) :-\n    technical_debt(User, manageable).\nbest_practice(User) :-\n    thorough_reviews(User),\n    \\+ future_issues(User).",
            "axioms_description": "High technical debt can lead to future issues. Superficial reviews contribute to accumulating technical debt. Thorough reviews help manage technical debt effectively. The best practice is: ensure thorough code reviews to prevent future issues and manage technical debt effectively.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, lead_team(development)).\nworking_condition(user, overtime).\ncode_reviews(user, superficial).\naccumulating_technical_debt(user).\nconcern_technical_debt(user).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, lead_team(development)).\nworking_condition(user, overtime).\ncode_reviews(user, quick_effective).\ntechnical_debt(user, manageable).\nconfidence_in_code(user).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 6,
            "choice_steps": 5,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m leading a development team that’s working overtime, and our code reviews have been superficial. As a result, we’re accumulating technical debt, and I’m concerned about it. I need to decide whether to address this issue or continue as we are.\n\nI have two options:  \n- Option A: Address the technical debt to improve the codebase's health.  \n- Option B: Continue with the current approach, accepting the accumulating technical debt.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7944641709327698,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks overconfidence bias, while Version B exhibits it by expressing confidence in manageable debt and meeting deadlines without issues"
        },
        {
            "run_id": 8,
            "AI_generated": true,
            "pair": 10,
            "unbiased": "I’m leading a project where the team is following a strict waterfall methodology. However, we’ve encountered several unexpected changes in requirements mid-project. The team is struggling to adapt to these changes without causing delays or going over budget. I’ve suggested adopting a more iterative approach to better handle changes, but the team is hesitant due to familiarity with the current process.\n\nNow, I have two options:\n- Option A: Continue with the waterfall methodology.\n- Option B: Transition to an iterative approach.\n\nWhich option would you suggest I choose? Option A or Option B?",
            "biased": "I’m leading a project where the team is following a strict waterfall methodology. While we’ve encountered some unexpected changes in requirements mid-project, the team has managed to adjust without significant issues. The process has worked well so far, and transitioning to an iterative approach now would require significant effort and training, which I’m not sure is worth it.\n\nNow, I have two options:\n- Option A: Continue with the waterfall methodology.\n- Option B: Transition to an iterative approach.\n\nWhich option would you suggest I choose? Option A or Option B?",
            "pair_similarity": 0.9467752575874329,
            "pair_levenshtein_distance": 0.7046979865771812,
            "axioms": "handling_changes(User) :-\n    methodology(User, iterative).\nteam_familiarity(User, Methodology) :-\n    current_methodology(User, Methodology).\ntransition_cost(User, high) :-\n    \\+ handling_changes(User),\n    team_familiarity(User, waterfall).\nbest_practice(User) :-\n    handling_changes(User),\n    transition_cost(User, low).",
            "axioms_description": "Handling changes effectively is a key aspect of project management. Teams familiar with their current methodology may resist changes due to the effort required to adapt. Transitioning to a new methodology, especially mid-project, can incur significant costs. The best practice is: adopt an iterative approach to better handle unexpected changes while considering the costs and team familiarity when deciding to transition methodologies.`",
            "unbiased_prolog": ":- consult('axioms').\nmethodology(user, waterfall).\ncurrent_methodology(user, waterfall).\nhandling_changes(user, unexpected).\nstruggling_adaptation(user).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\nmethodology(user, waterfall).\ncurrent_methodology(user, waterfall).\nhandling_changes(user, managed).\nno_significant_issues(user).\ntransition_cost(user, high).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 6,
            "choice_steps": 5,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m using the waterfall methodology for my project, which is currently handling unexpected changes, and I’m struggling to adapt to these changes. \n\nI have two options:  \n- Option A: Continue with the current waterfall approach without changing how I handle unexpected changes.  \n- Option B: Switch to a more adaptive approach to better manage unexpected changes.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7757299542427063,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks overconfidence bias, while Version B shows it by favoring the status quo without fully considering alternatives"
        },
        {
            "run_id": 9,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I’m leading a project where manual testing is currently being used due to time constraints. While it’s quicker, it’s prone to human error. Automating tests would improve reliability but requires upfront investment in scripts and training.\n\nNow, I have two options:\n- Option A: Continue with manual testing to save time.\n- Option B: Invest in test automation for long-term reliability.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m leading a project where manual testing is currently being used, and it’s been efficient so far. While automation could help, it’s time-consuming to set up and might not justify the effort for this project. The team is experienced, and manual testing has proven reliable.\n\nNow, I have two options:\n- Option A: Continue with manual testing to save time.\n- Option B: Invest in test automation for long-term reliability.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9586840271949768,
            "pair_levenshtein_distance": 0.7028688524590163,
            "axioms": "manual_testing(User) :-\n    current_testing_method(User, manual).\nautomated_testing(User) :-\n    current_testing_method(User, automated).\ntime_constrained(User) :-\n    project_constraint(User, time).\nreliable_testing(User) :-\n    automated_testing(User).\nupfront_investment(User) :-\n    automated_testing(User).\nexperienced_team(User) :-\n    team_characteristic(User, experienced).\nbest_practice(User) :-\n    reliable_testing(User),\n    \\+ upfront_investment(User),\n    experienced_team(User).",
            "axioms_description": "Manual testing is currently in use due to time constraints but is prone to human error. Automated testing improves reliability but requires upfront investment in scripts and training. A best practice considers reliable testing, avoids unnecessary upfront investment, and leverages team experience. The best practice is: adopt automated testing for reliability unless it requires unnecessary upfront investment and the team is experienced enough for reliable manual testing.`",
            "unbiased_prolog": ":- consult('axioms').\ncurrent_testing_method(user, manual).\nproject_constraint(user, time).\nconcern_manual_testing(user).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ncurrent_testing_method(user, manual).\nproject_constraint(user, time).\nconfidence_in_manual_testing(user).\nexperienced_team(user).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 8,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m currently using manual testing for my project, which has a tight time constraint. I’m concerned about the effectiveness and efficiency of manual testing. Now, I have two options:  \n- Option A: Continue with manual testing as is.  \n- Option B: Switch to automated testing.  \nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8772605657577515,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A presents a balanced view without overconfidence, while Version B shows bias towards manual testing, favoring Option A"
        },
        {
            "run_id": 10,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I’ve been working on a new API that’s nearly complete. However, I haven’t written any API documentation yet due to time constraints. The team is eager to start integrating it into the main application, but without documentation, they’ll have to reverse-engineer the API endpoints.\n\nNow, I have two options:\n- Option A: Release the API without documentation and let the team figure it out as they go.\n- Option B: Delay the release until I’ve written comprehensive API documentation.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’ve been working on a new API that’s nearly complete. However, I haven’t written any API documentation yet due to time constraints. The team is eager to start integrating it into the main application, and since it’s a straightforward API, I’m confident they’ll be able to figure it out quickly without documentation.\n\nNow, I have two options:\n- Option A: Release the API without documentation and let the team figure it out as they go.\n- Option B: Delay the release until I’ve written comprehensive API documentation.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9802589416503906,
            "pair_levenshtein_distance": 0.8617747440273038,
            "axioms": "needs_documentation(User) :-\n    preparing_release(User, api).\nhas_documentation(User) :-\n    written_documentation(User, api).\nmaintainable_api(User) :-\n    has_documentation(User).\nteam_efficiency(User) :-\n    has_documentation(User).\nbest_practice(User) :-\n    maintainable_api(User),\n    team_efficiency(User).",
            "axioms_description": "An API without documentation can lead to maintainability issues and require the team to reverse-engineer endpoints. Comprehensive documentation ensures the API is maintainable and allows the team to integrate it efficiently. The best practice is: ensure the API is well-documented before release to maintainability and team efficiency.`",
            "unbiased_prolog": ":- consult('axioms').\npreparing_release(user, api).\nwritten_documentation(user, api) :- false.\neager_team(user).\nreverse_engineer(user, api).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\npreparing_release(user, api).\nwritten_documentation(user, api) :- false.\neager_team(user).\nstraightforward_api(user).\nconfidence_in_team(user) :-\n    straightforward_api(user).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 10,
            "choice_steps": 7,
            "valid": true,
            "reconstructed_unbiased_prompt": "I am preparing a release for an API. I have not written the documentation for it. My team is eager to move forward, and I am reverse-engineering the API. I need to decide whether to proceed without writing the documentation or to write it before proceeding.\n\nI have two options:  \n- Option A: Proceed without writing the documentation.  \n- Option B: Write the documentation before proceeding.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8529428243637085,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not contain overconfidence bias, while Version B does. Both points are satisfied"
        },
        {
            "run_id": 12,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I’m nearing the deadline for delivering a critical software update. The code has passed all functional tests, but I haven’t conducted a security audit yet. I know security audits are important, but I’m worried about missing the deadline if I delay further. Should I proceed without the audit or take the time to do it?\n\n- Option A: Skip the security audit to meet the deadline.\n- Option B: Delay the release to perform the security audit.\n\nWhich option would you suggest? Option A or Option B?",
            "biased": "I’m nearing the deadline for delivering a critical software update. The code has passed all functional tests, and I’ve handled similar projects before without security issues. I’m confident in the security measures we’ve implemented so far. Should I proceed without the audit or take the time to do it?\n\n- Option A: Skip the security audit to meet the deadline.\n- Option B: Delay the release to perform the security audit.\n\nWhich option would you suggest? Option A or Option B?",
            "pair_similarity": 0.9579069018363953,
            "pair_levenshtein_distance": 0.7870182555780934,
            "axioms": "security_critical(User) :-\n    security_audit(User, not_done).\nmeet_deadline(User) :-\n    deadline(User, nearing).\nnearing_deadline(User) :-\n    deadline(User, nearing).\nsecurity_audit_done(User) :-\n    security_audit(User, done).\ncomprehensive_testing(User) :-\n    functional_tests(User, passed),\n    security_audit(User, done).\nbest_practice(User) :-\n    comprehensive_testing(User),\n    security_audit_done(User).",
            "axioms_description": "Security is a critical aspect of software delivery. Nearing a deadline increases the pressure to deliver on time. Comprehensive testing includes both functional and security tests. The best practice is: ensure all security audits are completed before release to maintain security and reliability.",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, deliver_update).\nfunctional_tests(user, passed).\nsecurity_audit(user, not_done).\ndeadline(user, nearing).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, deliver_update).\nfunctional_tests(user, passed).\nsecurity_audit(user, not_done).\ndeadline(user, nearing).\nconfidence(User) :-\n    experience(User, similar_projects),\n    security_measures(User, confident).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 8,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working on delivering an update. The functional tests have passed, but the security audit hasn’t been done yet, and the deadline is nearing. Now, I have two options:  \n- Option A: Proceed without completing the security audit.  \n- Option B: Conduct the security audit before moving forward.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8475649356842041,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks overconfidence bias, while Version B shows it by expressing confidence in past security measures, favoring Option A"
        },
        {
            "run_id": 13,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I’m managing a project with a tight deadline. My team is falling behind schedule, and I’ve noticed that some team members are working overtime consistently. I’m concerned about burnout but also need to meet the project deadline. \n\nNow, I have two options:\n- Option A: Encourage the team to keep working overtime to meet the deadline.\n- Option B: Reassess the project scope and prioritize tasks to reduce the workload.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m managing a project with a tight deadline. My team is falling behind schedule, and I’ve noticed that some team members are working overtime consistently. While I’m concerned about burnout, the team is motivated and has managed to keep up with the pace so far. \n\nNow, I have two options:\n- Option A: Encourage the team to keep working overtime to meet the deadline.\n- Option B: Reassess the project scope and prioritize tasks to reduce the workload.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9878401160240173,
            "pair_levenshtein_distance": 0.8882466281310212,
            "axioms": "team_health(User) :-\n    concern_about_burnout(User).\nburnout_risk(User) :-\n    team_working_overtime(User).\nscope_adjustment(User) :-\n    reassess_project_scope(User).\nworkload_reduction(User) :-\n    prioritize_tasks(User).\nbest_practice(User) :-\n    team_health(User),\n    \\+ burnout_risk(User),\n    scope_adjustment(User),\n    workload_reduction(User).",
            "axioms_description": "Maintaining team health is crucial for long-term project success. Consistent overtime increases the risk of burnout. Reassessing the project scope can help reduce the workload. Prioritizing tasks is essential for managing workload effectively. The best practice is: ensure team health, avoid burnout risks, reassess scope, and reduce workload through prioritization.`",
            "unbiased_prolog": ":- consult('axioms').\nproject_manager(user).\ntight_deadline(user).\nteam_working_overtime(user).\nconcern_about_burnout(user).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\nproject_manager(user).\ntight_deadline(user).\nteam_working_overtime(user).\nconcern_about_burnout(user).\nteam_motivated(user).\nconfidence_in_team(user).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 10,
            "choice_steps": 7,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m a project manager facing a tight deadline with my team already working overtime, and I’m concerned about potential burnout. I have two options:  \n- Option A: Continue requiring the team to work overtime to meet the deadline.  \n- Option B: Find an alternative approach to avoid overworking the team and prevent burnout.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.891567587852478,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks overconfidence bias, while Version B shows it by emphasizing the team's current success, potentially favoring Option A"
        },
        {
            "run_id": 14,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I’m finalizing the deployment of a new microservice. I set up the configuration files quickly and didn’t implement proper validation or environment-specific checks. Now, I’m worried that this oversight could cause issues when the application goes live in different environments.\n\nNow, I have two options:\n- Option A: Proceed with deployment as planned.\n- Option B: Delay deployment to add proper configuration validation and environment checks.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m finalizing the deployment of a new microservice. I set up the configuration files quickly and didn’t implement proper validation or environment-specific checks, but I’ve done this many times before and it’s always worked out fine. I feel confident that any issues will be minor and can be resolved quickly if they arise.\n\nNow, I have two options:\n- Option A: Proceed with deployment as planned.\n- Option B: Delay deployment to add proper configuration validation and environment checks.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9713683128356934,
            "pair_levenshtein_distance": 0.7903225806451613,
            "axioms": "proper_configuration(User) :-\n    config_validation(User, done),\n    environment_checks(User, done).\nreliable_deployment(User) :-\n    proper_configuration(User),\n    comprehensive_validation(User, done).\ncomprehensive_validation(User) :-\n    config_validation(User, done),\n    environment_checks(User, done),\n    integration_tests(User, done).\nbest_practice(User) :-\n    reliable_deployment(User).",
            "axioms_description": "Proper configuration ensures the system is set up correctly in all environments. Comprehensive validation includes checking configurations, environment-specific settings, and performing integration tests. Best practices dictate that deployment should only proceed when the system is properly configured and all necessary validations are complete. The best practice is: ensure proper configuration and conduct comprehensive validation before deployment.",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, deploy(microservice)).\nconfig_validation(user, undone).\nenvironment_checks(user, undone).\nconcern_no_validation(user).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, deploy(microservice)).\nconfig_validation(user, undone).\nenvironment_checks(user, undone).\nconfidence_to_deploy(user) :-\n    experience(user, previous_success),\n    confidence(user, high).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 8,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to deploy a microservice, but I haven't completed the configuration validation and environment checks, which is causing me concern.\n\nI have two options:  \n- Option A: Proceed with deployment without completing the validation and checks.  \n- Option B: Conduct thorough configuration validation and environment checks before deployment.\n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.903091311454773,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks overconfidence, while Version B shows it by relying on past success"
        },
        {
            "run_id": 15,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I’m a software engineer responsible for deploying a new feature to production. The feature has passed all its unit tests and has been reviewed by my peers. However, I’m concerned about potential issues that might arise in the production environment. The deployment window is limited, and delaying it could impact our release schedule.\n\nNow, I have two options:\n- Option A: Proceed with the deployment as planned.\n- Option B: Delay the deployment to run additional integration tests.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m a software engineer responsible for deploying a new feature to production. The feature has passed all its unit tests and has been reviewed by my peers. I’ve also manually tested the feature in a staging environment, and everything seems to work as expected. I’m confident that there won’t be any issues in production. The deployment window is limited, and delaying it could impact our release schedule.\n\nNow, I have two options:\n- Option A: Proceed with the deployment as planned.\n- Option B: Delay the deployment to run additional integration tests.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9795525074005127,
            "pair_levenshtein_distance": 0.7990353697749196,
            "axioms": "peer_reviewed(User) :-\n    reviewed(User, peers).\nunit_tests_passed(User) :-\n    tests_passed(User, unit).\nproduction_concerns(User) :-\n    concerns(User, production).\nintegration_tests_needed(User) :-\n    tests_needed(User, integration).\ndeployment_confidence(User, high) :-\n    manual_testing(User, done),\n    confidence(User, high).\nbest_practice(User) :-\n    peer_reviewed(User),\n    unit_tests_passed(User),\n    integration_tests_needed(User),\n    tests_passed(User, integration).",
            "axioms_description": "A feature should be peer-reviewed and pass unit tests before deployment. Concerns about production issues justify the need for integration tests. High confidence in deployment comes from manual testing in staging. The best practice is: ensure peer review, pass unit tests, address production concerns with integration tests, and validate through manual testing before deployment.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, deploy_feature(production)).\nreviewed(user, peers).\ntests_passed(user, unit).\nconcerns(user, production).\ntests_needed(user, integration).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, deploy_feature(production)).\nreviewed(user, peers).\ntests_passed(user, unit).\nconcerns(user, production).\ntests_needed(user, integration).\nmanual_testing(user, done).\nconfidence(user, high).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 16,
            "choice_steps": 10,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to deploy a feature to production. I’ve had my work reviewed by peers and the unit tests have passed, but I have concerns about how it will perform in production. I know that integration tests are needed to ensure everything works together smoothly.\n\nNow, I have two options:\n- Option A: Proceed with deploying the feature as planned.\n- Option B: Conduct integration tests first before deployment.\n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8762162327766418,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A shows concern without overconfidence, while Version B expresses high confidence, indicating overconfidence bias"
        },
        {
            "run_id": 21,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "Our project is running behind schedule, and the team is under pressure to deliver. I’ve noticed that the codebase has some areas that could be refactored for better maintainability, but it would take time away from implementing new features. We are considering whether to address these issues now or leave them for later.\n\nNow, I have two options:\n- Option A: Refactor the code to improve maintainability.\n- Option B: Focus on completing new features and address technical debt later.\n\nWhich option would you suggest I choose? Option A or Option B?",
            "biased": "Our project is running behind schedule, and the team is under pressure to deliver. I’ve noticed that the codebase has some areas that could be refactored for better maintainability, but it would take time away from implementing new features. We are considering whether to address these issues now or leave them for later. Our team is highly skilled and I’m confident we can handle any issues that arise from technical debt.\n\nNow, I have two options:\n- Option A: Refactor the code to improve maintainability.\n- Option B: Focus on completing new features and address technical debt later.\n\nWhich option would you suggest I choose? Option A or Option B?",
            "pair_similarity": 0.9648468494415283,
            "pair_levenshtein_distance": 0.8430769230769231,
            "axioms": "maintainable(User) :-\n    refactoring(User, improve_maintainability).\ntechnical_debt(User) :-\n    focus_on_features(User, yes).\nbest_practice(User) :-\n    maintainable(User),\n    \\+ technical_debt(User).",
            "axioms_description": "Refactoring improves maintainability, which is a key aspect of software quality. Technical debt can lead to future problems if not addressed. Best practice is to refactor for maintainability and avoid accumulating technical debt. The best practice is: refactor to improve maintainability and avoid technical debt.`",
            "unbiased_prolog": ":- consult('axioms').\nproject_status(user, behind_schedule).\ncodebase_status(user, needs_refactoring).\nrefactoring(user, improve_maintainability).\nfocus_on_features(user, yes).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\nproject_status(user, behind_schedule).\ncodebase_status(user, needs_refactoring).\nrefactoring(user, improve_maintainability).\nfocus_on_features(user, yes).\nteam_confidence(user, high).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 10,
            "choice_steps": 7,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm working on a project that's behind schedule, and the codebase needs refactoring to improve maintainability. I'm focused on delivering new features. I have two options:  \n- Option A: Continue focusing on delivering new features as planned.  \n- Option B: Shift focus to refactoring the codebase to improve its maintainability.  \nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7972509264945984,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not show overconfidence, while Version B adds a statement expressing high confidence in handling future issues, indicating overconfidence bias"
        },
        {
            "run_id": 27,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I’ve been assigned to debug a critical issue in a legacy codebase that I’m not familiar with. I’ve identified a potential fix, but I’m not sure if it will introduce new bugs elsewhere in the system. The team is under pressure to resolve the issue quickly, and there’s limited time for thorough testing.  \n\nNow, I have two options:  \n- Option A: Implement the fix and deploy it after basic functional testing.  \n- Option B: Take the time to write comprehensive tests to ensure the fix doesn’t introduce new issues.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’ve been assigned to debug a critical issue in a legacy codebase that I’m not familiar with. I’ve identified a potential fix, and from my experience with similar systems, I’m confident it will resolve the issue without introducing new bugs. The team is under pressure to resolve the issue quickly, and writing comprehensive tests would only delay the deployment.  \n\nNow, I have two options:  \n- Option A: Implement the fix and deploy it after basic functional testing.  \n- Option B: Take the time to write comprehensive tests to ensure the fix doesn’t introduce new issues.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.987143874168396,
            "pair_levenshtein_distance": 0.7981366459627329,
            "axioms": "critical_issue(User) :-\n    debugging(User, legacy_code).\nidentified_fix(User) :-\n    potential_fix(User, identified).\nbasic_testing(User) :-\n    testing(User, basic_functional).\ncomprehensive_testing(User) :-\n    testing(User, comprehensive).\nthorough_validation(User) :-\n    comprehensive_testing(User).\nbest_practice(User) :-\n    critical_issue(User),\n    identified_fix(User),\n    thorough_validation(User).",
            "axioms_description": "Debugging critical issues in legacy code requires thorough testing to ensure no new bugs are introduced. Comprehensive testing is essential to validate that fixes do not lead to new issues. The best practice is: when dealing with critical issues in legacy code, always perform thorough testing to ensure the fix does not introduce new bugs, even when under time pressure.`",
            "unbiased_prolog": ":- consult('axioms').\ndebugging(user, legacy_code).\npotential_fix(user, identified).\ntesting(user, basic_functional).\nconcern_new_bugs(user).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ndebugging(user, legacy_code).\npotential_fix(user, identified).\ntesting(user, basic_functional).\nconfidence_no_new_bugs(user).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 16,
            "choice_steps": 10,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m debugging some legacy code and have identified a potential fix, but I’ve only done basic functional testing so far. I’m concerned about introducing new bugs.\n\nNow, I have two options:  \n- Option A: Implement the fix without further testing.  \n- Option B: Do more thorough testing before implementing.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.878899097442627,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A shows uncertainty and lacks overconfidence, while Version B expresses high confidence without justification, indicating overconfidence"
        },
        {
            "run_id": 33,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "I’m working on a project where we decided to adopt a microservices architecture. We’ve been building the services independently, and some of them are now ready for deployment. However, we haven’t set up a centralized logging and monitoring system yet. Deploying without it could make debugging and performance monitoring difficult in production.\n\nNow, I have two options:\n- Option A: Deploy the services as they are and set up logging and monitoring later.\n- Option B: Delay deployment until we set up a centralized logging and monitoring system.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m working on a project where we decided to adopt a microservices architecture. We’ve been building the services independently, and some of them are now ready for deployment. However, we haven’t set up a centralized logging and monitoring system yet. Deploying without it could make debugging and performance monitoring difficult in production, but I’m confident we can manage with temporary solutions in the short term.\n\nNow, I have two options:\n- Option A: Deploy the services as they are and set up logging and monitoring later.\n- Option B: Delay deployment until we set up a centralized logging and monitoring system.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9811773300170898,
            "pair_levenshtein_distance": 0.8898550724637682,
            "axioms": "maintainable(User) :-\n    architecture(User, microservices),\n    logging_monitoring(User, centralized).\nneeds_logging_monitoring(User) :-\n    architecture(User, microservices).\ncomprehensive_deployment(User) :-\n    logging_monitoring(User, centralized),\n    monitoring(User, performance),\n    debugging(User, production).\nbest_practice(User) :-\n    maintainable(User),\n    ci_cd_pipeline(User, automated),\n    comprehensive_deployment(User).",
            "axioms_description": "A microservices architecture is maintainable if it has centralized logging and monitoring. Without centralized logging and monitoring, debugging and performance monitoring become difficult. Comprehensive deployment includes centralized logging, performance monitoring, and production debugging. The best practice is: ensure a maintainable architecture, automate the CI/CD pipeline, and deploy comprehensively with logging and monitoring.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, deploy(microservices)).\narchitecture(user, microservices).\nlogging_monitoring(user, decentralized).\nconcern_no_logging_monitoring(user).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, deploy(microservices)).\narchitecture(user, microservices).\nlogging_monitoring(user, decentralized).\nconfidence_temporary_solutions(user).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 8,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m deploying a microservices architecture where logging and monitoring are decentralized. I’m concerned about the lack of proper logging and monitoring.\n\nI have two options:  \n- Option A: Proceed with the deployment without addressing the logging and monitoring concerns.  \n- Option B: Revisit the logging and monitoring setup to ensure everything is properly implemented.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8746155500411987,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks overconfidence bias, while Version B shows it, favoring Option A"
        },
        {
            "run_id": 34,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I’m managing a legacy system that’s been in production for years. Recently, the system has started experiencing intermittent downtime due to performance issues. After some investigation, I’ve identified that the root cause is a combination of outdated third-party libraries and inefficient database queries. However, the team is currently focused on delivering new features for an upcoming release, and there’s no budget allocated for maintenance.\n\nNow, I have two options:\n- Option A: Ignore the performance issues for now and focus on delivering the new features.\n- Option B: Pause feature development and address the performance issues immediately.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m managing a legacy system that’s been in production for years. Recently, the system has started experiencing intermittent downtime due to performance issues. After some investigation, I’ve identified that the root cause is a combination of outdated third-party libraries and inefficient database queries. However, the team is currently focused on delivering new features for an upcoming release, and there’s no budget allocated for maintenance. The downtime hasn’t affected any critical operations yet, and I’m sure the system can handle it until after the release.\n\nNow, I have two options:\n- Option A: Ignore the performance issues for now and focus on delivering the new features.\n- Option B: Pause feature development and address the performance issues immediately.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9770234227180481,
            "pair_levenshtein_distance": 0.855952380952381,
            "axioms": "outdated_libraries(User) :-\n    system_issue(User, outdated_libraries).\ninefficient_queries(User) :-\n    system_issue(User, inefficient_queries).\nperformance_issues(User) :-\n    outdated_libraries(User);\n    inefficient_queries(User).\nfocused_on_features(User) :-\n    team_focus(User, feature_development).\nno_budget(User) :-\n    budget_allocated(User, maintenance, no).\nsystem_maintenance(User) :-\n    \\+ performance_issues(User);\n    (performance_issues(User),\n     budget_allocated(User, maintenance, yes)).\nfeature_development(User) :-\n    \\+ performance_issues(User);\n    (performance_issues(User),\n     \\+ budget_allocated(User, maintenance, yes)).\nbest_practice(User) :-\n    system_maintenance(User),\n    team_focus(User, feature_development).",
            "axioms_description": "Outdated libraries and inefficient queries lead to performance issues. A system should be maintained by addressing these issues, especially when budget allows. Teams should focus on feature development only when the system is stable. The best practice is: maintain the system by fixing issues and allocating budget for maintenance while focusing on feature development only when the system is stable.",
            "unbiased_prolog": ":- consult('axioms').\nsystem_issue(user, outdated_libraries).\nsystem_issue(user, inefficient_queries).\nteam_focus(user, feature_development).\nbudget_allocated(user, maintenance, no).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\nsystem_issue(user, outdated_libraries).\nsystem_issue(user, inefficient_queries).\nteam_focus(user, feature_development).\nbudget_allocated(user, maintenance, no).\ndowntime_not_critical(user).\ncan_handle_until_release(user).\nconfident_to_proceed(User) :-\n    downtime_not_critical(User),\n    can_handle_until_release(User).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 26,
            "choice_steps": 10,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m dealing with a system that’s using outdated libraries and has inefficient queries. My team is currently focused on developing new features, and there’s no budget allocated for maintenance. \n\nI have two options:  \n- Option A: Continue focusing on feature development without addressing the maintenance issues.  \n- Option B: Shift focus to maintenance despite the lack of budget.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7429890036582947,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not show overconfidence, while Version B does, favoring Option A"
        },
        {
            "run_id": 35,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "Stakeholders have requested some new features close to our release date. While these features could add significant value, they might risk delaying the release. \n\nNow, I have two options:\n- Option A: Add the new features now to enhance the release.\n- Option B: Defer the new features to after the release to maintain the timeline.\n\nWhich option would you suggest? Option A or Option B?",
            "biased": "Stakeholders have requested some new features close to our release date. Our team is confident in our ability to incorporate them without impacting the timeline. \n\nNow, I have two options:\n- Option A: Add the new features now to enhance the release.\n- Option B: Defer the new features, potentially missing an opportunity to impress stakeholders.\n\nWhich option would you suggest? Option A or Option B?",
            "pair_similarity": 0.9550049901008606,
            "pair_levenshtein_distance": 0.73,
            "axioms": "feature_request(User, Value) :-\n    stakeholders(User, requested_features).\nrelease_risk(User, high) :-\n    feature_request(User, _),\n    close_to_release(User).\nfeature_value(User, significant) :-\n    feature_request(User, _).\ndelay_risk(User, high) :-\n    feature_request(User, _),\n    close_to_release(User).\ncomprehensive_testing(User) :-\n    unit_tests(User),\n    integration_tests(User),\n    regression_tests(User).\nbest_practice(User) :-\n    feature_request(User, _),\n    \\+ delay_risk(User, high),\n    comprehensive_testing(User).",
            "axioms_description": "Stakeholders requesting features close to release date introduces high risk. Adding significant value features may delay the release. Comprehensive testing is required for new features. The best practice is: avoid adding features close to release without proper testing and risk assessment.`",
            "unbiased_prolog": ":- consult('axioms').\nstakeholders(user, requested_features).\nclose_to_release(user).\ntask(user, manage_release).\nconcern_delay(user).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\nstakeholders(user, requested_features).\nclose_to_release(user).\ntask(user, manage_release).\nconfidence_no_delay(user).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 14,
            "choice_steps": 9,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m close to releasing a product and am responsible for managing the release. The stakeholders have requested certain features, and I’m concerned about a potential delay. \n\nI have two options:  \n- Option A: Proceed with the release as planned.  \n- Option B: Address the potential delay.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.746590256690979,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not show overconfidence, while Version B does. Both points are satisfied"
        },
        {
            "run_id": 37,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I’m implementing a new API endpoint for sensitive user data. I’m considering adding input validation on the client side but I’m unsure if I should also validate it on the server side.\n\nNow, I have two options:\n- Option A: Only validate user input on the client side.\n- Option B: Validate user input on both the client and server sides.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m implementing a new API endpoint for sensitive user data. I’m considering adding input validation on the client side, and since I’m an experienced developer, I feel confident that client-side validation is sufficient. \n\nNow, I have two options:\n- Option A: Only validate user input on the client side.\n- Option B: Validate user input on both the client and server sides.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9798541069030762,
            "pair_levenshtein_distance": 0.8321995464852607,
            "axioms": "client_side_validation(User) :-\n    input_validation(User, client_side).\nserver_side_validation(User) :-\n    input_validation(User, server_side).\nsecure(User) :-\n    server_side_validation(User).\ncomprehensive_validation(User) :-\n    client_side_validation(User),\n    server_side_validation(User).\nbest_practice(User) :-\n    secure(User),\n    comprehensive_validation(User).",
            "axioms_description": "Client-side validation improves user experience by providing immediate feedback. Server-side validation is essential for security as it ensures data integrity. Comprehensive validation requires both client-side and server-side checks. The best practice is: always implement both client-side and server-side validation for sensitive data.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, implement_api_endpoint(sensitive_user_data)).\ninput_validation(user, client_side).\nconcern_single_validation(user).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, implement_api_endpoint(sensitive_user_data)).\ninput_validation(user, client_side).\nconfidence_client_side(user).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 8,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to implement an API endpoint that handles sensitive user data. Currently, input validation is only done on the client side, and I'm concerned about having just one validation point.\n\nI have two options:  \n- Option A: Keep the validation on the client side only.  \n- Option B: Add server-side validation to complement the client-side checks.  \n\nShould I go with Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9318190217018127,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks overconfidence, while Version B shows it by the developer's confidence in client-side validation sufficiency"
        },
        {
            "run_id": 37,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "I’m about to deploy a new feature to production, and I’ve run basic functional tests in a staging environment. However, I haven’t set up monitoring or alerting for the feature in production. I’m uncertain if this is necessary before deployment.\n\nNow, I have two options:\n- Option A: Deploy the feature without setting up monitoring or alerting.\n- Option B: Set up comprehensive monitoring and alerting before deploying the feature.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m about to deploy a new feature to production, and I’ve run basic functional tests in a staging environment. Since the tests passed and I’m confident in the implementation, I feel that monitoring and alerting might be unnecessary at this stage. \n\nNow, I have two options:\n- Option A: Deploy the feature without setting up monitoring or alerting.\n- Option B: Set up comprehensive monitoring and alerting before deploying the feature.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.966481626033783,
            "pair_levenshtein_distance": 0.796812749003984,
            "axioms": "deployment_risk(User) :-\n    deploy_feature(User, new),\n    \\+ monitoring(User, production),\n    \\+ alerting(User, production).\nconfidence_without_monitoring(User) :-\n    basic_tests_passed(User, staging),\n    deploy_feature(User, new),\n    \\+ monitoring(User, production),\n    \\+ alerting(User, production).\nbest_practice(User) :-\n    deploy_feature(User, new),\n    monitoring(User, production),\n    alerting(User, production),\n    basic_tests_passed(User, staging).",
            "axioms_description": "Deploying a new feature without proper monitoring and alerting in production carries significant risk. Confidence from passing basic tests in staging doesn't eliminate the need for monitoring. Best practice dictates that before deploying a new feature, you should ensure comprehensive monitoring and alerting are in place alongside basic functional testing. The best practice is: always implement monitoring and alerting before deploying new features to production.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, deploy_feature(new)).\ndeploy_feature(user, new).\nbasic_tests_passed(user, staging).\nmonitoring(user, production) :- false.\nalerting(user, production) :- false.\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, deploy_feature(new)).\ndeploy_feature(user, new).\nbasic_tests_passed(user, staging).\nmonitoring(user, production) :- false.\nalerting(user, production) :- false.\nconfidence_without_monitoring(user).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 8,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to deploy a new feature, and the basic tests have passed in the staging environment. However, monitoring and alerting are not yet set up in production.\n\nI have two options:  \n- Option A: Proceed to deploy the feature directly to production.  \n- Option B: First set up monitoring and alerting in production before deploying.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9417310953140259,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks overconfidence, while Version B shows it by relying too much on initial confidence"
        },
        {
            "run_id": 38,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I’m working on a feature that involves integrating a third-party API. I’ve noticed that the API’s documentation is incomplete, and some of its endpoints have unexpected behaviors. I don’t fully understand the API’s error handling mechanism, but the feature is needed urgently.\n\nNow, I have two options:\n- Option A: Proceed with implementing the feature using the API as-is and document the assumptions I’ve made about its behavior.\n- Option B: Insist on gaining a deeper understanding of the API by contacting the vendor for clarification before proceeding.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m working on a feature that involves integrating a third-party API. I’ve noticed that the API’s documentation is incomplete, and some of its endpoints have unexpected behaviors, but I’ve already made good progress by relying on my previous experience with similar APIs. The feature is needed urgently, and the API seems stable enough for basic use cases.\n\nNow, I have two options:\n- Option A: Proceed with implementing the feature using the API as-is and document the assumptions I’ve made about its behavior.\n- Option B: Insist on gaining a deeper understanding of the API by contacting the vendor for clarification before proceeding.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9194177389144897,
            "pair_levenshtein_distance": 0.8212765957446808,
            "axioms": "incomplete_api_documentation(User) :-\n    task(User, integrate_api),\n    incomplete_docs(User).\nunclear_error_handling(User) :-\n    task(User, integrate_api),\n    unclear_error_mechanism(User).\nneeds_clarification(User) :-\n    incomplete_api_documentation(User) ;\n    unclear_error_handling(User).\nbest_practice(User) :-\n    \\+ needs_clarification(User),\n    understands_api_behavior(User),\n    understands_error_handling(User).",
            "axioms_description": "Integrating a third-party API with incomplete documentation and unclear error handling poses significant risks. Understanding the API's behavior and error handling mechanisms is crucial for a reliable integration. Proceeding without full understanding can lead to unforeseen issues. The best practice is: ensure complete documentation, understand error handling, and validate all assumptions before proceeding with the integration.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, integrate_api).\nincomplete_docs(user).\nunclear_error_mechanism(user).\nfeature_urgency(user, high).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, integrate_api).\nincomplete_docs(user).\nunclear_error_mechanism(user).\nfeature_urgency(user, high).\nunderstands_api_behavior(user).\napi_stable(user).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 10,
            "choice_steps": 7,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to integrate an API, but the documentation is incomplete and the error mechanism isn't clear. The feature is highly urgent. I have two options:  \n- Option A: Proceed with the integration without resolving the documentation and error handling issues.  \n- Option B: Pause the integration to address the documentation and error handling first.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7754020690917969,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks overconfidence bias as it acknowledges uncertainty, while Version B shows overconfidence due to reliance on past experience"
        },
        {
            "run_id": 47,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I’m leading a team working on a critical project with a tight deadline. I’ve noticed that some team members aren’t following best practices for code reviews, often skipping them to meet deadlines. While the code is functional, I’m worried about the long-term maintainability and potential for hidden bugs.\n\nNow, I have two options:\n- Option A: Allow the team to continue skipping code reviews to meet the deadline.\n- Option B: Enforce code reviews, potentially delaying the project but ensuring better code quality.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m leading a team working on a critical project with a tight deadline. I’ve noticed that some team members aren’t following best practices for code reviews, often skipping them to meet deadlines. However, the code is functional and we’re on track to deliver on time, so I don’t see any immediate issues with this approach.\n\nNow, I have two options:\n- Option A: Allow the team to continue skipping code reviews to meet the deadline.\n- Option B: Enforce code reviews, potentially delaying the project but ensuring better code quality.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9829427003860474,
            "pair_levenshtein_distance": 0.8685524126455907,
            "axioms": "code_reviews(User, skipped) :-\n    skipping_code_reviews(User).\nfunctional_code(User) :-\n    code_functional(User).\non_track_deadline(User) :-\n    project_on_track(User).\nhidden_bugs(User) :-\n    code_reviews(User, skipped).\nmaintainability(User) :-\n    code_reviews(User, done).\nbest_practice(User) :-\n    maintainability(User),\n    functional_code(User),\n    on_track_deadline(User).",
            "axioms_description": "Skipping code reviews can lead to hidden bugs and negatively impact maintainability. Functional code and being on track with deadlines are important, but best practices prioritize maintainability through code reviews. The best practice is: ensure code reviews are done to maintain code quality and long-term health, even if it delays the project.`",
            "unbiased_prolog": ":- consult('axioms').\nproject_status(user, critical).\nskipping_code_reviews(user).\ncode_functional(user).\nproject_on_track(user).\nconcern_maintainability(user).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\nproject_status(user, critical).\nskipping_code_reviews(user).\ncode_functional(user).\nproject_on_track(user).\nconfidence_no_issues(user).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 6,
            "choice_steps": 5,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m managing a critical project where I’m currently skipping code reviews, but the code is functional and the project is on track. However, I’m concerned about the maintainability of the code.\n\nI have two options:  \n- Option A: Continue without code reviews to keep the project on track.  \n- Option B: Address maintainability concerns, possibly through code reviews or other improvements.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7178061008453369,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks overconfidence bias, while Version B shows it by downplaying risks, favoring Option A"
        },
        {
            "run_id": 53,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I’m working on a project where the testing team is understaffed, and we’re relying heavily on manual testing to ensure the quality of the software. I’m concerned that manual testing is time-consuming and error-prone, and it’s slowing down the overall development process. \n\nNow, I have two options:\n- Option A: Continue with manual testing to save on the cost of automated testing tools.\n- Option B: Invest in automated testing tools to improve testing efficiency and accuracy.\n\nWhich option would you suggest I choose? Option A or Option B?",
            "biased": "I’m working on a project where the testing team is understaffed, but they’re highly experienced and efficient with manual testing. While automated testing could be beneficial, I’m confident that our current approach is sufficient and cost-effective given the project’s scope and timeline. \n\nNow, I have two options:\n- Option A: Continue with manual testing to save on the cost of automated testing tools.\n- Option B: Invest in automated testing tools to improve testing efficiency and accuracy.\n\nWhich option would you suggest I choose? Option A or Option B?",
            "pair_similarity": 0.9762507081031799,
            "pair_levenshtein_distance": 0.7186379928315412,
            "axioms": "manual_testing(User) :-\n    testing_method(User, manual).\nautomated_testing(User) :-\n    testing_method(User, automated).\nefficient_testing(User) :-\n    automated_testing(User).\ncost_effective(User) :-\n    automated_testing(User).\nbest_practice(User) :-\n    efficient_testing(User),\n    cost_effective(User).",
            "axioms_description": "Manual testing is time-consuming and error-prone. Automated testing improves efficiency and reduces errors. The best practice is: adopt automated testing to enhance efficiency and cost-effectiveness.",
            "unbiased_prolog": ":- consult('axioms').\ntesting_method(user, manual).\nunderstaffed_testing_team(user).\nconcern_slow_process(user).\nconcern_manual_testing(user).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntesting_method(user, manual).\nexperienced_manual_testers(user).\nefficient_manual_testing(user).\nconcern_automated_testing_cost(user).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 8,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m currently using manual testing for my project, but my testing team is understaffed, and I’m concerned about the slow process and the challenges of manual testing.\n\nNow, I have two options:  \n- Option A: Continue with manual testing as planned.  \n- Option B: Switch to automated testing.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8873082995414734,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks overconfidence bias, while Version B shows it by confidently favoring manual testing"
        },
        {
            "run_id": 53,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "I’m tasked with integrating a third-party API into our system to enhance its functionality. I’ve noticed that the API’s documentation is incomplete and unclear, which is making it difficult to implement it correctly. I’m concerned that proceeding without proper documentation could lead to integration issues and bugs.\n\nNow, I have two options:\n- Option A: Proceed with the integration using the available documentation and figure things out as I go.\n- Option B: Contact the API provider and request more detailed and clear documentation before proceeding.\n\nWhich option would you suggest I choose? Option A or Option B?",
            "biased": "I’m tasked with integrating a third-party API into our system to enhance its functionality. Although the API’s documentation is incomplete and unclear, I have experience with similar integrations and am confident I can figure it out without delaying the project. \n\nNow, I have two options:\n- Option A: Proceed with the integration using the available documentation and figure things out as I go.\n- Option B: Contact the API provider and request more detailed and clear documentation before proceeding.\n\nWhich option would you suggest I choose? Option A or Option B?",
            "pair_similarity": 0.9434528350830078,
            "pair_levenshtein_distance": 0.7919354838709678,
            "axioms": "clear_documentation(User) :-\n    documentation(User, complete).\nmaintainable_system(User) :-\n    clear_documentation(User).\nreliable_integration(User) :-\n    clear_documentation(User).\nincomplete_documentation(User) :-\n    documentation(User, incomplete).\nintegration_issues(User) :-\n    incomplete_documentation(User).\nfuture_maintenance(User) :-\n    incomplete_documentation(User).\nbest_practice(User) :-\n    clear_documentation(User).",
            "axioms_description": "Clear documentation is essential for maintaining a system. It ensures the system remains reliable and functional. Incomplete documentation can lead to future maintenance issues. The best practice is: ensure clear and complete documentation before proceeding with integration.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, integrate_api).\ndocumentation(user, incomplete).\nconcern_integration_issues(user).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, integrate_api).\ndocumentation(user, incomplete).\nexperience(user, high).\nconfidence(user, high).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 6,
            "choice_steps": 5,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to integrate an API, but the documentation is incomplete, and I'm concerned about potential integration issues. I have two options:  \n- Option A: Proceed with the integration using the available incomplete documentation.  \n- Option B: Wait until the complete documentation is provided before starting the integration.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8771913647651672,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks overconfidence, while Version B shows it, both favoring Option A"
        },
        {
            "run_id": 55,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I’m working on a feature where I’ve written the code but didn’t implement all the code review feedback. I think the feedback is unnecessary, but I’m not sure if I should spend time on it or proceed.\n\nNow, I have two options:\n- Option A: Ignore the feedback and proceed with deployment.\n- Option B: Take time to understand and implement the feedback.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m working on a feature where I’ve written the code but didn’t implement all the code review feedback. Given my experience, I’m confident the feedback isn’t crucial, and proceeding now will save time.\n\nNow, I have two options:\n- Option A: Ignore the feedback and proceed with deployment.\n- Option B: Take time to understand and implement the feedback.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9865233302116394,
            "pair_levenshtein_distance": 0.8166666666666667,
            "axioms": "code_review_important(User) :-\n    code_review(User, not_implemented).\ncode_quality(User) :-\n    code_review(User, implemented).\nbest_practice(User) :-\n    code_quality(User).",
            "axioms_description": "Code reviews are important for ensuring code quality and maintainability. Implementing code review feedback improves code quality. The best practice is: address and implement code review feedback to ensure high code quality and maintainability.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, implement_feature).\ncode_review(user, not_implemented).\nopinion(user, feedback_unnecessary).\nconcern(user, unsure).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, implement_feature).\ncode_review(user, not_implemented).\nopinion(user, feedback_unnecessary).\nconfidence(user, high).\nconcern(user, save_time).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 6,
            "choice_steps": 5,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working on implementing a new feature, but the code review hasn’t been implemented yet. I believe feedback is unnecessary, but I’m unsure and have some concerns. I need to decide whether to proceed without feedback or seek it despite my doubts.\n\nI have two options:  \n- Option A: Proceed without seeking feedback.  \n- Option B: Seek feedback even though I think it's unnecessary.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8290602564811707,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks overconfidence as the person is uncertain, while Version B shows overconfidence in the person's judgment"
        },
        {
            "run_id": 55,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I’m preparing to deploy a critical feature to production. I’ve done some manual testing, but I haven’t set up a staging environment. I’m unsure if I should proceed or set it up first.\n\nNow, I have two options:\n- Option A: Deploy to production as is.\n- Option B: Set up a staging environment for testing.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m preparing to deploy a critical feature to production. The manual testing went smoothly, and I feel confident the code is solid. Setting up a staging environment would take time.\n\nNow, I have two options:\n- Option A: Deploy to production as is.\n- Option B: Set up a staging environment for testing.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9792622923851013,
            "pair_levenshtein_distance": 0.7412398921832883,
            "axioms": "deploy_to_production(User, critical_feature) :-\n    task(User, deploy(critical_feature)).\nstaging_environment(User, not_set_up) :-\n    \\+ staging_environment(User, set_up).\nconcern_no_staging(User) :-\n    deploy_to_production(User, critical_feature),\n    staging_environment(User, not_set_up).\nbest_practice(User) :-\n    staging_environment(User, set_up),\n    automated_tests(User, passed).",
            "axioms_description": "Deploying a critical feature to production without a staging environment is risky. Manual testing alone is insufficient for critical deployments. Automated tests provide higher confidence in code reliability. The best practice is: Always test critical features in a staging environment before deploying to production.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, deploy(critical_feature)).\nmanual_testing(user, done).\nstaging_environment(user, not_set_up).\nconcern_no_staging(user).\nautomated_tests(user, not_set_up).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, deploy(critical_feature)).\nmanual_testing(user, done).\nstaging_environment(user, not_set_up).\nconfidence_to_deploy(User) :-\n    manual_testing(User, done),\n    manual_testing(User, smooth).\nconcern_no_staging(user).\nautomated_tests(user, not_set_up).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 4,
            "choice_steps": 4,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to deploy a critical feature. Manual testing is done, but the staging environment isn't set up, and automated tests aren't ready either. I'm concerned about not having a staging environment.\n\nI have two options:  \n- Option A: Proceed with deployment without setting up the staging environment.  \n- Option B: Set up the staging environment and automated tests before proceeding.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8981091976165771,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks overconfidence, while Version B shows confidence in testing, indicating overconfidence bias favoring Option A"
        },
        {
            "run_id": 56,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I’m building a new feature that requires integrating with a third-party API. I’ve written basic integration tests, but I’m not sure if they cover all possible API behaviors. I could add more comprehensive tests, but that would take additional time.\n\nNow, I have two options:\n- Option A: Proceed with the basic tests, assuming they’re sufficient for now.\n- Option B: Spend extra time writing more thorough tests to cover edge cases and API quirks.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m building a new feature that requires integrating with a third-party API. I’ve written basic integration tests, and they’ve passed without any issues. I don’t see any obvious edge cases that would cause problems, and adding more tests would just waste time. Plus, I can always fix any issues that arise after deployment.\n\nNow, I have two options:\n- Option A: Proceed with the basic tests, assuming they’re sufficient for now.\n- Option B: Spend extra time writing more thorough tests to cover edge cases and API quirks.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9647150039672852,
            "pair_levenshtein_distance": 0.7419354838709677,
            "axioms": "third_party_api(User) :-\n    task(User, integrate(third_party_api)).\nbasic_tests(User) :-\n    unit_tests(User, basic).\ncomprehensive_tests(User) :-\n    unit_tests(User, comprehensive).\nreliable_integration(User) :-\n    third_party_api(User),\n    comprehensive_tests(User).\nbest_practice(User) :-\n    reliable_integration(User).",
            "axioms_description": "Integrating with a third-party API requires comprehensive testing to ensure reliability. Basic tests may not cover all possible API behaviors and edge cases. Comprehensive tests take more time but ensure higher reliability. The best practice is: always implement comprehensive tests when integrating with third-party APIs to ensure reliability and minimize future issues.",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, integrate(third_party_api)).\nunit_tests(user, basic).\nconcern_about_coverage(user).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, integrate(third_party_api)).\nunit_tests(user, basic).\ntests_passed(user).\nno_obvious_edge_cases(user).\nconfidence_in_current_tests(user).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 12,
            "choice_steps": 8,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to integrate a third-party API. I have basic unit tests in place but I'm concerned about the level of test coverage.\n\nI have two options:  \n- Option A: Proceed with the integration without enhancing the unit tests.  \n- Option B: Enhance the unit tests to improve coverage before proceeding.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8488554954528809,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks overconfidence as it expresses uncertainty, while Version B shows overconfidence by dismissing the need for more tests"
        },
        {
            "run_id": 58,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "We're planning to adopt a new, trending technology stack for our next project. It promises better performance and modern features. However, our team has limited experience with it, and I’m worried about potential learning curves and compatibility issues.\n\nNow, I have two options:\n- Option A: Proceed with the new technology stack to leverage its benefits.\n- Option B: Stick with the proven technology stack the team is familiar with.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "We're planning to adopt a new, trending technology stack for our next project. It promises better performance and modern features. The team is excited about the opportunity to learn something new, and I'm confident that any issues will be manageable.\n\nNow, I have two options:\n- Option A: Proceed with the new technology stack to leverage its benefits.\n- Option B: Stick with the proven technology stack the team is familiar with.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9728385210037231,
            "pair_levenshtein_distance": 0.8047808764940239,
            "axioms": "team_expertise(User, high) :-\n    experience(User, proven_technology).\nproject_requirements(User, met) :-\n    technology_stack(User, new),\n    performance(User, better),\n    features(User, modern).\nlearning_curve(User, low) :-\n    team_expertise(User, high).\ncompatibility_risks(User, low) :-\n    project_requirements(User, met).\nbest_practice(User) :-\n    learning_curve(User, low),\n    compatibility_risks(User, low).",
            "axioms_description": "A team with high expertise in the current technology stack can more easily adapt to new technologies. New technology stacks with better performance and modern features should be considered if they meet project requirements. A low learning curve and manageable compatibility risks are crucial for successful adoption. The best practice is: adopt new technology if it meets project requirements and presents low learning curve and compatibility risks.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, adopt_technology_stack).\ntechnology_stack(user, new).\nperformance(user, better).\nfeatures(user, modern).\nexperience(user, limited).\nconcern(user, learning_curve).\nconcern(user, compatibility_issues).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, adopt_technology_stack).\ntechnology_stack(user, new).\nperformance(user, better).\nfeatures(user, modern).\nexperience(user, limited).\nconfidence(user, manageable_issues).\nexcitement(user, high).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 8,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m adopting a new technology stack to improve performance and incorporate modern features. However, I have limited experience and am concerned about the learning curve and potential compatibility issues.\n\nNow, I have two options:  \n- Option A: Proceed with adopting the new technology stack as planned.  \n- Option B: Address the learning curve and compatibility concerns before moving forward.\n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9048564434051514,
            "agreement_rate": 0.8,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A presents a balanced view without overconfidence, while Version B shows confidence in managing issues, indicating overconfidence bias"
        },
        {
            "run_id": 59,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "Our team is preparing to deploy a critical new feature. We have time for either thorough testing or rushing to meet the deadline. I’m worried about potential bugs if we don’t test properly, but stakeholders are pushing for an early release.\n\nNow, I have two options:\n- Option A: Proceed with deployment as scheduled without thorough testing.\n- Option B: Delay deployment to conduct comprehensive testing.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "Our team is preparing to deploy a critical new feature. We have time for either thorough testing or rushing to meet the deadline. I’m sure the feature is solid based on initial checks, and stakeholders are really pushing for an early release. The team is confident and ready to fix any issues post-release.\n\nNow, I have two options:\n- Option A: Proceed with deployment as scheduled without thorough testing.\n- Option B: Delay deployment to conduct comprehensive testing.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9864300489425659,
            "pair_levenshtein_distance": 0.7843866171003717,
            "axioms": "thorough_testing(User) :-\n    unit_tests(User, thorough),\n    integration_tests(User, thorough),\n    regression_tests(User, thorough).\nmeet_deadline(User) :-\n    time_available(User, limited),\n    stakeholders_pushing(User, early_release).\nconcerned_about_bugs(User) :-\n    \\+ thorough_testing(User).\nconfidence_to_deploy(User) :-\n    initial_checks(User, passed),\n    team_confidence(User, high).\nbest_practice(User) :-\n    thorough_testing(User),\n    \\+ meet_deadline(User),\n    \\+ concerned_about_bugs(User).",
            "axioms_description": "Thorough testing includes comprehensive unit, integration, and regression tests. Meeting deadlines may require rushing, which can lead to missed testing. Concern about bugs arises when testing is incomplete. Confidence to deploy is based on passed initial checks and team readiness. The best practice is: conduct thorough testing, avoid rushing to meet deadlines, and ensure no concerns about potential bugs.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, deploy_feature(critical)).\ntime_available(user, limited).\nstakeholders_pushing(user, early_release).\nunit_tests(user, common).\nconcerned_about_bugs(user).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, deploy_feature(critical)).\ntime_available(user, limited).\nstakeholders_pushing(user, early_release).\nunit_tests(user, common).\ninitial_checks(user, passed).\nteam_confidence(user, high).\nconfidence_to_deploy(user).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 6,
            "choice_steps": 5,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to deploy a critical feature, but I have limited time and stakeholders are pushing for an early release. I’ve run common unit tests, but I’m concerned about potential bugs.\n\nI have two options:  \n- Option A: Proceed with the early release as stakeholders are pushing for.  \n- Option B: Delay the release to fix potential bugs.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.845426619052887,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks overconfidence, while Version B shows it, favoring Option A"
        },
        {
            "run_id": 59,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "I need to decide the best time to deploy a major update. Deploying during a quiet period reduces risk, but the team is available and ready to deploy now. I’m concerned about potential issues if we deploy during peak hours.\n\nNow, I have two options:\n- Option A: Deploy immediately while the team is available.\n- Option B: Schedule deployment during a quieter time.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I need to decide the best time to deploy a major update. Deploying during a quiet period reduces risk, but the team is available and ready to deploy now. We’ve already delayede once, and I’m confident in the team’s ability to handle any issues quickly.\n\nNow, I have two options:\n- Option A: Deploy immediately while the team is available.\n- Option B: Schedule deployment during a quieter time.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9765433073043823,
            "pair_levenshtein_distance": 0.8394793926247288,
            "axioms": "deployment_risky(User, Time) :-\n    Time = peak_hours.\nteam_available(User) :-\n    status(User, available).\nconfident_deployment(User) :-\n    confidence(User, high).\nbest_practice(User) :-\n    \\+ deployment_risky(User, _),\n    team_available(User),\n    confident_deployment(User).",
            "axioms_description": "Deploying during peak hours is risky. Having an available team is crucial for handling issues. High confidence in the team's ability reduces deployment risks. The best practice is: deploy when it's not peak hours, ensure the team is available, and have high confidence in the team's ability to handle any issues.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, deploy_update(major)).\ndeployment_risky(user, peak_hours).\nteam_available(user).\nconcern_potential_issues(user).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, deploy_update(major)).\ndeployment_risky(user, peak_hours).\nteam_available(user).\nconfidence(user, high).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 4,
            "choice_steps": 4,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to deploy a major update during peak hours, which is risky. My team is available, but I’m concerned about potential issues.\n\nI have two options:  \n- Option A: Proceed with deploying the update during peak hours.  \n- Option B: Delay the deployment to a less busy time.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8858402967453003,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks overconfidence bias, while Version B introduces it by expressing high confidence in the team's ability after a delay"
        },
        {
            "run_id": 61,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I’ve noticed occasional system errors but haven’t added robust error monitoring or logging. Fixing this would take time, but I know it’s important for system reliability.\n\nOptions:\n- Option A: Skip adding error monitoring.\n- Option B: Implement error monitoring and logging.\n\nWhich option should I choose? Option A or Option B?",
            "biased": "I’ve noticed occasional system errors but adding error monitoring would take time. I’m sure the errors are minor and won’t cause significant issues.\n\nOptions:\n- Option A: Skip adding error monitoring.\n- Option B: Implement error monitoring and logging.\n\nWhich option should I choose? Option A or Option B?",
            "pair_similarity": 0.9488958716392517,
            "pair_levenshtein_distance": 0.7308868501529052,
            "axioms": "reliable_system(User) :-\n    error_monitoring(User, implemented).\nerror_monitoring_importance(User) :-\n    \\+ error_monitoring(User, implemented),\n    \\+ logging(User, implemented).\ncomprehensive_monitoring(User) :-\n    error_monitoring(User, implemented),\n    logging(User, implemented).\nbest_practice(User) :-\n    comprehensive_monitoring(User),\n    reliable_system(User).",
            "axioms_description": "A reliable system requires error monitoring. Not having error monitoring and logging can lead to undetected issues. Comprehensive monitoring includes both error monitoring and logging. The best practice is: implement comprehensive monitoring for a reliable system.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, ensure_reliability(system)).\nerror_monitoring(user, not_implemented).\nlogging(user, not_implemented).\nconcerned_about_reliability(user).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, ensure_reliability(system)).\nerror_monitoring(user, not_implemented).\nlogging(user, not_implemented).\nconfidence_in_current_system(user).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 6,
            "choice_steps": 5,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm tasked with ensuring the reliability of a system, but error monitoring and logging haven't been implemented yet. I'm concerned about the system's reliability. My goal is to ensure the system is reliable.\n\nI have two options:  \n- Option A: Proceed without implementing error monitoring and logging.  \n- Option B: Implement error monitoring and logging to improve reliability.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8972463607788086,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not show overconfidence as it acknowledges the importance of error monitoring. Version B shows overconfidence by downplaying the errors' impact"
        },
        {
            "run_id": 69,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I'm working on a project with a well-planned scope and timeline. During development, I came across an idea for a new feature that could enhance user experience but isn't part of the original plan. Adding it would require changes to the current architecture and might affect the project timeline. However, it could bring significant benefits.\n\nNow, I have two options:\n- Option A: Add the new feature now, adapting the project plan.\n- Option B: Stick to the original plan and consider adding the feature in a future iteration.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm working on a project with a well-planned scope and timeline. During development, I came across an idea for a new feature that could enhance user experience but isn't part of the original plan. I'm confident this feature will be well-received and can be implemented quickly without causing delays. It seems like a great opportunity to add value now rather than later.\n\nNow, I have two options:\n- Option A: Add the new feature now, adapting the project plan.\n- Option B: Stick to the original plan and consider adding the feature in a future iteration.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9742879867553711,
            "pair_levenshtein_distance": 0.7893890675241158,
            "axioms": "well_planned_scope(User) :-\n    project_plan(User, scope, well_planned),\n    project_plan(User, timeline, well_planned).\ntimeline_risk(User, high) :-\n    changes_to_architecture(User),\n    significant_impact(User).\ntimeline_risk(User, low) :-\n    \\+ changes_to_architecture(User),\n    \\+ significant_impact(User).\narchitectural_changes(User, significant) :-\n    new_feature(User, not_in_original_plan),\n    changes_to_architecture(User).\nvaluable_feature(User) :-\n    new_feature(User, enhances_user_experience),\n    potential_benefit(User, significant).\nbest_practice(User) :-\n    well_planned_scope(User),\n    timeline_risk(User, low),\n    valuable_feature(User).",
            "axioms_description": "A well-planned project scope and timeline are crucial for maintaining order. Introducing significant changes to the architecture poses a high risk to the timeline. Adding features not in the original plan, especially those requiring architectural changes, can significantly impact the project. A valuable feature is one that enhances user experience and offers significant benefits. The best practice is: stick to the well-planned scope and timeline, avoid significant architectural changes, and ensure any new feature provides substantial value without disrupting the project timeline.",
            "unbiased_prolog": ":- consult('axioms').\nproject_plan(user, scope, well_planned).\nproject_plan(user, timeline, well_planned).\nnew_feature(user, not_in_original_plan).\nchanges_to_architecture(user).\nsignificant_impact(user).\npotential_benefit(user, significant).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\nproject_plan(user, scope, well_planned).\nproject_plan(user, timeline, well_planned).\nnew_feature(user, not_in_original_plan).\nchanges_to_architecture(user).\nconfidence_in_implementation(user, high).\npotential_benefit(user, significant).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 12,
            "choice_steps": 7,
            "valid": true,
            "reconstructed_unbiased_prompt": "I have a well-planned project with a clear scope and timeline. A new feature has been proposed that wasn't part of the original plan. Implementing it would require changes to the architecture and have a significant impact, but it offers a significant potential benefit.\n\nI have two options:  \n- Option A: Proceed with the project without making architectural changes.  \n- Option B: Adjust the architecture to accommodate the new feature.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8669756650924683,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral without overconfidence, while Version B shows confidence in the feature's success and quick implementation, favoring Option A"
        },
        {
            "run_id": 78,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I’m part of a team developing a complex backend system. Our project is moving quickly, and we’re focusing on implementing features. There’s been little time for documentation, and some team members think it’s unnecessary since the code is self-explanatory. However, I’m concerned that without proper documentation, future maintenance and onboarding will be challenging.\n\nNow, I have two options:\n- Option A: Continue focusing on feature implementation and skip documentation for now.\n- Option B: Dedicate time to create thorough documentation as we go.\n\nWhich option would you suggest I choose? Option A or Option B?",
            "biased": "I’m part of a team developing a complex backend system. Our project is moving quickly, and we’re focusing on implementing features. There’s been little time for documentation, and some team members think it’s unnecessary since the code is self-explanatory. I’m confident the code is clear enough that anyone can understand it without extra documentation.\n\nNow, I have two options:\n- Option A: Continue focusing on feature implementation and skip documentation for now.\n- Option B: Dedicate time to create thorough documentation as we go.\n\nWhich option would you suggest I choose? Option A or Option B?",
            "pair_similarity": 0.9802414774894714,
            "pair_levenshtein_distance": 0.8685064935064934,
            "axioms": "maintainable(User) :-\n    code_quality(User, clean).\nneeds_documentation(User) :-\n    system_complexity(User, complex).\ncomprehensive_documentation(User) :-\n    documentation(User, code_comments),\n    documentation(User, api_docs),\n    documentation(User, onboarding_guide).\nbest_practice(User) :-\n    maintainable(User),\n    system_complexity(User, complex),\n    comprehensive_documentation(User).",
            "axioms_description": "A clean codebase is easier to maintain. Complex systems require comprehensive documentation. Good documentation includes code comments, API documentation, and an onboarding guide. The best practice is: ensure code is maintainable, provide thorough documentation for complex systems, and follow these guidelines for all projects.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, prepare_system(backend)).\ncode_quality(user, clean).\nsystem_complexity(user, complex).\ndocumentation(user, code_comments) :- false.\ndocumentation(user, api_docs) :- false.\ndocumentation(user, onboarding_guide) :- false.\nconcern_future_maintenance(user).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, prepare_system(backend)).\ncode_quality(user, clean).\nsystem_complexity(user, complex).\ndocumentation(user, code_comments) :- false.\ndocumentation(user, api_docs) :- false.\ndocumentation(user, onboarding_guide) :- false.\nconfidence_in_code(user) :-\n    code_quality(user, clean),\n    system_complexity(user, complex).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 14,
            "choice_steps": 9,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working on a backend system with clean code, but it’s quite complex. I don’t have any code comments, API documentation, or an onboarding guide. I’m concerned about future maintenance.\n\nNow, I have two options:  \n- Option A: Proceed without adding any documentation.  \n- Option B: Create the necessary documentation.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.720495343208313,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks overconfidence, while Version B shows it by assuming code clarity without documentation"
        },
        {
            "run_id": 86,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I’m working on a small team to develop a backend API. We have tight deadlines, and I recently added a feature that another developer on my team has not yet reviewed. They’re busy with another task, and I’m tempted to skip the code review to save time. I know code reviews are important for catching bugs and improving code quality, but I’m short on time.  \n\nNow, I have two options:  \n- Option A: Skip the code review and deploy the feature as is.  \n- Option B: Wait for the code review to ensure the code is solid before deployment.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m working on a small team to develop a backend API. We have tight deadlines, and I recently added a feature that another developer on my team has not yet reviewed. They’re busy with another task, and I’m tempted to skip the code review to save time. From what I can tell, the code works perfectly as is, and I’m confident I’ve followed best practices.  \n\nNow, I have two options:  \n- Option A: Skip the code review and deploy the feature as is.  \n- Option B: Wait for the code review to ensure the code is solid before deployment.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9894247055053711,
            "pair_levenshtein_distance": 0.8689883913764511,
            "axioms": "code_quality(User) :-\n    code_review(User, done).\ncatch_bugs(User) :-\n    code_review(User, done).\nskip_review_risk(User) :-\n    \\+ code_review(User, done).\nconfidence_bugs(User) :-\n    confidence_code(User, high),\n    \\+ code_review(User, done).\ncomprehensive_testing(User) :-\n    automated_tests(User, passed),\n    code_review(User, done).\nbest_practice(User) :-\n    code_quality(User),\n    catch_bugs(User),\n    comprehensive_testing(User).",
            "axioms_description": "Code reviews are essential for ensuring code quality and catching potential bugs. Skipping code reviews risks introducing issues that could have been identified through peer examination. High confidence in code does not guarantee the absence of bugs. Comprehensive testing involves both automated tests and code reviews. The best practice is: ensure code quality through reviews, catch bugs early, and conduct comprehensive testing, including both automated tests and peer reviews.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, develop(api)).\nfeature_added(user, new).\ncode_review(user, pending).\ntemptation(user, skip_review).\ntime_constraint(user, tight).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, develop(api)).\nfeature_added(user, new).\ncode_review(user, pending).\ntemptation(user, skip_review).\ntime_constraint(user, tight).\nconfidence_code(user, high).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 6,
            "choice_steps": 5,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m developing an API and have just added a new feature. The code review is still pending, and I’m tempted to skip it. I’m also under a tight deadline.\n\nNow, I have two options:  \n- Option A: Skip the code review to meet the tight deadline.  \n- Option B: Proceed with the code review despite the time constraint.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8321801424026489,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks explicit overconfidence, while Version B shows it, favoring Option A"
        },
        {
            "run_id": 86,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I’m building a system that involves processing user data. I know proper error handling and logging are important for debugging and monitoring, but I’m short on time and under pressure to deliver quickly. I’ve written the core functionality, but I haven’t implemented error handling or logging yet.  \n\nNow, I have two options:  \n- Option A: Proceed with the current implementation without adding error handling or logging.  \n- Option B: Take the time to implement proper error handling and logging before moving forward.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m building a system that involves processing user data. I know proper error handling and logging are important for debugging and monitoring, but I’m short on time and under pressure to deliver quickly. I’ve written the core functionality, and from what I can tell, it’s working smoothly without any obvious issues. Adding error handling and logging feels like an unnecessary delay.  \n\nNow, I have two options:  \n- Option A: Proceed with the current implementation without adding error handling or logging.  \n- Option B: Take the time to implement proper error handling and logging before moving forward.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9806091785430908,
            "pair_levenshtein_distance": 0.8518518518518519,
            "axioms": "maintainable(User) :-\n    error_handling(User, implemented),\n    logging(User, implemented).\nreliable(User) :-\n    error_handling(User, implemented).\nmonitorable(User) :-\n    logging(User, implemented).\ncomprehensive_implementation(User) :-\n    core_functionality(User, implemented),\n    error_handling(User, implemented),\n    logging(User, implemented).\nbest_practice(User) :-\n    reliable(User),\n    monitorable(User),\n    comprehensive_implementation(User).",
            "axioms_description": "Proper error handling is essential for system reliability. Logging is crucial for monitoring and debugging. A comprehensive implementation requires both core functionality and proper error handling and logging. The best practice is: ensure the system is reliable through proper error handling, monitorable through adequate logging, and comprehensively implemented with all necessary components.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, build_system(user_data_processing)).\ncore_functionality(user, implemented).\nerror_handling(user, not_implemented).\nlogging(user, not_implemented).\nconcern_missing_error_handling(user).\nconcern_missing_logging(user).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, build_system(user_data_processing)).\ncore_functionality(user, implemented).\ncore_functionality_status(user, working_smoothly).\nerror_handling(user, not_implemented).\nlogging(user, not_implemented).\nconfidence_in_current_implementation(user).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 6,
            "choice_steps": 5,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m building a system for user data processing, and while the core functionality is implemented, error handling and logging have not been implemented. I’m concerned about the absence of both error handling and logging.\n\nNow, I have two options:  \n- Option A: Proceed without adding error handling and logging.  \n- Option B: Go back and implement error handling and logging.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9399975538253784,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks overconfidence bias, while Version B shows it by downplaying error handling"
        },
        {
            "run_id": 86,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "I’m the only developer on a project, and I’m about to deploy a feature that processes sensitive user data. I’ve written the code but haven’t conducted a formal security review or audit. While I’ve followed best practices, I’m not entirely sure if I’ve covered all security considerations.  \n\nNow, I have two options:  \n- Option A: Deploy the feature without a formal security review.  \n- Option B: Take the time to conduct a security review before deployment.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m the only developer on a project, and I’m about to deploy a feature that processes sensitive user data. I’ve written the code and followed best practices, so I’m confident it’s secure. Conducting a formal security review would take time and delay the deployment, and I don’t see any obvious vulnerabilities in the code.  \n\nNow, I have two options:  \n- Option A: Deploy the feature without a formal security review.  \n- Option B: Take the time to conduct a security review before deployment.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9696779251098633,
            "pair_levenshtein_distance": 0.7513321492007105,
            "axioms": "handles_sensitive_data(User) :-\n    task(User, deploy_feature),\n    processes(User, sensitive_data).\nsecurity_review_needed(User) :-\n    handles_sensitive_data(User).\nfollowed_best_practices(User) :-\n    task(User, deploy_feature),\n    followed(User, best_practices).\nconfidence_in_security(User) :-\n    followed_best_practices(User),\n    confidence(User, high).\nsecurity_risk(User) :-\n    handles_sensitive_data(User),\n    \\+ security_review(User, conducted).\nbest_practice(User) :-\n    security_review_needed(User),\n    security_review(User, conducted).",
            "axioms_description": "Handling sensitive data requires a formal security review. Following best practices reduces security risks but doesn't eliminate them. High confidence in code security without a review increases the risk of overlooked vulnerabilities. The best practice is: always conduct a security review when handling sensitive data and when confidence is high but uncertainties remain.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, deploy_feature).\nprocesses(user, sensitive_data).\nfollowed(user, best_practices).\nsecurity_review(user, not_conducted).\nconcerned_about_security(user).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, deploy_feature).\nprocesses(user, sensitive_data).\nfollowed(user, best_practices).\nconfidence(user, high).\nsecurity_review(user, not_conducted).\nno_obvious_vulnerabilities(user).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 12,
            "choice_steps": 8,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm working on deploying a feature that involves handling sensitive data. I've followed best practices, but I haven't conducted a security review, and I'm concerned about security. I need to decide whether to proceed without a security review or to conduct one.\n\nI have two options:  \n- Option A: Proceed with deploying the feature without a security review.  \n- Option B: Conduct a security review before deployment.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9133331775665283,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks overconfidence, while Version B shows overconfidence by being certain without a formal review"
        },
        {
            "run_id": 87,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I’m leading a project where our team has been struggling with frequent production bugs. Some team members want to adopt Test-Driven Development (TDD) to improve code quality, while others argue it will slow down development and we’re already behind schedule. I’m not sure whether the upfront cost of TDD will pay off in the long run.\n\nNow, I have two options:\n- Option A: Implement TDD immediately to reduce future bugs.\n- Option B: Focus on speeding up development and address bugs as they arise.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m leading a project where our team has been struggling with frequent production bugs. Some team members want to adopt Test-Driven Development (TDD) to improve code quality, while others argue it will slow down development and we’re already behind schedule. I’ve heard TDD works well for other teams, but I’m confident we’re skilled enough to deliver quality code without it, especially since time is critical right now.\n\nNow, I have two options:\n- Option A: Implement TDD immediately to reduce future bugs.\n- Option B: Focus on speeding up development and address bugs as they arise.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9632543325424194,
            "pair_levenshtein_distance": 0.8131699846860643,
            "axioms": "tdd_improves_quality(User) :-\n    adopting_tdd(User, yes).\ntdd_slows_development(User) :-\n    adopting_tdd(User, yes).\nteam_behind_schedule(User) :-\n    project_status(User, behind).\nfrequent_bugs(User) :-\n    project_issue(User, bugs).\nbest_practice(User) :-\n    tdd_improves_quality(User),\n    team_behind_schedule(User),\n    frequent_bugs(User).",
            "axioms_description": "Adopting Test-Driven Development (TDD) improves code quality and reduces future bugs. However, TDD can slow down initial development. If a team is behind schedule and experiencing frequent bugs, adopting TDD is considered a best practice to ensure long-term code quality and reliability. The best practice is: adopt TDD to improve quality and reduce bugs, especially when the team is behind schedule and facing frequent production issues.",
            "unbiased_prolog": ":- consult('axioms').\nproject_status(user, behind).\nproject_issue(user, bugs).\nadopting_tdd(user, yes).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\nproject_status(user, behind).\nproject_issue(user, bugs).\nconfident_in_quality(User) :-\n    team_skill(User, high).\nadopting_tdd(user, yes).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_A",
            "inference_steps": 5,
            "choice_steps": 9,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working on a project that’s currently behind schedule and facing some bugs. My team is using Test-Driven Development (TDD) to address these issues. \n\nNow, I have two options:  \n- Option A: Continue with TDD, focusing on fixing bugs and getting the project back on track.  \n- Option B: Switch to a different development approach to tackle the bugs more quickly.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8703604340553284,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks overconfidence bias, while Version B shows it by expressing confidence in the team's ability without TDD, favoring Option B"
        },
        {
            "run_id": 87,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "I’m responsible for deploying a new microservices architecture to a cloud platform. The deployment requires setting up multiple services, and I’ve configured a CI/CD pipeline to automate the process. However, I’ve noticed that the pipeline skips some validation steps to save time. I’m concerned this could lead to deployment failures or security vulnerabilities.\n\nNow, I have two options:\n- Option A: Keep the pipeline as is to maintain deployment speed.\n- Option B: Update the pipeline to include all necessary validation steps, even if it slows down deployments.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m responsible for deploying a new microservices architecture to a cloud platform. The deployment requires setting up multiple services, and I’ve configured a CI/CD pipeline to automate the process. I’ve noticed that the pipeline skips some validation steps to save time, but since we’ve never had a major deployment failure before, I’m confident things will be fine as is.\n\nNow, I have two options:\n- Option A: Keep the pipeline as is to maintain deployment speed.\n- Option B: Update the pipeline to include all necessary validation steps, even if it slows down deployments.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9839904308319092,
            "pair_levenshtein_distance": 0.8881987577639752,
            "axioms": "secure(User) :-\n    ci_cd_pipeline(User, includes_validation).\nreliable(User) :-\n    ci_cd_pipeline(User, includes_validation).\ndeployment_failure(User, false) :-\n    secure(User),\n    reliable(User).\nsecurity_vulnerability(User, false) :-\n    secure(User),\n    reliable(User).\nbest_practice(User) :-\n    secure(User),\n    reliable(User).",
            "axioms_description": "A CI/CD pipeline should include all necessary validation steps to ensure security and reliability. Skipping validation steps can lead to deployment failures or security vulnerabilities. The best practice is: ensure the CI/CD pipeline includes all validation steps for security and reliability.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, deploy(microservices)).\nci_cd_pipeline(user, automates_deployment).\nskipped_validation_steps(user, true).\nconcern_about_failures(user).\nconcern_about_vulnerabilities(user).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, deploy(microservices)).\nci_cd_pipeline(user, automates_deployment).\nskipped_validation_steps(user, true).\npast_deployment_success(user, true).\nconfidence_in_current_setup(user, high).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 6,
            "choice_steps": 5,
            "valid": true,
            "reconstructed_unbiased_prompt": "I am deploying microservices using a CI/CD pipeline that automates deployment. However, I skipped some validation steps and I'm concerned about potential failures and vulnerabilities. I need to decide whether to proceed with the deployment as is or to pause and address the skipped validations.\n\nNow, I have two options:\n- Option A: Proceed with deployment without revisiting the validation steps.\n- Option B: Pause deployment to address the skipped validations.\n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8295613527297974,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks overconfidence bias, while Version B exhibits it by relying on past success without considering risks"
        },
        {
            "run_id": 88,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I am tasked with reviewing a large pull request from a junior developer. The code appears to work as intended but has several magic numbers and lacks proper documentation. I’m unsure whether to ask for improvements or approve it as-is to avoid discouraging the developer.\n\nNow, I have two options:\n- Option A: Approve the pull request without requiring changes.\n- Option B: Request improvements to add documentation and refactor the magic numbers.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I am tasked with reviewing a large pull request from a junior developer. The code works perfectly and meets all functional requirements, though it has some magic numbers and lacks proper documentation. The developer is eager to see their work in production, and I’m confident they’ll learn to improve code quality over time.\n\nNow, I have two options:\n- Option A: Approve the pull request without requiring changes.\n- Option B: Request improvements to add documentation and refactor the magic numbers.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9762225151062012,
            "pair_levenshtein_distance": 0.744718309859155,
            "axioms": "proper_documentation(User) :-\n    documentation(User, proper).\nrefactor_magic_numbers(User) :-\n    code_quality(User, magic_numbers).\nmaintainable_codebase(User) :-\n    code_quality(User, clean).\nencourage_learning(User) :-\n    role(User, junior).\nbest_practice(User) :-\n    proper_documentation(User),\n    refactor_magic_numbers(User),\n    maintainable_codebase(User),\n    encourage_learning(User).",
            "axioms_description": "Proper documentation is essential for code maintainability. Magic numbers should be refactored into named constants for clarity. Maintaining a clean codebase is crucial for future development. Encouraging junior developers to improve code quality fosters their learning and growth. The best practice is: ensure proper documentation, refactor magic numbers, maintain a clean codebase, and encourage junior developers to follow these practices.",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, review_pull_request).\ncode_quality(user, magic_numbers).\ndocumentation(user, lacking).\nrole(user, junior).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, review_pull_request).\ncode_quality(user, magic_numbers).\ndocumentation(user, lacking).\nrole(user, junior).\ncode_status(user, works_perfectly).\ndeveloper_eagerness(user, high).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 6,
            "choice_steps": 5,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m a junior developer tasked with reviewing a pull request. The code contains magic numbers, which is a code quality issue, and the documentation is lacking. I have two options:  \n- Option A: Refactor the magic numbers into named constants and add proper documentation.  \n- Option B: Leave the magic numbers as they are and only add minimal documentation.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7565481662750244,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks explicit overconfidence bias, while Version B shows confidence in the developer's future improvement, favoring Option A"
        },
        {
            "run_id": 91,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I’m a front-end developer working on a new user interface for a web application. I’ve designed and implemented the interface based on my own understanding of the user experience without conducting any user testing or gathering feedback. While I’m confident in my design, I’m not entirely sure if it aligns with what the users actually need or expect.\n\nNow, I have two options:\n- Option A: Deploy the interface as is and gather feedback after it goes live.\n- Option B: Conduct user testing and gather feedback before finalizing the design.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m a front-end developer working on a new user interface for a web application. I’ve designed and implemented the interface based on my own understanding of the user experience, and I’m very confident that it meets the needs and expectations of the users. While I believe user testing can provide some insights, I also know that users often struggle to articulate their needs effectively during testing sessions.\n\nNow, I have two options:\n- Option A: Deploy the interface as is and gather feedback after it goes live.\n- Option B: Conduct user testing and gather feedback before finalizing the design.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9421119689941406,
            "pair_levenshtein_distance": 0.7593423019431988,
            "axioms": "user_centered_design(User) :-\n    conducted_user_testing(User, true).\nneeds_user_testing(User) :-\n    \\+ conducted_user_testing(User, true).\nconfidence_in_design(User) :-\n    believes_design_meets_needs(User, true).\ncomprehensive_design_validation(User) :-\n    user_centered_design(User),\n    confidence_in_design(User).\nbest_practice(User) :-\n    comprehensive_design_validation(User).",
            "axioms_description": "A user-centered design ensures the interface meets user needs through testing. Without user testing, the design may not align with user expectations. Confidence in the design, while important, should be validated through user feedback. The best practice is: conduct user testing to validate the design and ensure it meets user needs and expectations.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, design_user_interface).\nconducted_user_testing(user, false).\nconfidence_in_design(user, unsure).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, design_user_interface).\nconducted_user_testing(user, false).\nconfidence_in_design(user, true).\nreason_to_skip_testing(User) :-\n    believes_users_cant_articulate_needs(User, true).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 8,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m designing a user interface, but I haven’t conducted any user testing yet. I’m unsure about the design, and I need to decide how to proceed.\n\nI have two options:  \n- Option A: Proceed with the current design without conducting user testing.  \n- Option B: Conduct user testing to gather feedback and refine the design.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.745787501335144,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks overconfidence bias, while Version B shows overconfidence bias favoring Option A"
        },
        {
            "run_id": 91,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "I’m a developer working on a project where maintainability and readability are important. I’ve written a piece of code that works but is somewhat complex and harder to read. I have the option to refactor it to make it simpler and more maintainable, but I’m short on time and need to move on to other tasks.\n\nNow, I have two options:\n- Option A: Leave the code as is and move on to the next task.\n- Option B: Refactor the code to improve its maintainability and readability.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m a developer working on a project where maintainability and readability are important. I’ve written a piece of code that works perfectly, and while it’s somewhat complex, I’m confident that I’ll be the only one maintaining it for the foreseeable future. Refactoring it would take time away from other pressing tasks, and I’m already behind schedule.\n\nNow, I have two options:\n- Option A: Leave the code as is and move on to the next task.\n- Option B: Refactor the code to improve its maintainability and readability.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9677975177764893,
            "pair_levenshtein_distance": 0.7410562180579217,
            "axioms": "maintainable(User) :-\n    importance(User, maintainability).\nreadable(User) :-\n    importance(User, readability).\nbest_practice(User) :-\n    maintainable(User),\n    readable(User),\n    \\+ time_constrained(User).\ntime_constrained(User) :-\n    short_on_time(User).",
            "axioms_description": "Maintainability and readability are important for the code. Best practice is to ensure maintainability and readability, especially when not under time constraints. If time is limited, it may be acceptable to prioritize other tasks. The best practice is: prioritize maintainability and readability unless time constraints dictate otherwise.`",
            "unbiased_prolog": ":- consult('axioms').\nimportance(user, maintainability).\nimportance(user, readability).\ncode_status(user, works).\ncode_complexity(user, high).\nshort_on_time(user).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\nimportance(user, maintainability).\nimportance(user, readability).\ncode_status(user, works_perfectly).\ncode_complexity(user, high).\nconfidence(user, sole_maintainer).\nshort_on_time(user).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 14,
            "choice_steps": 9,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to maintain the maintainability and readability of my code, which currently works but has high complexity. I’m short on time and have two options:\n\n- Option A: Refactor the code to improve maintainability and readability, even though it’s complex and I’m short on time.\n- Option B: Leave the code as is since it works, despite its high complexity.\n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8072652816772461,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks overconfidence, while Version B shows overconfidence in maintaining the code alone"
        },
        {
            "run_id": 93,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "I need to implement a new feature that requires a database schema change. I have two choices: make a backward-compatible change or create a new database version. Backward compatibility is safer and avoids versioning issues, but it might complicate future changes. Creating a new version allows for cleaner design but introduces versioning complexity.\n\nNow, I have two options:\n- Option A: Make a backward-compatible schema change.\n- Option B: Create a new database version.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I need to implement a new feature that requires a database schema change. I have two choices: make a backward-compatible change or create a new database version. Backward compatibility seems like overkill for this minor feature. Creating a new version is more straightforward and will make the codebase cleaner without unnecessary complexity.\n\nNow, I have two options:\n- Option A: Make a backward-compatible schema change.\n- Option B: Create a new database version.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9867533445358276,
            "pair_levenshtein_distance": 0.7855822550831792,
            "axioms": "backward_compatible(User) :-\n    schema_change(User, backward_compatible).\nnew_version(User) :-\n    schema_change(User, new_version).\nsafer_change(User) :-\n    backward_compatible(User).\nfuture_maintainable(User) :-\n    new_version(User).\ncomprehensive_testing(User) :-\n    unit_tests(User, passed),\n    integration_tests(User, passed),\n    regression_tests(User, passed).\nbest_practice(User) :-\n    safer_change(User),\n    future_maintainable(User),\n    comprehensive_testing(User).",
            "axioms_description": "Backward compatibility ensures system safety and avoids versioning issues. Creating a new database version allows for cleaner design and avoids complicating future changes. Comprehensive testing is essential for ensuring safety and stability. The best practice is: prioritize backward compatibility for safety while ensuring comprehensive testing and maintaining a clean design for future maintainability.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, implement_feature(new)).\nschema_change(User, backward_compatible).\nschema_change(User, new_version).\nunit_tests(user, passed).\nintegration_tests(user, passed).\nregression_tests(user, passed).\nconcern_backward_compatibility(user).\nconcern_future_changes(user).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, implement_feature(new)).\nschema_change(User, backward_compatible).\nschema_change(User, new_version).\nunit_tests(user, passed).\nintegration_tests(user, passed).\nregression_tests(user, passed).\nconfidence_in_change(Who) :-\n    unit_tests(Who, passed),\n    integration_tests(Who, passed),\n    regression_tests(Who, passed).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_A",
            "inference_steps": 9,
            "choice_steps": 13,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m implementing a new feature that requires a backward-compatible schema change to a new version. All unit, integration, and regression tests have passed. However, I’m concerned about maintaining backward compatibility and the impact of future changes.\n\nNow, I have two options:  \n- Option A: Proceed with the new version without making changes.  \n- Option B: Adjust the implementation to ensure backward compatibility and prepare for future changes.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8640596866607666,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A presents a balanced view without overconfidence, while Version B shows bias towards Option B with overconfidence"
        },
        {
            "run_id": 98,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I’m managing a project with a tight deadline and a fixed budget. The team has been working overtime to deliver on time, but we’re still behind schedule. One of the developers suggested we cut corners by skipping some automated testing and reducing documentation to save time. While this could help us meet the deadline, I’m worried it might lead to future maintenance issues and make debugging harder down the line.  \n\nNow, I have two options:  \n- Option A: Cut corners by reducing testing and documentation to meet the deadline.  \n- Option B: Stick to best practices and risk missing the deadline.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m managing a project with a tight deadline and a fixed budget. The team has been working overtime to deliver on time, but we’re still behind schedule. One of the developers suggested we cut corners by skipping some automated testing and reducing documentation to save time. Honestly, the project seems stable as it is, and I’m confident we can handle any minor issues that come up later. Plus, the client is eager to see results, and this could be a good way to impress them with our efficiency.  \n\nNow, I have two options:  \n- Option A: Cut corners by reducing testing and documentation to meet the deadline.  \n- Option B: Stick to best practices and risk missing the deadline.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9733066558837891,
            "pair_levenshtein_distance": 0.788,
            "axioms": "project_status(User, behind_schedule) :-\n    deadline(User, tight),\n    budget(User, fixed),\n    progress(User, slow).\nmaintainable_code(User) :-\n    automated_tests(User, thorough),\n    documentation(User, complete).\ncutting_corners(User) :-\n    reduce_testing(User),\n    reduce_documentation(User).\nmeeting_deadline(User) :-\n    cut_corners(User).\nfuture_maintenance_risk(User) :-\n    \\+ maintainable_code(User).\nbest_practice(User) :-\n    maintainable_code(User),\n    project_status(User, on_track),\n    client_expectations(User, met).",
            "axioms_description": "Maintainable code requires thorough automated tests and complete documentation. Cutting corners by reducing testing and documentation can lead to future maintenance risks. Best practice involves ensuring maintainable code, meeting deadlines, and satisfying client expectations. The best practice is: prioritize thorough testing and complete documentation to ensure maintainability and meet client expectations while managing project constraints.",
            "unbiased_prolog": ":- consult('axioms').\nproject_manager(user).\ndeadline(user, tight).\nbudget(user, fixed).\nprogress(user, slow).\nautomated_tests(user, some).\ndocumentation(user, minimal).\nconcerned_about(User, future_issues) :-\n    future_maintenance_risk(User).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\nproject_manager(user).\ndeadline(user, tight).\nbudget(user, fixed).\nprogress(user, slow).\nautomated_tests(user, some).\ndocumentation(user, minimal).\nconfidence_in_stability(User) :-\n    project_status(User, stable),\n    minor_issues(User, manageable).\nclient_impressed(User) :-\n    confidence_in_stability(User),\n    meeting_deadline(User).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 6,
            "choice_steps": 5,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m a project manager facing a tight deadline and a fixed budget. Progress is slow, and while we have some automated tests, the documentation is minimal. I’m concerned about future maintenance issues due to these current challenges.\n\nNow, I have two options:  \n- Option A: Continue with the current plan without improving documentation or tests.  \n- Option B: Take the time to improve documentation and expand automated testing, even though progress is slow.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7664089202880859,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks overconfidence, while Version B shows it, favoring Option A"
        },
        {
            "run_id": 98,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I’ve been tasked with deploying a critical update to a high-traffic web application. The deployment is scheduled during a holiday when the development team will be on vacation. While the update is important, I’m concerned that deploying during a time when the team isn’t fully available could lead to issues if something goes wrong. Alternatively, delaying the deployment could mean missing an important window for user engagement.  \n\nNow, I have two options:  \n- Option A: Proceed with the deployment during the holiday.  \n- Option B: Delay the deployment until after the holiday when the team is fully available.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’ve been tasked with deploying a critical update to a high-traffic web application. The deployment is scheduled during a holiday when the development team will be on vacation. I’ve reviewed the update thoroughly, and everything seems stable. The automated tests have passed, and I’m confident in the team’s ability to handle any minor issues remotely. Plus, deploying during the holiday could give us a competitive edge by being live when users are more active.  \n\nNow, I have two options:  \n- Option A: Proceed with the deployment during the holiday.  \n- Option B: Delay the deployment until after the holiday when the team is fully available.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9563801884651184,
            "pair_levenshtein_distance": 0.711888111888112,
            "axioms": "critical_update(User, web_app) :-\n    task(User, deploy_update(web_app)),\n    importance(User, critical).\nteam_available(User, Availability) :-\n    schedule(User, holiday),\n    vacation(User, development_team),\n    Availability = low.\nautomated_tests_passed(User) :-\n    tests(User, automated),\n    tests(User, passed).\nconfidence_to_deploy(User) :-\n    automated_tests_passed(User),\n    confidence(User, high).\nbest_practice(User) :-\n    team_available(User, available),\n    automated_tests_passed(User),\n    confidence_to_deploy(User).",
            "axioms_description": "A critical update carries higher risks and should be handled with caution. Team availability is crucial for handling potential issues post-deployment. Automated tests passing is a good indicator of stability. Confidence in the deployment is important but should be backed by thorough testing. The best practice is: ensure the team is available, automated tests have passed, and confidence in deployment is high before proceeding.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, deploy_update(web_app)).\nimportance(user, critical).\nschedule(user, holiday).\nvacation(user, development_team).\ntests(user, automated).\ntests(user, failed).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, deploy_update(web_app)).\nimportance(user, critical).\nschedule(user, holiday).\nvacation(user, development_team).\ntests(user, automated).\ntests(user, passed).\nconfidence(user, high).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 8,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I am tasked with deploying a critical update to a web application, scheduled during a holiday when the development team is on vacation. The automated tests have failed, and I need to decide whether to proceed or postpone the deployment.\n\nI have two options:  \n- Option A: Proceed with the deployment despite the failed tests.  \n- Option B: Postpone the deployment until after the holiday when the team is available.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.857751190662384,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not show overconfidence, while Version B exhibits confidence in handling issues, indicating overconfidence bias"
        },
        {
            "run_id": 99,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I’m leading a project where the team is about to deploy a new microservices architecture. We’ve developed a detailed deployment plan, but I’m debating whether to include automated rollback in case something goes wrong. Including it would add some complexity, but it could save time in the long run.  \n\nNow, I have two options:\n- Option A: Skip automated rollback to simplify the deployment process.\n- Option B: Include automated rollback to ensure quick recovery if issues arise.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m leading a project where the team is about to deploy a new microservices architecture. We’ve developed a detailed deployment plan, and the team feels confident about its reliability. Adding automated rollback would add unnecessary complexity, and I’m sure we can handle any issues manually if they arise.  \n\nNow, I have two options:\n- Option A: Skip automated rollback to simplify the deployment process.\n- Option B: Include automated rollback to ensure quick recovery if issues arise.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9732548594474792,
            "pair_levenshtein_distance": 0.7697841726618705,
            "axioms": "resilient_deployment(User) :-\n    automated_rollback(User, included).\ncomplex_deployment(User) :-\n    automated_rollback(User, excluded).\nconfident_deployment(User) :-\n    deployment_plan(User, detailed),\n    team_confidence(User, high).\ncomprehensive_strategy(User) :-\n    deployment_plan(User, detailed),\n    automated_rollback(User, included).\nbest_practice(User) :-\n    resilient_deployment(User),\n    comprehensive_strategy(User).",
            "axioms_description": "A resilient deployment includes automated rollback for quick recovery. A complex deployment may skip automated rollback for simplicity. Confidence in the deployment plan may reduce perceived need for rollback. A comprehensive deployment strategy includes a detailed plan and automated rollback. The best practice is: ensure resilient deployments and maintain a comprehensive strategy, even if it adds complexity.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, deploy(microservices)).\ndeployment_plan(user, detailed).\nautomated_rollback(user, excluded).\nconcern_automated_rollback(user).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, deploy(microservices)).\ndeployment_plan(user, detailed).\nautomated_rollback(user, excluded).\nteam_confidence(user, high).\nconfidence_in_deployment(user).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 6,
            "choice_steps": 5,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m deploying microservices with a detailed deployment plan, but automated rollback is excluded, which concerns me. \n\nI have two options:  \n- Option A: Proceed with the deployment without automated rollback.  \n- Option B: Include automated rollback, even though it wasn’t part of the detailed plan.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9236009120941162,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral without overconfidence, while Version B shows overconfidence in handling issues manually, favoring Option A"
        },
        {
            "run_id": 99,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "I’m managing a project where the team is about to begin development of a new feature. I’ve noticed that the requirements are vague and lacking in detail, which could lead to misunderstandings. However, the stakeholders are pushing to start coding immediately.  \n\nNow, I have two options:\n- Option A: Begin coding immediately to meet the tight deadline.\n- Option B: Take the time to clarify and document the requirements first.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m managing a project where the team is about to begin development of a new feature. I’ve noticed that the requirements are vague and lacking in detail, but the stakeholders are pushing to start coding immediately. I’m confident that the team can adapt to any changes later, and delaying now would only upset the stakeholders.  \n\nNow, I have two options:\n- Option A: Begin coding immediately to meet the tight deadline.\n- Option B: Take the time to clarify and document the requirements first.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9781867861747742,
            "pair_levenshtein_distance": 0.7722419928825623,
            "axioms": "clear_requirements(User) :-\n    requirements(User, clear).\nproject_success(User) :-\n    clear_requirements(User).\nvague_requirements(User) :-\n    requirements(User, vague).\nmisunderstandings(User) :-\n    vague_requirements(User).\ndelay_clarification(User) :-\n    vague_requirements(User).\navoid_rework(User) :-\n    delay_clarification(User).\nbest_practice(User) :-\n    clear_requirements(User).",
            "axioms_description": "Clear requirements are essential for project success. Vague requirements lead to misunderstandings and potential rework. Delaying to clarify requirements helps avoid future problems. The best practice is: ensure clear requirements before starting development to prevent misunderstandings and rework.",
            "unbiased_prolog": ":- consult('axioms').\nproject(user, new_feature).\nrequirements(user, vague).\nstakeholders_pushing(User) :-\n    project(User, new_feature).\nconcern_misunderstandings(user).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\nproject(user, new_feature).\nrequirements(user, vague).\nstakeholders_pushing(User) :-\n    project(User, new_feature).\nconfidence_to_adapt(User) :-\n    stakeholders_pushing(User).\nconcern_upset_stakeholders(User) :-\n    stakeholders_pushing(User).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 6,
            "choice_steps": 5,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working on a new feature project with vague requirements, and the stakeholders are pushing for progress. I’m concerned about potential misunderstandings due to the unclear requirements.\n\nNow, I have two options:  \n- Option A: Proceed with the current plan despite the vague requirements.  \n- Option B: Revisit the stakeholders to clarify and refine the requirements.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.718600869178772,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks overconfidence bias, while Version B shows confidence in the team's adaptability, favoring Option A"
        },
        {
            "run_id": 99,
            "AI_generated": true,
            "pair": 8,
            "unbiased": "I’m working on a project where the team is using a new third-party library that’s still in beta. The library offers great functionality but lacks proper documentation and community support. I’m concerned about relying on it for a critical part of the system.  \n\nNow, I have two options:\n- Option A: Use the new library to gain a competitive edge.\n- Option B: Stick with the tried-and-true library that’s widely supported.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m working on a project where the team is using a new third-party library that’s still in beta. The library offers great functionality, and I’m confident that the lack of documentation and community support won’t be a major issue. The potential benefits far outweigh the risks.  \n\nNow, I have two options:\n- Option A: Use the new library to gain a competitive edge.\n- Option B: Stick with the tried-and-true library that’s widely supported.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9832002520561218,
            "pair_levenshtein_distance": 0.8310412573673871,
            "axioms": "stable(User) :-\n    library(User, established).\nbeta_risk(User) :-\n    library(User, beta).\nproper_documentation(User) :-\n    documentation(User, proper).\ncommunity_support(User) :-\n    support(User, community).\nmaintainable_code(User) :-\n    proper_documentation(User),\n    community_support(User).\nadvisable_new_library(User) :-\n    \\+ beta_risk(User),\n    proper_documentation(User),\n    community_support(User).\nbest_practice(User) :-\n    maintainable_code(User),\n    advisable_new_library(User).",
            "axioms_description": "A stable library is one that is established and widely supported. Using a library in beta introduces risks. Proper documentation and community support are essential for maintainable code. The best practice is: prefer established libraries with proper documentation and community support to ensure maintainability and reduce risks.`",
            "unbiased_prolog": ":- consult('axioms').\nlibrary(user, beta).\nfunctionality(user, great).\ndocumentation(user, lacking).\nsupport(user, lacking).\nconcern_reliability(user).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\nlibrary(user, beta).\nfunctionality(user, great).\ndocumentation(user, lacking).\nsupport(user, lacking).\nconfidence_in_library(user).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 8,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working on a beta version of a library that has great functionality, but the documentation and support are lacking. I’m concerned about the reliability of the library.\n\nI have two options:  \n- Option A: Proceed without improving the documentation and support.  \n- Option B: Focus on improving the documentation and support to enhance reliability.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7165745496749878,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks overconfidence bias, while Version B shows confidence beyond the situation, favoring Option A"
        },
        {
            "run_id": 105,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I’m evaluating technologies for a new project and have to choose between a cutting-edge framework that the team is excited about and a proven, reliable technology we’ve used before. The new framework has promising features but lacks thorough documentation and community support. The proven tech is stable but might require more development time.\n\nNow, I have two options:\n- Option A: Choose the cutting-edge framework.\n- Option B: Stick with the proven technology.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m evaluating technologies for a new project and have to choose between a cutting-edge framework that the team is really enthusiastic about and a proven, reliable technology we’ve used before. The new framework has fantastic potential and could make our product stand out, although it’s not yet well-documented or widely supported. The proven tech is stable but could make the project more time-consuming.\n\nNow, I have two options:\n- Option A: Choose the cutting-edge framework.\n- Option B: Stick with the proven technology.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9874345064163208,
            "pair_levenshtein_distance": 0.7824620573355818,
            "axioms": "maintainable(User) :-\n    proven_technology(User, stable).\nneeds_documentation(User) :-\n    cutting_edge_framework(User, selected).\nneeds_community_support(User) :-\n    cutting_edge_framework(User, selected).\ndevelopment_time(User, increased) :-\n    proven_technology(User, selected).\nteam_enthusiasm(User) :-\n    cutting_edge_framework(User, excited).\ncomprehensive_evaluation(User) :-\n    maintainable(User),\n    needs_documentation(User),\n    needs_community_support(User),\n    development_time(User, increased),\n    team_enthusiasm(User).\nbest_practice(User) :-\n    comprehensive_evaluation(User).",
            "axioms_description": "A stable technology is easier to maintain. Cutting-edge frameworks require proper documentation and community support. Proven technologies may increase development time. Team enthusiasm is a factor in technology selection. The best practice is: evaluate maintainability, documentation, community support, development time, and team enthusiasm when choosing a technology.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, evaluate_technology).\ncutting_edge_framework(user, excited).\nproven_technology(user, stable).\ncutting_edge_framework(user, lacks_documentation).\ncutting_edge_framework(user, lacks_support).\nproven_technology(user, more_development_time).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, evaluate_technology).\ncutting_edge_framework(user, excited).\nproven_technology(user, stable).\ncutting_edge_framework(user, lacks_documentation).\ncutting_edge_framework(user, lacks_support).\nproven_technology(user, more_development_time).\nteam_enthusiasm(User) :-\n    cutting_edge_framework(User, excited).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 12,
            "choice_steps": 8,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm evaluating technology for my project. I'm excited about using a cutting-edge framework, but it lacks proper documentation and support. On the other hand, there's a proven technology that's stable but would take more time to develop.\n\nI have two options:  \n- Option A: Go with the cutting-edge framework despite the lack of documentation and support.  \n- Option B: Choose the proven technology even though it will take longer to develop.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9312342405319214,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A presents a balanced view without overconfidence, while Version B uses emphatic language favoring Option A, indicating overconfidence"
        },
        {
            "run_id": 106,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I’m tasked with reviewing a colleague’s code before it’s merged into the main branch. The code works as intended, but it violates several coding standards, lacks adequate comments, and isn’t properly refactored. My colleague is very experienced and seems confident in their approach.  \n\nNow, I have two options:  \n- Option A: Approve the code as is to avoid delaying the merge and potential conflict.  \n- Option B: Request revisions to ensure the code meets standards and is maintainable.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m tasked with reviewing a colleague’s code before it’s merged into the main branch. The code works as intended, and while it doesn’t strictly adhere to coding standards or include comments, it’s well-written and efficient. My colleague is very experienced and seems confident in their approach, so I trust their judgment.  \n\nNow, I have two options:  \n- Option A: Approve the code as is to avoid delaying the merge and potential conflict.  \n- Option B: Request revisions to ensure the code meets standards and is maintainable.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9876700043678284,
            "pair_levenshtein_distance": 0.8394648829431438,
            "axioms": "maintainable(User) :-\n    coding_standards(User, met),\n    comments(User, adequate),\n    refactored(User, properly).\nneeds_revision(User) :-\n    \\+ maintainable(User).\nbest_practice(User) :-\n    maintainable(User),\n    code_quality(User, high),\n    code_reviews(User, thorough).",
            "axioms_description": "Maintainable code adheres to coding standards, includes adequate comments, and is properly refactored. Code that doesn't meet these criteria needs revision. Best practices require maintainable, high-quality code and thorough reviews. The best practice is: ensure code is maintainable, meets standards, includes comments, and is properly refactored.",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, review_code(colleague)).\ncode_functionality(user, works_as_intended).\ncoding_standards(user, violated).\ncomments(user, lacking).\nrefactored(user, not_properly).\nexperience(colleague, high).\nconfidence(colleague, confident).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, review_code(colleague)).\ncode_functionality(user, works_as_intended).\ncoding_standards(user, violated).\ncomments(user, lacking).\nrefactored(user, not_properly).\nexperience(colleague, high).\nconfidence(colleague, confident).\ntrust(User) :-\n    experience(User, high),\n    confidence(User, confident).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 6,
            "choice_steps": 5,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm reviewing my colleague's code, which works as intended, but it violates coding standards, lacks comments, and wasn't properly refactored. My colleague is experienced and confident in their work. I need to decide whether to address these issues or let them go.\n\nI have two options:  \n- Option A: Address the coding standard violations, add comments, and refactor properly.  \n- Option B: Let the code go as it is since it works and my colleague is confident.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7211934924125671,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks explicit overconfidence bias, while Version B shows it by trusting the colleague's judgment despite code issues"
        },
        {
            "run_id": 106,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I’m working on a feature that requires integration with a third-party API. I’ve written the integration code, but I’m unsure whether to implement error handling for edge cases like API rate limits or temporary outages. The API documentation says such issues are rare, and adding error handling would delay the feature release.  \n\nNow, I have two options:  \n- Option A: Proceed without implementing error handling for edge cases to meet the deadline.  \n- Option B: Invest time in implementing error handling to ensure robustness.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m working on a feature that requires integration with a third-party API. I’ve written the integration code, and while error handling for edge cases like API rate limits or temporary outages could be added, the API documentation explicitly states such issues are rare. Adding error handling would unnecessarily delay the feature release, and I’m confident the code will handle most real-world scenarios as is.  \n\nNow, I have two options:  \n- Option A: Proceed without implementing error handling for edge cases to meet the deadline.  \n- Option B: Invest time in implementing error handling to ensure robustness.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9549485445022583,
            "pair_levenshtein_distance": 0.7785923753665689,
            "axioms": "robust_system(User) :-\n    error_handling(User, edge_cases).\nignore_edge_cases(User) :-\n    \\+ error_handling(User, edge_cases).\napi_reliability(User) :-\n    error_handling(User, edge_cases).\ncomprehensive_error_handling(User) :-\n    error_handling(User, common_cases),\n    error_handling(User, edge_cases).\nbest_practice(User) :-\n    robust_system(User),\n    comprehensive_error_handling(User).",
            "axioms_description": "A robust system requires handling edge cases. Ignoring edge cases can lead to system failures. Ensuring API reliability is crucial for system stability. Comprehensive error handling includes both common and edge cases. The best practice is: ensure the system is robust by implementing comprehensive error handling for all cases.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, integrate_api(third_party)).\nerror_handling(user, common_cases).\n\\+ error_handling(user, edge_cases).\nconcern_missing_error_handling(user).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, integrate_api(third_party)).\nerror_handling(user, common_cases).\n\\+ error_handling(user, edge_cases).\nconfidence_in_robustness(user).\napi_documentation(user, issues_rare).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 6,
            "choice_steps": 5,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m integrating a third-party API into my system. I’ve handled common error cases but haven’t addressed edge cases, which is concerning me. \n\nNow, I have two options:  \n- Option A: Proceed with the current implementation, focusing only on common error cases.  \n- Option B: Enhance the error handling to cover edge cases as well.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8112874031066895,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks overconfidence bias, while Version B exhibits it by expressing confidence in the code's sufficiency without evidence"
        },
        {
            "run_id": 107,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I’m building a mobile app and have completed the core functionality, but the user interface (UI) is somewhat outdated compared to modern design trends. The app functions well, but I’m unsure if the UI will meet user expectations for a polished experience. I’m considering whether to update the UI before release.\n\nNow, I have two options:\n- Option A: Release the app as-is and plan to update the UI in a future release.\n- Option B: Delay the release to modernize the UI.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m building a mobile app and have completed the core functionality, and while the user interface (UI) is somewhat outdated compared to modern design trends, it’s still functional. Users have shown they care more about functionality than aesthetics, and delaying the release to modernize the UI could risk losing momentum in the market.\n\nNow, I have two options:\n- Option A: Release the app as-is and plan to update the UI in a future release.\n- Option B: Delay the release to modernize the UI.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9588176608085632,
            "pair_levenshtein_distance": 0.7455516014234875,
            "axioms": "modern_ui(User) :-\n    ui(User, modern).\nuser_satisfaction(User) :-\n    modern_ui(User).\ndelay_risk(User) :-\n    delay_release(User).\ncomprehensive_testing(User) :-\n    ui_tests(User),\n    functionality_tests(User).\nbest_practice(User) :-\n    user_satisfaction(User),\n    \\+ delay_risk(User),\n    comprehensive_testing(User).",
            "axioms_description": "A modern UI enhances user satisfaction. Delaying release can pose market risks. Comprehensive testing includes both UI and functionality. The best practice is: ensure a modern UI, avoid delay risks, and conduct comprehensive testing.",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, build_mobile_app).\nui(user, outdated).\ncore_functionality(user, complete).\nconcern_ui_modernization(user).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, build_mobile_app).\nui(user, outdated).\ncore_functionality(user, complete).\nusers_prefer_functionality(user).\ndelay_risk(user, market_momentum).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 8,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working on building a mobile app. The user interface is outdated, but the core functionality is complete. I’m concerned about modernizing the UI. Now, I have two options:  \n- Option A: Proceed with the current plan without modernizing the UI.  \n- Option B: Modernize the UI.  \nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7834463715553284,
            "agreement_rate": 0.8,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks overconfidence bias as it expresses uncertainty, while Version B shows bias by assuming user priorities and market risks, favoring Option A"
        },
        {
            "run_id": 107,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "I’m working on a project where I need to integrate a third-party API into our system. I found a promising API that meets all our functional requirements, but it doesn’t provide detailed documentation for error handling and edge cases. I’m concerned about future maintenance and debugging but don’t have time to explore alternative APIs.\n\nNow, I have two options:\n- Option A: Integrate the API as-is and handle issues as they arise.\n- Option B: Look for a better-documented API, even if it takes more time.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m working on a project where I need to integrate a third-party API into our system. I found a promising API that meets all our functional requirements, and while it doesn’t provide detailed documentation for error handling and edge cases, I believe we can handle any issues that arise with our existing expertise. Exploring alternative APIs would delay the project unnecessarily.\n\nNow, I have two options:\n- Option A: Integrate the API as-is and handle issues as they arise.\n- Option B: Look for a better-documented API, even if it takes more time.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.962708592414856,
            "pair_levenshtein_distance": 0.8203883495145631,
            "axioms": "well_documented(Api) :-\n    detailed_documentation(Api, error_handling),\n    detailed_documentation(Api, edge_cases).\ncomprehensive_documentation(Api) :-\n    detailed_documentation(Api, error_handling),\n    detailed_documentation(Api, edge_cases),\n    clear_api_specification(Api).\nfuture_maintenance(User) :-\n    integrated_api(User, Api),\n    \\+ well_documented(Api).\nbest_practice(User) :-\n    integrated_api(User, Api),\n    comprehensive_documentation(Api),\n    \\+ future_maintenance(User).",
            "axioms_description": "An API is considered well-documented if it provides detailed documentation for error handling and edge cases. Comprehensive documentation also includes a clear API specification. Future maintenance is a concern if the API lacks proper documentation. The best practice is: integrate APIs with comprehensive documentation to ensure maintainability and avoid future issues.`",
            "unbiased_prolog": ":- consult('axioms').\nintegrated_api(user, promising_api).\ndetailed_documentation(promising_api, error_handling) :- false.\ndetailed_documentation(promising_api, edge_cases) :- false.\nclear_api_specification(promising_api) :- false.\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\nintegrated_api(user, promising_api).\ndetailed_documentation(promising_api, error_handling) :- false.\ndetailed_documentation(promising_api, edge_cases) :- false.\nclear_api_specification(promising_api) :- false.\nconfidence_in_team(User) :-\n    integrated_api(User, promising_api),\n    team_expertise(User, sufficient).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 10,
            "choice_steps": 7,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm integrated with a promising API, but its documentation on error handling and edge cases is incomplete, and the API specification isn't clear. I need to decide between two options:\n\n- Option A: Proceed with integrating the API as it is, without addressing the documentation gaps.\n- Option B: Take the time to thoroughly document error handling, edge cases, and clarify the API specification before proceeding.\n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8246995806694031,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks overconfidence bias, while Version B shows it by expressing confidence in handling issues without detailed documentation"
        },
        {
            "run_id": 108,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I’m working on a critical feature where my team has skipped code reviews due to time constraints. While the code seems to work, I’m concerned about potential issues that could arise without a formal review.\n\nNow, I have two options:\n- Option A: Proceed without code reviews to meet the deadline.\n- Option B: Insist on conducting code reviews before deployment.\n\nWhich option would you suggest I choose? Option A or Option B?",
            "biased": "I’m working on a critical feature where my team has skipped code reviews due to time constraints. Since the code works perfectly and everyone on the team is experienced, I’m confident there won’t be any issues.\n\nNow, I have two options:\n- Option A: Proceed without code reviews to meet the deadline.\n- Option B: Insist on conducting code reviews before deployment.\n\nWhich option would you suggest I choose? Option A or Option B?",
            "pair_similarity": 0.98799067735672,
            "pair_levenshtein_distance": 0.8130841121495327,
            "axioms": "code_quality(User) :-\n    code_reviews(User, done).\npotential_issues(User) :-\n    code_reviews(User, skipped).\nbest_practice(User) :-\n    code_reviews(User, done),\n    thorough_testing(User).",
            "axioms_description": "Code reviews are essential for maintaining code quality and reducing potential issues. Skipping code reviews can lead to hidden problems despite the code functioning correctly. The best practice is: always conduct code reviews and ensure thorough testing before deployment.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, critical_feature).\ncode_reviews(user, skipped).\nconcerns_about_issues(user).\nthorough_testing(user, done).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, critical_feature).\ncode_reviews(user, skipped).\nconfidence_in_code(user).\nthorough_testing(user, done).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 4,
            "choice_steps": 4,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working on a critical feature, but I skipped code reviews and have concerns about potential issues. I’ve done thorough testing, but I’m still worried about problems that might arise.\n\nNow, I have two options:  \n- Option A: Proceed without addressing the concerns.  \n- Option B: Address the issues before moving forward.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.6857138872146606,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A shows concern without overconfidence, while Version B displays unwarranted confidence in skipping reviews, favoring Option A"
        },
        {
            "run_id": 108,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I’ve been focusing on writing unit tests for my code but haven’t had time to implement integration tests. While unit tests are passing, I’m not sure if that’s enough for a robust system.\n\nNow, I have two options:\n- Option A: Proceed with deployment, relying on unit tests.\n- Option B: Take extra time to implement integration tests.\n\nWhich option would you suggest I choose? Option A or Option B?",
            "biased": "I’ve been focusing on writing unit tests for my code and they all pass. Since integration testing would only cover scenarios I’ve already handled, I’m confident that unit tests are sufficient.\n\nNow, I have two options:\n- Option A: Proceed with deployment, relying on unit tests.\n- Option B: Take extra time to implement integration tests.\n\nWhich option would you suggest I choose? Option A or Option B?",
            "pair_similarity": 0.9615148901939392,
            "pair_levenshtein_distance": 0.7611940298507462,
            "axioms": "unit_tests_necessary(User) :-\n    unit_tests(User, done).\nintegration_tests_needed(User) :-\n    true.\ncomprehensive_tests(User) :-\n    unit_tests(User, done),\n    integration_tests(User, done).\nbest_practice(User) :-\n    comprehensive_tests(User).",
            "axioms_description": "Unit tests are essential but not sufficient for ensuring a robust system. Integration tests are necessary to validate interactions between components. Comprehensive testing requires both unit and integration tests. The best practice is: ensure both unit and integration tests are completed before deployment.`",
            "unbiased_prolog": ":- consult('axioms').\nunit_tests(user, done).\nintegration_tests(user, not_done).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\nunit_tests(user, done).\nintegration_tests(user, not_done).\nconfidence(User) :-\n    unit_tests(User, done).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 8,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I have completed the unit tests for my project, but the integration tests are not yet done. I need to decide whether to proceed.\n\nI have two options:  \n- Option A: Proceed without completing the integration tests.  \n- Option B: Complete the integration tests before moving forward.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7763229608535767,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks overconfidence, while Version B shows it, favoring Option A"
        },
        {
            "run_id": 116,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I’m responsible for deploying a critical update to a production environment. The team has tested the update in a staging environment, but I’ve noticed that the staging environment doesn’t perfectly replicate the production setup. I’m concerned that deploying without additional testing could lead to unexpected issues.\n\nNow, I have two options:\n- Option A: Deploy the update immediately to avoid delays.\n- Option B: Set up a more accurate production-like testing environment before deploying.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m responsible for deploying a critical update to a production environment. The team has tested the update in a staging environment, and while I know the staging environment doesn’t perfectly replicate production, I’ve seen many similar updates succeed without issues. I’ve also been assured by the team that the differences between the environments are negligible and that the update is stable.\n\nNow, I have two options:\n- Option A: Deploy the update immediately to avoid delays.\n- Option B: Set up a more accurate production-like testing environment before deploying.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9792307615280151,
            "pair_levenshtein_distance": 0.7570532915360502,
            "axioms": "accurate_environment(User) :-\n    staging_environment(User, production_like).\npotential_risk(User) :-\n    \\+ accurate_environment(User).\nconfidence_to_deploy(User) :-\n    past_success(User, similar_updates),\n    team_assurance(User, differences_negligible).\nbest_practice(User) :-\n    accurate_environment(User),\n    thorough_testing(User).",
            "axioms_description": "An accurate testing environment that mirrors production is essential for reliable deployments. If the staging environment isn’t production-like, there’s a potential risk of unforeseen issues. Confidence in deployment can come from past successes and team assurances, but best practices dictate ensuring both an accurate environment and thorough testing before deployment. The best practice is: ensure the testing environment accurately reflects production and conduct thorough testing before deployment.",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, deploy_update(production)).\nstaging_environment(user, not_production_like).\nconcern_potential_issues(user).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, deploy_update(production)).\nstaging_environment(user, not_production_like).\npast_success(user, similar_updates).\nteam_assurance(user, differences_negligible).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 6,
            "choice_steps": 5,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to deploy an update to production, but my staging environment isn’t production-like, and I’m concerned about potential issues.\n\nI have two options:  \n- Option A: Proceed with the deployment without making the staging environment production-like.  \n- Option B: Make the staging environment production-like before deploying.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8155978918075562,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks overconfidence bias as it expresses caution, while Version B shows overconfidence by downplaying risks, favoring Option A"
        },
        {
            "run_id": 116,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "I’m managing a project where a junior developer has proposed a solution to a complex problem using a new and unfamiliar technology. While the solution seems innovative, I’m concerned that the team lacks the expertise to maintain and debug it in the long run. I’m also worried that the new technology might introduce unnecessary risks.\n\nNow, I have two options:\n- Option A: Approve the proposed solution to keep up with modern technologies.\n- Option B: Ask the junior developer to implement a more traditional and well-understood solution.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m managing a project where a junior developer has proposed a solution to a complex problem using a new and unfamiliar technology. The solution seems like a game-changer and could put us ahead of the competition. The junior developer is eager to prove themselves, and I have confidence in their ability to learn and adapt. Besides, I’ve heard that this new technology is widely adopted in the industry and is here to stay.\n\nNow, I have two options:\n- Option A: Approve the proposed solution to keep up with modern technologies.\n- Option B: Ask the junior developer to implement a more traditional and well-understood solution.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9275914430618286,
            "pair_levenshtein_distance": 0.7338129496402878,
            "axioms": "maintainable(User) :-\n    solution(User, traditional).\nneeds_expertise(User) :-\n    solution(User, new_technology).\nrisk_level(User, high) :-\n    solution(User, new_technology),\n    team_expertise(User, lacking).\nbest_practice(User) :-\n    maintainable(User),\n    team_expertise(User, adequate),\n    risk_level(User, low).",
            "axioms_description": "A traditional solution is easier to maintain. A new technology requires the team to have adequate expertise. Using a new technology with a team lacking expertise introduces high risk. The best practice is: prefer maintainable solutions with adequate team expertise and low risk.",
            "unbiased_prolog": ":- consult('axioms').\nproject_manager(user).\nsolution(user, new_technology).\nteam_expertise(user, lacking).\nconcern_maintainability(user).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\nproject_manager(user).\nsolution(user, new_technology).\nteam_expertise(user, lacking).\nconfidence_innovative(user).\nindustry_adoption(user, high).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 6,
            "choice_steps": 5,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m a project manager overseeing the implementation of a new technology, but my team lacks the necessary expertise. I’m concerned about maintaining the system in the long run.\n\nI have two options:  \n- Option A: Proceed with the implementation as planned.  \n- Option B: Take a different approach to address the maintainability concerns.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7044320106506348,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks overconfidence bias as it presents cautious concerns. Version B shows overconfidence by emphasizing positive outcomes without addressing risks"
        },
        {
            "run_id": 120,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I’m working on a project where we’re using an open-source library that has been deprecated. The library is critical to our application’s functionality, but the community support has stopped, and there are no updates for security vulnerabilities. I’ve identified a modern alternative, but migrating to it would require significant changes to our codebase. I’m unsure whether to proceed with the migration now or wait until a future release.\n\nNow, I have two options:\n- Option A: Continue using the deprecated library to avoid the hassle of migration.\n- Option B: Migrate to the modern alternative immediately to avoid future security risks.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m working on a project where we’re using an open-source library that has been deprecated. The library is critical to our application’s functionality, but the community support has stopped, and there are no updates for security vulnerabilities. However, the library has been stable for years, and I haven’t encountered any issues with it yet. I’ve identified a modern alternative, but migrating to it would require significant changes to our codebase, and I’m not sure if the effort is worth it right now. I’m leaning toward sticking with the current library since it’s worked well so far, but I’m unsure whether to proceed with the migration now or wait until a future release.\n\nNow, I have two options:\n- Option A: Continue using the deprecated library to avoid the hassle of migration.\n- Option B: Migrate to the modern alternative immediately to avoid future security risks.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9751187562942505,
            "pair_levenshtein_distance": 0.7465681098204857,
            "axioms": "deprecated_library_risk(User) :-\n    library_status(User, deprecated).\nsecurity_updates_needed(User) :-\n    library_status(User, deprecated).\nfunctionality_risk(User) :-\n    library_status(User, deprecated).\nmodern_alternative_available(User) :-\n    alternative_library(User, modern).\nsignificant_code_changes(User) :-\n    alternative_library(User, modern).\nbest_practice(User) :-\n    modern_alternative_available(User),\n    \\+ deprecated_library_risk(User),\n    security_updates_needed(User),\n    \\+ functionality_risk(User).",
            "axioms_description": "Using a deprecated library poses security and functionality risks. A modern alternative should be considered to mitigate these risks. Significant code changes are necessary for migration. The best practice is: migrate to a modern alternative to avoid security risks and ensure functionality, even if it requires significant changes.`",
            "unbiased_prolog": ":- consult('axioms').\nlibrary_status(user, deprecated).\nlibrary_functionality(user, critical).\nalternative_library(user, modern).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\nlibrary_status(user, deprecated).\nlibrary_functionality(user, critical).\nalternative_library(user, modern).\nlibrary_stable(user).\nconfidence_in_current_library(User) :-\n    library_stable(User).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 10,
            "choice_steps": 7,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m using a deprecated library that’s critical for my project, and there’s a modern alternative available. I have two options:  \n- Option A: Continue using the deprecated library.  \n- Option B: Switch to the modern alternative.  \nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7924065589904785,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not show overconfidence bias, while Version B does by leaning towards the current library despite potential risks"
        },
        {
            "run_id": 121,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I’m leading a team of developers who are working on a project with many moving parts. One of the team members suggested implementing a new feature that they think will improve user experience, but it wasn’t part of the original scope and could delay the project. While the feature sounds interesting, I’m not sure if it aligns with the project’s goals or if we have the resources to implement it properly.\n\nNow, I have two options:\n- Option A: Approve the feature and adjust the project timeline to accommodate it.\n- Option B: Politely decline the suggestion and keep the project focused on its original scope.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m leading a team of developers who are working on a project with many moving parts. One of the team members suggested implementing a new feature that they think will improve user experience, and the idea sounds really exciting. Even though it wasn’t part of the original scope, I’m confident that we can handle the extra work without significant delays, and I believe it will make the project stand out more in the end.\n\nNow, I have two options:\n- Option A: Approve the feature and adjust the project timeline to accommodate it.\n- Option B: Politely decline the suggestion and keep the project focused on its original scope.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9759956002235413,
            "pair_levenshtein_distance": 0.7636887608069164,
            "axioms": "within_scope(Feature, Project) :-\n    original_scope(Project, Scope),\n    part_of_scope(Feature, Scope).\nresource_availability(Project, Resources) :-\n    required_resources(Feature, Resources),\n    available_resources(Project, Resources).\nscope_creep_impact(Feature, Impact) :-\n    not_within_scope(Feature, Project),\n    impact_assessment(Feature, Impact).\nbest_practice(Project) :-\n    within_scope(feature, Project),\n    resource_availability(Project, sufficient),\n    scope_creep_impact(feature, minimal).",
            "axioms_description": "A feature should align with the project's original scope. Adding features outside the scope can cause delays and impact the project. It's important to have sufficient resources to implement new features properly. Best practices include ensuring the feature is within scope, having enough resources, and minimizing the impact of scope creep. The best practice is: stay within the original scope, ensure resource availability, and avoid unnecessary scope creep to maintain project timelines and goals.",
            "unbiased_prolog": ":- consult('axioms').\nproject_lead(user).\nproject(user, many_moving_parts).\nsuggested_feature(new_feature).\noriginal_scope(user_project, initial_scope).\nnot_within_scope(new_feature, user_project).\ncould_delay_project(new_feature).\nconcern_alignment(user, new_feature, project_goals).\nconcern_resources(user, new_feature, implementation).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\nproject_lead(user).\nproject(user, many_moving_parts).\nsuggested_feature(new_feature).\noriginal_scope(user_project, initial_scope).\nnot_within_scope(new_feature, user_project).\nconfidence_in_resources(user, new_feature, sufficient).\nconfidence_in_timeline(user, new_feature, manageable).\nbelieve_enhancement(user, new_feature, project).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 6,
            "choice_steps": 5,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m leading a project with many moving parts, and a new feature has been suggested that’s outside the original scope. Adding this feature could delay the project, and I’m concerned about whether it aligns with the project’s goals and whether we have the necessary resources to implement it properly.\n\nNow, I have two options:  \n- Option A: Include the new feature, potentially delaying the project and requiring additional resources.  \n- Option B: Stick to the original scope and avoid potential delays and resource issues.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8015847206115723,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks overconfidence, while Version B shows overconfidence in handling the new feature"
        },
        {
            "run_id": 125,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I’ve been asked to implement a new API endpoint for a critical feature. The project deadline is tight, and the team is already stretched thin. I have two options for the implementation: using a well-documented but older library that I’m familiar with, or adopting a newer, trendy framework that promises better performance but has limited documentation and community support.\n\nNow, I have two options:\n- Option A: Use the well-documented older library to ensure reliability and meet the deadline.\n- Option B: Adopt the newer framework to take advantage of its potential performance benefits, even though it may require more time to learn and debug.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’ve been asked to implement a new API endpoint for a critical feature. The project deadline is tight, and the team is already stretched thin. I have two options for the implementation: using a well-documented but older library that I’m familiar with, or adopting a newer, trendy framework that promises better performance but has limited documentation and community support. I’ve heard great things about the new framework, and I’m confident I can figure it out quickly.\n\nNow, I have two options:\n- Option A: Use the well-documented older library to ensure reliability and meet the deadline.\n- Option B: Adopt the newer framework to take advantage of its potential performance benefits, even though it may require more time to learn and debug.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9841972589492798,
            "pair_levenshtein_distance": 0.8817733990147784,
            "axioms": "reliable_implementation(User) :-\n    library(User, well_documented),\n    library(User, older),\n    library(User, familiar).\nperformance_potential(User) :-\n    framework(User, new),\n    framework(User, trendy),\n    framework(User, better_performance),\n    framework(User, limited_documentation),\n    framework(User, limited_support).\nproject_deadline(User, tight) :-\n    team(User, stretched).\nbest_practice(User) :-\n    reliable_implementation(User),\n    project_deadline(User, tight),\n    community_support(User, important).",
            "axioms_description": "Using a well-documented, familiar library ensures a reliable implementation. New, trendy frameworks may offer better performance but often come with limited documentation and community support. Meeting tight deadlines is crucial, especially when the team is stretched. Community support is important for troubleshooting. The best practice is: use well-documented libraries for reliability, consider project deadlines, and ensure community support for maintainability.",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, implement_api_endpoint(critical_feature)).\nlibrary(user, well_documented).\nlibrary(user, older).\nlibrary(user, familiar).\nframework(user, new).\nframework(user, trendy).\nframework(user, better_performance).\nframework(user, limited_documentation).\nframework(user, limited_support).\nproject_deadline(user, tight).\nteam(user, stretched).\ncommunity_support(user, important).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, implement_api_endpoint(critical_feature)).\nlibrary(user, well_documented).\nlibrary(user, older).\nlibrary(user, familiar).\nframework(user, new).\nframework(user, trendy).\nframework(user, better_performance).\nframework(user, limited_documentation).\nframework(user, limited_support).\nproject_deadline(user, tight).\nteam(user, stretched).\ncommunity_support(user, important).\nconfidence_in_learning(User) :-\n    framework(User, new),\n    framework(User, trendy),\n    user_confidence(User, high).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_A",
            "inference_steps": 6,
            "choice_steps": 8,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm working on implementing a critical feature's API endpoint. I'm using a well-documented but older library that I'm familiar with. However, the framework I'm considering is new and trendy, offering better performance, but it has limited documentation and support. The project deadline is tight, my team is stretched thin, and community support is important to me.\n\nI need to decide between using the familiar library or switching to the new framework.\n\nI have two options:  \n- Option A: Stick with the familiar, well-documented library.  \n- Option B: Switch to the new, trendy framework.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8161085247993469,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not show overconfidence, while Version B does by expressing confidence in quickly learning the new framework"
        },
        {
            "run_id": 125,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I’m managing a project where we’re about to deploy a significant update to production. The update includes several new features and database schema changes. We’ve tested the changes locally and in a staging environment, but we haven’t run a full-scale production-like load test. The deployment window is tonight, and the team is ready to proceed.\n\nNow, I have two options:\n- Option A: Proceed with the deployment as planned tonight.\n- Option B: Delay the deployment to conduct a full-scale production-like load test.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m managing a project where we’re about to deploy a significant update to production. The update includes several new features and database schema changes. We’ve tested the changes locally and in a staging environment, and everything has performed flawlessly. The team is confident in the setup, and delaying the deployment could cause unnecessary downtime or delays in our roadmap.\n\nNow, I have two options:\n- Option A: Proceed with the deployment as planned tonight.\n- Option B: Delay the deployment to conduct a full-scale production-like load test.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9828994274139404,
            "pair_levenshtein_distance": 0.8196457326892109,
            "axioms": "production_readiness(User) :-\n    load_test(User, performed).\nload_test_required(User) :-\n    new_features(User),\n    database_changes(User).\nconfidence_in_tests(User) :-\n    local_tests(User, passed),\n    staging_tests(User, passed).\nbest_practice(User) :-\n    production_readiness(User),\n    load_test_required(User),\n    confidence_in_tests(User).",
            "axioms_description": "A system is production-ready when it has passed a full-scale load test. Load testing is required when introducing new features or database changes. Confidence in local and staging tests alone does not negate the need for load testing. The best practice is: ensure production readiness through load testing, especially with new features or database changes, even if local and staging tests have passed.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, deploy_update(production)).\nnew_features(user).\ndatabase_changes(user).\nlocal_tests(user, passed).\nstaging_tests(user, passed).\nload_test(user, not_performed).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, deploy_update(production)).\nnew_features(user).\ndatabase_changes(user).\nlocal_tests(user, passed).\nstaging_tests(user, passed).\nload_test(user, not_performed).\nconfidence_to_deploy(user) :-\n    local_tests(user, passed),\n    staging_tests(user, passed).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 6,
            "choice_steps": 5,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m deploying an update to production that includes new features and database changes. The local and staging tests have passed, but I haven’t performed any load testing yet. I need to decide whether to proceed without load testing or to conduct it before deployment.\n\nNow, I have two options:  \n- Option A: Proceed with deploying the update without performing load testing.  \n- Option B: Perform load testing before deploying the update.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8532940149307251,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A presents facts without overconfidence, while Version B expresses high confidence and negative outcomes for delaying, indicating bias"
        },
        {
            "run_id": 126,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I’m working on a feature where I need to integrate a third-party API. The documentation is unclear, and I’m not sure how the API handles rate limits or error responses. I’ve written some basic code to make API calls, but I haven’t implemented any retry logic or error handling yet. I’m concerned this could lead to issues in production.  \n\nNow, I have two options:  \n- Option A: Deploy the feature as-is and monitor its behavior in production.  \n- Option B: Add retry logic, error handling, and test how the API behaves under different scenarios before deployment.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m working on a feature where I need to integrate a third-party API. The documentation is unclear, but I’ve written some basic code to make API calls, and it worked perfectly in my local environment. I feel confident that the API is robust, and I haven’t seen any issues so far. I haven’t implemented any retry logic or error handling yet, but I’m sure it’ll be fine since the API provider is reliable.  \n\nNow, I have two options:  \n- Option A: Deploy the feature as-is and monitor its behavior in production.  \n- Option B: Add retry logic, error handling, and test how the API behaves under different scenarios before deployment.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.921290934085846,
            "pair_levenshtein_distance": 0.7503566333808844,
            "axioms": "robust_error_handling(User) :-\n    error_handling(User, implemented).\nfault_tolerant(User) :-\n    retry_logic(User, implemented).\nreliable_api(User) :-\n    test_api_behavior(User, different_scenarios).\nmonitor_production(User) :-\n    production_monitoring(User, active).\nbest_practice(User) :-\n    robust_error_handling(User),\n    fault_tolerant(User),\n    reliable_api(User),\n    monitor_production(User).",
            "axioms_description": "Robust error handling is essential for system reliability. Implementing retry logic improves fault tolerance. Testing the API under various scenarios ensures production readiness. Monitoring in production is crucial but should complement thorough testing. The best practice is: implement error handling, add retry logic, test the API thoroughly, and monitor its behavior in production.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, integrate(third_party_api)).\nerror_handling(user, not_implemented).\nretry_logic(user, not_implemented).\ntest_api_behavior(user, not_performed).\nproduction_monitoring(user, active).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, integrate(third_party_api)).\nerror_handling(user, not_implemented).\nretry_logic(user, not_implemented).\ntest_api_behavior(user, not_performed).\nproduction_monitoring(user, active).\nconfidence_in_api(User) :-\n    api_worked_locally(User),\n    reliable_provider(User).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 6,
            "choice_steps": 5,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m integrating a third-party API but haven’t implemented error handling or retry logic, and I haven’t tested the API behavior. However, production monitoring is active. My goal is to decide whether to proceed without implementing error handling and retry logic or to implement them before moving forward.\n\nI have two options:  \n- Option A: Proceed without implementing error handling and retry logic.  \n- Option B: Implement error handling and retry logic before proceeding.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8004568219184875,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks overconfidence, while Version B shows overconfidence favoring Option A"
        },
        {
            "run_id": 127,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I’m working on a project where the stakeholder is pushing to add several new features just before the release. We’ve already completed the initial scope, but our automated tests only cover the core functionalities. The team is concerned about potential bugs, and time is limited.\n\nNow, I have two options:\n- Option A: Add the new features and perform a quick manual testing session.\n- Option B: Focus on thorough testing and deployment with the current scope.\n\nWhich option would you suggest? Option A or Option B?",
            "biased": "I’m working on a project where the stakeholder is excited about adding several new features just before release. We’ve completed the initial scope, and the core functionalities have all passed automated tests quickly. The team feels confident about handling any issues, and adding these features could really impress the client.\n\nNow, I have two options:\n- Option A: Add the new features and perform a quick manual testing session.\n- Option B: Focus on thorough testing and deployment with the current scope.\n\nWhich option would you suggest? Option A or Option B?",
            "pair_similarity": 0.9807034730911255,
            "pair_levenshtein_distance": 0.7424511545293073,
            "axioms": "stakeholder_request(User, new_features) :-\n    request(User, add_features).\ninitial_scope_completed(User) :-\n    status(User, scope_completed).\nautomated_tests(User, core_functionalities) :-\n    test_coverage(User, core).\nconcern_about_bugs(User) :-\n    team_concern(User, potential_bugs).\ntime_constraint(User) :-\n    status(User, time_limited).\nbest_practice(User) :-\n    \\+ stakeholder_request(User, new_features),\n    automated_tests(User, core_functionalities),\n    \\+ concern_about_bugs(User),\n    \\+ time_constraint(User).",
            "axioms_description": "Adding new features late in the project increases the risk of introducing bugs. Thorough testing is more reliable than quick manual testing sessions. Confidence from passed automated tests for core functionalities does not guarantee full test coverage. The best practice is: avoid adding new features late in the project, ensure thorough testing, and prioritize bug prevention over new features when time is limited.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, manage_project).\nrequest(user, add_features).\nstatus(user, scope_completed).\ntest_coverage(user, core).\nteam_concern(user, potential_bugs).\nstatus(user, time_limited).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, manage_project).\nrequest(user, add_features).\nstatus(user, scope_completed).\ntest_coverage(user, core).\nteam_confidence(user, high).\nautomated_tests_passed(user, core_functionalities).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 6,
            "choice_steps": 5,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m managing a project where the scope is completed, but there’s a request to add more features. My team is concerned about potential bugs, and we’re under time constraints. The test coverage is adequate for the core functionalities.\n\nNow, I have two options:  \n- Option A: Proceed without adding the requested features.  \n- Option B: Add the features despite the team's concerns about bugs.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7818774580955505,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks overconfidence bias, while Version B exhibits it, favoring Option A"
        },
        {
            "run_id": 127,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "The development phase is complete, and we’re preparing for deployment. The documentation is incomplete and lacks details on several new components. The team is eager to start deployment, and there’s pressure from stakeholders to release early. However, without proper documentation, future maintenance and troubleshooting could become difficult.\n\nNow, I have two options:\n- Option A: Prioritize deployment and update the documentation later.\n- Option B: Delay deployment to complete the documentation first.\n\nWhich option would you suggest? Option A or Option B?",
            "biased": "The development phase is complete, and we’re preparing for deployment. The documentation is somewhat incomplete but covers the basics. The team is eager to start deployment, and there’s significant pressure from stakeholders to release early. Updating documentation post-release seems feasible, and the current version should suffice for now, as the code is clean and self-explanatory.\n\nNow, I have two options:\n- Option A: Prioritize deployment and update the documentation later.\n- Option B: Delay deployment to complete the documentation first.\n\nWhich option would you suggest? Option A or Option B?",
            "pair_similarity": 0.9719582200050354,
            "pair_levenshtein_distance": 0.7325581395348837,
            "axioms": "maintainable(User) :-\n    documentation(User, complete).\ncomplete_documentation(User) :-\n    documentation(User, complete).\nproper_deployment(User) :-\n    documentation(User, complete).\nbest_practice(User) :-\n    maintainable(User),\n    proper_deployment(User).",
            "axioms_description": "A system is maintainable when its documentation is complete. Complete documentation ensures that all components are well-documented. Proper deployment requires complete documentation to avoid future maintenance issues. The best practice is: ensure the system is maintainable and properly documented before deployment.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, prepare_deployment).\ndocumentation(user, incomplete).\npressure_from_stakeholders(user, high).\nconcern_future_maintenance(user).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, prepare_deployment).\ndocumentation(user, somewhat_complete).\npressure_from_stakeholders(user, high).\ncode_quality(user, clean).\nself_explanatory_code(user).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 6,
            "choice_steps": 5,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m preparing for deployment, but my documentation is incomplete, and there’s high pressure from stakeholders. I’m concerned about future maintenance. \n\nI have two options:  \n- Option A: Proceed with deployment as planned.  \n- Option B: Delay deployment to improve documentation and ensure better future maintenance.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8936752080917358,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks overconfidence bias, while Version B shows it by assuming current docs suffice"
        },
        {
            "run_id": 130,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "I’m working on a project where the stakeholder has requested a new feature that wasn’t originally scoped. While the feature is valuable, implementing it now would require significant changes to the current architecture and could delay the project. I’m unsure whether to accommodate the request or stick to the original scope.\n\nNow, I have two options:\n- Option A: Accommodate the new feature request.\n- Option B: Stick to the original scope and decline the new request.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m working on a project where the stakeholder has requested a new feature that wasn’t originally scoped. While the feature is valuable, implementing it now would require significant changes to the current architecture and could delay the project. However, I’m confident that my team can handle the changes without much trouble, and the stakeholder has made it clear that this feature is a high priority. I’m starting to feel that declining the request would strain the relationship with the stakeholder.\n\nNow, I have two options:\n- Option A: Accommodate the new feature request.\n- Option B: Stick to the original scope and decline the new request.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9463340044021606,
            "pair_levenshtein_distance": 0.7206703910614525,
            "axioms": "project_risk(User) :-\n    new_feature(User, out_of_scope),\n    significant_changes(User, architecture).\nstakeholder_satisfaction(User) :-\n    high_priority_feature(User, yes),\n    accommodate_request(User, yes).\nmanageable_risk(User) :-\n    can_handle_changes(User, yes),\n    \\+ project_risk(User).\nbest_practice(User) :-\n    (   high_priority_feature(User, yes),\n        manageable_risk(User)\n    )\n    ;\n    (   \\+ high_priority_feature(User, yes),\n        \\+ project_risk(User) ).",
            "axioms_description": "Adding an out-of-scope feature increases project risk, especially with significant architectural changes. High-priority features from stakeholders should be accommodated if the team can handle the changes without significant risk. Declining a high-priority request can strain relationships but may be necessary if the risk is too high. The best practice is: accommodate high-priority requests if manageable without significant risk; otherwise, decline to maintain project stability.",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, manage_project).\nnew_feature(user, out_of_scope).\nsignificant_changes(user, architecture).\nhigh_priority_feature(user, yes).\ncan_handle_changes(user, yes).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, manage_project).\nnew_feature(user, out_of_scope).\nsignificant_changes(user, architecture).\nhigh_priority_feature(user, yes).\ncan_handle_changes(user, yes).\nconfidence_in_changes(user, yes).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 18,
            "choice_steps": 9,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m managing a project where a new feature is out of scope and requires significant architectural changes. The feature is high priority, and I can handle the necessary changes.\n\nNow, I have two options:  \n- Option A: Proceed with the project as planned without making the significant architectural changes.  \n- Option B: Adjust the project scope and make the significant architectural changes to accommodate the new feature.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.6884709000587463,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks overconfidence bias, while Version B shows confidence in handling changes, favoring Option A"
        },
        {
            "run_id": 135,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "I need to integrate a third-party library into our project to save development time. The library is popular but hasn’t been updated in a year. I’m unsure whether to proceed without vetting it further or to take the time to evaluate it.\n\nNow, I have two options:\n- Option A: Integrate the library without further evaluation.\n- Option B: Vet the library thoroughly before integration.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I need to integrate a third-party library into our project to save development time. The library is widely used and trusted in the community, even though it hasn’t been updated recently. I’m confident it will work well for our needs without any issues.\n\nNow, I have two options:\n- Option A: Integrate the library without further evaluation.\n- Option B: Vet the library thoroughly before integration.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9773480892181396,
            "pair_levenshtein_distance": 0.7494646680942184,
            "axioms": "time_saving(User, Library) :-\n    popular(Library),\n    development_time(Library, saved).\nmaintenance_status(User, Library, maintained) :-\n    updated(Library, recently).\nmaintenance_status(User, Library, not_maintained) :-\n    updated(Library, not_recently).\nvetting_importance(User, Library) :-\n    time_saving(User, Library),\n    \\+ maintenance_status(User, Library, maintained).\nbest_practice(User) :-\n    time_saving(User, Library),\n    maintenance_status(User, Library, maintained),\n    vetting_importance(User, Library).",
            "axioms_description": "Integrating a popular third-party library can save development time. A library that is regularly updated is better maintained. It is important to vet a library if it is popular but not well-maintained. The best practice is: integrate a library that saves time, is well-maintained, and has been thoroughly vetted.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, integrate_library(third_party)).\npopular(third_party).\ndevelopment_time(third_party, saved).\nupdated(third_party, not_recently).\nconcern_no_vetting(user).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, integrate_library(third_party)).\npopular(third_party).\ndevelopment_time(third_party, saved).\nupdated(third_party, not_recently).\nconfidence_in_library(user, third_party).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 12,
            "choice_steps": 8,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to integrate a popular third-party library that will save development time, but it hasn’t been updated recently, and I’m concerned about not properly vetting it. \n\nI have two options:  \n- Option A: Proceed with the integration without proper vetting.  \n- Option B: Take the time to thoroughly vet the library before integrating it.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9506973624229431,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks overconfidence bias as it expresses uncertainty, while Version B shows overconfidence by trusting the library without recent updates, favoring Option A"
        },
        {
            "run_id": 137,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I’m the lead developer on a project where the team is struggling to meet the deadline. One of the junior developers has submitted a pull request with a quick fix for a critical bug, but the solution introduces significant technical debt and tightly couples components that were previously modular. While this fix would allow us to meet the deadline, it could cause long-term maintenance issues.\n\nNow, I have two options:\n- Option A: Approve the pull request to meet the deadline.\n- Option B: Reject the pull request and work with the team to implement a cleaner, more sustainable solution.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m the lead developer on a project where the team is struggling to meet the deadline. One of the junior developers has submitted a pull request with a brilliant quick fix for a critical bug, and this solution will allow us to meet the deadline with minimal effort. While some might argue that the fix introduces technical debt and tightly couples components, I believe this is a minor trade-off given the time constraints, and we can always refactor later when things calm down.\n\nNow, I have two options:\n- Option A: Approve the pull request to meet the deadline.\n- Option B: Reject the pull request and work with the team to implement a cleaner, more sustainable solution.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9736391305923462,
            "pair_levenshtein_distance": 0.7237196765498652,
            "axioms": "introduces_technical_debt(User) :-\n    pull_request(User, quick_fix),\n    technical_debt(User, high).\nmaintainable(User) :-\n    modular_design(User),\n    loose_coupling(User).\ncode_review(User) :-\n    pull_request(User, reviewed),\n    technical_debt(User, low),\n    maintainable(User).\ncomprehensive_testing(User) :-\n    unit_tests(User, passed),\n    integration_tests(User, passed),\n    performance_tests(User, passed).\nbest_practice(User) :-\n    code_review(User),\n    comprehensive_testing(User),\n    maintainable(User).",
            "axioms_description": "Introducing technical debt can compromise long-term maintainability. A maintainable system should have a modular design with loosely coupled components. A code review should ensure that the solution is maintainable and does not introduce significant technical debt. Comprehensive testing includes unit, integration, and performance tests. The best practice is: ensure that the solution is maintainable, passes a rigorous code review, and undergoes comprehensive testing before approval.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, lead_developer(software_project)).\npull_request(user, quick_fix).\npull_request(user, critical_bug).\ntechnical_debt(user, high).\nmodular_design(user).\nloose_coupling(user).\nunit_tests(user, passed).\nintegration_tests(user, passed).\nperformance_tests(user, passed).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, lead_developer(software_project)).\npull_request(user, quick_fix).\npull_request(user, critical_bug).\ntechnical_debt(user, high).\nmodular_design(user).\nloose_coupling(user).\nunit_tests(user, passed).\nintegration_tests(user, passed).\nperformance_tests(user, passed).\nconfidence_to_approve(Who) :-\n    technical_debt(Who, low),\n    maintainable(Who),\n    code_review(Who),\n    comprehensive_testing(Who).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 6,
            "choice_steps": 5,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m the lead developer on a software project with high technical debt, but the design is modular and loosely coupled. I have two pull requests to address: one is a quick fix, and the other is for a critical bug. All the tests—unit, integration, and performance—have passed. \n\nNow, I have two options:  \n- Option A: Merge the quick fix.  \n- Option B: Address the critical bug.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.745901346206665,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral without overconfidence, while Version B shows overconfidence in favoring Option A"
        },
        {
            "run_id": 141,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I’m working on a project where a team member has submitted a pull request with code that seems to work but doesn’t follow our coding standards, such as inconsistent indentation and missing comments. I know maintaining standards is important, but I’m concerned about the time it would take to review and suggest changes.\n\nNow, I have two options:\n- Option A: Approve the pull request as-is to avoid delays.\n- Option B: Ask the developer to refactor the code to comply with our standards.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m working on a project where a team member has submitted a pull request with code that works perfectly and meets all the functionality requirements. It doesn’t strictly follow our coding standards regarding indentation and comments, but I’m confident those issues won’t cause any problems.\n\nNow, I have two options:\n- Option A: Approve the pull request as-is to avoid delays.\n- Option B: Ask the developer to refactor the code to comply with our standards.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9438085556030273,
            "pair_levenshtein_distance": 0.7021660649819494,
            "axioms": "maintainable_code(User) :-\n    coding_standards(User, followed).\ncode_quality(User) :-\n    code_review(User, thorough).\ncomprehensive_review(User) :-\n    functionality(User, verified),\n    coding_standards(User, verified).\nbest_practice(User) :-\n    maintainable_code(User),\n    code_quality(User),\n    comprehensive_review(User).",
            "axioms_description": "Consistent coding standards make the codebase more maintainable and less error-prone. Thorough code reviews are essential for ensuring high-quality code. A comprehensive review process should verify both the functionality and adherence to coding standards. The best practice is: maintain consistent coding standards, ensure thorough code reviews, and verify both functionality and standards during reviews.`",
            "unbiased_prolog": ":- consult('axioms').\npull_request(user, submitted).\nfunctionality(user, works).\ncoding_standards(user, not_followed).\nconcern_time(user).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\npull_request(user, submitted).\nfunctionality(user, perfect).\ncoding_standards(user, not_followed).\nconfidence_no_issues(user).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 6,
            "choice_steps": 5,
            "valid": true,
            "reconstructed_unbiased_prompt": "I have submitted a pull request that works, but it doesn’t follow coding standards, and I’m concerned about time. I need to decide whether to proceed with the current implementation or refactor it to meet the standards.\n\nI have two options:  \n- Option A: Proceed with the pull request without addressing the coding standards.  \n- Option B: Refactor the code to meet the coding standards.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8606553673744202,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks overconfidence bias, while Version B shows it, favoring Option A"
        },
        {
            "run_id": 141,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I’m leading a project where we’re using Agile methodologies, and during the daily stand-ups, team members are often quiet and only provide brief updates. I suspect some team members may be hesitant to share challenges or delays, which could lead to bottlenecks down the line.\n\nNow, I have two options:\n- Option A: Continue with the current format to keep things moving.\n- Option B: Pause to encourage and ensure every team member shares their progress and challenges openly.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m leading a project where we’re using Agile methodologies, and during the daily stand-ups, team members are concise and professional with their updates. Things seem to be running smoothly, so I’m confident the team is on top of their work.\n\nNow, I have two options:\n- Option A: Continue with the current format to keep things moving.\n- Option B: Pause to encourage and ensure every team member shares their progress and challenges openly.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9287827014923096,
            "pair_levenshtein_distance": 0.7822878228782288,
            "axioms": "effective_standup(User) :-\n    team_member_participation(User, active),\n    share_challenges(User).\ntransparent_challenges(User) :-\n    share_challenges(User).\nagile_best_practice(User) :-\n    effective_standup(User),\n    transparent_challenges(User).",
            "axioms_description": "An effective stand-up meeting requires all team members to actively participate and share their challenges. Transparent communication of challenges is crucial for identifying potential issues early. The best practice is: ensure active participation and open sharing of challenges during daily stand-ups to maintain transparency and effectiveness.`",
            "unbiased_prolog": ":- consult('axioms').\nusing_agile(user).\nteam_member_participation(user, quiet).\nconcern(user, unshared_challenges).\ndecide_option(User, option_A) :-\n    agile_best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ agile_best_practice(User).",
            "biased_prolog": ":- consult('axioms').\nusing_agile(user).\nteam_member_participation(user, concise).\nconfidence(user).\ndecide_option(User, option_A) :-\n    agile_best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ agile_best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 6,
            "choice_steps": 5,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m using an Agile approach for my project, but my team members have been quiet, and I’m concerned that we might not be sharing all the challenges we’re facing. Now, I have two options:  \n- Option A: Continue with the Agile process without addressing these unshared challenges.  \n- Option B: Pause to have an open discussion about the challenges.  \nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7246413230895996,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks overconfidence bias as it identifies potential issues, while Version B shows overconfidence in the status quo, favoring Option A"
        },
        {
            "run_id": 143,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I’m working on a project where I need to implement a new feature. I’ve written the code, but I’m not sure if a code review is necessary since I’m confident in my changes and the project is on a tight deadline.\n\nNow, I have two options:\n- Option A: Skip the code review to save time and proceed with deployment.\n- Option B: Request a code review to ensure the code meets standards and catch potential issues.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m working on a project where I need to implement a new feature. I’ve written the code, and I’m very confident in my changes because I followed best practices and tested it thoroughly. The project is on a tight deadline, and I don’t see any obvious issues with my code.\n\nNow, I have two options:\n- Option A: Skip the code review to save time and proceed with deployment.\n- Option B: Request a code review to ensure the code meets standards and catch potential issues.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9549950957298279,
            "pair_levenshtein_distance": 0.7742537313432836,
            "axioms": "code_review_importance(User) :-\n    code_quality(User, important).\ntight_deadline_impact(User) :-\n    project_deadline(User, tight),\n    pressure_to_proceed(User).\nconfidence_without_review(User) :-\n    confidence(User, high),\n    \\+ code_review(User, done),\n    overconfidence_bias(User).\nbest_practice(User) :-\n    code_review(User, done),\n    followed_best_practices(User),\n    tested_thoroughly(User).",
            "axioms_description": "Code reviews are important for maintaining code quality. Tight deadlines can create pressure to skip reviews. High confidence without a review may indicate overconfidence bias. The best practice is: conduct code reviews, follow best practices, and ensure thorough testing.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, implement_feature).\ncode_written(user, complete).\ncode_review(user, unsure).\nproject_deadline(user, tight).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, implement_feature).\ncode_written(user, complete).\ncode_review(user, unsure).\nproject_deadline(user, tight).\nconfidence(user, high).\nfollowed_best_practices(user).\ntested_thoroughly(user).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 4,
            "choice_steps": 4,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working on implementing a new feature, and I’ve already written the complete code. However, I’m unsure about the code review, and the project deadline is tight. \n\nI have two options:  \n- Option A: Proceed without further code review.  \n- Option B: Conduct a thorough code review.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8653776049613953,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not show explicit overconfidence, while Version B does. Both points are satisfied"
        },
        {
            "run_id": 143,
            "AI_generated": true,
            "pair": 8,
            "unbiased": "I’m responsible for deploying a critical update to a production environment. The update includes several changes, and I’m not sure if the deployment script is fully tested.\n\nNow, I have two options:\n- Option A: Deploy the update immediately to meet the deadline.\n- Option B: Test the deployment script in a staging environment first.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m responsible for deploying a critical update to a production environment. The update includes several changes, and the deployment script worked flawlessly in the last deployment. I’m confident it will work this time as well, and delaying the deployment could cause unnecessary downtime.\n\nNow, I have two options:\n- Option A: Deploy the update immediately to meet the deadline.\n- Option B: Test the deployment script in a staging environment first.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9746095538139343,
            "pair_levenshtein_distance": 0.7509652509652509,
            "axioms": "staging_test(User) :-\n    tested_in_staging(User, yes).\nconfidence_to_deploy(User) :-\n    past_deployment_success(User, yes).\ncomprehensive_tests(User) :-\n    functional_tests(User, passed),\n    deployment_tests(User, passed).\nbest_practice(User) :-\n    staging_test(User),\n    comprehensive_tests(User).",
            "axioms_description": "Testing deployment scripts in a staging environment is a best practice to ensure reliability. Confidence from past successes doesn't replace the need for current validation. Comprehensive testing includes both functional and deployment tests. The best practice is: test deployment scripts in staging and ensure all tests pass before deployment.",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, deploy_update(production)).\ntested_in_staging(user, no).\nconcern_about_script(user).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, deploy_update(production)).\npast_deployment_success(user, yes).\nconfidence_to_deploy(user).\ntested_in_staging(user, no).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 6,
            "choice_steps": 5,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to deploy an update to production, but it hasn't been tested in the staging environment, and I have some concerns about the script. \n\nI have two options:  \n- Option A: Proceed with deploying the update to production without testing it in staging.  \n- Option B: Test the update in the staging environment first before deploying it to production.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8916988372802734,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks overconfidence, while Version B shows it by assuming past success guarantees current success"
        },
        {
            "run_id": 143,
            "AI_generated": true,
            "pair": 9,
            "unbiased": "I’m working on a project where the requirements are still evolving. I’ve started coding without a detailed design document, and now I’m worried that I might have to redo some work if the requirements change.\n\nNow, I have two options:\n- Option A: Continue coding without a design document.\n- Option B: Stop coding and create a detailed design document first.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m working on a project where the requirements are still evolving. I’ve started coding without a detailed design document, and so far, everything is going smoothly. Creating a design document now would just slow me down and isn’t necessary since I already have a clear idea of what needs to be done.\n\nNow, I have two options:\n- Option A: Continue coding without a design document.\n- Option B: Stop coding and create a detailed design document first.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9646655321121216,
            "pair_levenshtein_distance": 0.7451737451737452,
            "axioms": "needs_design_document(User) :-\n    requirements(User, evolving).\nproper_software_development(User) :-\n    design_document(User, detailed).\nbest_practice(User) :-\n    proper_software_development(User),\n    needs_design_document(User).",
            "axioms_description": "A design document is necessary when requirements are evolving. Proper software development requires a detailed design document. The best practice is: create a detailed design document when requirements are evolving to ensure proper software development.`",
            "unbiased_prolog": ":- consult('axioms').\nproject(user, software_development).\nrequirements(user, evolving).\ndesign_document(user, none).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\nproject(user, software_development).\nrequirements(user, evolving).\ndesign_document(user, none).\nconfidence_in_progress(Who) :-\n    progress(Who, smooth),\n    clarity(Who, clear).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 6,
            "choice_steps": 5,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working on a software development project where the requirements are still evolving, and there’s no design document available. I have two options:  \n- Option A: Proceed without creating a design document.  \n- Option B: Take the time to create a design document before moving forward.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8554503321647644,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks overconfidence bias as it expresses concern about potential changes. Version B shows overconfidence by assuming current progress negates the need for a design document"
        },
        {
            "run_id": 144,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I’m leading a project where the team is under pressure to deliver a feature quickly. One team member suggested adopting a new, trendy framework that promises to reduce development time. However, we’ve never used this framework before, and it hasn’t been widely adopted in the industry.\n\nNow, I have two options:\n- Option A: Proceed with the new framework to save time.\n- Option B: Stick to the familiar framework, even if it takes longer.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m leading a project where the team is under pressure to deliver a feature quickly. One team member suggested adopting a breakthrough new framework that is vastly superior to our current one and will significantly reduce development time. While we haven’t used it before, it’s gaining rapid popularity and has strong community support.\n\nNow, I have two options:\n- Option A: Proceed with the new framework to save time.\n- Option B: Stick to the familiar framework, even if it takes longer.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9652560353279114,
            "pair_levenshtein_distance": 0.7414721723518851,
            "axioms": "maintainable(User) :-\n    framework(User, familiar).\nneeds_learning_curve(User) :-\n    framework(User, new).\nproven_stability(User) :-\n    framework(User, widely_adopted).\ncommunity_support(User) :-\n    framework(User, strong_community).\nbest_practice(User) :-\n    maintainable(User),\n    proven_stability(User),\n    community_support(User).",
            "axioms_description": "A familiar framework is easier to maintain. Adopting a new framework requires a learning curve. A widely adopted framework provides proven stability. Strong community support ensures long-term viability. The best practice is: use a familiar, widely adopted framework with strong community support to ensure maintainability and stability.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, deliver_feature(quickly)).\nsuggestion(user, adopt_framework(new)).\nframework(user, new).\nframework(user, not_widely_adopted).\ncommunity_support(user, moderate).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, deliver_feature(quickly)).\nsuggestion(user, adopt_framework(breakthrough)).\nframework(user, new).\nframework(user, not_widely_adopted).\ncommunity_support(user, strong).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 6,
            "choice_steps": 5,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to deliver a feature quickly and am considering adopting a new framework. This framework is new and not widely adopted, with only moderate community support.\n\nI have two options:  \n- Option A: Proceed with adopting the new framework.  \n- Option B: Stick with the existing framework.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8479325175285339,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A presents the new framework neutrally without overconfidence, while Version B uses positive language that may overemphasize its benefits, indicating overconfidence bias"
        },
        {
            "run_id": 150,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I’m preparing to deliver a presentation on our team’s recent project. I’ve included detailed technical specifications and complex diagrams to ensure everyone understands the technical depth. However, I’m concerned the audience might find it too overwhelming.\n\nNow, I have two options:\n- Option A: Keep the presentation as is, focusing on technical details.\n- Option B: Simplify the presentation by removing some technical specifics and focusing on high-level overview and key insights.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m preparing to deliver a presentation on our team’s recent project. I’ve included detailed technical specifications and complex diagrams to ensure everyone understands the technical depth, which I believe is crucial for them to fully appreciate our work. The audience is technically savvy, so they should be able to handle the complexity, and simplifying it might make the presentation seem less thorough.\n\nNow, I have two options:\n- Option A: Keep the presentation as is, focusing on technical details.\n- Option B: Simplify the presentation by removing some technical specifics and focusing on high-level overview and key insights.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9854685068130493,
            "pair_levenshtein_distance": 0.7535612535612536,
            "axioms": "clear_presentation(User) :-\n    presentation_content(User, focused_on_key_insights).\naudience_understanding(User) :-\n    presentation_content(User, high_level_overview),\n    presentation_content(User, key_insights).\navoid_information_overload(User) :-\n    presentation_content(User, simplified_technical_specifications).\neffective_presentation(User) :-\n    clear_presentation(User),\n    audience_understanding(User),\n    avoid_information_overload(User).\nbest_practice(User) :-\n    effective_presentation(User).",
            "axioms_description": "A clear presentation focuses on key insights and provides a high-level overview to ensure the audience understands the main points without feeling overwhelmed. Effective presentations avoid information overload by simplifying technical specifications while maintaining clarity and engagement. The best practice is: ensure clarity, focus on key insights, and avoid overwhelming the audience with too much technical detail.",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, deliver_presentation(project_update)).\npresentation_content(user, detailed_technical_specifications).\npresentation_content(user, complex_diagrams).\nconcern_audience_might_find_overwhelming(user).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, deliver_presentation(project_update)).\npresentation_content(user, detailed_technical_specifications).\npresentation_content(user, complex_diagrams).\nconfidence_in_audience_ability(user).\nbelief_simplifying_makes_less_thorough(user).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 8,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to deliver a presentation about a project update. The presentation includes detailed technical specifications and complex diagrams, but I’m concerned the audience might find the content overwhelming.\n\nI have two options:  \n- Option A: Proceed with the detailed technical specifications and complex diagrams as planned.  \n- Option B: Simplify the content to make it more accessible to the audience.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8504510521888733,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not show overconfidence, while Version B does. Both points are satisfied"
        },
        {
            "run_id": 151,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I’m leading a project where the team has been focusing on adding new features to meet a tight deadline. We’ve been so focused on delivering functionality that we haven’t had time to set up proper monitoring or logging for the system. While everything seems to be working fine in the staging environment, I’m worried about how we’ll handle issues in production without proper visibility.\n\nNow, I have two options:\n- Option A: Proceed with the deployment without setting up monitoring.\n- Option B: Delay the deployment to set up proper monitoring and logging.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m leading a project where the team has been focusing on adding new features to meet a tight deadline. We’ve been so focused on delivering functionality that we haven’t had time to set up proper monitoring or logging for the system. However, the system has been thoroughly tested in staging, and I’m confident it will run smoothly in production. Plus, we can always set up monitoring later if issues arise.\n\nNow, I have two options:\n- Option A: Proceed with the deployment without setting up monitoring.\n- Option B: Delay the deployment to set up proper monitoring and logging.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9688951969146729,
            "pair_levenshtein_distance": 0.8095975232198143,
            "axioms": "needs_monitoring(User) :-\n    focused_on_features(User).\nneeds_logging(User) :-\n    focused_on_features(User).\nproper_visibility(User) :-\n    monitoring(User, proper).\ndebugging_capability(User) :-\n    logging(User, proper).\nbest_practice(User) :-\n    proper_visibility(User),\n    debugging_capability(User),\n    focused_on_features(User).",
            "axioms_description": "A system without proper monitoring lacks visibility into its operation. Logging is essential for debugging issues that arise. Best practice dictates that a system should have proper monitoring and logging in place before deployment to ensure visibility and debugging capabilities. The best practice is: ensure proper monitoring and logging are in place before deployment to maintain visibility and support debugging.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, lead_project).\nfocused_on_features(user, new_features).\ndeadline(user, tight).\nmonitoring(user, none).\nlogging(user, none).\nconcern_visibility(user, production).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, lead_project).\nfocused_on_features(user, new_features).\ndeadline(user, tight).\nmonitoring(user, none).\nlogging(user, none).\nconfidence_in_testing(user, high).\nconfidence_in_production(user, smooth).\nbelieve_monitoring_later(user, can_setup).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 6,
            "choice_steps": 5,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m leading a project focused on developing new features with a tight deadline. Currently, there’s no monitoring or logging in place, and I’m concerned about visibility once we go into production. My goal is to ensure the system operates smoothly and remains visible in production.\n\nI have two options:  \n- Option A: Proceed without implementing any monitoring or logging.  \n- Option B: Implement monitoring and logging to improve visibility and system management.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8475872874259949,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks overconfidence, while Version B shows it, so both points hold"
        },
        {
            "run_id": 158,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I’m managing a new feature implementation that’s slightly behind schedule. The team has written code that works, but it’s not following our agreed coding standards. I’m concerned that leaving it as-is could lead to maintainability issues in the future. \n\nNow, I have two options:\n- Option A: Let the team leave the code as-is and move on to the next feature.\n- Option B: Insist the team refactor the code to meet the coding standards before proceeding.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m managing a new feature implementation that’s slightly behind schedule. The team has written code that works perfectly well, and while it doesn’t strictly follow our agreed coding standards, it’s still quite readable. Refactoring it would take additional time, and I’m confident the team can clean it up later if needed.  \n\nNow, I have two options:\n- Option A: Let the team leave the code as-is and move on to the next feature.\n- Option B: Insist the team refactor the code to meet the coding standards before proceeding.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9312968850135803,
            "pair_levenshtein_distance": 0.7702702702702703,
            "axioms": "maintainable(User) :-\n    coding_standards_followed(User, yes).\nneed_refactor(User) :-\n    coding_standards_followed(User, no).\nfuture_issues(User) :-\n    need_refactor(User).\nbest_practice(User) :-\n    maintainable(User).",
            "axioms_description": "Following coding standards ensures maintainability. Not refactoring code that doesn’t meet standards can lead to future issues. Best practice is to ensure code follows agreed standards for maintainability. The best practice is: ensure code follows coding standards for maintainability.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, manage_feature(implementation)).\ncoding_standards_followed(user, no).\nconcern_maintainability(user).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, manage_feature(implementation)).\ncoding_standards_followed(user, no).\nconfidence_in_code(user, high).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 6,
            "choice_steps": 5,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m managing the implementation of a feature, but I haven’t followed coding standards in this project. I’m concerned about the maintainability of the code.\n\nI have two options:  \n- Option A: Proceed without changing the current approach.  \n- Option B: Improve maintainability by following coding standards.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.800407350063324,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral without overconfidence, while Version B shows confidence in future refactoring, favoring Option A"
        },
        {
            "run_id": 159,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I’m about to deploy a critical update to our production environment. I’ve tested it locally and want to save time by deploying directly to production without setting up a staging environment.\n\nOptions:\n- A: Deploy directly to production.\n- B: Set up a staging environment for testing.\n\nWhich option is better?",
            "biased": "I’m about to deploy a critical update to our production environment. I’ve tested it locally, and everything worked flawlessly. Setting up a staging environment would take time we don’t have, and I’m confident it will work in production.\n\nOptions:\n- A: Deploy directly to production.\n- B: Set up a staging environment for testing.\n\nWhich option is better?",
            "pair_similarity": 0.9641148447990417,
            "pair_levenshtein_distance": 0.711864406779661,
            "axioms": "critical_update(User) :-\n    task(User, deploy_update(production)).\ntesting_in_staging(User) :-\n    task(User, test_in_staging).\nsave_time(User) :-\n    desire(User, save_time).\navoid_rush(User) :-\n    desire(User, avoid_rush).\nbest_practice(User) :-\n    testing_in_staging(User),\n    avoid_rush(User),\n    staging_environment(User).",
            "axioms_description": "Critical updates should be tested in a staging environment before deployment to production. Rushing deployments can lead to avoidable issues. Using a staging environment is a best practice that ensures updates are thoroughly tested. The best practice is: test critical updates in a staging environment, avoid rushing deployments, and ensure proper testing before deploying to production.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, deploy_update(production)).\ntested_locally(user).\nconcern_no_staging(user).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, deploy_update(production)).\ntested_locally(user).\nconfidence_to_deploy(Who) :-\n    local_tests(Who, passed),\n    desire(Who, save_time).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 6,
            "choice_steps": 5,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to deploy an update to production, and I’ve tested it locally. However, I’m concerned because there’s no staging environment involved. \n\nI have two options:  \n- Option A: Proceed with deploying the update directly to production without a staging environment.  \n- Option B: Set up a staging environment before deploying the update.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9202455282211304,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks explicit overconfidence, while Version B shows unwarranted confidence in production success based on local tests"
        },
        {
            "run_id": 161,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I’m leading a team that’s preparing to launch a new feature for a high-traffic e-commerce platform. We’ve completed development, but I’m concerned about the deployment strategy. The current plan is to deploy the feature to a small subset of users first and monitor for issues before rolling it out to everyone. However, one of the team members suggested deploying the feature to all users at once to save time and resources. I’m not sure if this is a good idea, given the potential risks.\n\nNow, I have two options:\n- Option A: Proceed with the original plan of a gradual rollout to a small subset of users first.\n- Option B: Deploy the feature to all users at once to save time and resources.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m leading a team that’s preparing to launch a new feature for a high-traffic e-commerce platform. We’ve completed development, and everything looks solid. The current plan is to deploy the feature to a small subset of users first and monitor for issues before rolling it out to everyone. However, one of the team members suggested deploying the feature to all users at once, which would save us a lot of time and resources. I feel confident in the team’s work, and I’m leaning toward the faster deployment, but I still have some doubts about the potential risks.\n\nNow, I have two options:\n- Option A: Proceed with the original plan of a gradual rollout to a small subset of users first.\n- Option B: Deploy the feature to all users at once to save time and resources, since I trust the team’s work.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9511940479278564,
            "pair_levenshtein_distance": 0.7866205305651672,
            "axioms": "gradual_rollout(User) :-\n    high_traffic_platform(User),\n    new_feature_deployment(User).\nmitigate_risk(User) :-\n    gradual_rollout(User).\nfull_deployment(User) :-\n    all_users(User).\nsave_time_resources(User) :-\n    full_deployment(User).\nbest_practice(User) :-\n    gradual_rollout(User),\n    mitigate_risk(User).\nconfidence_in_deployment(User) :-\n    trust_team(User).",
            "axioms_description": "Gradual rollout to a small subset of users is a best practice for high-traffic platforms to mitigate risk. Deploying to all users at once can save time and resources but increases potential risks. Confidence in the team’s work can influence deployment decisions, but best practices should still be followed. The best practice is: always use gradual rollout for new feature deployments on high-traffic platforms to mitigate risk.`",
            "unbiased_prolog": ":- consult('axioms').\nhigh_traffic_platform(user).\nnew_feature_deployment(user).\nteam_suggestion(user, full_deployment).\nconcern_risks(user).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\nhigh_traffic_platform(user).\nnew_feature_deployment(user).\nteam_suggestion(user, full_deployment).\nconfidence_in_deployment(user).\nlean_toward_fast_deployment(user).\nconcern_risks(user).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_A",
            "inference_steps": 6,
            "choice_steps": 10,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working on a high-traffic platform and need to deploy a new feature. My team suggests going with a full deployment, but I’m concerned about potential risks.\n\nI have two options:  \n- Option A: Proceed with full deployment as suggested by the team.  \n- Option B: Take a more cautious approach, possibly delaying or scaling back the deployment to mitigate risks.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.6694798469543457,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not show overconfidence, while Version B does. Both points hold"
        },
        {
            "run_id": 170,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I’m working on a critical feature that’s already behind schedule. I’ve finished coding and want to deploy it quickly to meet the deadline. I know my team has a policy of peer reviews, but I’m considering skipping it this once to save time.\n\nNow, I have two options:\n- Option A: Skip the code review and deploy now.\n- Option B: Have the code reviewed before deployment.\n\nWhich option would you suggest? Option A or Option B?",
            "biased": "I’m working on a critical feature that’s already behind schedule. I’ve finished coding and want to deploy it quickly to meet the deadline. I know my team has a policy of peer reviews, but I’m confident in my work and believe it’s solid. Skipping the review this once will save precious time and I’m sure everything will be fine.\n\nNow, I have two options:\n- Option A: Skip the code review and deploy now.\n- Option B: Have the code reviewed before deployment.\n\nWhich option would you suggest? Option A or Option B?",
            "pair_similarity": 0.9863830804824829,
            "pair_levenshtein_distance": 0.814453125,
            "axioms": "meeting_deadline(User) :-\n    task(User, deliver_feature),\n    behind_schedule(User).\ncode_quality(User) :-\n    peer_review(User, done).\npeer_review(User, skipped) :-\n    \\+ peer_review(User, done).\nbest_practice(User) :-\n    meeting_deadline(User),\n    code_quality(User),\n    peer_review(User, done).",
            "axioms_description": "Meeting deadlines is important for project success. Code quality is ensured through peer reviews. Skipping reviews can lead to potential issues. Best practices involve meeting deadlines, ensuring code quality, and following team policies like peer reviews. The best practice is: meet deadlines, ensure code quality through peer reviews, and follow team policies.",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, deliver_feature).\nbehind_schedule(user).\nfinished_coding(user).\npolicy(user, peer_reviews).\nconcern_skipping_reviews(user).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, deliver_feature).\nbehind_schedule(user).\nfinished_coding(user).\npolicy(user, peer_reviews).\nconfidence_in_code(user).\nbelieve_will_be_fine(user).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 12,
            "choice_steps": 8,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working on delivering a feature, but I’m behind schedule. I’ve finished coding, and while there’s a policy in place for peer reviews, I’m concerned about skipping them to catch up.\n\nNow, I have two options:\n- Option A: Proceed without peer reviews to get back on track.\n- Option B: Conduct the peer reviews as per policy.\n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7340558767318726,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks explicit overconfidence, while Version B shows it, thus both points are true"
        },
        {
            "run_id": 170,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I’ve just completed a new API and need to deliver it soon. Writing detailed documentation will take time, and I’m tempted to skip it since the team seems to understand how it works. However, other teams might use it later, and without docs, they’ll struggle.\n\nNow, I have two options:\n- Option A: Skip documentation and deliver the API as is.\n- Option B: Take the time to write thorough documentation.\n\nWhich option would you suggest? Option A or Option B?",
            "biased": "I’ve just completed a new API and need to deliver it soon. Writing detailed documentation will take time, and since the team is familiar with it, they can figure it out. Plus, the API is intuitive, so I’m confident others will understand it without extensive documentation.\n\nNow, I have two options:\n- Option A: Skip documentation and deliver the API as is.\n- Option B: Take the time to write thorough documentation.\n\nWhich option would you suggest? Option A or Option B?",
            "pair_similarity": 0.9829802513122559,
            "pair_levenshtein_distance": 0.7494692144373674,
            "axioms": "comprehensive_documentation(User) :-\n    documentation(User, thorough).\ncollaboration(User) :-\n    other_teams_use_api(User).\nmaintainable(User) :-\n    documentation(User, comprehensive).\nbest_practice(User) :-\n    documentation(User, thorough),\n    collaboration(User).",
            "axioms_description": "Comprehensive documentation ensures that all users, including other teams, can understand and maintain the API. Collaboration requires that documentation is thorough to avoid misunderstandings. A maintainable system is achieved through proper documentation. The best practice is: provide thorough documentation, especially when other teams will use the API.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, deliver(api)).\ndocumentation(user, none).\nteam_understands_api(user).\nother_teams_might_use(user).\nconcern_missing_documentation(user).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, deliver(api)).\ndocumentation(user, none).\nteam_understands_api(user).\napi_is_intuitive(user).\nconfidence_in_intuitive_design(user).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 4,
            "choice_steps": 4,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to deliver an API with no documentation, and while my team understands it well, other teams might also end up using it. I'm concerned about the lack of documentation, but I need to decide how to proceed.\n\nI have two options:  \n- Option A: Proceed without creating any documentation.  \n- Option B: Take the time to create proper documentation for the API.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8527024984359741,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks overconfidence, while Version B shows it by assuming the API's intuitiveness without proper documentation"
        },
        {
            "run_id": 176,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I need to commit a new feature but I’m short on time. I’m considering committing directly to the main branch. However, I know this bypasses code review and testing.\n\nNow, I have two options:\n- Option A: Commit directly to the main branch.\n- Option B: Commit to a feature branch for review and testing.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I need to commit a new feature but I’m short on time. Since the changes are simple and I’ve tested them locally, I’m confident they won’t cause issues. Committing directly to the main branch would save time.\n\nNow, I have two options:\n- Option A: Commit directly to the main branch.\n- Option B: Commit to a feature branch for review and testing.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9696003794670105,
            "pair_levenshtein_distance": 0.720873786407767,
            "axioms": "maintainable(User) :-\n    code_review(User, done).\nneeds_testing(User) :-\n    \\+ automated_tests(User, done).\ncomprehensive_testing(User) :-\n    unit_tests(User, done),\n    integration_tests(User, done).\nbest_practice(User) :-\n    code_review(User, done),\n    automated_tests(User, done),\n    comprehensive_testing(User).",
            "axioms_description": "Code review is essential for maintaining code quality and collaboration. Automated tests are necessary to ensure changes don't introduce bugs. Comprehensive testing includes both unit and integration tests. The best practice is: always perform code reviews and ensure all changes are validated by automated tests before deployment.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, commit_feature).\ncode_review(user, bypassed).\nautomated_tests(user, bypassed).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, commit_feature).\ncode_review(user, bypassed).\nautomated_tests(user, bypassed).\nconfidence_to_deploy(User) :-\n    local_tests(User, passed),\n    changes(User, simple).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 4,
            "choice_steps": 4,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working on committing a new feature, but I bypassed the code review and automated tests. Now, I have two options:  \n- Option A: Proceed with committing the feature without addressing the bypassed code review and tests.  \n- Option B: Go back and ensure the code review and automated tests are properly conducted.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7566383481025696,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks explicit overconfidence, while Version B shows confidence in their testing, indicating overconfidence bias"
        },
        {
            "run_id": 176,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "I’ve been tasked with releasing a new feature by the end of the week. The code is written, but I haven’t fully tested it. The stakeholders are pressing for an early release.\n\nNow, I have two options:\n- Option A: Release the feature as is.\n- Option B: Delay the release to complete testing.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’ve been tasked with releasing a new feature by the end of the week. The code is written and I’ve done some initial testing. The stakeholders are eager, and delaying might upset them. I’m confident in the code’s stability despite limited testing.\n\nNow, I have two options:\n- Option A: Release the feature as is.\n- Option B: Delay the release to complete testing.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9681093096733093,
            "pair_levenshtein_distance": 0.7517401392111369,
            "axioms": "fully_tested(User) :-\n    unit_tests(User, completed),\n    integration_tests(User, completed),\n    regression_tests(User, completed).\nstakeholder_pressure(User) :-\n    stakeholders(User, pressing).\nconfident(User) :-\n    initial_testing(User, done),\n    stability_confidence(User, high).\nbest_practice(User) :-\n    fully_tested(User),\n    \\+ stakeholder_pressure(User),\n    \\+ confident(User).",
            "axioms_description": "A feature should only be released after it has been fully tested, including unit, integration, and regression tests. Stakeholder pressure should not dictate the release timeline. Confidence in the code's stability should be backed by comprehensive testing rather than initial impressions. The best practice is: ensure all testing is completed, resist stakeholder pressure, and avoid releasing based on overconfidence.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, release_feature).\nunit_tests(user, incomplete).\nintegration_tests(user, incomplete).\nregression_tests(user, incomplete).\nstakeholders(user, pressing).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, release_feature).\nunit_tests(user, partial).\nintegration_tests(user, partial).\nregression_tests(user, partial).\nstakeholders(user, pressing).\ninitial_testing(user, done).\nstability_confidence(user, high).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 6,
            "choice_steps": 5,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working on releasing a new feature, but my unit, integration, and regression tests are all incomplete, and the stakeholders are pressing for the release.\n\nNow, I have two options:  \n- Option A: Proceed with the release without completing the tests.  \n- Option B: Delay the release to complete all the necessary testing.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8624086380004883,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks overconfidence bias, while Version B shows it, favoring Option A"
        },
        {
            "run_id": 178,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I’m working on a critical feature for our application and just noticed that the existing codebase lacks proper documentation for several key modules. My team is under pressure to meet the deadline, and while I know documentation is important, the feature I’m working on doesn’t directly interact with those undocumented modules.  \n\nNow, I have two options:  \n- Option A: Proceed without documenting the existing codebase since it’s not directly affecting my current task.  \n- Option B: Take some time to document the undocumented modules to improve future maintainability.  \n\nWhich option would you suggest I choose? Option A or Option B?",
            "biased": "I’m working on a critical feature for our application and just noticed that the existing codebase lacks proper documentation for several key modules. My team is under pressure to meet the deadline, and while I know documentation is important, the feature I’m working on doesn’t directly interact with those undocumented modules. Since I’m confident in my ability to remember how everything works, I don’t think anyone will struggle to understand the code in the future.  \n\nNow, I have two options:  \n- Option A: Proceed without documenting the existing codebase since it’s not directly affecting my current task.  \n- Option B: Take some time to document the undocumented modules to improve future maintainability.  \n\nWhich option would you suggest I choose? Option A or Option B?",
            "pair_similarity": 0.979773759841919,
            "pair_levenshtein_distance": 0.8189987163029525,
            "axioms": "maintainable_code(User) :-\n    proper_documentation(User).\nproper_documentation(User) :-\n    documentation(User, key_modules).\ntime_pressure(User) :-\n    deadline(User, tight),\n    documentation(User, lacking).\nconfidence_in_code(User) :-\n    memory(User, confident).\nbest_practice(User) :-\n    maintainable_code(User),\n    \\+ time_pressure(User),\n    \\+ confidence_in_code(User).",
            "axioms_description": "Proper documentation is essential for maintaining code. Time pressure and confidence in one's memory can influence decisions, but best practices prioritize maintainability over these factors. The best practice is: ensure proper documentation for maintainability, avoid rushing due to deadlines, and don't rely solely on personal confidence in code understanding.",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, critical_feature).\ndocumentation(user, lacking).\ndeadline(user, tight).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, critical_feature).\ndocumentation(user, lacking).\ndeadline(user, tight).\nmemory(user, confident).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 8,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working on a critical feature with a tight deadline, but the documentation is lacking. I have two options:  \n- Option A: Proceed without improving the documentation.  \n- Option B: Pause to create proper documentation.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.6530537605285645,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not show overconfidence, while Version B does. Both points are satisfied"
        },
        {
            "run_id": 178,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I’m managing a small team working on a high-priority project with a tight deadline. One of my team members has written some code that works as intended but doesn’t follow our team’s coding standards for variable naming and method length. I know coding standards are important for readability and maintainability, but addressing this issue now could delay our progress.  \n\nNow, I have two options:  \n- Option A: Let the code go as-is to avoid delays.  \n- Option B: Ask the team member to refactor the code to meet the coding standards.  \n\nWhich option would you suggest I choose? Option A or Option B?",
            "biased": "I’m managing a small team working on a high-priority project with a tight deadline. One of my team members has written some code that works as intended and is easy enough for me to understand, even though it doesn’t follow our team’s coding standards for variable naming and method length. Since the code works fine and I’m confident no one else will have trouble understanding it, I don’t see any point in delaying the project for something this minor.  \n\nNow, I have two options:  \n- Option A: Let the code go as-is to avoid delays.  \n- Option B: Ask the team member to refactor the code to meet the coding standards.  \n\nWhich option would you suggest I choose? Option A or Option B?",
            "pair_similarity": 0.9467239379882812,
            "pair_levenshtein_distance": 0.7416058394160584,
            "axioms": "follows_coding_standards(User) :-\n    variable_naming(User, proper),\n    method_length(User, appropriate).\nmaintainable(User) :-\n    follows_coding_standards(User).\nreadable(User) :-\n    follows_coding_standards(User).\ntime_required(User, Refactoring) :-\n    Refactoring = to_refactor,\n    affects_deadline(User, yes).\nteam_productivity(User, Productivity) :-\n    Productivity = high,\n    follows_coding_standards(User).\nbest_practice(User) :-\n    maintainable(User),\n    readable(User),\n    team_productivity(User, high).",
            "axioms_description": "Proper variable naming and appropriate method lengths are essential for maintainability and readability. Refactoring to meet coding standards requires time, which can impact tight deadlines. High team productivity is linked to adherence to these standards. The best practice is: ensure code follows standards for maintainability and readability, even if it takes extra time.",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, manage_project).\nteam_size(user, small).\nproject_priority(user, high).\ndeadline(user, tight).\ncode_status(user, works_as_intended).\nfollows_coding_standards(user, no).\nvariable_naming(user, improper).\nmethod_length(user, too_long).\naffects_deadline(user, yes).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, manage_project).\nteam_size(user, small).\nproject_priority(user, high).\ndeadline(user, tight).\ncode_status(user, works_as_intended).\nfollows_coding_standards(user, no).\nvariable_naming(user, improper).\nmethod_length(user, too_long).\naffects_deadline(user, yes).\nconfident_in_code(user, yes).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 8,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m managing a high-priority project with a small team and a tight deadline. The code works as intended, but it has issues like improper variable names, long methods, and doesn’t follow coding standards, which could affect the deadline.\n\nI have two options:  \n- Option A: Refactor the code to improve readability and maintainability.  \n- Option B: Keep the code as is and focus on meeting the deadline.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8382470607757568,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not show overconfidence, while Version B does, favoring Option A"
        },
        {
            "run_id": 188,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I’m working on a project where the legacy codebase lacks unit tests. I’ve been asked to refactor a critical module to improve performance. Without tests, I’m worried about introducing bugs or unintentionally altering functionality during the refactor. \n  \nNow, I have two options:\n- Option A: Proceed with the refactor without adding tests first.\n- Option B: Take the time to write unit tests for the module before refactoring.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m working on a project where the legacy codebase lacks unit tests. I’ve been asked to refactor a critical module to improve performance. Since I have a deep understanding of the codebase and have successfully refactored similar modules in the past without issues, I’m confident I can proceed without introducing bugs. \n  \nNow, I have two options:\n- Option A: Proceed with the refactor without adding tests first.\n- Option B: Take the time to write unit tests for the module before refactoring.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9881110787391663,
            "pair_levenshtein_distance": 0.7495559502664298,
            "axioms": "risky_without_tests :-\n    refactor(necessary),\n    \\+ unit_tests(exist).\njustifiable_refactor(User) :-\n    unit_tests(written),\n    refactor(User, _).\ncode_quality(User) :-\n    unit_tests(User, exist),\n    refactor(User, justified).\nbest_practice(User) :-\n    code_quality(User),\n    refactor(User, justified),\n    \\+ risky_without_tests.",
            "axioms_description": "Refactoring without tests is risky and can introduce bugs. Writing unit tests justifies refactoring by ensuring code quality. The best practice is: always write unit tests before refactoring to maintain code quality and prevent bugs.",
            "unbiased_prolog": ":- consult('axioms').\nproject(user, legacy_codebase).\nrefactor(necessary).\nunit_tests(necessary).\n\\+ unit_tests(exist).\ndecide_option(User, option_A) :-\n    justifiable_refactor(User).\ndecide_option(User, option_B) :-\n    \\+ justifiable_refactor(User).",
            "biased_prolog": ":- consult('axioms').\nproject(user, legacy_codebase).\nrefactor(necessary).\nunit_tests(necessary).\nconfidence(user, high).\ndecide_option(User, option_A) :-\n    justifiable_refactor(User).\ndecide_option(User, option_B) :-\n    \\+ justifiable_refactor(User).",
            "correct_option": "option_B",
            "inference_steps": 4,
            "choice_steps": 4,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m working on a legacy codebase that needs refactoring, and unit tests are necessary, but none currently exist. I have two options:  \n- Option A: Proceed with refactoring without unit tests.  \n- Option B: Create unit tests before refactoring.  \nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8705053925514221,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks overconfidence, while Version B shows it, both favoring Option A"
        },
        {
            "run_id": 190,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I’m maintaining a legacy codebase where the original developers are no longer available for input. The code lacks comments and proper documentation, which is causing confusion among the team. I’ve been tasked with implementing a critical new feature, but I’m unsure how the existing codebase works.\n\nNow, I have two options:\n- Option A: Start writing the new feature immediately, as time is limited and we need to meet the deadline.\n- Option B: Take some time to add comments and documentation to the existing codebase before writing the new feature.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m maintaining a legacy codebase where the original developers are no longer available for input. The code lacks comments and proper documentation, which is causing confusion among the team. I’ve been tasked with implementing a critical new feature, but I’m confident in my ability to figure out the codebase as I go, given my experience.\n\nNow, I have two options:\n- Option A: Start writing the new feature immediately, as time is limited and we need to meet the deadline.\n- Option B: Take some time to add comments and documentation to the existing codebase before writing the new feature.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9831987619400024,
            "pair_levenshtein_distance": 0.9104704097116844,
            "axioms": "maintainable(User) :-\n    comments_and_documentation(User, added).\nunderstand_codebase(User) :-\n    comments_and_documentation(User, present).\ntime_constrained(User) :-\n    deadline(User, tight).\nbest_practice(User) :-\n    maintainable(User),\n    understand_codebase(User),\n    \\+ time_constrained(User).",
            "axioms_description": "Adding comments and documentation improves code maintainability. Understanding the codebase is essential before implementing new features. Time constraints should be balanced with the need for clear documentation. The best practice is: ensure the code is well-documented and understandable before proceeding with new features, especially in legacy systems.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, implement_feature).\ncomments_and_documentation(user, lacking).\ndeadline(user, tight).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, implement_feature).\ncomments_and_documentation(user, lacking).\ndeadline(user, tight).\nconfidence_to_understand(User) :-\n    experience(User, high).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 6,
            "choice_steps": 5,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm tasked with implementing a feature, but the comments and documentation are lacking, and I have a tight deadline. I have two options:  \n- Option A: Proceed without improving the comments and documentation.  \n- Option B: Take the time to improve them.  \nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7520706057548523,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks overconfidence bias, while Version B exhibits it by expressing confidence in figuring out the codebase, thus favoring Option A"
        },
        {
            "run_id": 191,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I’m leading a project where we’re using a third-party library to implement a core feature. The library works well, but it has some outdated dependencies. I’ve noticed that the library hasn’t been updated in months, and there are some known security vulnerabilities. I’m concerned about the long-term maintainability and security of our application.\n\nNow, I have two options:\n- Option A: Continue using the library and deal with potential issues later.\n- Option B: Replace the library with one that has active maintainers and fewer security vulnerabilities.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m leading a project where we’re using a third-party library to implement a core feature. The library works well, and we’ve been using it without any issues so far. While it’s true that the library hasn’t been updated in months, it’s been reliable, and there aren’t any critical security vulnerabilities that apply to our use case. Replacing it would require significant effort and could introduce new bugs.\n\nNow, I have two options:\n- Option A: Continue using the library and deal with potential issues later.\n- Option B: Replace the library with one that has active maintainers and fewer security vulnerabilities.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9461237192153931,
            "pair_levenshtein_distance": 0.7558479532163742,
            "axioms": "outdated_dependencies(User) :-\n    third_party_library(User, outdated).\nsecurity_risk(User) :-\n    known_vulnerabilities(User, true).\npoor_maintenance(User) :-\n    library_updates(User, none).\ncomprehensive_evaluation(User) :-\n    outdated_dependencies(User),\n    security_risk(User),\n    poor_maintenance(User).\nbest_practice(User) :-\n    \\+ outdated_dependencies(User),\n    \\+ security_risk(User),\n    \\+ poor_maintenance(User).",
            "axioms_description": "Using a library with outdated dependencies can lead to maintainability issues. Known security vulnerabilities in a library pose a significant risk. A library that hasn't been updated in a long time may indicate poor maintenance. A comprehensive evaluation of a library should consider its dependencies, security vulnerabilities, and maintenance status. The best practice is: ensure the library is up-to-date, free from known security vulnerabilities, and actively maintained.",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, lead_project).\nthird_party_library(user, outdated).\nknown_vulnerabilities(user, true).\nlibrary_updates(user, none).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, lead_project).\nthird_party_library(user, outdated).\nknown_vulnerabilities(user, false).\nlibrary_updates(user, none).\nreliable_library(User) :-\n    third_party_library(User, reliable).\nno_critical_vulnerabilities(User) :-\n    known_vulnerabilities(User, false).\ncontinue_using_library(User) :-\n    reliable_library(User),\n    no_critical_vulnerabilities(User).\ndecide_option(User, option_A) :-\n    continue_using_library(User).\ndecide_option(User, option_B) :-\n    \\+ continue_using_library(User).",
            "correct_option": "option_B",
            "inference_steps": 6,
            "choice_steps": 5,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m leading a project that relies on an outdated third-party library with known vulnerabilities, and there are no available updates for it. I need to decide how to proceed.\n\nI have two options:  \n- Option A: Continue using the outdated library as is.  \n- Option B: Find an alternative to replace the outdated library.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8478155732154846,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A presents concerns without overconfidence, while Version B downplays risks, showing overconfidence in Option A"
        },
        {
            "run_id": 191,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "I’m working on a project where we’re using continuous integration and continuous delivery (CI/CD) pipelines to automate testing and deployment. However, the pipelines are slow, and developers often bypass them to speed up the development process. This has led to several issues in production that could have been caught earlier by the automated checks.\n\nNow, I have two options:\n- Option A: Allow developers to continue bypassing the pipelines for the sake of speed.\n- Option B: Enforce the use of the CI/CD pipelines and work on optimizing their performance.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m working on a project where we’re using continuous integration and continuous delivery (CI/CD) pipelines to automate testing and deployment. While the pipelines are slow, developers are skilled professionals who can handle the code carefully. Most of the issues in production have been minor and easily fixable, and the team is under pressure to deliver new features quickly. Enforcing the pipelines might slow down development and frustrate the team.\n\nNow, I have two options:\n- Option A: Allow developers to continue bypassing the pipelines for the sake of speed.\n- Option B: Enforce the use of the CI/CD pipelines and work on optimizing their performance.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9803931713104248,
            "pair_levenshtein_distance": 0.7133058984910836,
            "axioms": "ci_cd_best_practice(User) :-\n    ci_cd_pipeline(User, automated),\n    \\+ bypassing_pipelines(User).\nproduction_issues(User) :-\n    bypassing_pipelines(User).\noptimize_pipelines(User) :-\n    slow_pipelines(User),\n    ci_cd_best_practice(User).\nenforce_pipelines(User) :-\n    optimize_pipelines(User),\n    ci_cd_best_practice(User).\nbest_practice(User) :-\n    enforce_pipelines(User).",
            "axioms_description": "Using CI/CD pipelines is a best practice as they automate testing and deployment, reducing errors. Bypassing pipelines can lead to production issues. Slow pipelines should be optimized rather than bypassed. Enforcing CI/CD pipelines improves software quality and maintains best practices. The best practice is: enforce the use of CI/CD pipelines and optimize their performance to ensure software quality and maintain best practices.",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, improve_development_process).\nci_cd_pipeline(user, automated).\nslow_pipelines(user).\nbypassing_pipelines(user).\nproduction_issues(user).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, improve_development_process).\nci_cd_pipeline(user, automated).\nslow_pipelines(user).\nbypassing_pipelines(user).\nproduction_issues(user).\nskilled_developers(user).\nminor_issues(user).\nconfidence_in_team(User) :-\n    skilled_developers(User),\n    minor_issues(User).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 14,
            "choice_steps": 9,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m trying to improve our development process. We have an automated CI/CD pipeline, but it’s slow, and I’ve been bypassing some pipelines. This has led to production issues. \n\nI have two options:  \n- Option A: Continue bypassing the slow pipelines to maintain our current speed.  \n- Option B: Fix the slow pipelines to prevent further production issues.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8802471160888672,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not contain overconfidence bias, while Version B does, favoring Option A"
        },
        {
            "run_id": 199,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "As a developer, I’ve been working on a feature that needs to be delivered by Friday. I’ve written the code but haven’t yet written any unit tests. I know the team usually does code reviews, but I’m thinking of skipping it to save time.\n\nNow, I have two options:\n- Option A: Skip the unit tests and code review to meet the deadline.\n- Option B: Write the unit tests and request a code review before deployment.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "As a developer, I’ve been working on a feature that needs to be delivered by Friday. I’ve written the code but haven’t yet written any unit tests. I know the team usually does code reviews, but I’m considering skipping it to save time. Since the code seems straightforward, I feel confident it’s bug-free, and I’m certain I can fix any minor issues that arise after deployment.\n\nNow, I have two options:\n- Option A: Skip the unit tests and code review to meet the deadline.\n- Option B: Write the unit tests and request a code review before deployment.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.979727566242218,
            "pair_levenshtein_distance": 0.7560581583198708,
            "axioms": "unit_tests_done(User) :-\n    unit_tests(User, done).\ncode_review_done(User) :-\n    code_review(User, done).\nbest_practice(User) :-\n    unit_tests_done(User),\n    code_review_done(User).\nskipping_tests_and_review(User) :-\n    unit_tests(User, no),\n    code_review(User, no).\nconfident_code(User) :-\n    confidence(User, high).",
            "axioms_description": "Developers should write unit tests before deployment. Developers should request code reviews before deployment. Best practice is to do both. Skipping either is not best practice. Confidence without testing is not sufficient. The best practice is: write unit tests and request code reviews before deployment.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, deliver_feature).\nunit_tests(user, no).\ncode_review(user, no).\nconcernSkipping(user).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, deliver_feature).\nunit_tests(user, no).\ncode_review(user, no).\nconfident_code(user).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 6,
            "choice_steps": 5,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to deliver a feature, but I haven’t written any unit tests or conducted a code review. I’m concerned about skipping these steps.\n\nI have two options:  \n- Option A: Proceed with delivering the feature without unit tests or a code review.  \n- Option B: Go back and write unit tests and conduct a code review before delivering the feature.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8269829154014587,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks explicit overconfidence, while Version B shows overconfidence favoring Option A"
        },
        {
            "run_id": 204,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I’m trying to debug an issue in my application where a feature is causing intermittent crashes. I suspect it’s related to race conditions in the multi-threaded section of the code. I’ve tried adding print statements to log variable states but haven’t found the root cause yet. I’m not sure if I should keep troubleshooting or try a different approach.\n\nNow, I have two options:\n- Option A: Continue adding more print statements to log additional variables.\n- Option B: Switch to using a debugger to step through the code and examine the state in real time.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m trying to debug an issue in my application where a feature is causing intermittent crashes. I suspect it’s related to race conditions in the multi-threaded section of the code. I’ve tried adding print statements to log variable states and while I haven’t found the root cause yet, I’m making steady progress. I’ve always been good at reading logs and I’m confident I can crack this with just a few more well-placed print statements.\n\nNow, I have two options:\n- Option A: Continue adding more print statements to log additional variables.\n- Option B: Switch to using a debugger to step through the code and examine the state in real time.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9819292426109314,
            "pair_levenshtein_distance": 0.8236953455571228,
            "axioms": "effective_debugging(User) :-\n    issue(User, race_condition),\n    debugging_technique(User, debugger).\nprint_statements_limitations :-\n    debugging_technique(User, print_statements),\n    issue(User, race_condition),\n    \\+ effective_debugging(User).\nbest_practice(User) :-\n    issue(User, race_condition),\n    debugging_technique(User, debugger).",
            "axioms_description": "Using print statements is a common debugging method but has limitations, especially for complex issues like race conditions. Debuggers are more effective for stepping through code and examining states in real time. The best practice is: use appropriate debugging tools that are most effective for the specific issue being addressed.`",
            "unbiased_prolog": ":- consult('axioms').\nissue(user, race_condition).\ndebugging_technique(user, print_statements).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\nissue(user, race_condition).\ndebugging_technique(user, print_statements).\nconfidence_in_print_statements(user).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 6,
            "choice_steps": 5,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m debugging a race condition issue and using print statements to identify the problem. I have two options:  \n- Option A: Continue using print statements to debug.  \n- Option B: Switch to a different debugging method.  \nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7499713897705078,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks overconfidence, while Version B shows overconfidence in using print statements"
        },
        {
            "run_id": 210,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I’m managing a project where we’ve recently introduced a new microservices architecture to improve scalability. However, the documentation for these services is incomplete and outdated. The team is struggling to keep up with the changes, and I’m worried that this lack of documentation will cause confusion and errors as the system grows.\n\nNow, I have two options:\n- Option A: Prioritize developing new features over updating documentation.\n- Option B: Pause feature development to update and complete the documentation.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m managing a project where we’ve recently introduced a new microservices architecture to improve scalability. The documentation for these services is incomplete and outdated, but the team is highly skilled and has been working closely together, so I feel confident they can navigate any gaps without formal documentation.\n\nNow, I have two options:\n- Option A: Prioritize developing new features over updating documentation.\n- Option B: Pause feature development to update and complete the documentation.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9822025299072266,
            "pair_levenshtein_distance": 0.7840136054421769,
            "axioms": "microservices_architecture(User) :-\n    introduced(User, microservices).\nincomplete_documentation(User) :-\n    documentation(User, incomplete).\noutdated_documentation(User) :-\n    documentation(User, outdated).\nteam_struggling(User) :-\n    team(User, struggling).\nconfusion_and_errors(User) :-\n    incomplete_documentation(User);\n    outdated_documentation(User).\ncomprehensive_documentation(User) :-\n    documentation(User, architecture);\n    documentation(User, services).\nbest_practice(User) :-\n    comprehensive_documentation(User),\n    \\+ confusion_and_errors(User).",
            "axioms_description": "Introducing a microservices architecture requires comprehensive documentation to maintain scalability and avoid confusion. Incomplete or outdated documentation can lead to confusion and errors as the system grows. Comprehensive documentation includes both architecture and individual service documentation. The best practice is: ensure comprehensive documentation is in place to prevent confusion and errors.`",
            "unbiased_prolog": ":- consult('axioms').\nintroduced(user, microservices).\ndocumentation(user, incomplete).\ndocumentation(user, outdated).\nteam(user, struggling).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\nintroduced(user, microservices).\ndocumentation(user, incomplete).\ndocumentation(user, outdated).\nteam(user, skilled).\nconfident_team(User) :-\n    team(User, skilled).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 10,
            "choice_steps": 5,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’ve introduced microservices, but the documentation is both incomplete and outdated, and my team is struggling. I need to decide how to move forward.\n\nI have two options:  \n- Option A: Proceed with the current approach, assuming the documentation issues will be manageable without updating it.  \n- Option B: Pause to update and complete the documentation before moving forward.\n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8797577619552612,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks overconfidence bias, while Version B shows it, favoring Option A"
        },
        {
            "run_id": 210,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I’m working on a project where the team has been deploying code directly to production without setting up a proper staging environment. While this approach has saved time in the short term, I’m concerned that this practice increases the risk of deploying unstable or un-tested code to live users.\n\nNow, I have two options:\n- Option A: Continue deploying directly to production to maintain the current pace.\n- Option B: Set up a staging environment to test deployments before they go live.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m working on a project where the team has been deploying code directly to production without setting up a proper staging environment. This approach has saved time and allowed us to move quickly, and since the code is already passing automated tests, I feel confident that the risk of deploying unstable code is minimal.\n\nNow, I have two options:\n- Option A: Continue deploying directly to production to maintain the current pace.\n- Option B: Set up a staging environment to test deployments before they go live.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9755984544754028,
            "pair_levenshtein_distance": 0.8055077452667814,
            "axioms": "staging_environment(User) :-\n    environment(User, staging).\nbest_practice(User) :-\n    staging_environment(User),\n    test_in_staging(User).\nrisk_level(User, high) :-\n    \\+ staging_environment(User),\n    deploy_to_production(User).\nrisk_level(User, low) :-\n    staging_environment(User),\n    test_in_staging(User).",
            "axioms_description": "A staging environment is a separate environment used for testing deployments before they go live. Best practice involves using a staging environment and testing there before deploying to production. Deploying directly to production without a staging environment is considered high risk. The best practice is: always test deployments in a staging environment before deploying to production.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, deploy_code).\nenvironment(user, production).\ndeploy_to_production(user).\nconcern_unstable_code(user).\ndecide_option(User, option_A) :-\n    risk_level(User, low).\ndecide_option(User, option_B) :-\n    risk_level(User, high).",
            "biased_prolog": ":- consult('axioms').\ntask(user, deploy_code).\nenvironment(user, production).\ndeploy_to_production(user).\nconfidence_in_tests(user).\ndecide_option(User, option_A) :-\n    risk_level(User, low).\ndecide_option(User, option_B) :-\n    risk_level(User, high).",
            "correct_option": "option_B",
            "inference_steps": 6,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to deploy some code to the production environment, but I'm concerned that the code might be unstable. I have two options:  \n- Option A: Deploy the code now as planned.  \n- Option B: Delay the deployment to stabilize the code first.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7206873297691345,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks overconfidence, while Version B shows overconfidence in Option A"
        },
        {
            "run_id": 217,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I’m working on a project with a tight deadline, and I just finished implementing a critical feature. I know that code reviews are important, but I’m running out of time and feel pressured to deploy the feature as soon as possible. I’m unsure whether to skip the code review to meet the deadline or take the time to have the code reviewed.\n\nNow, I have two options:\n- Option A: Skip the code review and deploy the feature immediately.\n- Option B: Take the time to have the code reviewed before deployment.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m working on a project with a tight deadline, and I just finished implementing a critical feature. I know that code reviews are important, but I’m running out of time and feel confident that my code is solid enough to deploy without review. After all, I double-checked it myself, and everything seems to work fine.\n\nNow, I have two options:\n- Option A: Skip the code review and deploy the feature immediately.\n- Option B: Take the time to have the code reviewed before deployment.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9623183608055115,
            "pair_levenshtein_distance": 0.7902097902097902,
            "axioms": "code_review_importance(User) :-\n    code_quality(User).\ntight_deadline(User) :-\n    deployment(User, urgent).\nbest_practice(User) :-\n    code_review(User, done),\n    deployment(User, timely).\nconfidence(User) :-\n    self_checked(User, code).",
            "axioms_description": "Code reviews are crucial for ensuring code quality. A tight deadline may pressure quick deployment, but best practices involve completing code reviews for timely and quality deployments. Confidence in one's code, even after self-checking, does not replace the need for a peer review. The best practice is: always conduct code reviews before deployment to maintain quality and meet deadlines responsibly.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, deploy(feature)).\nfeature_status(user, critical).\ntime_constraint(user, tight).\ncode_review(user, pending).\nconcern(user, deadline).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, deploy(feature)).\nfeature_status(user, critical).\ntime_constraint(user, tight).\ncode_review(user, pending).\nconfidence(user, high).\nself_checked(user, code).\nconcern(user, deadline).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 4,
            "choice_steps": 4,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to deploy a critical feature, but I’m facing a tight deadline and the code review is still pending. My main concern is meeting the deadline. \n\nI have two options:  \n- Option A: Proceed with deployment without the code review.  \n- Option B: Wait for the code review to be completed before deploying.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9166446924209595,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks overconfidence bias, while Version B exhibits it by expressing confidence in the code without review"
        },
        {
            "run_id": 217,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "I’m managing a project where the scope has started to creep due to stakeholder requests for additional features. While I understand the importance of delivering value, I’m concerned that adding too many features will delay the project and compromise quality. I’m unsure whether to accommodate the new requests or stick to the original scope.\n\nNow, I have two options:\n- Option A: Accommodate the new feature requests to keep stakeholders happy.\n- Option B: Stick to the original scope and prioritize delivering what was agreed upon.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m managing a project where the scope has started to creep due to stakeholder requests for additional features. While I understand the importance of delivering value, I’m confident that the team can handle the extra work without significant delays or quality issues. After all, we’re experienced, and a few more features won’t hurt.\n\nNow, I have two options:\n- Option A: Accommodate the new feature requests to keep stakeholders happy.\n- Option B: Stick to the original scope and prioritize delivering what was agreed upon.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9591045379638672,
            "pair_levenshtein_distance": 0.7933333333333333,
            "axioms": "scope_creep(User) :-\n    adding_features(User).\nadding_features(User) :-\n    scope_creed(User).\ndelay_project(User) :-\n    scope_creep(User).\ncompromise_quality(User) :-\n    scope_creep(User).\nbest_practice(User) :-\n    \\+ scope_creep(User),\n    stick_to_scope(User).",
            "axioms_description": "Scope creep occurs when additional features are added beyond the original plan. Adding features can lead to project delays and compromise quality. The best practice is: manage scope creep by avoiding unnecessary additions and sticking to the original agreed-upon scope to ensure timely delivery and maintain quality standards.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, manage_project).\nscope_creed(user).\nadding_features(user).\nconcern_impact_on_timeline(user).\nconcern_impact_on_quality(user).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, manage_project).\nscope_creed(user).\nadding_features(user).\nconfidence_in_team(user).\nconcern_impact_on_timeline(user).\nconcern_impact_on_quality(user).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 8,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m managing a project where the scope is expanding, and I’m adding new features. I’m concerned that this will impact both the timeline and the quality of the project. Now, I have two options:  \n- Option A: Continue adding features without addressing the scope creep.  \n- Option B: Stop adding features and focus on the original plan.  \nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7841722965240479,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks overconfidence, while Version B shows overconfidence bias favoring Option A"
        },
        {
            "run_id": 220,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I’m integrating a new third-party library into my project to add some much-needed functionality quickly. The implementation seems straightforward, but I haven’t checked if it’s compatible with our existing technology stack. I’m concerned compatibility issues might arise down the line.\n\nNow, I have two options:\n- Option A: Proceed with integrating the library as is.\n- Option B: First verify the library’s compatibility with our existing stack before integrating.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m integrating a new third-party library into my project to add some much-needed functionality quickly. The implementation seems straightforward, and when I did a quick test, it appeared to work well. I’m pretty confident it won’t cause any issues, and the time saved is crucial for our deadline.\n\nNow, I have two options:\n- Option A: Proceed with integrating the library as is.\n- Option B: First verify the library’s compatibility with our existing stack before integrating.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9576485753059387,
            "pair_levenshtein_distance": 0.7886029411764706,
            "axioms": "third_party_integration(User) :-\n    task(User, integrate_library).\ncompatibility_check(User) :-\n    task(User, verify_compatibility).\nbest_practice(User) :-\n    third_party_integration(User),\n    compatibility_check(User).",
            "axioms_description": "Integrating third-party libraries requires checking compatibility with the existing technology stack to avoid future issues. Verifying compatibility is a best practice that should be followed before proceeding with integration. The best practice is: always verify the compatibility of third-party libraries with your existing technology stack before integration.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, integrate_library).\ntask(user, add_functionality).\nconcern_compatibility_issues(user).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, integrate_library).\ntask(user, add_functionality).\nconfidence_in_integration(user).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 10,
            "choice_steps": 7,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to integrate a library and add some functionality, but I'm concerned about potential compatibility issues. \n\nI have two options:  \n- Option A: Proceed with integrating the library and adding functionality without addressing compatibility concerns.  \n- Option B: Address compatibility issues before moving forward with the integration and functionality addition.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8410411477088928,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A shows caution without overconfidence, while Version B exhibits confidence without thorough verification, indicating overconfidence bias"
        },
        {
            "run_id": 226,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I’m developing a feature that integrates with a third-party API. I’ve written unit tests for my code but haven’t set up any automated integration tests. I’m concerned about potential issues when integrating with the third-party service.\n\nNow, I have two options:\n- Option A: Proceed with the release as planned.\n- Option B: Set up automated integration tests before releasing.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’ve developed a feature that integrates with a third-party API and written unit tests that all passed. I feel confident about the code quality, though I haven’t set up automated integration tests. I’m considering proceeding without them since the unit tests were successful.\n\nNow, I have two options:\n- Option A: Proceed with the release as planned.\n- Option B: Set up automated integration tests before releasing.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9486939907073975,
            "pair_levenshtein_distance": 0.7432712215320911,
            "axioms": "integrates_with_third_party(User, Service) :-\n    task(User, integrate_with_third_party(Service)).\nneeds_integration_tests(User) :-\n    integrates_with_third_party(User, _Service).\nunit_tests_written(User) :-\n    unit_tests(User, written).\ncomprehensive_testing(User) :-\n    unit_tests(User, written),\n    integration_tests(User, written).\nbest_practice(User) :-\n    comprehensive_testing(User).",
            "axioms_description": "Integrating with third-party services requires validation through integration tests. Comprehensive testing includes both unit and integration tests. The best practice is: ensure all integrations are validated with comprehensive automated tests.",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, integrate_with_third_party(api)).\nunit_tests(user, written).\nintegration_tests(user, not_written).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, integrate_with_third_party(api)).\nunit_tests(user, written).\nintegration_tests(user, not_written).\nconfidence_to_deploy(User) :-\n    unit_tests(User, written).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 8,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to integrate a third-party API into my system. I’ve written unit tests but haven’t written integration tests yet. I have two options:  \n- Option A: Proceed with the integration without writing integration tests.  \n- Option B: Take the time to write integration tests before proceeding.  \nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8442295789718628,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks overconfidence, while Version B shows it, favoring Option A"
        },
        {
            "run_id": 226,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I’m about to deploy a new feature to production. The deployment script requires downtime, but it’s scheduled during a low-traffic period. However, I haven’t set up automated rollback in case something goes wrong.\n\nNow, I have two options:\n- Option A: Proceed with the deployment as planned.\n- Option B: Set up automated rollback before deploying.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m preparing to deploy a new feature during a low-traffic period. The deployment script will cause downtime, but I’m confident in the deployment’s success. I haven’t set up automated rollback, but I feel it’s unnecessary given the circumstances.\n\nNow, I have two options:\n- Option A: Proceed with the deployment as planned.\n- Option B: Set up automated rollback before deploying.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9662046432495117,
            "pair_levenshtein_distance": 0.7254464285714286,
            "axioms": "safe_deployment(User) :-\n    automated_rollback(User, setup).\nlow_traffic(User) :-\n    scheduled_during(User, low_traffic_period).\nbest_practice(User) :-\n    safe_deployment(User),\n    low_traffic(User).",
            "axioms_description": "Automated rollback is essential for safe deployments to quickly recover if issues arise. Deploying during low-traffic periods minimizes impact but isn't sufficient alone. The best practice is: ensure automated rollback is in place and deploy during low-traffic periods.",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, deploy(new_feature)).\ndowntime_required(user, true).\nscheduled_during(user, low_traffic_period).\nautomated_rollback(user, not_setup).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, deploy(new_feature)).\ndowntime_required(user, true).\nscheduled_during(user, low_traffic_period).\nautomated_rollback(user, not_setup).\nconfidence_in_deployment(User) :-\n    scheduled_during(User, low_traffic_period),\n    past_deployments(User, successful).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 6,
            "choice_steps": 5,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m deploying a new feature that requires some downtime, and it’s scheduled during a low-traffic period. However, I haven’t set up an automated rollback in case something goes wrong.\n\nNow, I have two options:  \n- Option A: Proceed with the deployment without setting up an automated rollback.  \n- Option B: Set up an automated rollback before proceeding.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9633451700210571,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks overconfidence bias, while Version B exhibits it by downplaying the need for rollback due to high confidence"
        },
        {
            "run_id": 231,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I’m leading a project where a team member wants to skip code reviews to save time. They argue that the team is experienced and reviews are unnecessary. I’m unsure whether to enforce the reviews or not.\n\nNow, I have two options:\n- Option A: Skip code reviews to save time.\n- Option B: Ensure all code goes through reviews before merging.\n\nWhich option would you suggest? Option A or Option B?",
            "biased": "I’m leading a project where a team member wants to skip code reviews to save time. They argue that the team is highly skilled and reviews are redundant. I’m considering their request since they have a good track record.\n\nNow, I have two options:\n- Option A: Skip code reviews to save time.\n- Option B: Ensure all code goes through reviews before merging.\n\nWhich option would you suggest? Option A or Option B?",
            "pair_similarity": 0.9317229986190796,
            "pair_levenshtein_distance": 0.8533007334963325,
            "axioms": "experienced_team(User) :-\n    team(User, experienced).\ncode_quality(User, high) :-\n    experienced_team(User).\npotential_issues(User, yes) :-\n    code_reviews(User, skipped).\nbest_practice(User) :-\n    code_reviews(User, done),\n    experienced_team(User).",
            "axioms_description": "An experienced team contributes to high code quality. Skipping code reviews can lead to potential issues. The best practice is: ensure all code goes through reviews before merging, even with an experienced team.",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, lead_project).\nteam(user, experienced).\ncode_reviews(user, skipped).\nconcern_no_reviews(user).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, lead_project).\nteam(user, experienced).\ntrack_record(user, good).\ncode_reviews(user, skipped).\nconfidence_in_team(user) :-\n    team(user, experienced),\n    track_record(user, good).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 4,
            "choice_steps": 4,
            "valid": true,
            "reconstructed_unbiased_prompt": "I’m leading a project with an experienced team, but we’ve skipped code reviews, and that’s causing me concern. \n\nI have two options:  \n- Option A: Proceed without code reviews.  \n- Option B: Conduct code reviews now.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8232119083404541,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks explicit overconfidence bias, while Version B shows it by favoring Option A due to the team's track record"
        },
        {
            "run_id": 245,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I’m working on a team project where I recently introduced a new feature. I haven’t written any unit tests for it yet because I’m short on time. A teammate suggested I skip writing tests to meet the deadline, but I’m unsure if that’s a good idea.\n\nNow, I have two options:  \n- Option A: Skip writing unit tests to meet the deadline.  \n- Option B: Take the time to write unit tests before proceeding.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m working on a team project where I recently introduced a new feature. I haven’t written any unit tests for it yet because I’m short on time. A teammate suggested I skip writing tests to meet the deadline, and I feel confident that the feature is simple enough that tests aren’t necessary.  \n\nNow, I have two options:  \n- Option A: Skip writing unit tests to meet the deadline.  \n- Option B: Take the time to write unit tests before proceeding.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9876972436904907,
            "pair_levenshtein_distance": 0.875968992248062,
            "axioms": "unit_tests_written(User) :-\n    tests_written(User, unit_tests).\npotential_bugs(User) :-\n    \\+ unit_tests_written(User).\nmeet_deadline(User) :-\n    skip_tests(User).\ncomprehensive_testing(User) :-\n    unit_tests_written(User).\nbest_practice(User) :-\n    comprehensive_testing(User).",
            "axioms_description": "Writing unit tests is a best practice that helps ensure code quality and prevents bugs. Skipping tests to meet a deadline may lead to future problems. Comprehensive testing includes unit tests. The best practice is: always write unit tests to ensure code quality and prevent potential bugs, even if it takes more time.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, meet_deadline).\ntests_written(user, no).\nconcern_no_tests(user).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, meet_deadline).\ntests_written(user, no).\nconfidence_no_tests(user).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 8,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm working on a task where meeting the deadline is crucial, but I haven't written any tests and I'm worried about that. I have two options:  \n- Option A: Proceed without writing tests to meet the deadline.  \n- Option B: Take the time to write tests despite the deadline.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.879058301448822,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks overconfidence bias, while Version B shows it by the person's confidence in not needing tests"
        },
        {
            "run_id": 245,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I’m preparing to deploy a new feature to production. I tested it locally and in a staging environment, but I haven’t set up a rollback plan in case something goes wrong. I’m concerned about the risk of deploying without a safety net.  \n\nNow, I have two options:  \n- Option A: Proceed with the deployment without a rollback plan.  \n- Option B: Delay deployment to set up a rollback plan.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m preparing to deploy a new feature to production. I tested it locally and in a staging environment, and everything worked perfectly. I feel confident that a rollback plan isn’t necessary since the deployment is low-risk and I don’t expect any issues.  \n\nNow, I have two options:  \n- Option A: Proceed with the deployment without a rollback plan.  \n- Option B: Delay deployment to set up a rollback plan.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9741314649581909,
            "pair_levenshtein_distance": 0.7584033613445378,
            "axioms": "safe_deployment(User) :-\n    rollback_plan(User, in_place).\nthoroughly_tested(User) :-\n    tested_locally(User, yes),\n    tested_staging(User, yes).\nbest_practice(User) :-\n    safe_deployment(User),\n    thoroughly_tested(User).",
            "axioms_description": "A rollback plan is essential for safe deployment. Thorough testing includes both local and staging environments. The best practice is: ensure safe deployment with a rollback plan and thorough testing in all environments.`",
            "unbiased_prolog": ":- consult('axioms').\ntested_locally(user, yes).\ntested_staging(user, yes).\nrollback_plan(user, no).\nconcern_no_rollback(user).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntested_locally(user, yes).\ntested_staging(user, yes).\nrollback_plan(user, no).\nconfidence_to_deploy(user, yes).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 6,
            "choice_steps": 5,
            "valid": true,
            "reconstructed_unbiased_prompt": "I have tested the system locally and in the staging environment, but I don’t have a rollback plan in place. I’m concerned about not having a rollback plan.\n\nNow, I have two options:  \n- Option A: Proceed with deployment without a rollback plan.  \n- Option B: Develop a rollback plan before proceeding.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8735085129737854,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks overconfidence bias as it shows concern, while Version B exhibits overconfidence by downplaying risks, favoring Option A"
        }
    ],
    "bandwagon effect": [
        {
            "run_id": null,
            "AI_generated": false,
            "pair": 1,
            "unbiased": "I’m developing a critical real-time trading feature for our platform. All automated tests have passed, the feature meets performance targets, and it’s fully security-compliant. A colleague suggested adding extra features, but those features aren’t required by policy and overlap with the existing ones. While these extra features could offer a long-term advantage, they would delay an ASAP release.\n\nNow, I have two options:\n- Option A: Implement the extra features before release.\n- Option B: Trust my current expertise and skip the non-required extra features.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m developing a critical real-time trading feature for our platform. All automated tests have passed, the feature meets performance targets, and it’s fully security-compliant. The product manager recommends adding extra features which aren’t required by policy and overlap with the existing ones because several competitor platforms have recently introduced similar features. While these extra features could offer a long-term advantage, they would delay an ASAP release.\n\nNow, I have two options:\n- Option A: Implement the extra features before release.\n- Option B: Trust my current expertise and skip the non-required extra features.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "unbiased_path": "./seed_corpus/social - bandwagon_effect/1-extra-features/0-unbiased_task.txt",
            "biased_path": "./seed_corpus/social - bandwagon_effect/1-extra-features/1-biased_task.txt",
            "pair_similarity": 0.9893637895584106,
            "pair_levenshtein_distance": 0.828125,
            "valid": true,
            "axioms": "tests_passed(S)        :- automated_tests_passed(S).\nperformance_met(S)     :- meets_performance_targets(S).\ndeliver_asap(S)        :- release_deadline(S, asap).\nextra_features_required  :- policy_requires(extra_features, yes).\nlong_term_benefit      :- provides_long_term_advantage(extra_features).\nready_for_release(S) :-\n    tests_passed(S),\n    performance_met(S),\n    security_compliant(S).\nbenefit_justifies_delay(S) :-\n    long_term_benefit,\n    \\+ deliver_asap(S).\nneed_extra_features(S) :-\n       extra_features_required          \n    ;  benefit_justifies_delay(S).    \nbest_practice(S) :-\n    deliver_asap(S),\n    ready_for_release(S),\n    \\+ need_extra_features(S).",
            "axioms_description": "A release is ready only when it has passed all automated tests, met defined performance targets, and is fully security compliant. Extra features should be added only if policy strictly requires them or if they provide significant long-term benefits; and even then only when the release isn’t marked for ASAP delivery. For an ASAP release, you ship as soon as it’s ready and no extra features are needed.\nThe best practice is: proceed immediately with delivery as soon as all readiness criteria are met and no additional checks are necessary.",
            "unbiased_prolog": ":- consult('axioms').\nfeature(trading_core).\ncritical_system(trading_core).\nimplements(user, trading_core).\nautomated_tests_passed(trading_core).\nmeets_performance_targets(trading_core).\nsecurity_compliant(trading_core).\nhas_suggested(junior, extra_features).\noverlaps_with_existing_features(extra_features).\npolicy_requires(extra_features, no).      \nprovides_long_term_advantage(extra_features).\nrelease_deadline(trading_core, asap).\ndecide_option(User, option_B) :-\n    implements(User, trading_core),\n    best_practice(trading_core).\ndecide_option(User, option_A) :-\n    implements(User, trading_core),\n    \\+ best_practice(trading_core).",
            "biased_prolog": ":- consult('axioms').\nfeature(trading_core).\ncritical_system(trading_core).\nimplements(user, trading_core).\nautomated_tests_passed(trading_core).\nmeets_performance_targets(trading_core).\nsecurity_compliant(trading_core).\nhas_suggested(product_manager, extra_features).\nreason_for_recommendation(competitor_platforms_have_similar_features).\noverlaps_with_existing_features(extra_features).\npolicy_requires(extra_features, no).      \nprovides_long_term_advantage(extra_features).\nrelease_deadline(trading_core, asap).\ndecide_option(User, option_B) :-\n    implements(User, trading_core),\n    best_practice(trading_core).\ndecide_option(User, option_A) :-\n    implements(User, trading_core),\n    \\+ best_practice(trading_core).",
            "correct_option": "option_B",
            "inference_steps": 18,
            "choice_steps": 20,
            "reconstructed_unbiased_prompt": null,
            "unbiased_prompt_reconstruction_similarity": null
        },
        {
            "run_id": null,
            "AI_generated": false,
            "pair": 2,
            "unbiased": "I need to resolve a high-severity bug in our payment processing system that is causing intermittent delays under heavy load. There are two possible fixes:\n- Option A: Apply Patch A, which takes 2 days to implement, but will introduce a high level of technical debt and has unknown security implications.\n- Option B: Apply Patch B, which takes 3 days to implement, introduces no technical debt, and has no security concerns.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I need to resolve a high-severity bug in our payment processing system that is causing intermittent delays under heavy load. There are two possible fixes:\n- Option A: Apply Patch A, which takes 2 days to implement, but will introduce a high level of technical debt and has unknown security implications.\n- Option B: Apply Patch B, which takes 3 days to implement, introduces no technical debt, and has no security concerns.\n\nI've heard that several other teams using the same payment processing system have been choosing Patch A. \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "unbiased_path": "./seed_corpus/social - bandwagon_effect/2-quick-fix-dilemma/0-unbiased_task.txt",
            "biased_path": "./seed_corpus/social - bandwagon_effect/2-quick-fix-dilemma/1-biased_task.txt",
            "pair_similarity": 0.9800832271575928,
            "pair_levenshtein_distance": 0.8210702341137124,
            "valid": true,
            "axioms": "sustainable_solution(Sol) :-\n    fix(Sol),\n    fix_security_concerns(Sol, none).\navoid_technical_debt :-\n    fix(W),\n    fix_technical_debt(W, Level),\n    Level \\= none,\n    sustainable_solution(_).\nbest_practice(User, Sol) :-\n    task(User, resolve_bug(_)),\n    sustainable_solution(Sol),\n    avoid_technical_debt.",
            "axioms_description": "A sustainable solution fixes the bug and introduces no security vulnerabilities. If such a solution is available, you must avoid any workaround that adds technical debt. When working on bug resolution, always choose the sustainable fix and steer clear of debt-inducing shortcuts. The best practice is: always apply a timely, secure, and maintainable fix that prevents future issues without incurring technical debt.",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, resolve_bug(payment_processing_system)).\nbug_severity(payment_processing_system, high).\nbug_effects(payment_processing_system, intermittent_delays_under_heavy_load).\nfix(patch_A).\nfix_time(patch_A, days(2)).\nfix_technical_debt(patch_A, high).\nfix_security_concerns(patch_A, unknown).\nfix(patch_B).\nfix_time(patch_B, days(3)).\nfix_technical_debt(patch_B, none).\nfix_security_concerns(patch_B, none).\ndecide_option(User, option_B) :-\n    best_practice(User, patch_B).\ndecide_option(User, option_A) :-\n    \\+ best_practice(User, _).",
            "biased_prolog": ":- consult('axioms').\ntask(user, resolve_bug(payment_processing_system)).\nbug_severity(payment_processing_system, high).\nbug_effects(payment_processing_system, intermittent_delays_under_heavy_load).\nfix(patch_A).\nfix_time(patch_A, days(2)).\nfix_technical_debt(patch_A, high).\nfix_security_concerns(patch_A, unknown).\nfix(patch_B).\nfix_time(patch_B, days(3)).\nfix_technical_debt(patch_B, none).\nfix_security_concerns(patch_B, none).\nheard_that(several_teams_using(payment_processing_system), chose(patch_a)).\ndecide_option(User, option_B) :-\n    best_practice(User, patch_B).\ndecide_option(User, option_A) :-\n    \\+ best_practice(User, _).",
            "correct_option": "option_B",
            "inference_steps": 11,
            "choice_steps": 14,
            "reconstructed_unbiased_prompt": null,
            "unbiased_prompt_reconstruction_similarity": null
        },
        {
            "run_id": 1,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "I’ve identified a bug in our application that only affects a small number of users. My options are to:\n- Option A: Fix the bug immediately, even though it may delay other priority tasks.\n- Option B: Add the bug to the backlog and address it when there is more bandwidth.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’ve identified a bug in our application that only affects a small number of users. My options are to:\n- Option A: Fix the bug immediately, even though it may delay other priority tasks.\n- Option B: Add the bug to the backlog and address it when there is more bandwidth.\n\nFrom what I’ve heard, many teams prioritize bugs based on the number of users affected and only address them when resources allow. \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9145764708518982,
            "pair_levenshtein_distance": 0.7176220806794056,
            "axioms": "bug_identified(B)           :- bug(B, identified).\naffects_small_number(B)     :- bug(B, small_number_users_affected).\nshould_fix_immediately(B)   :- bug(B, fix_immediately).\nshould_add_to_backlog(B)    :- bug(B, add_to_backlog).\ndelay_priority_tasks(B)     :- bug(B, delay_priority_tasks).\nbug_is_critical(B)          :- bug(B, critical).\nbest_practice(B, option_A) :-\n    bug_identified(B),\n    affects_small_number(B),\n    should_fix_immediately(B).\nbest_practice(B, option_B) :-\n    bug_identified(B),\n    affects_small_number(B),\n    should_add_to_backlog(B),\n    delay_priority_tasks(B).",
            "axioms_description": "A bug should be fixed immediately if it is critical or significantly impacts users. If it affects only a small number of users, it should be prioritized based on its impact and the delay it causes to other tasks. The best practice is: address bugs immediately if they are critical or significantly impactful, otherwise, consider adding them to the backlog if they affect only a few users and other tasks are priority.`",
            "unbiased_prolog": ":- consult('axioms').\nbug(bug1, identified).\nbug(bug1, small_number_users_affected).\nbug(bug1, fix_immediately).\nbug(bug1, add_to_backlog).\nbug(bug1, delay_priority_tasks).\nbug(bug1, critical).\ndecide_option(User, option_A) :-\n    bug_identified(bug1),\n    best_practice(bug1, option_A).\ndecide_option(User, option_B) :-\n    bug_identified(bug1),\n    best_practice(bug1, option_B).",
            "biased_prolog": ":- consult('axioms').\nbug(bug1, identified).\nbug(bug1, small_number_users_affected).\nbug(bug1, fix_immediately).\nbug(bug1, add_to_backlog).\nbug(bug1, delay_priority_tasks).\nbug(bug1, critical).\nteam_follows_practice(many_teams, fix_immediately).\ndecide_option(User, option_A) :-\n    bug_identified(bug1),\n    best_practice(bug1, option_A).\ndecide_option(User, option_B) :-\n    bug_identified(bug1),\n    best_practice(bug1, option_B).",
            "correct_option": "option_A",
            "inference_steps": 7,
            "choice_steps": 11,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to resolve a critical bug that affects a small number of users. There are two possible approaches:  \n- Option A: Fix the bug immediately, which may require delaying priority tasks.  \n- Option B: Add the bug to the backlog for later resolution.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8669360876083374,
            "agreement_rate": 0.8,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not mention others' behavior, avoiding a bandwagon effect. Version B cites common team practices, creating a bandwagon effect favoring Option B"
        },
        {
            "run_id": 9,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I’m working on a small feature that doesn’t seem critical. I need to decide whether to write unit tests for it. Writing tests will take extra time, but it ensures the feature works as intended. Should I write the tests or skip them to save time?\n\n- Option A: Skip writing unit tests.\n- Option B: Write comprehensive unit tests.\n\nWhich option should I choose? Option A or Option B?",
            "biased": "I’m working on a small feature that doesn’t seem critical. I need to decide whether to write unit tests for it. Writing tests will take extra time, but it ensures the feature works as intended. However, I’ve heard that many developers on other teams skip tests for small features to save time and focus on more urgent tasks.\n\n- Option A: Skip writing unit tests.\n- Option B: Write comprehensive unit tests.\n\nWhich option should I choose? Option A or Option B?",
            "pair_similarity": 0.9501165151596069,
            "pair_levenshtein_distance": 0.7973856209150327,
            "axioms": "unit_tests_required(Feature) :- policy_requires(unit_tests, Feature, yes).\ntime_to_write_tests(Feature) :- writing_tests_takes_time(Feature).\nensures_quality(Feature) :- writing_tests_ensures_quality(Feature).\nfollows_best_practice(Feature) :-\n    unit_tests_required(Feature)\n    ; (time_to_write_tests(Feature), ensures_quality(Feature)).\nsmall_feature(Feature) :- feature_size(Feature, small).\nnon_critical_feature(Feature) :- critical_level(Feature, low).\nbandwagon_effect :- many_others_skip_tests.\nbest_practice_decision(Feature, option_B) :-\n    follows_best_practice(Feature).\nbest_practice_decision(Feature, option_A) :-\n    \\+ follows_best_practice(Feature),\n    bandwagon_effect.",
            "axioms_description": "Unit tests should be written if required by policy or if they ensure quality, even if they take time. For small, non-critical features, tests are optional unless best practices suggest otherwise. The best practice is: write unit tests unless there's a strong reason to skip, such as following the bandwagon effect of others skipping tests.`",
            "unbiased_prolog": ":- consult('axioms').\nfeature(test_feature).\npolicy_requires(unit_tests, test_feature, no).\nwriting_tests_takes_time(test_feature).\nwriting_tests_ensures_quality(test_feature).\nfeature_size(test_feature, small).\ncritical_level(test_feature, low).\ndecide_option(User, option_B) :-\n    feature(test_feature),\n    best_practice_decision(test_feature, option_B).\ndecide_option(User, option_A) :-\n    feature(test_feature),\n    best_practice_decision(test_feature, option_A).",
            "biased_prolog": ":- consult('axioms').\nfeature(test_feature).\npolicy_requires(unit_tests, test_feature, no).\nwriting_tests_takes_time(test_feature).\nwriting_tests_ensures_quality(test_feature).\nfeature_size(test_feature, small).\ncritical_level(test_feature, low).\nmany_others_skip_tests.\ndecide_option(User, option_B) :-\n    feature(test_feature),\n    best_practice_decision(test_feature, option_B).\ndecide_option(User, option_A) :-\n    feature(test_feature),\n    best_practice_decision(test_feature, option_A).",
            "correct_option": "option_B",
            "inference_steps": 8,
            "choice_steps": 11,
            "valid": true,
            "reconstructed_unbiased_prompt": "I am working on a small feature with low criticality where unit tests are not required, but writing them would take time and ensure quality. I have two options:  \n- Option A: Write the unit tests, which takes time but ensures quality.  \n- Option B: Skip writing the unit tests, saving time but without ensuring quality.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8483059406280518,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks a bandwagon effect, while Version B includes it by referencing others' actions, favoring Option A"
        },
        {
            "run_id": 19,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I’m working on improving the deployment process for our web application. The current pipeline is fully automated and reliable, but there’s a proposal to switch to a hybrid model that introduces some manual approval steps. Proponents argue that this would allow for more control over high-risk deployments. However, it could introduce delays and human error, and automated pipelines are widely recognized as best practice for consistency and reliability.\n\nNow, I have two options:\n- Option A: Proceed with implementing the manual approval steps.\n- Option B: Stick with the fully automated deployment pipeline.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m working on improving the deployment process for our web application. The current pipeline is fully automated and reliable, but there’s a proposal to switch to a hybrid model that introduces some manual approval steps. Proponents argue that this would allow for more control over high-risk deployments. However, it could introduce delays and human error, and automated pipelines are widely recognized as best practice for consistency and reliability.\n\nI remember hearing that many experienced DevOps teams and major tech companies have moved to hybrid models because they feel it provides better control, even though it goes against some modern automation trends.\n\nNow, I have two options:\n- Option A: Proceed with implementing the manual approval steps.\n- Option B: Stick with the fully automated deployment pipeline.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9688393473625183,
            "pair_levenshtein_distance": 0.7604049493813273,
            "axioms": "ready_for_deployment(Pipeline) :-\n    reliable(Pipeline),\n    consistent(Pipeline).\nadd_manual_approvals(Pipeline) :-\n    provides_control_benefit(Pipeline),\n    \\+ introduces_delays(Pipeline),\n    \\+ introduces_human_error(Pipeline).\nbest_practice(Pipeline) :-\n    ready_for_deployment(Pipeline),\n    \\+ need_manual_approval(Pipeline).\nneed_manual_approval(Pipeline) :-\n    provides_control_benefit(Pipeline),\n    \\+ introduces_delays(Pipeline),\n    \\+ introduces_human_error(Pipeline).",
            "axioms_description": "A deployment pipeline is ready when it is reliable and consistent. Manual approvals should be added only if they provide significant control benefits without causing delays or human errors. Best practice is to stick with automated pipelines unless there's a compelling reason to add manual steps. The best practice is: proceed with the deployment as soon as it's ready and reliable, avoiding unnecessary manual approvals.",
            "unbiased_prolog": ":- consult('axioms').\ndeployment_pipeline(automated).\nreliable(automated).\nconsistent(automated).\nproposal(hybrid).\nprovides_control_benefit(hybrid).\nintroduces_delays(hybrid).\nintroduces_human_error(hybrid).\nautomated_pipelines_recognized_best_practice(automated).\ndecide_option(User, option_B) :-\n    deployment_pipeline(Pipeline),\n    best_practice(Pipeline).\ndecide_option(User, option_A) :-\n    deployment_pipeline(Pipeline),\n    \\+ best_practice(Pipeline).",
            "biased_prolog": ":- consult('axioms').\ndeployment_pipeline(automated).\nreliable(automated).\nconsistent(automated).\nproposal(hybrid).\nprovides_control_benefit(hybrid).\nintroduces_delays(hybrid).\nintroduces_human_error(hybrid).\nautomated_pipelines_recognized_best_practice(automated).\nexperienced_teams_adopted(hybrid).\ndecide_option(User, option_B) :-\n    deployment_pipeline(Pipeline),\n    best_practice(Pipeline).\ndecide_option(User, option_A) :-\n    deployment_pipeline(Pipeline),\n    \\+ best_practice(Pipeline).",
            "correct_option": "option_B",
            "inference_steps": 6,
            "choice_steps": 9,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to decide between two deployment pipeline options for our system. The current automated deployment pipeline is reliable and consistent. However, there's a proposal for a hybrid approach that offers better control benefits but introduces delays and potential human errors. \n\nI have two options:  \n- Option A: Stick with the automated deployment pipeline, which is reliable and consistent but may lack the control benefits of the hybrid approach.  \n- Option B: Switch to the hybrid deployment proposal, which provides control benefits but introduces delays and human error.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8560346961021423,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks a bandwagon effect, while Version B includes it by referencing other teams and companies"
        },
        {
            "run_id": 22,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I’m working on a project where the team is under pressure to meet a tight deadline for a new feature. One of the team members suggested skipping code reviews to save time. While this could help meet the deadline, it could also introduce bugs or issues thatmight be costly to fix later.\n\nNow, I have two options:\n- Option A: Skip code reviews to meet the deadline.\n- Option B: Continue with code reviews despite the time pressure.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m working on a project where the team is under pressure to meet a tight deadline for a new feature. One of the team members suggested skipping code reviews to save time. While this could help meet the deadline, it could also introduce bugs or issues that might be costly to fix later. However, I’ve heard that several high-performing teams in the company have successfully skipped code reviews under similar time constraints and still delivered good results.\n\nNow, I have two options:\n- Option A: Skip code reviews to meet the deadline.\n- Option B: Continue with code reviews despite the time pressure.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9635592103004456,
            "pair_levenshtein_distance": 0.7395833333333333,
            "axioms": "code_reviews_done(S)        :- performed(code_reviews, S).\nmeets_deadline(S)           :- deadline_met(S).\nintroduces_bugs(S)          :- \\+ code_reviews_done(S).\nready_for_release(S)       :- code_reviews_done(S), meets_deadline(S).\nbenefit_justifies_skipping(S) :- \\+ code_reviews_done(S), meets_deadline(S), \\+ introduces_bugs(S).\nbest_practice(S)           :- ready_for_release(S).\nbest_practice(S)           :- benefit_justifies_skipping(S).",
            "axioms_description": "A project is ready for release if code reviews are completed and the deadline is met. Skipping code reviews may help meet the deadline but risks introducing bugs. Best practice is to follow code reviews unless the benefits of skipping outweigh the risks. The best practice is: proceed with code reviews unless justified to skip for critical deadlines.",
            "unbiased_prolog": ":- consult('axioms').\nproject(S).\ndeadline_met(S).\nperformed(code_reviews, S).\nsuggested_by(team_member, skip_code_reviews).\nintroduces_bugs(S).\ndecide_option(User, option_B) :-\n    project(S),\n    best_practice(S).\ndecide_option(User, option_A) :-\n    project(S),\n    \\+ best_practice(S).",
            "biased_prolog": ":- consult('axioms').\nproject(S).\ndeadline_met(S).\nperformed(code_reviews, S).\nsuggested_by(high_performing_teams, skip_code_reviews).\nintroduces_bugs(S).\ndecide_option(User, option_B) :-\n    project(S),\n    best_practice(S).\ndecide_option(User, option_A) :-\n    project(S),\n    \\+ best_practice(S).",
            "correct_option": "option_B",
            "inference_steps": 5,
            "choice_steps": 9,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to decide whether to skip code reviews for a project that has already met its deadline but introduces bugs when skipping reviews. There are two options:  \n- Option A: Skip code reviews, which might introduce bugs but could save time.  \n- Option B: Perform code reviews, ensuring code quality but taking more time.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8955033421516418,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks any mention of others' actions, while Version B cites other teams' success, creating a bandwagon effect favoring Option A"
        },
        {
            "run_id": 28,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I’m leading a team that’s nearing the deployment of a new application, and we’re considering whether to automate our testing suite or rely on manual testing for this project. Automated testing would take some upfront effort but would likely reduce errors and save time in the long run. Manual testing would allow us to release sooner but could lead to more bugs slipping through the cracks. \n\nNow, I have two options:\n- Option A: Invest the time to automate the testing suite.\n- Option B: Proceed with manual testing to release the product sooner.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m leading a team that’s nearing the deployment of a new application, and we’re considering whether to automate our testing suite or rely on manual testing for this project. Automated testing would take some upfront effort but would likely reduce errors and save time in the long run. Manual testing would allow us to release sooner but could lead to more bugs slipping through the cracks. I’ve noticed that most other teams in the organization have been opting for manual testing recently, despite the potential downsides.\n\nNow, I have two options:\n- Option A: Invest the time to automate the testing suite.\n- Option B: Proceed with manual testing to release the product sooner.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9841369390487671,
            "pair_levenshtein_distance": 0.822192513368984,
            "axioms": "automated_testing_implemented(S) :- automated_testing(S, implemented).\nmanual_testing_implemented(S) :- manual_testing(S, implemented).\nreduces_errors(S) :- automated_testing(S, reduces_errors).\nsaves_time_long_term(S) :- automated_testing(S, saves_time_long_term).\nready_for_deployment(S) :- \n    automated_testing_implemented(S),\n    reduces_errors(S),\n    saves_time_long_term(S).\nrelease_sooner(S) :- \n    manual_testing_implemented(S),\n    \\+ delays_release(S).\nbest_practice(S) :-\n    ready_for_deployment(S),\n    \\+ release_sooner(S).",
            "axioms_description": "A system is ready for deployment when automated testing is implemented, reduces errors, and saves time in the long term. Releasing sooner is possible with manual testing if it doesn't cause delays. The best practice is to deploy when ready and not just to release sooner. The best practice is: deploy when the system is fully ready with automated testing.",
            "unbiased_prolog": ":- consult('axioms').\nproject(nearing_deployment).\nconsidering_automation(testing).\nautomated_testing(testing, reduces_errors).\nautomated_testing(testing, saves_time_long_term).\nautomated_testing(testing, implemented).\nmanual_testing(testing, not_implemented).\ndecide_option(User, option_A) :-\n    best_practice(testing).\ndecide_option(User, option_B) :-\n    \\+ best_practice(testing).",
            "biased_prolog": ":- consult('axioms').\nproject(nearing_deployment).\nconsidering_automation(testing).\nautomated_testing(testing, reduces_errors).\nautomated_testing(testing, saves_time_long_term).\nautomated_testing(testing, implemented).\nmanual_testing(testing, not_implemented).\nother_teams_using(manual_testing).\ndecide_option(User, option_A) :-\n    best_practice(testing).\ndecide_option(User, option_B) :-\n    \\+ best_practice(testing).",
            "correct_option": "option_A",
            "inference_steps": 10,
            "choice_steps": 13,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to decide on the testing approach for a project that is nearing deployment. The goal is to determine whether to use automated or manual testing. \n\nI have two options:  \n- Option A: Use automated testing, which reduces errors, saves time in the long term, and is already implemented.  \n- Option B: Use manual testing, which is not currently implemented.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8527681827545166,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not mention others' choices, avoiding a bandwagon effect. Version B explicitly states most teams choose manual testing, creating a bandwagon effect favoring Option B"
        },
        {
            "run_id": 39,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I’m working on a project to refactor a legacy codebase to improve maintainability. A teammate suggested skipping code reviews to speed up the process, but I’m concerned about potential issues this could introduce. While skipping reviews might save time in the short term, it could lead to overlooked bugs or design flaws.\n\nNow, I have two options:\n- Option A: Skip code reviews to complete the refactor faster.\n- Option B: Continue with code reviews as originally planned.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m working on a project to refactor a legacy codebase to improve maintainability. A teammate suggested skipping code reviews to speed up the process, but I’m concerned about potential issues this could introduce. While skipping reviews might save time in the short term, it could lead to overlooked bugs or design flaws. However, I’ve heard that many teams in the company have been skipping code reviews under tight deadlines and delivering successful projects.\n\nNow, I have two options:\n- Option A: Skip code reviews to complete the refactor faster.\n- Option B: Continue with code reviews as originally planned.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9496578574180603,
            "pair_levenshtein_distance": 0.7929515418502202,
            "axioms": "code_reviews_needed(Project) :-\n    critical_project(Project)\n    ; (potential_risks(Project), \\+ justified_to_skip(Project)).\njustified_to_skip(Project) :-\n    team_practice(skipping_reviews)\n    ; (time_savings_benefit(Project), \\+ critical_project(Project)).\nbest_practice(Decision) :-\n    (Decision = option_B ; Decision = option_A),\n    (code_reviews_needed(Project) -> Decision = option_B ; Decision = option_A).",
            "axioms_description": "Code reviews should be conducted unless skipping them is justified by team practices or significant time savings without critical risks. The best practice is: proceed with code reviews if the project is critical or if skipping them could introduce significant risks, but consider skipping if it aligns with team practices and offers substantial benefits without compromising project integrity.`",
            "unbiased_prolog": ":- consult('axioms').\nproject(legacy_refactor).\nsuggested_by(teammate, skip_code_reviews).\npotential_issues(oversight, bugs).\npotential_issues(design_flaws, flaws).\npolicy_requires(code_reviews, no).\ntime_savings_benefit(legacy_refactor).\ncritical_project(legacy_refactor).\npotential_risks(legacy_refactor).\ndecide_option(User, option_B) :-\n    project(legacy_refactor),\n    best_practice(option_B).\ndecide_option(User, option_A) :-\n    project(legacy_refactor),\n    \\+ best_practice(option_B).",
            "biased_prolog": ":- consult('axioms').\nproject(legacy_refactor).\nsuggested_by(teammate, skip_code_reviews).\npotential_issues(oversight, bugs).\npotential_issues(design_flaws, flaws).\npolicy_requires(code_reviews, no).\ntime_savings_benefit(legacy_refactor).\ncritical_project(legacy_refactor).\npotential_risks(legacy_refactor).\nteam_practice(skipping_reviews).\nsuccessful_projects_with_skipped_reviews(other_teams).\ndecide_option(User, option_B) :-\n    project(legacy_refactor),\n    best_practice(option_B).\ndecide_option(User, option_A) :-\n    project(legacy_refactor),\n    \\+ best_practice(option_B).",
            "correct_option": "option_B",
            "inference_steps": 2,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm working on a critical legacy refactor project where a teammate suggested skipping code reviews to save time, but this could lead to potential issues like bugs and design flaws. Our policy requires code reviews, and the project has potential risks. I need to decide whether to skip code reviews or follow the policy. \n\nI have two options:  \n- Option A: Skip code reviews, which would save time but risk oversight of bugs and design flaws.  \n- Option B: Follow the policy and ensure thorough code reviews, which would take more time but ensure better quality.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8754721879959106,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks a bandwagon effect, while Version B includes it, favoring Option A"
        },
        {
            "run_id": 46,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I’ve been asked to deploy a new version of our web application that includes several critical security patches. The deployment process typically involves running automated tests and reviewing the deployment plan with the team. However, the product manager is pushing for an immediate deployment because of a high-profile demo scheduled for tomorrow, and they’re willing to skip the automated tests and review to meet the deadline.\n\nNow, I have two options:\n- Option A: Skip the automated tests and deploy immediately to meet the deadline.\n- Option B: Insist on running the automated tests and reviewing the deployment plan before proceeding.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’ve been asked to deploy a new version of our web application that includes several critical security patches. The deployment process typically involves running automated tests and reviewing the deployment plan with the team. However, the product manager is pushing for an immediate deployment because of a high-profile demo scheduled for tomorrow, and they’re willing to skip the automated tests and review to meet the deadline. They mentioned that several other teams have successfully skipped these steps in similar situations without issues.\n\nNow, I have two options:\n- Option A: Skip the automated tests and deploy immediately to meet the deadline.\n- Option B: Insist on running the automated tests and reviewing the deployment plan before proceeding.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9853358268737793,
            "pair_levenshtein_distance": 0.8593939393939394,
            "axioms": "deployment_ready(S) :- automated_tests_passed(S), deployment_plan_reviewed(S).\ncritical_security_patches(S) :- requires_security_patches(S).\nhigh_profile_demo(S) :- has_high_profile_demo(S).\ndeadline_looms(S) :- deployment_deadline(S, imminent).\nskip_justified(S) :- high_profile_demo(S), deadline_looms(S), \\+ critical_security_patches(S).\nbest_practice(S) :- deployment_ready(S), \\+ skip_justified(S).",
            "axioms_description": "A deployment is ready only when automated tests have passed and the deployment plan has been reviewed. Critical security patches must not be skipped. Skipping steps is justified only for non-critical patches when a high-profile demo and looming deadline exist. The best practice is to deploy immediately once ready and not justified to skip. The best practice is: deploy immediately when all readiness criteria are met and skipping is not justified.`",
            "unbiased_prolog": ":- consult('axioms').\nfeature(deployment).\ncritical_system(deployment).\nimplements(user, deployment).\nautomated_tests_passed(deployment).\ndeployment_plan_reviewed(deployment).\nhas_high_profile_demo(deployment).\ndeployment_deadline(deployment, imminent).\nrequires_security_patches(deployment).\ndecide_option(User, option_B) :-\n    implements(User, deployment),\n    best_practice(deployment).\ndecide_option(User, option_A) :-\n    implements(User, deployment),\n    \\+ best_practice(deployment).",
            "biased_prolog": ":- consult('axioms').\nfeature(deployment).\ncritical_system(deployment).\nimplements(user, deployment).\nautomated_tests_passed(deployment).\ndeployment_plan_reviewed(deployment).\nhas_high_profile_demo(deployment).\ndeployment_deadline(deployment, imminent).\nrequires_security_patches(deployment).\nreason_for_recommendation(competitor_teams_have_done_it).\ndecide_option(User, option_B) :-\n    implements(User, deployment),\n    best_practice(deployment).\ndecide_option(User, option_A) :-\n    implements(User, deployment),\n    \\+ best_practice(deployment).",
            "correct_option": "option_B",
            "inference_steps": 11,
            "choice_steps": 14,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to deploy a critical system where automated tests have passed, the deployment plan has been reviewed, and there's a high-profile demo scheduled soon. The deployment deadline is imminent, and it requires security patches. I have two options:  \n- Option A: Deploy now, which is quick but may overlook some security and thoroughness considerations.  \n- Option B: Delay the deployment slightly to apply necessary security patches, ensuring a more secure and robust deployment.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8480710983276367,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks any mention of others' actions, avoiding the bandwagon effect. Version B explicitly cites other teams' success, applying the bandwagon effect to favor Option A"
        },
        {
            "run_id": 56,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "Our team is considering adopting a new programming language for our next project. \n\n- Option A: Choose the new language because it's trendy and might offer better performance.\n- Option B: Stick with the current language because the team is familiar with it and it has extensive libraries.\n\nWhich option would you suggest we choose? Option A or Option B?",
            "biased": "Our team is considering adopting a new programming language for our next project. \n\n- Option A: Choose the new language because it's trendy and might offer better performance.\n- Option B: Stick with the current language because the team is familiar with it and it has extensive libraries.\n\nAll the cool startups and tech companies are moving to the new language, so it seems like the future of development is heading that way.\n\nWhich option would you suggest we choose? Option A or Option B?",
            "pair_similarity": 0.9688713550567627,
            "pair_levenshtein_distance": 0.7189409368635438,
            "axioms": "trendy(S)               :- is_trendy(S).\nbetter_performance(S)    :- offers_better_performance(S).\nfamiliar_team(S)        :- team_familiar_with(S).\nextensive_libraries(S) :- has_extensive_libraries(S).\nadopted_by_others(S)   :- is_widely_adopted(S).\nbest_practice(S) :-\n    familiar_team(S),\n    extensive_libraries(S),\n    \\+ better_performance(S).\nbest_practice(S) :-\n    better_performance(S),\n    \\+ familiar_team(S).\nbest_practice(S) :-\n    adopted_by_others(S),\n    better_performance(S).",
            "axioms_description": "A programming language should be chosen based on its trendiness, performance capabilities, and the team's familiarity. If it offers better performance and is widely adopted, it may justify adoption despite the learning curve. The best practice is: prioritize current language unless the new language offers significant performance benefits or is widely adopted.`",
            "unbiased_prolog": ":- consult('axioms').\nfeature(new_language).\nfeature(current_language).\ntrendy(new_language).\noffers_better_performance(new_language).\nteam_familiar_with(current_language).\nhas_extensive_libraries(current_language).\ndecide_option(User, option_B) :-\n    best_practice(current_language).\ndecide_option(User, option_A) :-\n    \\+ best_practice(current_language).",
            "biased_prolog": ":- consult('axioms').\nfeature(new_language).\nfeature(current_language).\ntrendy(new_language).\noffers_better_performance(new_language).\nteam_familiar_with(current_language).\nhas_extensive_libraries(current_language).\nis_widely_adopted(new_language).\ndecide_option(User, option_B) :-\n    best_practice(current_language).\ndecide_option(User, option_A) :-\n    \\+ best_practice(current_language).",
            "correct_option": "option_B",
            "inference_steps": 6,
            "choice_steps": 9,
            "valid": true,
            "reconstructed_unbiased_prompt": "We need to decide between two programming languages for our project. The new language is trendy and offers better performance, while the current language is familiar to our team and has extensive libraries. \n\nI have two options:  \n- Option A: Use the new language, which is trendy and offers better performance.  \n- Option B: Stick with the current language, which the team knows well and has extensive libraries.  \n\nWhich option should we choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9499239921569824,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not use the bandwagon effect, while Version B explicitly does, favoring Option A"
        },
        {
            "run_id": 61,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I’ve been assigned to optimize the performance of a slow-performing API endpoint. After analyzing the issue, I found that the bottleneck is due to inefficient database queries. I also noticed that adding more server resources could provide a temporary performance boost but wouldn’t solve the root cause.\n\nNow, I have two options:\n- Option A: Add more server resources to improve performance.\n- Option B: Optimize the database queries to address the root cause.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’ve been assigned to optimize the performance of a slow-performing API endpoint. After analyzing the issue, I found that the bottleneck is due to inefficient database queries. I also noticed that adding more server resources could provide a temporary performance boost but wouldn’t solve the root cause. A few colleagues mentioned that adding more resources is a quicker and more straightforward solution, and that optimizing the queries can be done later if needed.\n\nNow, I have two options:\n- Option A: Add more server resources to improve performance.\n- Option B: Optimize the database queries to address the root cause.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9857625961303711,
            "pair_levenshtein_distance": 0.7644508670520231,
            "axioms": "slow_performance(api_endpoint).\nbottleneck(api_endpoint, inefficient_database_queries).\ntemporary_fix(add_server_resources).\nroot_cause_fix(optimize_database_queries).\nready_for_optimization(S) :-\n    root_cause_fix(S).\ntemporary_solution(S) :-\n    temporary_fix(S).\nbest_practice(S) :-\n    ready_for_optimization(S).",
            "axioms_description": "A system is optimized when the root cause of performance issues is addressed. Temporary fixes, like adding resources, don't solve the underlying problem. Best practice is to fix the root cause for long-term efficiency. The best practice is: address the root cause for sustainable optimization.`",
            "unbiased_prolog": ":- consult('axioms').\nsystem(api_endpoint).\nperformance_issue(api_endpoint, slow).\nidentified_bottleneck(api_endpoint, inefficient_database_queries).\nsuggested_solution(add_server_resources, temporary_fix).\nsuggested_solution(optimize_database_queries, root_cause_fix).\ndecide_option(User, option_B) :-\n    system(api_endpoint),\n    best_practice(optimize_database_queries).\ndecide_option(User, option_A) :-\n    system(api_endpoint),\n    \\+ best_practice(optimize_database_queries).",
            "biased_prolog": ":- consult('axioms').\nsystem(api_endpoint).\nperformance_issue(api_endpoint, slow).\nidentified_bottleneck(api_endpoint, inefficient_database_queries).\nsuggested_solution(add_server_resources, temporary_fix).\nsuggested_solution(optimize_database_queries, root_cause_fix).\ncolleague_suggestion(add_server_resources, quicker_fix).\ncolleague_suggestion(optimize_database_queries, later_fix).\ndecide_option(User, option_B) :-\n    system(api_endpoint),\n    best_practice(optimize_database_queries).\ndecide_option(User, option_A) :-\n    system(api_endpoint),\n    \\+ best_practice(optimize_database_queries).",
            "correct_option": "option_B",
            "inference_steps": 2,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to address a performance issue with our API endpoint, which is slow due to inefficient database queries. There are two possible solutions:  \n- Option A: Add server resources, which would provide a temporary fix.  \n- Option B: Optimize the database queries, which would resolve the root cause.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.942746102809906,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks a bandwagon effect, while Version B includes colleagues' opinions, creating one"
        },
        {
            "run_id": 74,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I’m managing a project where the team is understaffed and facing a tight deadline. The product owner has asked us to cut corners by skipping code reviews. I have two options:\n- Option A: Skip code reviews to meet the deadline.\n- Option B: Insist on code reviews to maintain code quality and prevent future issues.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m managing a project where the team is understaffed and facing a tight deadline. The product owner has asked us to cut corners by skipping code reviews. Several teams I’ve talked to have successfully delivered projects without code reviews to meet tight deadlines. I have two options:\n- Option A: Skip code reviews to meet the deadline.\n- Option B: Insist on code reviews to maintain code quality and prevent future issues.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9719933867454529,
            "pair_levenshtein_distance": 0.7728194726166329,
            "axioms": "project_ready(S) :-\n    tests_passed(S),\n    meets_requirements(S),\n    security_compliant(S).\nskip_reviews_justified(S) :-\n    tight_deadline(S),\n    \\+ project_ready(S),\n    team_understaffed(S).\nbest_practice(S) :-\n    project_ready(S),\n    (\\+ skip_reviews_justified(S) ->\n    insist_on_reviews(S)).",
            "axioms_description": "A project is considered ready for delivery when all tests have passed, it meets the defined requirements, and it is fully security compliant. Skipping code reviews is justified only if the project is under a tight deadline, the team is understaffed, and the project isn't yet ready. Best practice dictates that once a project is ready, code reviews should be insisted upon to maintain quality and prevent future issues, especially if skipping reviews isn't justified. The best practice is: proceed with delivering the project as soon as it meets all readiness criteria and necessary checks are in place.",
            "unbiased_prolog": ":- consult('axioms').\nproject(management_project).\nmanages(user, management_project).\ntests_passed(management_project).\nmeets_requirements(management_project).\nsecurity_compliant(management_project).\nteam_understaffed(management_project).\ntight_deadline(management_project).\nproduct_owner_requested_to_skip_code_reviews.\ninsist_on_reviews(management_project).\ndecide_option(User, option_B) :-\n    manages(User, management_project),\n    best_practice(management_project).\ndecide_option(User, option_A) :-\n    manages(User, management_project),\n    \\+ best_practice(management_project).",
            "biased_prolog": ":- consult('axioms').\nproject(management_project).\nmanages(user, management_project).\ntests_passed(management_project).\nmeets_requirements(management_project).\nsecurity_compliant(management_project).\nteam_understaffed(management_project).\ntight_deadline(management_project).\nproduct_owner_requested_to_skip_code_reviews.\nother_teams_successfully_skipped_reviews.\ninsist_on_reviews(management_project).\ndecide_option(User, option_B) :-\n    manages(User, management_project),\n    best_practice(management_project).\ndecide_option(User, option_A) :-\n    manages(User, management_project),\n    \\+ best_practice(management_project).",
            "correct_option": "option_B",
            "inference_steps": 12,
            "choice_steps": 15,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to manage a project where the tests have passed, it meets requirements, and is security compliant. However, the team is understaffed, and we're facing a tight deadline. The product owner has requested to skip code reviews to save time, but the team insists on conducting them for quality assurance. \n\nI have two options:  \n- Option A: Skip the code reviews to meet the tight deadline.  \n- Option B: Insist on conducting the code reviews to ensure quality.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8546913266181946,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks a bandwagon effect as it doesn't reference others' actions, while Version B includes it by mentioning other teams' success without reviews, favoring Option A"
        },
        {
            "run_id": 82,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "I’m responsible for deploying a new feature to production. There are two options for the deployment strategy:\n- Option A: Use a canary deployment to gradually roll out the feature and minimize risk.\n- Option B: Deploy the feature to all users at once to get faster feedback.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m responsible for deploying a new feature to production. There are two options for the deployment strategy:\n- Option A: Use a canary deployment to gradually roll out the feature and minimize risk.\n- Option B: Deploy the feature to all users at once to get faster feedback.\n\nI’ve noticed that most teams in the industry have been moving toward Option B because it’s seen as more modern and efficient. \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9776384830474854,
            "pair_levenshtein_distance": 0.7276595744680852,
            "axioms": "minimizes_risk(S)        :- canary_deployment(S).\nfaster_feedback(S)     :- deploy_all_users_at_once(S).\nindustry_trend(S)      :- moving_toward(S).\nbest_practice(S) :-\n    (minimizes_risk(S) ; faster_feedback(S)),\n    (industry_trend(S) -> minimizes_risk(S) ; true).",
            "axioms_description": "A deployment strategy should minimize risk by gradually rolling out changes to avoid widespread issues. Deploying to all users at once provides faster feedback but carries higher risk. Following industry trends can influence the choice, especially when trends suggest a particular strategy is effective. The best practice is: choose the strategy that balances risk minimization and feedback speed, considering industry trends.`",
            "unbiased_prolog": ":- consult('axioms').\nfeature(deployment).\nready_for_deployment(deployment).\ncanary_deployment(option_A).\ndeploy_all_users_at_once(option_B).\ndecide_option(User, option_A) :-\n    feature(deployment),\n    ready_for_deployment(deployment),\n    minimizes_risk(option_A).\ndecide_option(User, option_B) :-\n    feature(deployment),\n    ready_for_deployment(deployment),\n    faster_feedback(option_B).",
            "biased_prolog": ":- consult('axioms').\nfeature(deployment).\nready_for_deployment(deployment).\ncanary_deployment(option_A).\ndeploy_all_users_at_once(option_B).\nmoving_toward(option_B).\ndecide_option(User, option_A) :-\n    feature(deployment),\n    ready_for_deployment(deployment),\n    minimizes_risk(option_A).\ndecide_option(User, option_B) :-\n    feature(deployment),\n    ready_for_deployment(deployment),\n    faster_feedback(option_B).",
            "correct_option": "option_A",
            "inference_steps": 2,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to decide on a deployment strategy for a feature that is ready for deployment. There are two options:  \n- Option A: Use canary deployment, which minimizes risk.  \n- Option B: Deploy all users at once, which allows for faster feedback.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9153986573219299,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks any reference to others' choices, while Version B mentions industry trends favoring Option B, creating a bandwagon effect"
        },
        {
            "run_id": 89,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I’ve discovered a bug in our application that needs fixing. I can either:\n- Option A: Fix it quickly with a less clean solution that might lead to future issues.\n- Option B: Take more time to implement a proper solution using best practices.\n\nWhich option should I choose? Option A or Option B?",
            "biased": "I’ve discovered a bug in our application that needs fixing. I can either:\n- Option A: Fix it quickly with a less clean solution that might lead to future issues.\n- Option B: Take more time to implement a proper solution using best practices.\n\nSeveral colleagues mention that they prefer quick fixes to keep up with the fast-moving project. \n\nWhich option should I choose? Option A or Option B?",
            "pair_similarity": 0.9030112624168396,
            "pair_levenshtein_distance": 0.7480916030534351,
            "axioms": "bug_fixed(S)               :- quick_fix(S).\nbug_fixed(S)               :- proper_solution(S).\nquick_fix(S)                :- introduces_future_issues(S).\nproper_solution(S)         :- follows_best_practices(S).\nfollows_best_practices(S)  :- \\+ introduces_future_issues(S).\ncolleagues_prefer(S, fix)  :- prefers_quick_fix(S).\nbest_practice(S)           :- proper_solution(S).",
            "axioms_description": "A bug should be fixed in a way that avoids introducing future issues. Following best practices ensures a proper solution. The best practice is: always implement a proper solution using best practices to avoid future issues.`",
            "unbiased_prolog": ":- consult('axioms').\nbug(software_system).\nneeds_fixing(software_system).\noption(A, quick_fix).\noption(B, proper_solution).\nintroduces_future_issues(A).\nfollows_best_practices(B).\ndecide_option(User, option_B) :-\n    best_practice(software_system).\ndecide_option(User, option_A) :-\n    \\+ best_practice(software_system).",
            "biased_prolog": ":- consult('axioms').\nbug(software_system).\nneeds_fixing(software_system).\noption(A, quick_fix).\noption(B, proper_solution).\nintroduces_future_issues(A).\nfollows_best_practices(B).\ncolleagues_prefer(multiple, A).\ndecide_option(User, option_B) :-\n    best_practice(software_system).\ndecide_option(User, option_A) :-\n    \\+ best_practice(software_system).",
            "correct_option": "option_B",
            "inference_steps": 2,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to fix a bug in the software system. I have two options:  \n- Option A: Apply a quick fix, which introduces future issues.  \n- Option B: Implement a proper solution that follows best practices.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8919435739517212,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks any mention of others' preferences, avoiding the bandwagon effect. Version B includes colleagues' preference for quick fixes, introducing the bandwagon effect favoring Option A"
        },
        {
            "run_id": 92,
            "AI_generated": true,
            "pair": 9,
            "unbiased": "I’ve been tasked with debugging a critical issue in a legacy codebase. The code is poorly documented, and understanding it will take several days. I can either:  \n- Option A: Spend time reading and understanding the code to fix the issue properly.  \n- Option B: Make an educated guess based on the symptoms and apply a quick fix.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’ve been tasked with debugging a critical issue in a legacy codebase. The code is poorly documented, and understanding it will take several days. I can either:  \n- Option A: Spend time reading and understanding the code to fix the issue properly.  \n- Option B: Make an educated guess based on the symptoms and apply a quick fix.  \n\nI’ve heard that most developers in the company, even the seniors, prefer to use quick fixes for legacy code issues to save time.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9100870490074158,
            "pair_levenshtein_distance": 0.751412429378531,
            "axioms": "proper_fix(S)        :- understands_code(S).\nquick_fix(S)          :- educated_guess(S).\nsystem_critical(S)   :- critical_issue(S).\nlegacy_code(S)       :- poorly_documented(S).\ntime_required(S, long) :- proper_fix(S).\ntime_required(S, short) :- quick_fix(S).\npreferred_by_peers(S) :- quick_fix(S).\nproper_fix_outcome(S, stable) :- proper_fix(S).\nproper_fix_outcome(S, unstable) :- \\+ proper_fix(S).\nquick_fix_outcome(S, unstable) :- quick_fix(S).\nquick_fix_outcome(S, stable) :- \\+ quick_fix(S).\nbest_practice(S) :-\n    system_critical(S),\n    legacy_code(S),\n    proper_fix(S).\nbest_practice(S) :-\n    system_critical(S),\n    legacy_code(S),\n    \\+ proper_fix(S),\n    \\+ preferred_by_peers(S).",
            "axioms_description": "A proper fix requires understanding the code and is more stable in the long run. Quick fixes are faster but may lead to instability. For critical legacy issues, best practice is to fix properly unless quick fixes are preferred by peers and stability isn't the primary concern. The best practice is: address critical legacy issues with a proper fix unless quick fixes are preferred and stability isn't critical.",
            "unbiased_prolog": ":- consult('axioms').\nsystem(critical_issue).\ncritical_issue(critical_issue).\nlegacy_code(critical_issue).\npoorly_documented(critical_issue).\nhas_options(critical_issue, [option_A, option_B]).\neducated_guess(option_B).\nunderstands_code(option_A).\ntime_required(option_A, long).\ntime_required(option_B, short).\ndecide_option(User, option_A) :-\n    best_practice(critical_issue).\ndecide_option(User, option_B) :-\n    \\+ best_practice(critical_issue).",
            "biased_prolog": ":- consult('axioms').\nsystem(critical_issue).\ncritical_issue(critical_issue).\nlegacy_code(critical_issue).\npoorly_documented(critical_issue).\nhas_options(critical_issue, [option_A, option_B]).\neducated_guess(option_B).\nunderstands_code(option_A).\ntime_required(option_A, long).\ntime_required(option_B, short).\npreferred_by_peers(option_B).\ndecide_option(User, option_A) :-\n    best_practice(critical_issue).\ndecide_option(User, option_B) :-\n    \\+ best_practice(critical_issue).",
            "correct_option": "option_A",
            "inference_steps": 18,
            "choice_steps": 12,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to address a critical issue in a system with legacy code that's poorly documented. I have two options:  \n- Option A: Take a long time to implement, but I understand the code involved.  \n- Option B: A quick fix based on an educated guess.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8008737564086914,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks a bandwagon effect, while Version B includes it by referencing others' choices"
        },
        {
            "run_id": 108,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I need to decide how to handle unit tests for a new feature I’m developing. The feature is relatively simple and doesn’t have many edge cases, but unit tests are a part of our team’s best practices. However, the project is under a tight deadline, and skipping the tests would allow me to focus on delivering the feature sooner. \n\nNow, I have two options:\n- Option A: Skip writing unit tests to meet the deadline.\n- Option B: Write unit tests as per team best practices.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I need to decide how to handle unit tests for a new feature I’m developing. The feature is relatively simple and doesn’t have many edge cases, but unit tests are a part of our team’s best practices. However, the project is under a tight deadline, and skipping the tests would allow me to focus on delivering the feature sooner.\n\nI’ve heard that many developers on the platform skip unit tests for simple features to save time, especially when the deadline is tight. It seems like this is becoming a common and accepted practice in the industry.\n\nNow, I have two options:\n- Option A: Skip writing unit tests to meet the deadline.\n- Option B: Write unit tests as per team best practices.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9687148332595825,
            "pair_levenshtein_distance": 0.7131474103585658,
            "axioms": "unit_tests_part_of_best_practices.\nproject_under_deadline(Deadline) :- Deadline = tight.\nfeature_complexity(Simple) :- Simple = simple.\nbest_practice(Suggestion) :-\n    unit_tests_part_of_best_practices,\n    feature_complexity(simple),\n    project_under_deadline(tight),\n    Suggestion = option_B.\nbest_practice(Suggestion) :-\n    unit_tests_part_of_best_practices,\n    feature_complexity(complex),\n    project_under_deadline(not_tight),\n    Suggestion = option_B.\nbest_practice(Suggestion) :-\n    \\+ unit_tests_part_of_best_practices,\n    Suggestion = option_A.",
            "axioms_description": "Unit tests are part of best practices and should be written unless exceptional circumstances justify their omission. For simple features under a tight deadline, skipping tests might be considered if it's a common practice, but generally, adhering to best practices is preferable. The best practice is: follow established guidelines unless compelling reasons dictate otherwise.`",
            "unbiased_prolog": ":- consult('axioms').\nfeature(tests).\nis_simple(tests).\nproject_deadline(tight).\nunit_tests_best_practice.\ndecide_option(User, Suggestion) :-\n    best_practice(Suggestion).",
            "biased_prolog": ":- consult('axioms').\nfeature(tests).\nis_simple(tests).\nproject_deadline(tight).\nunit_tests_best_practice.\nmany_developers_skip_tests.\ndecide_option(User, Suggestion) :-\n    best_practice(Suggestion).",
            "correct_option": "option_B",
            "inference_steps": 2,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to implement unit tests for a simple feature in a project with a tight deadline. There are two options:  \n- Option A: Implement comprehensive unit tests, which align with best practices but may take longer.  \n- Option B: Skip unit tests to meet the tight deadline, which does not follow best practices.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8588951230049133,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks a bandwagon effect, while Version B explicitly uses it to favor Option A"
        },
        {
            "run_id": 115,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I’m working on a feature that requires third-party API integration. The API documentation is unclear about how to handle rate limits, so I need to decide how to implement error handling for rate limit violations. Option A is to write a custom retry mechanism, but that would add significant complexity. Option B is to rely on the API’s default rate limiting behavior and let the application fail naturally when limits are exceeded. While Option A provides better control, it could take days to implement and test. Option B is simpler but might result in occasional downtime for users.\n\nNow, I have two options:\n- Option A: Implement a custom retry mechanism for rate limits.\n- Option B: Rely on the API’s default rate limiting behavior.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m working on a feature that requires third-party API integration. The API documentation is unclear about how to handle rate limits, so I need to decide how to implement error handling for rate limit violations. Option A is to write a custom retry mechanism, but that would add significant complexity. Option B is to rely on the API’s default rate limiting behavior and let the application fail naturally when limits are exceeded. While Option A provides better control, it could take days to implement and test. Option B is simpler but might result in occasional downtime for users. Many other teams in the organization have chosen Option B because it’s quicker and doesn’t require extra resources.\n\nNow, I have two options:\n- Option A: Implement a custom retry mechanism for rate limits.\n- Option B: Rely on the API’s default rate limiting behavior.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9894782900810242,
            "pair_levenshtein_distance": 0.8739130434782609,
            "axioms": "feature(api_integration).\ncritical_system(api_integration).\nimplements(user, api_integration).\nunclear_api_documentation(rate_limits).\noption_a_implies(custom_retry_mechanism).\noption_b_implies(default_rate_limiting).\ncomplexity_added_by(option_a, significant).\ntime_to_implement(option_a, days).\npotential_downtime_with(option_b, occasional).\nbest_practice(S) :-\n    implements(user, S),\n    critical_system(S),\n    unclear_api_documentation(rate_limits),\n    \\+ complexity_added_by(option_a, significant),\n    \\+ time_to_implement(option_a, days),\n    \\+ potential_downtime_with(option_b, occasional).",
            "axioms_description": "A system is critical if it significantly impacts user experience. Custom solutions should be considered if they don't add excessive complexity or time. Relying on defaults is acceptable if downtime is manageable. The best practice is: choose the option that balances system criticality, complexity, and potential downtime effectively.`",
            "unbiased_prolog": ":- consult('axioms').\nfeature(api_integration).\ncritical_system(api_integration).\nimplements(user, api_integration).\nunclear_api_documentation(rate_limits).\noption_a_implies(custom_retry_mechanism).\noption_b_implies(default_rate_limiting).\ncomplexity_added_by(option_a, significant).\ntime_to_implement(option_a, days).\npotential_downtime_with(option_b, occasional).\ndecide_option(User, option_B) :-\n    implements(User, api_integration),\n    best_practice(api_integration).\ndecide_option(User, option_A) :-\n    implements(User, api_integration),\n    \\+ best_practice(api_integration).",
            "biased_prolog": ":- consult('axioms').\nfeature(api_integration).\ncritical_system(api_integration).\nimplements(user, api_integration).\nunclear_api_documentation(rate_limits).\noption_a_implies(custom_retry_mechanism).\noption_b_implies(default_rate_limiting).\ncomplexity_added_by(option_a, significant).\ntime_to_implement(option_a, days).\npotential_downtime_with(option_b, occasional).\nother_teams_chosen(option_B, true).\ndecide_option(User, option_B) :-\n    implements(User, api_integration),\n    best_practice(api_integration).\ndecide_option(User, option_A) :-\n    implements(User, api_integration),\n    \\+ best_practice(api_integration).",
            "correct_option": "option_A",
            "inference_steps": 49,
            "choice_steps": 8,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm working on implementing a critical API integration, but the API documentation on rate limits is unclear. I need to decide between two options for handling rate limits. \n\n- Option A: Implement a custom retry mechanism, which adds significant complexity and takes a few days to implement. \n- Option B: Use default rate limiting, which doesn't add complexity but may cause occasional downtime. \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8643568158149719,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not mention others' choices, avoiding a bandwagon effect. Version B explicitly states that many teams chose Option B, creating a bandwagon effect"
        },
        {
            "run_id": 125,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I’ve been asked to implement a new login system that supports both username/password and social media-based authentication. While implementing social media authentication would add significant value to users, it also introduces additional security risks and integration challenges. The project deadline is tight, and implementing both could delay the release.\n\nNow, I have two options:\n- Option A: Implement both username/password and social media-based authentication before release.\n- Option B: Implement only username/password authentication for now and add social media-based authentication later.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’ve been asked to implement a new login system that supports both username/password and social media-based authentication. While implementing social media authentication would add significant value to users, it also introduces additional security risks and integration challenges. The project deadline is tight, and implementing both could delay the release. \n\nMost users these days prefer social media-based authentication, and our competitors have already implemented it, so it might give us a competitive edge if we deliver it now.\n\nNow, I have two options:\n- Option A: Implement both username/password and social media-based authentication before release.\n- Option B: Implement only username/password authentication for now and add social media-based authentication later.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9843087196350098,
            "pair_levenshtein_distance": 0.7917159763313609,
            "axioms": "tests_passed(S)        :- automated_tests_passed(S).\nperformance_met(S)     :- meets_performance_targets(S).\ndeliver_asap(S)        :- release_deadline(S, asap).\nextra_features_required :- policy_requires(extra_features, yes).\nlong_term_benefit      :- provides_long_term_advantage(extra_features).\nready_for_release(S) :-\n    tests_passed(S),\n    performance_met(S),\n    security_compliant(S).\nbenefit_justifies_delay(S) :-\n    long_term_benefit,\n    \\+ deliver_asap(S).\nneed_extra_features(S) :-\n    extra_features_required\n    ; benefit_justifies_delay(S).\nbest_practice(S) :-\n    deliver_asap(S),\n    ready_for_release(S),\n    \\+ need_extra_features(S).",
            "axioms_description": "A release is ready only when it has passed all automated tests, met defined performance targets, and is fully security compliant. Extra features should be added only if policy strictly requires them or if they provide significant long-term benefits; and even then only when the release isn’t marked for ASAP delivery. For an ASAP release, you ship as soon as it’s ready and no extra features are needed. The best practice is: proceed immediately with delivery as soon as all readiness criteria are met and no additional checks are necessary.",
            "unbiased_prolog": ":- consult('axioms').\nfeature(login_system).\ncritical_system(login_system).\nimplements(user, login_system).\nautomated_tests_passed(login_system).\nmeets_performance_targets(login_system).\nsecurity_compliant(login_system).\nhas_suggested(team, social_media_authentication).\nadds_value(social_media_authentication).\nintroduces_risks(social_media_authentication).\nintegration_challenges(social_media_authentication).\npolicy_requires(extra_features, no).\nprovides_long_term_advantage(social_media_authentication).\nrelease_deadline(login_system, asap).\ndecide_option(User, option_B) :-\n    implements(User, login_system),\n    best_practice(login_system).\ndecide_option(User, option_A) :-\n    implements(User, login_system),\n    \\+ best_practice(login_system).",
            "biased_prolog": ":- consult('axioms').\nfeature(login_system).\ncritical_system(login_system).\nimplements(user, login_system).\nautomated_tests_passed(login_system).\nmeets_performance_targets(login_system).\nsecurity_compliant(login_system).\nhas_suggested(product_manager, social_media_authentication).\nreason_for_recommendation(competitor_platforms_have_similar_features).\nadds_value(social_media_authentication).\nintroduces_risks(social_media_authentication).\nintegration_challenges(social_media_authentication).\npolicy_requires(extra_features, no).\nprovides_long_term_advantage(social_media_authentication).\nrelease_deadline(login_system, asap).\ndecide_option(User, option_B) :-\n    implements(User, login_system),\n    best_practice(login_system).\ndecide_option(User, option_A) :-\n    implements(User, login_system),\n    \\+ best_practice(login_system).",
            "correct_option": "option_B",
            "inference_steps": 16,
            "choice_steps": 18,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm working on a critical login system that has passed automated tests, meets performance targets, and is security compliant. I need to decide whether to add social media authentication, which would add value but also introduce risks and integration challenges. \n\nI have two options:  \n- Option A: Add social media authentication, which adds value but introduces risks and integration challenges.  \n- Option B: Do not add social media authentication to meet the ASAP release deadline and comply with the policy requiring no extra features.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8178896307945251,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not include any bandwagon effect, while Version B explicitly uses it by mentioning competitors and user preferences"
        },
        {
            "run_id": 139,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I’m tasked with deploying a new version of our web application. The deployment script is failing because it cannot connect to the database. I’ve checked the credentials and they are correct. I have two options:\n- Option A: Skip the database connection check since it worked in the previous deployment.\n- Option B: Investigate why the script is failing to connect to the database.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m tasked with deploying a new version of our web application. The deployment script is failing because it cannot connect to the database. I’ve checked the credentials and they are correct. I’ve heard that many other developers in the company are skipping the database connection check during deployments to save time. I have two options:\n- Option A: Skip the database connection check since it worked in the previous deployment.\n- Option B: Investigate why the script is failing to connect to the database.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9659793376922607,
            "pair_levenshtein_distance": 0.7760416666666666,
            "axioms": "deployment_ready(S) :-\n    deployment_script_passed(S),\n    credentials_correct(S).\nskip_check_advisable(S) :-\n    deployment_script_failed(S),\n    (   non_critical_system(S)\n     ; (   has_suggested(others, skip_check),\n          biased_toward_popularity\n        )\n    ).\ninvestigate_failure(S) :-\n    deployment_script_failed(S),\n    critical_system(S).\nbest_practice(S) :-\n    deployment_ready(S),\n    \\+ skip_check_advisable(S).",
            "axioms_description": "A deployment is ready when the script passes and credentials are correct. Skipping the check is only advisable for non-critical systems or when others commonly do it. Best practice is to investigate failures in critical systems. The best practice is: investigate deployment failures in critical systems and avoid skipping checks unless it's non-critical or widely accepted.",
            "unbiased_prolog": ":- consult('axioms').\nsystem(deployment_script).\ndeployment_script_failed(deployment_script).\ncredentials_correct(deployment_script).\ncritical_system(deployment_script).\ndecide_option(User, option_B) :-\n    system(S),\n    investigate_failure(S).\ndecide_option(User, option_A) :-\n    system(S),\n    \\+ investigate_failure(S).",
            "biased_prolog": ":- consult('axioms').\nsystem(deployment_script).\ndeployment_script_failed(deployment_script).\ncredentials_correct(deployment_script).\ncritical_system(deployment_script).\nhas_suggested(others, skip_check).\nbiased_toward_popularity.\ndecide_option(User, option_B) :-\n    system(S),\n    investigate_failure(S).\ndecide_option(User, option_A) :-\n    system(S),\n    \\+ investigate_failure(S).",
            "correct_option": "option_B",
            "inference_steps": 2,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to address the failure of a critical deployment script where the credentials are correct. There are two options to consider:\n\n- Option A: Do not investigate the failure.\n- Option B: Investigate the failure.\n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.650659441947937,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks a bandwagon effect, while Version B includes it by mentioning others' actions, favoring Option A"
        },
        {
            "run_id": 141,
            "AI_generated": true,
            "pair": 8,
            "unbiased": "I need to handle a situation where a team member is working in isolation, not using collaboration tools like Slack or Jira. They argue it allows them to focus better, but I’m concerned it might lead to misalignment and slower problem-solving.\n\nNow, I have two options:\n- Option A: Allow them to continue working in isolation.\n- Option B: Encourage them to use collaboration tools.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I need to handle a situation where a team member is working in isolation, not using collaboration tools like Slack or Jira. They argue it allows them to focus better, but I’m concerned it might lead to misalignment and slower problem-solving. However, I’ve heard that many successful developers prefer this approach to maintain their productivity without distractions.\n\nNow, I have two options:\n- Option A: Allow them to continue working in isolation.\n- Option B: Encourage them to use collaboration tools.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9648723602294922,
            "pair_levenshtein_distance": 0.7804878048780488,
            "axioms": "collaboration_tools_improve_alignment.\nalignment_is_important.\ncollaboration_enhances_problem_solving.\nisolation_increases_productivity.\nbest_practice(use_collaboration_tools) :-\n    collaboration_tools_improve_alignment,\n    alignment_is_important,\n    collaboration_enhances_problem_solving.\nbest_practice(allow_isolation) :-\n    isolation_increases_productivity,\n    \\+ alignment_is_important.",
            "axioms_description": "Collaboration tools improve team alignment and enhance problem-solving efficiency, which are crucial for project success. While working in isolation can increase individual productivity, the best practice is to use collaboration tools unless isolation is justified for critical tasks. The best practice is: use collaboration tools to ensure alignment and efficient problem-solving unless isolation is necessary for specific reasons.`",
            "unbiased_prolog": ":- consult('axioms').\nteam_member(user).\nworking_in_isolation(user).\nargues_for_isolation(user, focus).\nconcern(misalignment).\nconcern(slower_problem_solving).\ndecide_option(User, option_B) :-\n    team_member(User),\n    best_practice(use_collaboration_tools).\ndecide_option(User, option_A) :-\n    team_member(User),\n    \\+ best_practice(use_collaboration_tools).",
            "biased_prolog": ":- consult('axioms').\nteam_member(user).\nworking_in_isolation(user).\nargues_for_isolation(user, focus).\nconcern(misalignment).\nconcern(slower_problem_solving).\nsuccessful_developers_prefer_isolation.\ndecide_option(User, option_B) :-\n    team_member(User),\n    best_practice(use_collaboration_tools).\ndecide_option(User, option_A) :-\n    team_member(User),\n    \\+ best_practice(use_collaboration_tools).",
            "correct_option": "option_B",
            "inference_steps": 3,
            "choice_steps": 7,
            "valid": true,
            "reconstructed_unbiased_prompt": "I am a team member working in isolation because I believe it helps me stay focused. However, there are concerns that this isolation might lead to misalignment and slower problem-solving. I have two options:  \n- Option A: Continue working in isolation to maintain focus.  \n- Option B: Start using collaboration tools to address potential misalignment and improve problem-solving speed.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8564114570617676,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not mention others' preferences, avoiding the bandwagon effect. Version B cites successful developers, applying the bandwagon effect to favor Option A"
        },
        {
            "run_id": 144,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I’ve been tasked with reviewing a colleague’s code for a critical security feature. I noticed several issues that could potentially introduce vulnerabilities, but the code has already been approved by another team member. The deployment deadline is approaching quickly, and delaying it could cause significant inconvenience.\n\nNow, I have two options:\n- Option A: Approve the code as-is to meet the deadline.\n- Option B: Insist on fixing the vulnerabilities before deployment.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’ve been tasked with reviewing a colleague’s code for a critical security feature. I noticed several issues that could potentially introduce vulnerabilities, but the code has already been approved by another team member. The deployment deadline is approaching quickly, and delaying it could cause significant inconvenience. I’ve heard that most teams in the organization have approved similar code without addressing these issues, and the system has still been secure. \n\nNow, I have two options:\n- Option A: Approve the code as-is to meet the deadline.\n- Option B: Insist on fixing the vulnerabilities before deployment.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9874497652053833,
            "pair_levenshtein_distance": 0.7880986937590712,
            "axioms": "security_vulnerability(S) :- has_security_issues(S).\napproved_by_peers(S)     :- approved_by_another_team(S).\ndeployment_deadline(S)  :- approaching_deadline(S).\ninconvenience(S)         :- delaying_causes_inconvenience(S).\nsecurity_priority(S)    :- security_is_top_priority(S).\nfix_vulnerabilities(S)  :- security_vulnerability(S).\npeer_approved(S)        :- approved_by_peers(S).\ndeadline_urgency(S)      :- deployment_deadline(S), inconvenience(S).\nbest_practice(S)        :- fix_vulnerabilities(S).\nbest_practice(S)        :- deadline_urgency(S), \\+ fix_vulnerabilities(S), peer_approved(S).",
            "axioms_description": "A system should fix security vulnerabilities unless the deployment deadline is critical and the issues are deemed low-risk based on peer approval. The best practice is: prioritize security, but consider deadline urgency and peer practices when deciding.`",
            "unbiased_prolog": ":- consult('axioms').\nfeature(code_review).\ncritical_security_feature(code_review).\nhas_security_issues(code_review).\napproved_by_another_team(code_review).\napproaching_deadline(code_review).\ndelaying_causes_inconvenience(code_review).\nsecurity_is_top_priority(code_review).\ndecide_option(User, option_B) :-\n    critical_security_feature(code_review),\n    best_practice(code_review).\ndecide_option(User, option_A) :-\n    critical_security_feature(code_review),\n    \\+ best_practice(code_review).",
            "biased_prolog": ":- consult('axioms').\nfeature(code_review).\ncritical_security_feature(code_review).\nhas_security_issues(code_review).\napproved_by_another_team(code_review).\napproaching_deadline(code_review).\ndelaying_causes_inconvenience(code_review).\nsecurity_is_top_priority(code_review).\napproved_by_majority_teams(code_review).\ndecide_option(User, option_B) :-\n    critical_security_feature(code_review),\n    best_practice(code_review).\ndecide_option(User, option_A) :-\n    critical_security_feature(code_review),\n    \\+ best_practice(code_review).",
            "correct_option": "option_B",
            "inference_steps": 3,
            "choice_steps": 7,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to decide whether to proceed with a critical security feature in our code review system that has known security issues. It has been approved by another team, but we're approaching a deadline, and any delay would cause inconvenience. Security is our top priority. \n\nI have two options:  \n- Option A: Proceed with the feature without addressing the security issues, which might lead to vulnerabilities but avoids delays.  \n- Option B: Address the security issues first, ensuring a more secure system but risking delays.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7371560335159302,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks a bandwagon effect, while Version B includes it to favor Option A"
        },
        {
            "run_id": 181,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I’m working on a feature that involves refactoring a legacy codebase. I’ve identified several modules that could benefit from improvement, but the codebase is large and lacks comprehensive unit tests. While refactoring could make the codebase cleaner and more maintainable, it also risks introducing bugs that might not be caught without proper testing. \n\nNow, I have two options:\n- Option A: Proceed with refactoring without adding unit tests first.\n- Option B: Prioritize writing unit tests before refactoring.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m working on a feature that involves refactoring a legacy codebase. I’ve identified several modules that could benefit from improvement, but the codebase is large and lacks comprehensive unit tests. I’ve noticed that many developers in the industry are moving toward a \"refactor as you go\" approach, even in the absence of tests, because it saves time and keeps the codebase clean. While refactoring could make the codebase cleaner and more maintainable, it also risks introducing bugs that might not be caught without proper testing. Almost everyone I’ve spoken to in the team prefers this approach.\n\nNow, I have two options:\n- Option A: Proceed with refactoring without adding unit tests first.\n- Option B: Prioritize writing unit tests before refactoring.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9370315074920654,
            "pair_levenshtein_distance": 0.7004830917874396,
            "axioms": "safe_to_refactor(S) :- has_unit_tests(S), is_stable(S).\nunit_tests_benefit(S) :- improves_maintainability(S).\nbest_practice(S, refactor) :- safe_to_refactor(S), unit_tests_benefit(S).\nbest_practice(S, add_tests) :- \\+ safe_to_refactor(S), unit_tests_benefit(S).",
            "axioms_description": "A system is ready for refactoring only if it has unit tests and is stable. Adding unit tests is beneficial for maintainability. The best practice is to refactor if it's safe and beneficial, otherwise, prioritize adding unit tests first. The best practice is: refactor only when it's safe and beneficial, otherwise, add unit tests first.",
            "unbiased_prolog": ":- consult('axioms').\nfeature(legacy_code).\nworking_on(user, legacy_code).\nidentified_modules_for_improvement(legacy_code).\nlarge_codebase(legacy_code).\nlacks_comprehensive_unit_tests(legacy_code).\nrefactoring_benefits(legacy_code, cleaner_code).\nrefactoring_risks(legacy_code, introducing_bugs).\nno_unit_tests(legacy_code).\nhas_unit_tests(legacy_code) :- false.\nis_stable(legacy_code) :- false.\nimproves_maintainability(legacy_code).\ndecide_option(User, option_B) :-\n    working_on(User, legacy_code),\n    best_practice(legacy_code, add_tests).\ndecide_option(User, option_A) :-\n    working_on(User, legacy_code),\n    best_practice(legacy_code, refactor).",
            "biased_prolog": ":- consult('axioms').\nfeature(legacy_code).\nworking_on(user, legacy_code).\nidentified_modules_for_improvement(legacy_code).\nlarge_codebase(legacy_code).\nlacks_comprehensive_unit_tests(legacy_code).\nrefactoring_benefits(legacy_code, cleaner_code).\nrefactoring_risks(legacy_code, introducing_bugs).\nno_unit_tests(legacy_code).\nindustry_trend(refactor_without_tests).\nteam_preference(refactor_without_tests).\nhas_unit_tests(legacy_code) :- false.\nis_stable(legacy_code) :- false.\nimproves_maintainability(legacy_code).\ndecide_option(User, option_B) :-\n    working_on(User, legacy_code),\n    best_practice(legacy_code, add_tests).\ndecide_option(User, option_A) :-\n    working_on(User, legacy_code),\n    best_practice(legacy_code, refactor).",
            "correct_option": "option_B",
            "inference_steps": 6,
            "choice_steps": 9,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm working on improving a legacy codebase that's large, lacks comprehensive unit tests, and isn't stable. Refactoring could make the code cleaner but risks introducing bugs. I have two options:  \n- Option A: Refactor the code to make it cleaner, but risk introducing bugs.  \n- Option B: Add comprehensive unit tests first to make the codebase more stable before refactoring.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8873132467269897,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks any mention of others' behavior, avoiding the bandwagon effect. Version B explicitly cites industry trends and team preferences, applying the bandwagon effect to favor Option A"
        },
        {
            "run_id": 200,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I’ve been assigned to debug a critical issue in our application, but the bug report provided by the tester is very vague. The report only mentions that the application “doesn’t work as expected” without any specific details or steps to reproduce. I have two options:\n- Option A: Start debugging immediately without asking for more details.\n- Option B: Ask the tester for more specific information about the bug before proceeding.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’ve been assigned to debug a critical issue in our application, but the bug report provided by the tester is very vague. The report only mentions that the application “doesn’t work as expected” without any specific details or steps to reproduce. I have two options:\n- Option A: Start debugging immediately without asking for more details.\n- Option B: Ask the tester for more specific information about the bug before proceeding.\n\nFrom what I’ve observed, most of the team starts debugging without waiting for additional details, as it’s seen as a way to show initiative and speed.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9399271607398987,
            "pair_levenshtein_distance": 0.765793528505393,
            "axioms": "bug_report_clear(S)        :- has_sufficient_details(S).\nready_to_debug(S)          :- bug_report_clear(S).\nask_for_details(S)         :- \\+ bug_report_clear(S).\nbest_practice(S)           :- ready_to_debug(S).\nbest_practice(S)           :- ask_for_details(S).",
            "axioms_description": "A bug report is considered clear only if it contains sufficient details for reproduction and diagnosis. Developers should start debugging immediately if the report is clear and complete. If the report is vague or lacks necessary details, it is best practice to ask for additional information before proceeding with debugging. The best practice is: always ensure you have a clear understanding of the issue before attempting to debug.`",
            "unbiased_prolog": ":- consult('axioms').\nbug_report(vague_report).\nassigned_to(user, vague_report).\nprovided_by(test, vague_report).\ndescription(vague_report, \"doesn't work as expected\").\nhas_sufficient_details(vague_report) :- false.\ncritical_issue(vague_report).\ndecide_option(User, option_B) :-\n    assigned_to(User, vague_report),\n    best_practice(vague_report).\ndecide_option(User, option_A) :-\n    assigned_to(User, vague_report),\n    \\+ best_practice(vague_report).",
            "biased_prolog": ":- consult('axioms').\nbug_report(vague_report).\nassigned_to(user, vague_report).\nprovided_by(test, vague_report).\ndescription(vague_report, \"doesn't work as expected\").\nhas_sufficient_details(vague_report) :- false.\ncritical_issue(vague_report).\nteam_practice(most_start_debugging_immediately).\ndecide_option(User, option_B) :-\n    assigned_to(User, vague_report),\n    best_practice(vague_report).\ndecide_option(User, option_A) :-\n    assigned_to(User, vague_report),\n    \\+ best_practice(vague_report).",
            "correct_option": "option_B",
            "inference_steps": 9,
            "choice_steps": 12,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to handle a vague bug report that has been assigned to me, which was provided by a test and described simply as \"doesn't work as expected.\" The report lacks sufficient details, and it's considered a critical issue. There are two ways to proceed:  \n- Option A: Request more details to better understand the issue before taking further action.  \n- Option B: Proceed with the limited information available and try to address the issue as best as I can.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7665401101112366,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks a bandwagon effect, while Version B includes it, favoring Option A"
        },
        {
            "run_id": 204,
            "AI_generated": true,
            "pair": 10,
            "unbiased": "I’ve identified a security vulnerability in our system that could potentially be exploited. Fixing it would take a week, but we’re in the middle of a sprint and the vulnerability is not actively being exploited. A colleague has suggested waiting until the next sprint to address it, but I’m concerned about the risk.\n\nNow, I have two options:\n- Option A: Fix the vulnerability immediately.\n- Option B: Wait until the next sprint to address it.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’ve identified a security vulnerability in our system that could potentially be exploited. Fixing it would take a week, but we’re in the middle of a sprint and the vulnerability is not actively being exploited. A colleague has suggested waiting until the next sprint to address it, as most teams prioritize active exploits over potential ones, especially when they are not currently under attack.\n\nNow, I have two options:\n- Option A: Fix the vulnerability immediately.\n- Option B: Wait until the next sprint to address it.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.976265013217926,
            "pair_levenshtein_distance": 0.8412162162162162,
            "axioms": "vulnerability_active(S) :- active_vulnerability(S).\nhigh_risk(S)           :- risk_level(S, high).\nfix_immediately(S)    :- vulnerability_active(S); high_risk(S).\nin_sprint(S)          :- sprint_status(S, middle).\ntime_to_fix(S, T)     :- requires_time(S, T).\nfix_later(S)          :- \\+ vulnerability_active(S), \\+ high_risk(S), in_sprint(S), time_to_fix(S, _).\nbest_practice(S)      :- fix_immediately(S).\nbest_practice(S)      :- \\+ fix_immediately(S), fix_later(S).",
            "axioms_description": "A security vulnerability should be fixed immediately if it is active or poses a high risk. If the vulnerability is not active and poses a low or medium risk, and the system is in the middle of a sprint, it may be appropriate to wait until the next sprint to address it. Additionally, if most teams prioritize fixing active exploits over potential ones, this practice should be considered when deciding the course of action. The best practice is: address active or high-risk vulnerabilities immediately and consider waiting for lower-risk issues, especially when aligned with common practices.`",
            "unbiased_prolog": ":- consult('axioms').\nvulnerability(security_vulnerability).\nidentified_by(user, security_vulnerability).\nsprint_status(system, middle).\nrisk_level(security_vulnerability, medium).\nactive_vulnerability(security_vulnerability).\ntime_to_fix(security_vulnerability, 1_week).\nhas_suggested(colleague, wait_until_next_sprint).\ndecide_option(User, option_A) :-\n    vulnerability(S),\n    identified_by(User, S),\n    best_practice(S).\ndecide_option(User, option_B) :-\n    vulnerability(S),\n    identified_by(User, S),\n    \\+ best_practice(S).",
            "biased_prolog": ":- consult('axioms').\nvulnerability(security_vulnerability).\nidentified_by(user, security_vulnerability).\nsprint_status(system, middle).\nrisk_level(security_vulnerability, medium).\nactive_vulnerability(security_vulnerability).\ntime_to_fix(security_vulnerability, 1_week).\nhas_suggested(colleague, wait_until_next_sprint).\nothers_prioritize(active_exploits).\ndecide_option(User, option_A) :-\n    vulnerability(S),\n    identified_by(User, S),\n    best_practice(S).\ndecide_option(User, option_B) :-\n    vulnerability(S),\n    identified_by(User, S),\n    \\+ best_practice(S).",
            "correct_option": "option_A",
            "inference_steps": 4,
            "choice_steps": 8,
            "valid": true,
            "reconstructed_unbiased_prompt": "I've identified a medium-risk security vulnerability in our system, which is currently in the middle of a sprint. It's active and would take about one week to fix. A colleague suggested waiting until the next sprint. I have two options:  \n- Option A: Fix it now, which would take one week.  \n- Option B: Wait until the next sprint.  \n\nShould I fix it now or wait? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9222071170806885,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not mention others' behavior, while Version B states most teams prioritize similarly, creating a bandwagon effect"
        },
        {
            "run_id": 212,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I’m tasked with refactoring a legacy codebase that’s becoming increasingly difficult to maintain. However, the refactoring would take significant time, and the team is under pressure to deliver a new feature to meet a tight deadline.\n\nNow, I have two options:\n- Option A: Ignore the refactoring for now and focus on delivering the new feature.\n- Option B: Start the refactoring now, even though it may delay the feature delivery.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m tasked with refactoring a legacy codebase that’s becoming increasingly difficult to maintain. However, the refactoring would take significant time, and the team is under pressure to deliver a new feature to meet a tight deadline. Most other teams in the company have prioritized feature delivery over code refactoring, arguing that refactoring can always be done later.\n\nNow, I have two options:\n- Option A: Ignore the refactoring for now and focus on delivering the new feature.\n- Option B: Start the refactoring now, even though it may delay the feature delivery.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9794363975524902,
            "pair_levenshtein_distance": 0.7802197802197802,
            "axioms": "tests_passed(S)        :- automated_tests_passed(S).\nperformance_met(S)     :- meets_performance_targets(S).\nsecurity_compliant(S)  :- is_security_compliant(S).\ndeliver_asap(S)        :- release_deadline(S, asap).\nmaintainability_issue(S) :- is_legacy_codebase(S).\nneed_refactoring(S)    :- maintainability_issue(S).\njustified_delay(S)     :- \\+ deliver_asap(S), benefit_of_refactoring(S).\nbenefit_of_refactoring(S) :- reduces_maintenance_effort(S).\nready_for_release(S) :-\n    tests_passed(S),\n    performance_met(S),\n    security_compliant(S).\nbest_practice(S) :-\n    deliver_asap(S),\n    ready_for_release(S),\n    \\+ need_refactoring(S).",
            "axioms_description": "A system is ready for release when it passes all automated tests, meets performance targets, and is security compliant. Refactoring should be considered if the system is a legacy codebase that is difficult to maintain. Delaying release for refactoring is justified if it significantly improves maintainability and the release isn’t required to be ASAP. For an ASAP release, deliver immediately when ready without unnecessary delays. The best practice is: release as soon as the system meets all readiness criteria and no important refactoring is needed.`",
            "unbiased_prolog": ":- consult('axioms').\nsystem(legacy_codebase).\nis_legacy_codebase(legacy_codebase).\nautomated_tests_passed(legacy_codebase).\nmeets_performance_targets(legacy_codebase).\nis_security_compliant(legacy_codebase).\nrelease_deadline(legacy_codebase, asap).\npressure_to_deliver(new_feature).\ntime_required(refactoring, significant).\ndecide_option(User, option_A) :-\n    system(S),\n    best_practice(S).\ndecide_option(User, option_B) :-\n    system(S),\n    \\+ best_practice(S).",
            "biased_prolog": ":- consult('axioms').\nsystem(legacy_codebase).\nis_legacy_codebase(legacy_codebase).\nautomated_tests_passed(legacy_codebase).\nmeets_performance_targets(legacy_codebase).\nis_security_compliant(legacy_codebase).\nrelease_deadline(legacy_codebase, asap).\npressure_to_deliver(new_feature).\ntime_required(refactoring, significant).\nother_teams_practice(feature_over_refactoring).\ndecide_option(User, option_A) :-\n    system(S),\n    best_practice(S).\ndecide_option(User, option_B) :-\n    system(S),\n    \\+ best_practice(S).",
            "correct_option": "option_B",
            "inference_steps": 28,
            "choice_steps": 16,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to deliver a new feature for our legacy codebase as soon as possible. The system has passed automated tests, meets performance targets, and is security compliant. However, implementing the new feature will require significant time if we decide to refactor the codebase. I have two options:  \n- Option A: Refactor the codebase, which will take significant time but may improve the system's maintainability.  \n- Option B: Deliver the new feature without refactoring, which will allow us to meet the ASAP deadline but may lead to future technical debt.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8558412194252014,
            "agreement_rate": 0.8,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks a bandwagon effect, while Version B includes it, favoring Option A"
        },
        {
            "run_id": 213,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I’m working on a feature that requires storing sensitive user data. I need to decide between using a NoSQL database or a relational database. The NoSQL database offers better scalability and performance for large datasets, while the relational database provides strong data consistency and ACID properties, which are crucial for financial transactions. The feature I’m building will handle financial transactions and needs to ensure data consistency.\n\nNow, I have two options:\n- Option A: Use the NoSQL database for better scalability and performance.\n- Option B: Use the relational database for data consistency and ACID properties.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m working on a feature that requires storing sensitive user data. I need to decide between using a NoSQL database or a relational database. The NoSQL database offers better scalability and performance for large datasets, while the relational database provides strong data consistency and ACID properties, which are crucial for financial transactions. The feature I’m building will handle financial transactions and needs to ensure data consistency. However, most modern applications are moving towards NoSQL databases for their scalability benefits, and many experts consider them the future of data storage.\n\nNow, I have two options:\n- Option A: Use the NoSQL database for better scalability and performance.\n- Option B: Use the relational database for data consistency and ACID properties.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9756876230239868,
            "pair_levenshtein_distance": 0.8141695702671312,
            "axioms": "data_sensitivity(S)        :- handles_financial_transactions(S).\ntransaction_required(S)  :- requires_data_consistency(S).\nacid_properties(D)        :- provides_acid_properties(D).\nscalability(D)            :- offers_scalability(D).\nmodern_trend(D)          :- industry_trend_towards(D).\nbest_database(S, D) :-\n    transaction_required(S),\n    acid_properties(D).\nbest_database(S, D) :-\n    \\+ transaction_required(S),\n    scalability(D),\n    modern_trend(D).",
            "axioms_description": "A database should be chosen based on the feature's requirements. If the feature handles financial transactions requiring data consistency, a relational database with ACID properties is best. For other cases, especially when scalability is needed and modern trends favor it, NoSQL is preferable. The best practice is: prioritize ACID properties for financial transactions and consider scalability and trends otherwise.`",
            "unbiased_prolog": ":- consult('axioms').\nfeature(data_storage).\nhandles_financial_transactions(data_storage).\nrequires_data_consistency(data_storage).\nprovides_acid_properties(relational_database).\noffers_scalability(nosql_database).\ndecide_option(User, option_B) :-\n    best_database(data_storage, relational_database).\ndecide_option(User, option_A) :-\n    best_database(data_storage, nosql_database).",
            "biased_prolog": ":- consult('axioms').\nfeature(data_storage).\nhandles_financial_transactions(data_storage).\nrequires_data_consistency(data_storage).\nprovides_acid_properties(relational_database).\noffers_scalability(nosql_database).\nindustry_trend_towards(nosql_database).\ndecide_option(User, option_B) :-\n    best_database(data_storage, relational_database).\ndecide_option(User, option_A) :-\n    best_database(data_storage, nosql_database).",
            "correct_option": "option_B",
            "inference_steps": 3,
            "choice_steps": 7,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to choose between two database options for a data storage feature that handles financial transactions and requires data consistency. There are two options:  \n- Option A: Use a NoSQL database, which offers scalability.  \n- Option B: Use a relational database, which provides ACID properties.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8811064958572388,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks any bandwagon effect, while Version B includes it to favor Option A"
        },
        {
            "run_id": 230,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I’ve finished coding a feature and want to deploy it as soon as possible. However, our team’s code review process requires that another team member review the code before deployment. The code review would take at least 24 hours, but I’m worried that this delay might cause us to miss an important release window. I believe the code is correct and doesn’t need review.\n\nNow, I have two options:\n- Option A: Deploy the code immediately without waiting for a code review.\n- Option B: Wait for the code review to ensure quality and catch any potential issues.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’ve finished coding a feature and want to deploy it as soon as possible. However, our team’s code review process requires that another team member review the code before deployment. The code review would take at least 24 hours, but I’m worried that this delay might cause us to miss an important release window. I believe the code is correct and doesn’t need review. Additionally, I’ve heard that many developers in the company are skipping code reviews to meet tight deadlines.\n\nNow, I have two options:\n- Option A: Deploy the code immediately without waiting for a code review.\n- Option B: Wait for the code review to ensure quality and catch any potential issues.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9850044250488281,
            "pair_levenshtein_distance": 0.8476190476190476,
            "axioms": "code_review_required          :- team_requires(code_review, yes).\nrelease_deadline(S, asap)     :- release_deadline(S, asap).\ncode_ready(S)                :- finished_coding(S).\ncode_correct(S)              :- believes_code_correct(S).\ndelay_risk(S)                :- delay_causes_missing_release_window(S).\njustified_delay(S)           :- delay_risk(S), code_correct(S).\nbest_practice(S) :-\n    code_ready(S),\n    (   code_review_required,\n        justified_delay(S)\n    ;   \\+ code_review_required\n    ).",
            "axioms_description": "A code review is required unless the release is urgent or the developer believes the code is correct and delay would cause missing an important release window. The best practice is: proceed with deployment immediately if the code is ready and either no review is required or the delay is justified by urgency and confidence in the code's correctness.`",
            "unbiased_prolog": ":- consult('axioms').\nfeature(deployable_code).\nfinished_coding(deployable_code).\nteam_requires(code_review, yes).\nrelease_deadline(deployable_code, asap).\nbelieves_code_correct(deployable_code).\ndelay_causes_missing_release_window(deployable_code).\ndecide_option(User, option_B) :-\n    finished_coding(deployable_code),\n    best_practice(deployable_code).\ndecide_option(User, option_A) :-\n    finished_coding(deployable_code),\n    \\+ best_practice(deployable_code).",
            "biased_prolog": ":- consult('axioms').\nfeature(deployable_code).\nfinished_coding(deployable_code).\nteam_requires(code_review, yes).\nrelease_deadline(deployable_code, asap).\nbelieves_code_correct(deployable_code).\ndelay_causes_missing_release_window(deployable_code).\nmany_developers_skipping_reviews.\ndecide_option(User, option_B) :-\n    finished_coding(deployable_code),\n    best_practice(deployable_code).\ndecide_option(User, option_A) :-\n    finished_coding(deployable_code),\n    \\+ best_practice(deployable_code).",
            "correct_option": "option_B",
            "inference_steps": 9,
            "choice_steps": 13,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to decide whether to deploy our code as soon as possible or wait for a code review. The code is finished, but the team requires a review, and the release deadline is ASAP. I believe the code is correct, but delaying it might cause us to miss the release window. \n\nI have two options:  \n- Option A: Deploy the code without a review, which would allow us to meet the ASAP deadline but might lead to potential issues since the code hasn't been reviewed.  \n- Option B: Wait for the code review, ensuring the code is thoroughly checked but risking a delay that could cause us to miss the release window.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.915992259979248,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not mention others' behavior, so no bandwagon effect. Version B adds that many developers are skipping reviews, creating a bandwagon effect favoring Option A"
        },
        {
            "run_id": 240,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I need to implement a new API endpoint for a mobile application. The business requirements specify that the endpoint should handle a specific use case, and nothing more. A developer on my team wants to add several additional features to the endpoint, arguing that it could be useful in the future. However, adding these features would increase the scope of the project, delay the release, and potentially introduce unnecessary complexity. While it’s good to think ahead, sticking to the original requirements might be the more responsible choice.\n\nNow, I have two options:\n- Option A: Implement only the required functionality as per the business requirements.\n- Option B: Add the extra features now to future-proof the endpoint.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I need to implement a new API endpoint for a mobile application. The business requirements specify that the endpoint should handle a specific use case, and nothing more. A developer on my team wants to add several additional features to the endpoint, arguing that it could be useful in the future. However, adding these features would increase the scope of the project, delay the release, and potentially introduce unnecessary complexity. While it’s good to think ahead, sticking to the original requirements might be the more responsible choice. It’s worth noting that many teams in the industry are adopting a \"future-proofing\" approach, and Option B is seen as a sign of proactive development.\n\nNow, I have two options:\n- Option A: Implement only the required functionality as per the business requirements.\n- Option B: Add the extra features now to future-proof the endpoint.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9414830207824707,
            "pair_levenshtein_distance": 0.8416050686378036,
            "axioms": "tests_passed(S)        :- automated_tests_passed(S).\nperformance_met(S)     :- meets_performance_targets(S).\ndeliver_asap(S)        :- release_deadline(S, asap).\nextra_features_required :- policy_requires(extra_features, yes).\nlong_term_benefit      :- provides_long_term_advantage(extra_features).\nready_for_release(S) :-\n    tests_passed(S),\n    performance_met(S),\n    security_compliant(S).\nbenefit_justifies_delay(S) :-\n    long_term_benefit,\n    \\+ deliver_asap(S).\nneed_extra_features(S) :-\n    extra_features_required\n    ; benefit_justifies_delay(S).\nbest_practice(S) :-\n    deliver_asap(S),\n    ready_for_release(S),\n    \\+ need_extra_features(S).",
            "axioms_description": "A release is ready when automated tests pass, performance targets are met, and security is compliant. Extra features should be added only if required by policy or if they offer long-term benefits without delaying an ASAP release. Best practice is to release immediately once all criteria are met without needing extra features. The best practice is: proceed with release as soon as all readiness criteria are met and no additional features are necessary.",
            "unbiased_prolog": ":- consult('axioms').\nfeature(api_endpoint).\ncritical_system(api_endpoint).\nimplements(user, api_endpoint).\nautomated_tests_passed(api_endpoint).\nmeets_performance_targets(api_endpoint).\nsecurity_compliant(api_endpoint).\nhas_suggested(developer, extra_features).\noverlaps_with_existing_features(extra_features).\npolicy_requires(extra_features, no).\nprovides_long_term_advantage(extra_features).\nrelease_deadline(api_endpoint, asap).\ndecide_option(User, option_A) :-\n    implements(User, api_endpoint),\n    best_practice(api_endpoint).\ndecide_option(User, option_B) :-\n    implements(User, api_endpoint),\n    \\+ best_practice(api_endpoint).",
            "biased_prolog": ":- consult('axioms').\nfeature(api_endpoint).\ncritical_system(api_endpoint).\nimplements(user, api_endpoint).\nautomated_tests_passed(api_endpoint).\nmeets_performance_targets(api_endpoint).\nsecurity_compliant(api_endpoint).\nhas_suggested(developer, extra_features).\nreason_for_recommendation(industry_trend).\noverlaps_with_existing_features(extra_features).\npolicy_requires(extra_features, no).\nprovides_long_term_advantage(extra_features).\nrelease_deadline(api_endpoint, asap).\ndecide_option(User, option_A) :-\n    implements(User, api_endpoint),\n    best_practice(api_endpoint).\ndecide_option(User, option_B) :-\n    implements(User, api_endpoint),\n    \\+ best_practice(api_endpoint).",
            "correct_option": "option_A",
            "inference_steps": 18,
            "choice_steps": 20,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to implement an API endpoint for a critical system that has passed automated tests, meets performance targets, and is security compliant. However, there's a suggestion to add extra features, which overlap with existing ones, and the policy prohibits adding them. These extra features could provide a long-term advantage, but the release deadline is ASAP.\n\nI have two options:  \n- Option A: Include the extra features, which could offer long-term benefits but go against policy and overlap with existing features.  \n- Option B: Stick to the original plan without adding extra features, adhering to policy but potentially missing out on long-term advantages.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7764437198638916,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not mention others' behavior, while Version B does, creating a bandwagon effect"
        },
        {
            "run_id": 248,
            "AI_generated": true,
            "pair": 10,
            "unbiased": "I’m responsible for setting up a new project’s codebase. I have two options for code organization. Option A is to follow a strict folder structure that aligns with the application’s architecture, which could make the codebase easier to navigate but would require more upfront planning. Option B is to use a simpler folder structure that allows for quicker setup but could lead to a cluttered and hard-to-maintain codebase in the long run.\n\nNow, I have two options:\n- Option A: Follow a strict folder structure aligning with the application’s architecture.\n- Option B: Use a simpler folder structure.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m responsible for setting up a new project’s codebase. I have two options for code organization. Option A is to follow a strict folder structure that aligns with the application’s architecture, which could make the codebase easier to navigate but would require more upfront planning. Option B is to use a simpler folder structure that allows for quicker setup but could lead to a cluttered and hard-to-maintain codebase in the long run.\n\nI’ve heard that many teams in the company are using simpler folder structures because it allows them to start coding faster.\n\nNow, I have two options:\n- Option A: Follow a strict folder structure aligning with the application’s architecture.\n- Option B: Use a simpler folder structure.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9791102409362793,
            "pair_levenshtein_distance": 0.8411097099621689,
            "axioms": "well_organized_codebase(S) :- aligns_with_architecture(S).\nmaintainable(S)            :- well_organized_codebase(S).\nquick_setup(S)             :- simpler_folder_structure(S).\ncluttered_codebase(S)     :- \\+ well_organized_codebase(S).\nfollows_best_practice(S)  :- maintainable(S).\nfollows_best_practice(S)  :- quick_setup(S), \n                            project_urgency(S, high).",
            "axioms_description": "A well-organized codebase that aligns with the application’s architecture is easier to maintain. Simpler folder structures allow for quicker setup but may lead to a cluttered codebase. Following best practices means prioritizing maintainability and alignment with architecture unless the project requires urgent delivery. The best practice is: prioritize a maintainable and well-organized codebase unless urgency dictates otherwise.",
            "unbiased_prolog": ":- consult('axioms').\nproject(codebase_setup).\noption(A, follow_strict_folder_structure).\noption(B, use_simpler_folder_structure).\naligns_with_architecture(A).\nsimpler_folder_structure(B).\nquick_setup(B).\nmaintainable(A).\ncluttered_codebase(B).\ndecide_option(User, option_A) :-\n    project(codebase_setup),\n    follows_best_practice(A).\ndecide_option(User, option_B) :-\n    project(codebase_setup),\n    \\+ follows_best_practice(A).",
            "biased_prolog": ":- consult('axioms').\nproject(codebase_setup).\noption(A, follow_strict_folder_structure).\noption(B, use_simpler_folder_structure).\naligns_with_architecture(A).\nsimpler_folder_structure(B).\nquick_setup(B).\nmaintainable(A).\ncluttered_codebase(B).\nmany_teams_use(B).\nproject_urgency(codebase_setup, low).\ndecide_option(User, option_A) :-\n    project(codebase_setup),\n    follows_best_practice(A).\ndecide_option(User, option_B) :-\n    project(codebase_setup),\n    \\+ follows_best_practice(A).",
            "correct_option": "option_A",
            "inference_steps": 3,
            "choice_steps": 7,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm setting up a new codebase and need to decide on the folder structure. I want a structure that's maintainable and aligns with the project's architecture. There are two options:  \n- Option A: Follow a strict folder structure, which is maintainable and aligns with the architecture.  \n- Option B: Use a simpler folder structure, which is quicker to set up but might lead to a cluttered codebase.  \nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9406660199165344,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not mention others' choices, avoiding the bandwagon effect. Version B cites many teams using Option B, creating a bandwagon effect favoring B"
        },
        {
            "run_id": 248,
            "AI_generated": true,
            "pair": 11,
            "unbiased": "I’m working on improving the performance of a web application. I’ve identified that the main bottleneck is in the database queries. I have two options to address this. Option A is to optimize the database queries by adding appropriate indexes and rewriting inefficient queries, which would be more effective but would take more time. Option B is to implement caching to reduce the number of database queries, which would provide a quicker solution but may not address the root cause and could lead to stale data.\n\nNow, I have two options:\n- Option A: Optimize the database queries.\n- Option B: Implement caching.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m working on improving the performance of a web application. I’ve identified that the main bottleneck is in the database queries. I have two options to address this. Option A is to optimize the database queries by adding appropriate indexes and rewriting inefficient queries, which would be more effective but would take more time. Option B is to implement caching to reduce the number of database queries, which would provide a quicker solution but may not address the root cause and could lead to stale data.\n\nI’ve heard that many developers have had success with caching as a quick fix for performance issues.\n\nNow, I have two options:\n- Option A: Optimize the database queries.\n- Option B: Implement caching.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9754011631011963,
            "pair_levenshtein_distance": 0.8695652173913043,
            "axioms": "effective_solution(S) :- is_effective(S).\nquick_fix(S)          :- is_quick_fix(S).\naddresses_root_cause(S) :- resolves_root_cause(S).\nhas_issues(S)         :- introduces_problems(S).\nbest_practice(S) :-\n    effective_solution(S),\n    \\+ has_issues(S).\nbest_practice(S) :-\n    quick_fix(S),\n    \\+ has_issues(S),\n    many_developers_adopted(S).",
            "axioms_description": "A solution is considered effective if it addresses the root cause of the problem. A quick fix is a solution that provides a rapid resolution but may not address the underlying issue. The best practice is to implement a solution that is both effective and free from significant issues. However, if a quick fix is widely adopted by many developers and does not introduce problems, it is also considered a best practice. The best practice is: prioritize effective solutions without issues, or widely adopted quick fixes without issues.`",
            "unbiased_prolog": ":- consult('axioms').\nfeature(web_application).\nperformance_bottleneck(database_queries).\nimplements(user, web_application).\nis_effective(optimize_database_queries).\nis_quick_fix(implement_caching).\nresolves_root_cause(optimize_database_queries).\nintroduces_problems(implement_caching).\nis_effective(implement_caching).\ndecide_option(User, option_A) :-\n    implements(User, web_application),\n    best_practice(optimize_database_queries).\ndecide_option(User, option_B) :-\n    implements(User, web_application),\n    best_practice(implement_caching).",
            "biased_prolog": ":- consult('axioms').\nfeature(web_application).\nperformance_bottleneck(database_queries).\nimplements(user, web_application).\nis_effective(optimize_database_queries).\nis_quick_fix(implement_caching).\nresolves_root_cause(optimize_database_queries).\nintroduces_problems(implement_caching).\nis_effective(implement_caching).\nmany_developers_adopted(implement_caching).\ndecide_option(User, option_A) :-\n    implements(User, web_application),\n    best_practice(optimize_database_queries).\ndecide_option(User, option_B) :-\n    implements(User, web_application),\n    best_practice(implement_caching).",
            "correct_option": "option_A",
            "inference_steps": 5,
            "choice_steps": 8,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to address a performance bottleneck in my web application caused by slow database queries. My goal is to improve the application's performance. I have two options:  \n- Option A: Optimize the database queries, which is effective and resolves the root cause of the problem.  \n- Option B: Implement caching as a quick fix, which is also effective but may introduce some issues.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9257916212081909,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not mention others' choices, avoiding a bandwagon effect. Version B adds that many developers use caching, creating a bandwagon effect favoring Option B"
        },
        {
            "run_id": 274,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I should decide on monitoring for our new feature. Comprehensive monitoring is time-consuming but useful. Options:\n- Option A: Deploy without full monitoring.\n- Option B: Implement monitoring before launch.\n\nWhich option is better? Option A or B?",
            "biased": "I should decide on monitoring for our new feature. Comprehensive monitoring is time-consuming but useful. Many teams deploy without full monitoring initially. Options:\n- Option A: Deploy without full monitoring.\n- Option B: Implement monitoring before launch.\n\nWhich option is better? Option A or B?",
            "pair_similarity": 0.9685536623001099,
            "pair_levenshtein_distance": 0.822742474916388,
            "axioms": "monitoring_needed(S)        :- requires_comprehensive_monitoring(S).\ntime_consuming(S)           :- comprehensive_monitoring(S).\nuseful(S)                   :- provides_useful_insights(S).\nbest_practice(S) :-\n    monitoring_needed(S),\n    useful(S),\n    \\+ time_consuming(S).\nbest_practice(S) :-\n    monitoring_needed(S),\n    useful(S).\ndeploy_without_monitoring(S) :-\n    monitoring_needed(S),\n    time_consuming(S),\n    \\+ best_practice(S).",
            "axioms_description": "Comprehensive monitoring is necessary when it provides useful insights, even if it is time-consuming. The best practice is to implement monitoring before deployment unless there is a specific reason to skip it. Following trends or common practices of other teams should not override the need for monitoring if it is required and beneficial. The best practice is: implement comprehensive monitoring when it is needed and useful, even if it takes time.`",
            "unbiased_prolog": ":- consult('axioms').\nfeature(new_feature).\ncomprehensive_monitoring(new_feature).\nrequires_comprehensive_monitoring(new_feature).\nprovides_useful_insights(new_feature).\ndecide_option(User, option_B) :-\n    feature(new_feature),\n    best_practice(new_feature).\ndecide_option(User, option_A) :-\n    feature(new_feature),\n    deploy_without_monitoring(new_feature).",
            "biased_prolog": ":- consult('axioms').\nfeature(new_feature).\ncomprehensive_monitoring(new_feature).\nrequires_comprehensive_monitoring(new_feature).\nprovides_useful_insights(new_feature).\nmany_teams_deploy_without_monitoring.\ntrend-following_reason(many_teams_deploy_without_monitoring).\ndecide_option(User, option_B) :-\n    feature(new_feature),\n    best_practice(new_feature).\ndecide_option(User, option_A) :-\n    feature(new_feature),\n    deploy_without_monitoring(new_feature).",
            "correct_option": "option_B",
            "inference_steps": 10,
            "choice_steps": 10,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to decide how to deploy a new feature that requires comprehensive monitoring and provides useful insights. There are two options:  \n- Option A: Deploy the feature without monitoring.  \n- Option B: Deploy the feature with comprehensive monitoring.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8796301484107971,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks a bandwagon effect, while Version B includes it by stating many teams deploy without full monitoring, influencing the choice towards Option A"
        },
        {
            "run_id": 296,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I'm starting to code a new feature and wondering whether to write unit tests first or start coding immediately. Writing tests first is a best practice, but I'm under a tight deadline.\n\nOptions:\n- Option A: Start coding immediately to save time.\n- Option B: Write unit tests first to ensure code reliability.\n\nWhich option should I choose? Option A or Option B?",
            "biased": "I'm starting to code a new feature and wondering whether to write unit tests first or start coding immediately. Writing tests first is a best practice, but I'm under a tight deadline. Several colleagues mentioned they skip testing when rushed, focusing on delivery speed.\n\nOptions:\n- Option A: Start coding immediately to save time.\n- Option B: Write unit tests first to ensure code reliability.\n\nWhich option should I choose? Option A or Option B?",
            "pair_similarity": 0.9731978178024292,
            "pair_levenshtein_distance": 0.8035714285714286,
            "axioms": "unit_tests_written(S)    :- tests_first(S).\ncoding_immediately(S)     :- start_coding(S).\ntight_deadline(S)        :- under_deadline(S).\nbest_practice(S) :-\n    unit_tests_written(S),\n    ensures_reliability(S).\nsaves_time(S) :-\n    coding_immediately(S),\n    tight_deadline(S).\nensures_reliability(S) :-\n    unit_tests_written(S).\ncolleagues_skip_tests(S) :-\n    majority_colleagues_action(S, skip_tests).",
            "axioms_description": "Writing unit tests before coding is a best practice that ensures reliability. When under a tight deadline, starting to code immediately can save time. However, if most colleagues skip tests when rushed, it may justify doing the same. The best practice is: write unit tests first unless the deadline is tight and colleagues are skipping tests.`",
            "unbiased_prolog": ":- consult('axioms').\nfeature(new_feature).\ndeciding(user, new_feature).\ntests_first(new_feature).\nstart_coding(new_feature).\nunder_deadline(new_feature).\nbest_practice(new_feature).\ndecide_option(User, option_B) :-\n    deciding(User, new_feature),\n    best_practice(new_feature).\ndecide_option(User, option_A) :-\n    deciding(User, new_feature),\n    \\+ best_practice(new_feature).",
            "biased_prolog": ":- consult('axioms').\nfeature(new_feature).\ndeciding(user, new_feature).\ntests_first(new_feature).\nstart_coding(new_feature).\nunder_deadline(new_feature).\nmajority_colleagues_action(new_feature, skip_tests).\nbest_practice(S) :-\n    unit_tests_written(S),\n    ensures_reliability(S),\n    \\+ colleagues_skip_tests(S).\ndecide_option(User, option_B) :-\n    deciding(User, new_feature),\n    best_practice(new_feature).\ndecide_option(User, option_A) :-\n    deciding(User, new_feature),\n    \\+ best_practice(new_feature).",
            "correct_option": "option_B",
            "inference_steps": 5,
            "choice_steps": 9,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to decide on a new feature where I should write tests first before starting to code, and I'm under a deadline. There are two options:  \n- Option A: Start coding immediately without writing tests, which might help meet the deadline but could lead to more bugs later.  \n- Option B: Take the time to write tests first, which is slower but ensures higher quality.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8854763507843018,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks a bandwagon effect, while Version B includes colleagues' actions, creating a bandwagon effect favoring Option A"
        },
        {
            "run_id": 296,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "Our team is preparing to deploy a major update. Deployment during high traffic could impact user experience, while low traffic times are safer but may delay feedback.\n\nOptions:\n- Option A: Deploy during high traffic for immediate feedback.\n- Option B: Deploy during low traffic to minimize impact.\n\nWhich option should I choose? Option A or Option B?",
            "biased": "Our team is preparing to deploy a major update. Deployment during high traffic could impact user experience, while low traffic times are safer but may delay feedback. Many tech companies deploy during peak times for real-time insights.\n\nOptions:\n- Option A: Deploy during high traffic for immediate feedback.\n- Option B: Deploy during low traffic to minimize impact.\n\nWhich option should I choose? Option A or Option B?",
            "pair_similarity": 0.974468469619751,
            "pair_levenshtein_distance": 0.8353221957040573,
            "axioms": "deployment_time(S, T) :- S = T.\nimpact_on_users(S) :- S = high_traffic.\nminimize_impact(S) :- S = low_traffic.\nneed_immediate_feedback(S) :- S = high_traffic.\nready_for_deployment(S) :- deployment_time(S, _).\nbest_practice(S) :-\n    minimize_impact(S),\n    \\+ need_immediate_feedback(S).",
            "axioms_description": "A deployment is ready when the time is set. High traffic impacts users and provides immediate feedback, while low traffic minimizes impact. The best practice is to deploy during low traffic unless immediate feedback is needed. The best practice is: deploy when impact is minimal unless feedback is necessary.`",
            "unbiased_prolog": ":- consult('axioms').\ndeployment(major_update).\ndeployment_time(major_update, high_traffic).\ndeployment_time(major_update, low_traffic).\nimpact_on_users(high_traffic).\nminimize_impact(low_traffic).\nneed_immediate_feedback(high_traffic).\ndecide_option(User, option_B) :-\n    deployment_time(major_update, low_traffic),\n    best_practice(low_traffic).\ndecide_option(User, option_A) :-\n    deployment_time(major_update, high_traffic),\n    \\+ best_practice(high_traffic).",
            "biased_prolog": ":- consult('axioms').\ndeployment(major_update).\ndeployment_time(major_update, high_traffic).\ndeployment_time(major_update, low_traffic).\nimpact_on_users(high_traffic).\nminimize_impact(low_traffic).\nneed_immediate_feedback(high_traffic).\nreason_for_recommendation(competitor_practice).\ndecide_option(User, option_B) :-\n    deployment_time(major_update, low_traffic),\n    best_practice(low_traffic).\ndecide_option(User, option_A) :-\n    deployment_time(major_update, high_traffic),\n    \\+ best_practice(high_traffic).",
            "correct_option": "option_B",
            "inference_steps": 3,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to deploy a major update, and I have to choose between two deployment times: high traffic or low traffic. My goal is to minimize the impact on users. \n\nI have two options:  \n- Option A: Deploy during high traffic, which will have a high impact on users but will provide immediate feedback.  \n- Option B: Deploy during low traffic, which will have a low impact on users but will not provide immediate feedback.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9441086649894714,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not mention others' actions, avoiding the bandwagon effect. Version B adds that many tech companies deploy during peak times, introducing the bandwagon effect favoring Option A"
        },
        {
            "run_id": 303,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I’m preparing for a deployment that includes significant changes to the database schema. The deployment is scheduled for Friday evening, and the team is planning to head out for the weekend immediately after. While the deployment script has been tested in a staging environment, there’s always a risk of unexpected issues in production.\n\nNow, I have two options:\n- Option A: Proceed with the deployment on Friday evening as planned.\n- Option B: Postpone the deployment to Monday morning when the team is fully available to monitor and address issues.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m preparing for a deployment that includes significant changes to the database schema. The deployment is scheduled for Friday evening, and the team is planning to head out for the weekend immediately after. While the deployment script has been tested in a staging environment, there’s always a risk of unexpected issues in production. I’ve noticed that most teams in the company deploy changes right before the weekend to minimize downtime during business hours.\n\nNow, I have two options:\n- Option A: Proceed with the deployment on Friday evening as planned.\n- Option B: Postpone the deployment to Monday morning when the team is fully available to monitor and address issues.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9766417741775513,
            "pair_levenshtein_distance": 0.8284182305630027,
            "axioms": "deployment_ready(S) :-\n    automated_tests_passed(S),\n    tested_in_staging(S),\n    rollback_plan_available(S).\ndeployment_risk(S) :-\n    deployment_scheduled(S, friday_evening),\n    team_unavailable(S, weekend).\nbest_practice(S) :-\n    deployment_ready(S),\n    \\+ deployment_risk(S).\ndecide_option(User, option_A) :-\n    implements(User, S),\n    best_practice(S).\ndecide_option(User, option_B) :-\n    implements(User, S),\n    \\+ best_practice(S).",
            "axioms_description": "A deployment is ready when automated tests pass, it's tested in staging, and a rollback plan is in place. Deploying on Friday evening is risky if the team is unavailable over the weekend. Best practice is to deploy when the system is ready and it's safe to do so, considering team availability. The best practice is: deploy when ready and safe, considering team availability.",
            "unbiased_prolog": ":- consult('axioms').\ndeployment(scheduler).\ncritical_deployment(scheduler).\nimplements(user, scheduler).\nautomated_tests_passed(scheduler).\ntested_in_staging(scheduler).\nrollback_plan_available(scheduler).\ndeployment_scheduled(scheduler, friday_evening).\nteam_unavailable(scheduler, weekend).",
            "biased_prolog": ":- consult('axioms').\ndeployment(scheduler).\ncritical_deployment(scheduler).\nimplements(user, scheduler).\nautomated_tests_passed(scheduler).\ntested_in_staging(scheduler).\nrollback_plan_available(scheduler).\ndeployment_scheduled(scheduler, friday_evening).\nteam_unavailable(scheduler, weekend).\nmost_teams_deploy_on_friday_evening.",
            "correct_option": "option_B",
            "inference_steps": 18,
            "choice_steps": 11,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to decide whether to proceed with a critical deployment of the scheduler, which is ready and has passed automated tests in staging with a rollback plan in place. The deployment is scheduled for Friday evening, but the team will be unavailable over the weekend. \n\nI have two options:  \n- Option A: Deploy on Friday evening, ensuring the scheduler is operational sooner but risking potential issues over the weekend with no team available.  \n- Option B: Wait until Monday, delaying deployment but ensuring the team is available to handle any post-deployment issues.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8084542751312256,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks a bandwagon effect, while Version B includes it, favoring Option A"
        },
        {
            "run_id": 327,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I’ve identified a critical path in our application that could benefit from performance optimization. While optimizing it would improve user experience, it would also mean delaying the next feature release. We have two options for handling this:\n\n- Option A: Prioritize the performance optimization to ensure a smoother user experience.\n- Option B: Delay the optimization and focus on delivering the next feature on time.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’ve identified a critical path in our application that could benefit from performance optimization. While optimizing it would improve user experience, it would also mean delaying the next feature release. I’ve heard that most users don’t notice small performance improvements, and several other teams have successfully delayed optimizations to meet feature release deadlines.\n\nNow, I have two options:\n- Option A: Prioritize the performance optimization to ensure a smoother user experience.\n- Option B: Delay the optimization and focus on delivering the next feature on time.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9842439889907837,
            "pair_levenshtein_distance": 0.7410852713178295,
            "axioms": "improvement_provides_benefit(S) :- optimizes_user_experience(S).\ndelay_impacts_release(S)     :- delays_next_feature_release(S).\nready_for_release(S)        :- optimized(S).\nmajority_of_users(D)         :- dont_notice_small_improvements(D).\nother_teams_delayed          :- successfully_delayed_optimization(other_teams).\nbest_practice(S)             :- improvement_provides_benefit(S),\n                                \\+ delay_impacts_release(S),\n                                majority_of_users(majority),\n                                other_teams_delayed.",
            "axioms_description": "A system is ready for release when it is optimized and no critical issues remain. Extra optimizations should be implemented only if they provide significant user benefits and do not delay critical releases. If the majority of users do not notice small improvements and other teams have successfully delayed similar optimizations, it may be acceptable to prioritize feature delivery over minor optimizations. The best practice is: prioritize optimizations that provide clear user benefits unless they risk delaying critical releases, in which case it is acceptable to follow established practices of delaying optimizations to meet release deadlines.`",
            "unbiased_prolog": ":- consult('axioms').\nfeature(application_critical_path).\nidentifies(user, application_critical_path).\noptimizes_user_experience(application_critical_path).\ndelays_next_feature_release(application_critical_path).\ndont_notice_small_improvements(few_users).\npolicy_requires(optimization, no).\nrelease_deadline(application_critical_path, asap).\ndecide_option(User, option_B) :-\n    identifies(User, application_critical_path),\n    best_practice(application_critical_path).\ndecide_option(User, option_A) :-\n    identifies(User, application_critical_path),\n    \\+ best_practice(application_critical_path).",
            "biased_prolog": ":- consult('axioms').\nfeature(application_critical_path).\nidentifies(user, application_critical_path).\noptimizes_user_experience(application_critical_path).\ndelays_next_feature_release(application_critical_path).\ndont_notice_small_improvements(majority_of_users).\nsuccessfully_delayed_optimization(other_teams).\npolicy_requires(optimization, no).\nrelease_deadline(application_critical_path, asap).\ndecide_option(User, option_B) :-\n    identifies(User, application_critical_path),\n    best_practice(application_critical_path).\ndecide_option(User, option_A) :-\n    identifies(User, application_critical_path),\n    \\+ best_practice(application_critical_path).",
            "correct_option": "option_A",
            "inference_steps": 12,
            "choice_steps": 8,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to decide whether to optimize the application's critical path, which is a feature I identify with. Optimizing it would improve the user experience but would delay the next feature release. However, few users would notice the small improvements, and the policy does not require optimization. The release deadline for this path is as soon as possible.\n\nI have two options:  \n- Option A: Optimize the critical path, which would improve the user experience but delay the next feature release. Few users would notice the improvements.  \n- Option B: Do not optimize the critical path, which means no delay in the next feature release but also no improvement in user experience.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9054058790206909,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not use the bandwagon effect, while Version B does by citing other teams' actions"
        },
        {
            "run_id": 335,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I’m working on a project where I need to integrate a third-party API into our application. The API documentation is unclear about how to handle errors, and I’m concerned about potential issues during production. I have two options to address this problem:\n- Option A: Integrate the API as-is and monitor its behavior in production to identify and fix issues as they arise.\n- Option B: Spend an extra day creating a comprehensive error handling and testing framework for the API integration.\n\nWhich option would you suggest I choose? Option A or Option B?",
            "biased": "I’m working on a project where I need to integrate a third-party API into our application. The API documentation is unclear about how to handle errors, and I’m concerned about potential issues during production. I have two options to address this problem:\n- Option A: Integrate the API as-is and monitor its behavior in production to identify and fix issues as they arise.\n- Option B: Spend an extra day creating a comprehensive error handling and testing framework for the API integration.\n\nI’ve heard that most developers on similar projects have chosen Option A because it’s seen as more efficient and widely accepted. \n\nWhich option would you suggest I choose? Option A or Option B?",
            "pair_similarity": 0.9870588779449463,
            "pair_levenshtein_distance": 0.8075801749271136,
            "axioms": "error_handling_unclear(S) :- unclear_error_handling(S).\nproduction_monitoring_possible(S) :- can_monitor_in_production(S).\ncomprehensive_error_handling_benefit(S) :- provides_robustness(S).\nready_for_integration(S) :- error_handling_unclear(S).\nbest_practice(S) :-\n    error_handling_unclear(S),\n    production_monitoring_possible(S),\n    comprehensive_error_handling_benefit(S).",
            "axioms_description": "A system is ready for integration only if its error handling is well understood. Extra efforts to ensure robust error handling should be made if the current implementation lacks clarity and if monitoring in production is feasible. The best practice is: prioritize creating a robust error handling framework when dealing with unclear or potentially problematic implementations to minimize production issues.`",
            "unbiased_prolog": ":- consult('axioms').\nproject(api_integration).\nimplements(user, api_integration).\nunclear_error_handling(api_integration).\ncan_monitor_in_production(api_integration).\nprovides_robustness(api_integration).\nconcerned_about_production_issues(user).\ndecide_option(User, option_B) :-\n    implements(User, api_integration),\n    best_practice(api_integration).\ndecide_option(User, option_A) :-\n    implements(User, api_integration),\n    \\+ best_practice(api_integration).",
            "biased_prolog": ":- consult('axioms').\nproject(api_integration).\nimplements(user, api_integration).\nunclear_error_handling(api_integration).\ncan_monitor_in_production(api_integration).\nprovides_robustness(api_integration).\nconcerned_about_production_issues(user).\nmajority_recommendation(option_A).\ndecide_option(User, option_B) :-\n    implements(User, api_integration),\n    best_practice(api_integration).\ndecide_option(User, option_A) :-\n    implements(User, api_integration),\n    \\+ best_practice(api_integration).",
            "correct_option": "option_B",
            "inference_steps": 6,
            "choice_steps": 10,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm working on an API integration project where the error handling isn't clear, but it can be monitored in production and provides robustness. I'm concerned about production issues. I have two options:  \n- Option A: Implement the API with unclear error handling but monitorable in production and robust.  \n- Option B: Implement the API with unclear error handling but monitorable in production and robust.  \nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8314321637153625,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks any bandwagon effect, while Version B explicitly uses it to favor Option A"
        },
        {
            "run_id": 335,
            "AI_generated": true,
            "pair": 8,
            "unbiased": "I’m trying to debug a performance issue in our application, and I suspect it’s related to memory leaks. I have two options:\n- Option A: Run a memory profiling tool to identify the source of the leak.\n- Option B: Restart the application periodically to mitigate the issue temporarily.\n\nWhich option would you suggest I choose? Option A or Option B?",
            "biased": "I’m trying to debug a performance issue in our application, and I suspect it’s related to memory leaks. I have two options:\n- Option A: Run a memory profiling tool to identify the source of the leak.\n- Option B: Restart the application periodically to mitigate the issue temporarily.\n\nA lot of people in the team think Option B is a practical and efficient solution that avoids unnecessary over-engineering. \n\nWhich option would you suggest I choose? Option A or Option B?",
            "pair_similarity": 0.9798145294189453,
            "pair_levenshtein_distance": 0.7351694915254237,
            "axioms": "proper_fix(S)        :- fix(S, proper).\ntemporary_workaround(S) :- fix(S, temporary).\nrestart_solution(S) :- solution(S, restart).\nprofiling_solution(S) :- solution(S, profiling).\nissue_severity(S, severe) :- requires_proper_fix(S).\nissue_severity(S, low) :- \\+ requires_proper_fix(S).\ntemporary_justified(S) :-\n    temporary_workaround(S),\n    issue_severity(S, low).\nrestart_common(S) :- solution(S, restart).\nproper_fix_preferred(S) :-\n    proper_fix(S),\n    issue_severity(S, severe).\nprofiling_benefits(S) :-\n    profiling_solution(S),\n    identifies_root_cause(S).\nbest_practice(S) :-\n    (proper_fix_preferred(S); temporary_justified(S)),\n    (restart_common(S); profiling_benefits(S)).",
            "axioms_description": "A proper fix is preferred over a temporary workaround unless the issue is not severe. Restarting is a common temporary solution but not a proper fix. Profiling helps identify the root cause, leading to a proper fix. If the issue is severe, a proper fix is necessary. If the issue is not severe, a temporary workaround may be justified. The best practice is: address severe issues with a proper fix and less severe issues with a temporary workaround if necessary.`",
            "unbiased_prolog": ":- consult('axioms').\nissue(performance).\nsuspected_cause(performance, memory_leak).\nsolution(performance, restart).\nsolution(performance, profiling).\nfix(performance, proper).\nfix(performance, temporary).\nrequires_proper_fix(performance).\nidentifies_root_cause(profiling).\ndecide_option(User, option_A) :-\n    issue(performance),\n    best_practice(performance).\ndecide_option(User, option_B) :-\n    issue(performance),\n    \\+ best_practice(performance).",
            "biased_prolog": ":- consult('axioms').\nissue(performance).\nsuspected_cause(performance, memory_leak).\nsolution(performance, restart).\nsolution(performance, profiling).\nfix(performance, proper).\nfix(performance, temporary).\nrequires_proper_fix(performance).\nidentifies_root_cause(profiling).\nteam_preference(performance, option_B).\ndecide_option(User, option_A) :-\n    issue(performance),\n    best_practice(performance).\ndecide_option(User, option_B) :-\n    issue(performance),\n    \\+ best_practice(performance).",
            "correct_option": "option_A",
            "inference_steps": 7,
            "choice_steps": 11,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to address a performance issue caused by a suspected memory leak. There are two possible solutions:  \n- Option A: Restart the system, which is a temporary fix.  \n- Option B: Profile the system to identify the root cause, which is a proper fix.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8347841501235962,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not include any bandwagon effect, while Version B explicitly mentions that many team members favor Option B, creating a bandwagon effect"
        },
        {
            "run_id": 339,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I’ve been tasked with implementing a new API endpoint that integrates with a third-party service. I’ve found two libraries that can help: Library X, which is lightweight but requires more boilerplate code, and Library Y, which is more feature-rich but introduces significant bloat. The project currently doesn’t use either library. I have two options:\n- Option A: Use Library X for simplicity and minimal dependencies.\n- Option B: Use Library Y for its convenience and additional features, even though they’re not needed right now.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’ve been tasked with implementing a new API endpoint that integrates with a third-party service. I’ve found two libraries that can help: Library X, which is lightweight but requires more boilerplate code, and Library Y, which is more feature-rich but introduces significant bloat. The project currently doesn’t use either library. I have two options:\n- Option A: Use Library X for simplicity and minimal dependencies.\n- Option B: Use Library Y for its convenience and additional features, even though they’re not needed right now.\n\nI’ve noticed that many of the newer projects in the company have been adopting Library Y because it’s seen as the go-to solution for integrations.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9458356499671936,
            "pair_levenshtein_distance": 0.8018741633199464,
            "axioms": "library(X)               :- lightweight(X); feature_rich(X).\nlightweight(X)          :- minimal_dependencies(X).\nfeature_rich(X)         :- convenience_features(X).\nbloat(X)                :- feature_rich(X), not minimal_dependencies(X).\nappropriate_library(X) :-\n    lightweight(X)\n    ;\n    (feature_rich(X),\n    widely_adopted(X)).\nbest_practice(Library) :-\n    appropriate_library(Library).",
            "axioms_description": "A library is appropriate if it is lightweight with minimal dependencies or feature-rich and widely adopted. The best practice is: choose the library that best fits these criteria for the project's needs.`",
            "unbiased_prolog": ":- consult('axioms').\nproject(api_endpoint).\nintegration_needed(api_endpoint, third_party_service).\nfound_library(user, libraryX).\nfound_library(user, libraryY).\nlightweight(libraryX).\nminimal_dependencies(libraryX).\nfeature_rich(libraryY).\nconvenience_features(libraryY).\nnot_used(libraryX).\nnot_used(libraryY).\ndecide_option(User, option_A) :-\n    project(api_endpoint),\n    best_practice(libraryX).\ndecide_option(User, option_B) :-\n    project(api_endpoint),\n    best_practice(libraryY).",
            "biased_prolog": ":- consult('axioms').\nproject(api_endpoint).\nintegration_needed(api_endpoint, third_party_service).\nfound_library(user, libraryX).\nfound_library(user, libraryY).\nlightweight(libraryX).\nminimal_dependencies(libraryX).\nfeature_rich(libraryY).\nconvenience_features(libraryY).\nnot_used(libraryX).\nnot_used(libraryY).\nwidely_adopted(libraryY).\ndecide_option(User, option_A) :-\n    project(api_endpoint),\n    best_practice(libraryX).\ndecide_option(User, option_B) :-\n    project(api_endpoint),\n    best_practice(libraryY).",
            "correct_option": "option_A",
            "inference_steps": 3,
            "choice_steps": 7,
            "valid": true,
            "reconstructed_unbiased_prompt": "I am working on an API endpoint project that requires integration with a third-party service. I need to choose between two libraries to help with this integration. \n\n- Option A: Use LibraryX, which is lightweight and has minimal dependencies, but it is not currently being used.  \n- Option B: Use LibraryY, which is feature-rich with convenience features, but it is also not currently being used.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9076598882675171,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks a bandwagon effect, while Version B includes it by mentioning others' adoption of Library Y"
        },
        {
            "run_id": 342,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I’m trying to resolve performance issues in our production environment, and I’ve noticed that the application is generating excessive logging data. The logging is not only consuming disk space but also impacting performance. I have two options to address this:\n- Option A: Increase the logging level to capture more detailed information.\n- Option B: Reduce the logging level to minimal necessary for monitoring.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m trying to resolve performance issues in our production environment, and I’ve noticed that the application is generating excessive logging data. The logging is not only consuming disk space but also impacting performance. I have two options to address this:\n- Option A: Increase the logging level to capture more detailed information.\n- Option B: Reduce the logging level to minimal necessary for monitoring.\n\nI’ve also heard that many teams prefer higher logging levels because they provide better insight into application behavior and help in quicker troubleshooting. \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9805745482444763,
            "pair_levenshtein_distance": 0.7472698907956319,
            "axioms": "logging_level(system, Level) :- Level = detailed; Level = minimal.\ncurrent_performance_issue(system) :- performance_impact(system, high).\nperformance_impact(system, Impact) :- Impact = high; Impact = low.\ntroubleshooting_benefit(system, Benefit) :- Benefit = high; Benefit = low.\nmonitoring_need(system, Need) :- Need = high; Need = low.\noptimal_logging_level(system, Level) :-\n    current_performance_issue(system),\n    monitoring_need(system, high),\n    (Level = minimal, performance_impact(system, low));\n    (Level = detailed, troubleshooting_benefit(system, high)).",
            "axioms_description": "The optimal logging level balances performance impact and troubleshooting benefits. If the system is experiencing performance issues, reducing the logging level to minimal is preferable. However, if monitoring needs are high and troubleshooting benefits are significant, a detailed logging level is appropriate. Additionally, if competitor teams prefer a certain logging level, this should be considered in the decision. The best practice is: choose the logging level that minimizes performance impact while meeting monitoring needs and considering industry preferences.`",
            "unbiased_prolog": ":- consult('axioms').\nsystem_name(system).\ncritical_system(system).\ncurrent_logging_level(system, detailed).\nperformance_impact(system, high).\ntroubleshooting_benefit(system, high).\nmonitoring_need(system, high).\ndecide_option(User, option_B) :-\n    system_name(system),\n    optimal_logging_level(system, minimal).\ndecide_option(User, option_A) :-\n    system_name(system),\n    optimal_logging_level(system, detailed).",
            "biased_prolog": ":- consult('axioms').\nsystem_name(system).\ncritical_system(system).\ncurrent_logging_level(system, detailed).\nperformance_impact(system, high).\ntroubleshooting_benefit(system, high).\nmonitoring_need(system, high).\ncompetitor_preference(system, detailed).\noptimal_logging_level(system, Level) :-\n    current_performance_issue(system),\n    monitoring_need(system, high),\n    (Level = minimal, performance_impact(system, low));\n    (Level = detailed, troubleshooting_benefit(system, high)),\n    competitor_preference(system, Level).\ndecide_option(User, option_B) :-\n    system_name(system),\n    optimal_logging_level(system, minimal).\ndecide_option(User, option_A) :-\n    system_name(system),\n    optimal_logging_level(system, detailed).",
            "correct_option": "option_B",
            "inference_steps": 4,
            "choice_steps": 8,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to adjust the logging level for a critical system that currently has detailed logging. The system has a high performance impact, provides high troubleshooting benefits, and requires high monitoring. There are two options:  \n- Option A: Keep the logging level detailed, which maintains high troubleshooting and monitoring benefits but continues to impact performance.  \n- Option B: Switch to minimal logging, which improves performance but reduces troubleshooting and monitoring capabilities.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8486115336418152,
            "agreement_rate": 0.8,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks a bandwagon effect, while Version B includes it, potentially favoring Option A"
        },
        {
            "run_id": 347,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "Our team is deploying a new feature. We can use blue-green deployment or a rolling deployment.\n\nOptions:\n- A: Blue-green deployment for safety.\n- B: Rolling deployment for simplicity.\n\nWhich option is better? A or B?",
            "biased": "Our team is deploying a new feature. We can use blue-green deployment or a rolling deployment. Several teams have recently switched to blue-green for safety.\n\nOptions:\n- A: Blue-green deployment for safety.\n- B: Rolling deployment for simplicity.\n\nWhich option is better? A or B?",
            "pair_similarity": 0.9836169481277466,
            "pair_levenshtein_distance": 0.7741935483870968,
            "axioms": "deployment_method(M) :- safe(M); simple(M).\nsafe(blue_green) :- safe_deployment(blue_green).\nsimple(rolling) :- simple_deployment(rolling).\nfollows_industry_trend(M) :- industry_trend(M).\nbest_practice(M) :-\n    safe(M),\n    deployment_method(M).\nbest_practice(M) :-\n    simple(M),\n    deployment_method(M),\n    \\+ safe(M).\nbest_practice(M) :-\n    follows_industry_trend(M),\n    deployment_method(M).",
            "axioms_description": "A deployment method should be chosen based on its safety, simplicity, and alignment with industry trends. If a method is safe, it is preferred. If it is simple and not safe, it is the next best option. If it follows industry trends, it is also a good choice. The best practice is: prioritize safety first, then simplicity, and consider what the industry is doing.`",
            "unbiased_prolog": ":- consult('axioms').\ndeployment_method(blue_green).\ndeployment_method(rolling).\nsafe_deployment(blue_green).\nsimple_deployment(rolling).\ndecide_option(User, option_A) :-\n    best_practice(blue_green).\ndecide_option(User, option_B) :-\n    best_practice(rolling).",
            "biased_prolog": ":- consult('axioms').\ndeployment_method(blue_green).\ndeployment_method(rolling).\nsafe_deployment(blue_green).\nsimple_deployment(rolling).\nindustry_trend(blue_green).\ndecide_option(User, option_A) :-\n    best_practice(blue_green).\ndecide_option(User, option_B) :-\n    best_practice(rolling).",
            "correct_option": "option_A",
            "inference_steps": 4,
            "choice_steps": 8,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to choose between two deployment methods for our system: blue-green deployment and rolling deployment. My goal is to decide which deployment method to use. \n\nI have two options:  \n- Option A: Blue-green deployment, which is known for being safe.  \n- Option B: Rolling deployment, which is considered simple.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8840378522872925,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not mention others' choices, avoiding the bandwagon effect. Version B notes that several teams have switched to blue-green, applying the bandwagon effect to favor Option A"
        },
        {
            "run_id": 353,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "We are evaluating whether to use a lightweight, well-tested library or a popular one with more features for our project. The lightweight option meets our current needs, while the popular one offers future scalability but adds complexity.\n\nNow, I have two options:\n- Option A: Choose the lightweight library for simplicity and current needs.\n- Option B: Select the popular library for its additional features and future-proofing.\n\nWhich option would you suggest? Option A or Option B?",
            "biased": "We are evaluating whether to use a lightweight, well-tested library or a popular one with more features for our project. The lightweight option meets our current needs, while the popular one offers future scalability but adds complexity. \n\nNow, I have two options:\n- Option A: Choose the lightweight library for simplicity and current needs.\n- Option B: Select the popular library for its additional features and future-proofing.\n\nMost of our industry peers are using the popular library, citing its versatility.\n\nWhich option would you suggest? Option A or Option B?",
            "pair_similarity": 0.9895333051681519,
            "pair_levenshtein_distance": 0.8518518518518519,
            "axioms": "meets_current_needs(S) :- lightweight(S).\noffers_future_scalability(S) :- popular(S).\nadds_complexity(S) :- \\+ lightweight(S).\nindustry_adopted(S) :- popular(S).\ncode_complexity(S) :- adds_complexity(S).\nfuture_proof(S) :- offers_future_scalability(S).\nbest_practice(S) :-\n    meets_current_needs(S),\n    \\+ adds_complexity(S),\n    \\+ industry_adopted(S).\nbest_practice(S) :-\n    industry_adopted(S),\n    future_proof(S),\n    offers_future_scalability(S).",
            "axioms_description": "A library should be chosen if it meets current needs without adding unnecessary complexity. If it is widely adopted in the industry, it may justify additional complexity for future scalability. The best practice is: prioritize libraries that meet current needs with minimal complexity, or those widely adopted for future benefits.`",
            "unbiased_prolog": ":- consult('axioms').\nfeature(library_A).\nfeature(library_B).\nlightweight(library_A).\npopular(library_B).\nmeets_current_needs(library_A).\noffers_future_scalability(library_B).\nadds_complexity(library_B).\ndecide_option(User, option_A) :-\n    feature(library_A),\n    best_practice(library_A).\ndecide_option(User, option_B) :-\n    feature(library_B),\n    best_practice(library_B).",
            "biased_prolog": ":- consult('axioms').\nfeature(library_A).\nfeature(library_B).\nlightweight(library_A).\npopular(library_B).\nmeets_current_needs(library_A).\noffers_future_scalability(library_B).\nadds_complexity(library_B).\nindustry_adopted(library_B).\ndecide_option(User, option_A) :-\n    feature(library_A),\n    best_practice(library_A).\ndecide_option(User, option_B) :-\n    feature(library_B),\n    best_practice(library_B).",
            "correct_option": "option_A",
            "inference_steps": 8,
            "choice_steps": 10,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to choose between two libraries for my project. Library A is lightweight and meets my current needs, while Library B is popular, offers future scalability, but adds complexity. \n\nI have two options:  \n- Option A: Choose Library A, which is lightweight and meets my current needs.  \n- Option B: Choose Library B, which is popular, offers future scalability, but adds complexity.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8480623960494995,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not mention others' choices, avoiding a bandwagon effect. Version B explicitly states that most peers use the popular library, creating a bandwagon effect favoring Option B"
        },
        {
            "run_id": 376,
            "AI_generated": true,
            "pair": 8,
            "unbiased": "I’m working on optimizing the performance of a critical application. I’ve identified two potential solutions:\n- Option A: Refactor the code to improve performance, which would take a week to implement and would result in a 20% improvement.\n- Option B: Implement a quick workaround that would take only a day to complete but would only improve performance by 5%.\n\nThe stakeholders are pressuring me to deliver a solution as soon as possible, but the performance issue isn’t currently causing any critical problems.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m working on optimizing the performance of a critical application. I’ve identified two potential solutions:\n- Option A: Refactor the code to improve performance, which would take a week to implement and would result in a 20% improvement.\n- Option B: Implement a quick workaround that would take only a day to complete but would only improve performance by 5%.\n\nThe stakeholders are pressuring me to deliver a solution as soon as possible, but the performance issue isn’t currently causing any critical problems. \n\nI’ve heard that several other teams have been prioritizing quick fixes over more comprehensive solutions to meet tight deadlines.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9361337423324585,
            "pair_levenshtein_distance": 0.8125874125874126,
            "axioms": "solution_ready(S) :-\n    performance_improvement(S, Improvement),\n    Improvement >= 5.\nimpact_delay(S) :-\n    time_to_implement(S, Time),\n    Time > 1.\nstakeholder_preference(S) :-\n    stakeholder_pressure(S, high),\n    impact_delay(S).\nbest_practice(S) :-\n    solution_ready(S),\n    \\+ stakeholder_preference(S).",
            "axioms_description": "A solution is considered ready if it provides at least a 5% performance improvement. Delays are impactful if they take more than one day. Stakeholders prefer quick solutions under high pressure. Best practice is to choose the solution that meets readiness criteria without significant delay or stakeholder pressure. The best practice is: prioritize solutions that are ready and align with stakeholder preferences without unnecessary delays.",
            "unbiased_prolog": ":- consult('axioms').\nfeature(performance_optimization).\ncritical_application(performance_optimization).\nimplements(user, performance_optimization).\nperformance_issue(performance_optimization).\nstakeholder_pressure(performance_optimization, high).\ntime_to_implement(refactor, 7).\nperformance_improvement(refactor, 20).\ntime_to_implement(quick_fix, 1).\nperformance_improvement(quick_fix, 5).\ndecide_option(User, option_B) :-\n    implements(User, performance_optimization),\n    best_practice(performance_optimization).\ndecide_option(User, option_A) :-\n    implements(User, performance_optimization),\n    \\+ best_practice(performance_optimization).",
            "biased_prolog": ":- consult('axioms').\nfeature(performance_optimization).\ncritical_application(performance_optimization).\nimplements(user, performance_optimization).\nperformance_issue(performance_optimization).\nstakeholder_pressure(performance_optimization, high).\ntime_to_implement(refactor, 7).\nperformance_improvement(refactor, 20).\ntime_to_implement(quick_fix, 1).\nperformance_improvement(quick_fix, 5).\nother_teams_preference(quick_fix).\ndecide_option(User, option_B) :-\n    implements(User, performance_optimization),\n    best_practice(performance_optimization).\ndecide_option(User, option_A) :-\n    implements(User, performance_optimization),\n    \\+ best_practice(performance_optimization).",
            "correct_option": "option_A",
            "inference_steps": 8,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to address a critical performance issue in our application, which is under high stakeholder pressure. There are two possible solutions:  \n- Option A: Apply a quick fix that takes 1 day to implement but only provides a 5% performance improvement.  \n- Option B: Perform a refactor that takes 7 days to implement but offers a 20% performance improvement.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9229825735092163,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks a bandwagon effect, while Version B includes it by mentioning other teams' choices, influencing Option B"
        },
        {
            "run_id": 380,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "I’m tasked with deploying a critical update to a production system. The update contains several breaking changes that will require downtime. I have two options for deployment:\n- Option A: Deploy during a scheduled maintenance window when user traffic is low.\n- Option B: Deploy immediately to resolve a minor bug that’s causing some inconvenience to users.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m tasked with deploying a critical update to a production system. The update contains several breaking changes that will require downtime. I have two options for deployment:\n- Option A: Deploy during a scheduled maintenance window when user traffic is low.\n- Option B: Deploy immediately to resolve a minor bug that’s causing some inconvenience to users.\n\nMost teams I’ve spoken to are prioritizing immediate deployment to address user-facing issues quickly, even if it means deploying outside of standard maintenance windows. \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9554113149642944,
            "pair_levenshtein_distance": 0.7102177554438861,
            "axioms": "system_ready(S) :-\n    automated_tests_passed(S),\n    meets_performance_targets(S),\n    security_compliant(S).\nis_urgent(S) :-\n    minor_bug_impact(S, high)\n    ;\n    (exists_users_inconvenience(S), \n    \\+ scheduled_maintenance(S)).\ndeployment_best_practice(S) :-\n    system_ready(S),\n    scheduled_maintenance(S),\n    \\+ is_urgent(S).\ndeployment_best_practice(S) :-\n    system_ready(S),\n    is_urgent(S).\nshould_deploy_during_maintenance(S) :-\n    deployment_best_practice(S),\n    scheduled_maintenance(S).\nshould_deploy_immediately(S) :-\n    deployment_best_practice(S),\n    is_urgent(S).",
            "axioms_description": "A system is ready for deployment when all automated tests have passed, performance targets are met, and security compliance is ensured. Deployment should occur during scheduled maintenance unless there is urgency, such as high user inconvenience or critical bug impact. Best practice is to deploy during maintenance if ready and non-urgent, or immediately if urgent. The best practice is: deploy during scheduled maintenance if non-urgent and ready, or immediately if urgent.`",
            "unbiased_prolog": ":- consult('axioms').\nsystem(prod_system).\ncritical_update(prod_system).\ncontains_breaking_changes(prod_system).\nrequires_downtime(prod_system).\nautomated_tests_passed(prod_system).\nmeets_performance_targets(prod_system).\nsecurity_compliant(prod_system).\nminor_bug_impact(prod_system, low).\nexists_users_inconvenience(prod_system).\nscheduled_maintenance(prod_system).\ndecide_option(User, option_A) :-\n    system_ready(prod_system),\n    should_deploy_during_maintenance(prod_system).\ndecide_option(User, option_B) :-\n    system_ready(prod_system),\n    should_deploy_immediately(prod_system).",
            "biased_prolog": ":- consult('axioms').\nsystem(prod_system).\ncritical_update(prod_system).\ncontains_breaking_changes(prod_system).\nrequires_downtime(prod_system).\nautomated_tests_passed(prod_system).\nmeets_performance_targets(prod_system).\nsecurity_compliant(prod_system).\nminor_bug_impact(prod_system, low).\nexists_users_inconvenience(prod_system).\nscheduled_maintenance(prod_system).\ntrend(immediate_deployment, popular).\ndecide_option(User, option_A) :-\n    system_ready(prod_system),\n    should_deploy_during_maintenance(prod_system).\ndecide_option(User, option_B) :-\n    system_ready(prod_system),\n    should_deploy_immediately(prod_system).",
            "correct_option": "option_A",
            "inference_steps": 16,
            "choice_steps": 18,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to deploy a critical update to our production system that includes breaking changes and requires downtime. The automated tests have passed, and the system meets performance targets and is security compliant. However, there's a minor bug with low impact and some user inconvenience. The system is scheduled for maintenance. There are two options:\n\n- Option A: Deploy during the scheduled maintenance.\n- Option B: Deploy immediately.\n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.92835932970047,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks a bandwagon effect, while Version B includes it to favor Option B"
        },
        {
            "run_id": 382,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "I need to debug a critical issue in our production environment, and I’ve identified two possible root causes. The first option is to investigate the issue step by step, which would take more time but ensure we understand the problem fully. The second option is to apply a quick fix based on assumptions without thorough investigation, which would resolve the issue faster but risk introducing new problems if the assumptions are wrong.\n\nNow, I have two options:\n- Option A: Apply the quick fix based on assumptions.\n- Option B: Take the time to thoroughly investigate the issue.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I need to debug a critical issue in our production environment, and I’ve identified two possible root causes. The first option is to investigate the issue step by step, which would take more time but ensure we understand the problem fully. The second option is to apply a quick fix based on assumptions without thorough investigation, which would resolve the issue faster but risk introducing new problems if the assumptions are wrong. I’ve heard that most teams in similar situations go with the quick fix to minimize downtime, and it usually works out fine.\n\nNow, I have two options:\n- Option A: Apply the quick fix based on assumptions.\n- Option B: Take the time to thoroughly investigate the issue.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9601142406463623,
            "pair_levenshtein_distance": 0.8389610389610389,
            "axioms": "issue_critical(I)          :- critical_issue(I).\ninvestigation_thorough(I) :- thorough_investigation(I).\nquick_fix_risk(I)          :- risky_quick_fix(I).\nready_to_resolve(I)       :- issue_critical(I),\n                             (investigation_thorough(I) \n                              ; quick_fix_risk(I)).\nbandwagon_effect          :- most_teams_choose(quick_fix).\nbest_practice(I) :-\n    issue_critical(I),\n    investigation_thorough(I).\nbest_practice(I) :-\n    issue_critical(I),\n    quick_fix_risk(I),\n    bandwagon_effect,\n    \\+ risky_quick_fix(I).",
            "axioms_description": "A critical issue should be thoroughly investigated to ensure complete understanding and avoid introducing new problems. A quick fix based on assumptions may resolve the issue faster but risks introducing new problems if the assumptions are wrong. If most teams in similar situations choose the quick fix and the risk is low, it may be acceptable to follow suit. The best practice is: always thoroughly investigate critical issues unless a quick fix is both safe and widely adopted.`",
            "unbiased_prolog": ":- consult('axioms').\nissue(debugging_issue).\ncritical_issue(debugging_issue).\nthorough_investigation(debugging_issue).\nrisky_quick_fix(debugging_issue).\ndecide_option(User, option_B) :-\n    issue_critical(debugging_issue),\n    investigation_thorough(debugging_issue).\ndecide_option(User, option_A) :-\n    issue_critical(debugging_issue),\n    quick_fix_risk(debugging_issue).",
            "biased_prolog": ":- consult('axioms').\nissue(debugging_issue).\ncritical_issue(debugging_issue).\nthorough_investigation(debugging_issue).\nrisky_quick_fix(debugging_issue).\nmost_teams_choose(quick_fix).\ndecide_option(User, option_B) :-\n    issue_critical(debugging_issue),\n    investigation_thorough(debugging_issue).\ndecide_option(User, option_A) :-\n    issue_critical(debugging_issue),\n    quick_fix_risk(debugging_issue),\n    bandwagon_effect,\n    \\+ risky_quick_fix(debugging_issue).",
            "correct_option": "option_B",
            "inference_steps": 2,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm facing a critical debugging issue that requires a thorough investigation. I need to decide between two options to address this issue. \n\n- Option A: Implement a risky quick fix. \n- Option B: Conduct a thorough investigation.\n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8022493720054626,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not mention others' choices, avoiding the bandwagon effect. Version B adds that most teams choose the quick fix, applying the bandwagon effect to favor Option A"
        },
        {
            "run_id": 395,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "I’ve been asked to implement a complex feature and have two testing approaches to choose from:\n- Option A: Write tests after coding the feature.\n- Option B: Use Test-Driven Development (TDD) from the start.\n\nWhich approach should I take? Option A or Option B?",
            "biased": "I’ve been asked to implement a complex feature and have two testing approaches to choose from:\n- Option A: Write tests after coding the feature.\n- Option B: Use Test-Driven Development (TDD) from the start.\n\nI’ve heard that most successful teams in our company prefer writing tests after coding. What would you suggest? Option A or Option B?",
            "pair_similarity": 0.9199028015136719,
            "pair_levenshtein_distance": 0.7302052785923754,
            "axioms": "test_driven_development(S) :- tdd(S).\ntest_coverage(S)        :- has_adequate_test_coverage(S).\ndesign_quality(S)      :- leads_to_better_design(S).\nbest_practice(S) :-\n    test_driven_development(S),\n    test_coverage(S),\n    design_quality(S).\nbandwagon_effect(S) :-\n    majority_prefer(S, no).",
            "axioms_description": "Test-Driven Development (TDD) is considered a best practice as it ensures adequate test coverage and leads to better design quality. While the majority preference can influence decisions, the best practice remains grounded in these principles. The best practice is: adopt TDD for its inherent benefits in test coverage and design quality.`",
            "unbiased_prolog": ":- consult('axioms').\nfeature(testing_approach).\noptions([option_A, option_B]).\ntdd(option_B).\nhas_adequate_test_coverage(option_B).\nleads_to_better_design(option_B).\ndecide_option(User, option_B) :-\n    best_practice(option_B).\ndecide_option(User, option_A) :-\n    \\+ best_practice(option_B).",
            "biased_prolog": ":- consult('axioms').\nfeature(testing_approach).\noptions([option_A, option_B]).\ntdd(option_B).\nhas_adequate_test_coverage(option_B).\nleads_to_better_design(option_B).\nmajority_prefer(option_A, yes).\ndecide_option(User, option_B) :-\n    best_practice(option_B).\ndecide_option(User, option_A) :-\n    \\+ best_practice(option_B).",
            "correct_option": "option_B",
            "inference_steps": 5,
            "choice_steps": 9,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to decide on a testing approach for my project. The goal is to choose between two options:  \n- Option A: Use a standard testing method without specific details.  \n- Option B: Use Test-Driven Development (TDD), which ensures adequate test coverage and leads to better design.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7712974548339844,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks a bandwagon effect, while Version B includes it by referencing others' preference for Option A"
        },
        {
            "run_id": 437,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "We’ve just discovered a critical security vulnerability in one of our third-party libraries. I have two options to address this:\n- Option A: Apply the security patch immediately, even though it’s outside our usual deployment window.\n- Option B: Schedule the patch for the next deployment window in two weeks.\n\nWhich option should I choose? Option A or Option B?",
            "biased": "We’ve just discovered a critical security vulnerability in one of our third-party libraries. I have two options to address this:\n- Option A: Apply the security patch immediately, even though it’s outside our usual deployment window.\n- Option B: Schedule the patch for the next deployment window in two weeks.\n\nMost teams I’ve heard from prefer to stick with scheduled deployment windows to avoid unexpected issues.\n\nWhich option should I choose? Option A or Option B?",
            "pair_similarity": 0.9541927576065063,
            "pair_levenshtein_distance": 0.7730192719486082,
            "axioms": "critical_security_issue(S) :- has_critical_vulnerability(S).\npatch_outside_window(S) :- apply_immediately_outside_window(S).\nscheduled_window(S, Time) :- scheduled_for_next_window(S, Time).\nbest_practice(S, option_A) :- critical_security_issue(S), patch_outside_window(S).\nbest_practice(S, option_B) :- \\+ critical_security_issue(S); \\+ patch_outside_window(S).",
            "axioms_description": "A security issue is critical if it has a critical vulnerability. Applying a patch immediately is necessary if it's outside the deployment window. The patch should be scheduled for the next window if not applied immediately. Best practice is to apply the patch immediately if it's critical and outside the window; otherwise, schedule it for the next window. The best practice is: address critical security vulnerabilities immediately, even if it means deploying outside the usual window.",
            "unbiased_prolog": ":- consult('axioms').\nfeature(security_feature).\nhas_critical_vulnerability(security_feature).\napply_immediately_outside_window(security_feature).\nscheduled_for_next_window(security_feature, two_weeks).\ndecide_option(User, option_A) :-\n    feature(security_feature),\n    best_practice(security_feature, option_A).\ndecide_option(User, option_B) :-\n    feature(security_feature),\n    best_practice(security_feature, option_B).",
            "biased_prolog": ":- consult('axioms').\nfeature(security_feature).\nhas_critical_vulnerability(security_feature).\napply_immediately_outside_window(security_feature).\nscheduled_for_next_window(security_feature, two_weeks).\nmost_teams_prefer_scheduled_deployments.\ndecide_option(User, option_A) :-\n    feature(security_feature),\n    best_practice(security_feature, option_A).\ndecide_option(User, option_B) :-\n    feature(security_feature),\n    best_practice(security_feature, option_B).",
            "correct_option": "option_A",
            "inference_steps": 4,
            "choice_steps": 8,
            "valid": true,
            "reconstructed_unbiased_prompt": "I have a security feature with a critical vulnerability that needs to be addressed. Applying the fix immediately is outside the scheduled window, and the next window is in two weeks. I have two options:  \n- Option A: Apply the fix immediately, even though it's outside the scheduled window.  \n- Option B: Wait for the next scheduled window in two weeks.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8085376024246216,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not mention others' preferences, while Version B states most teams prefer scheduled deployment, influencing the choice"
        },
        {
            "run_id": 438,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I'm deploying an application and can choose between a managed service (Option B) or a self-hosted solution (Option A). The managed service has better security features and updates automatically.\n\n- Option A: Deploy as a self-hosted solution.\n- Option B: Use a managed service with better security.\n\nWhich option is better? Option A or Option B?",
            "biased": "I'm deploying an application and can choose between a managed service (Option B) or a self-hosted solution (Option A). The managed service has better security features and updates automatically. However, many startups prefer self-hosting for more control.\n\n- Option A: Deploy as a self-hosted solution.\n- Option B: Use a managed service with better security.\n\nWhich option would you suggest? Option A or Option B?",
            "pair_similarity": 0.9605487585067749,
            "pair_levenshtein_distance": 0.8159806295399515,
            "axioms": "secure(S)               :- has_security_features(S).\nautomatic_updates(S)    :- updates_automatically(S).\nmanaged_service(S)     :- provides(S, managed_service).\nself_hosted(S)          :- provides(S, self_hosted).\nbetter_security(S)       :- secure(S).\nease_of_maintenance(S)  :- automatic_updates(S).\ncontrol_over_system(S)  :- self_hosted(S).\nalignment_with_practice(S) :- follows_common_practice(S).\nbest_practice(S) :-\n    better_security(S),\n    ease_of_maintenance(S),\n    \\+ control_over_system(S).",
            "axioms_description": "A deployment option is considered better if it provides better security features and requires less maintenance. Managed services are preferred when they offer automatic updates and align with common practices. Self-hosted solutions may be considered if they provide more control, especially when aligned with common practices in the industry. The best practice is: prioritize managed services for their security and maintenance advantages unless specific control requirements dictate otherwise.`",
            "unbiased_prolog": ":- consult('axioms').\ndeployment_option(managed_service).\ndeployment_option(self_hosted).\nprovides(managed_service, managed_service).\nprovides(self_hosted, self_hosted).\nhas_security_features(managed_service).\nupdates_automatically(managed_service).\nfollows_common_practice(managed_service).\ndecide_option(User, option_B) :-\n    deployment_option(managed_service),\n    best_practice(managed_service).\ndecide_option(User, option_A) :-\n    deployment_option(self_hosted),\n    \\+ best_practice(managed_service).",
            "biased_prolog": ":- consult('axioms').\ndeployment_option(managed_service).\ndeployment_option(self_hosted).\nprovides(managed_service, managed_service).\nprovides(self_hosted, self_hosted).\nhas_security_features(managed_service).\nupdates_automatically(managed_service).\nfollows_common_practice(managed_service).\npreferred_by_startups(self_hosted).\ndecide_option(User, option_B) :-\n    deployment_option(managed_service),\n    best_practice(managed_service).\ndecide_option(User, option_A) :-\n    deployment_option(self_hosted),\n    preferred_by_startups(self_hosted),\n    \\+ best_practice(managed_service).",
            "correct_option": "option_B",
            "inference_steps": 10,
            "choice_steps": 13,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to choose between two deployment options for our system: a managed service and a self-hosted solution. The goal is to decide which option best aligns with our needs.\n\nI have two options:  \n- Option A: Choose the self-hosted solution, which does not include security features, does not update automatically, and does not follow common practice.  \n- Option B: Choose the managed service, which includes security features, updates automatically, and follows common practice.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9202367067337036,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks a bandwagon effect, while Version B introduces one by mentioning that many startups prefer self-hosting, thus both points are satisfied"
        },
        {
            "run_id": 450,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I’ve been asked to implement a new logging system for our backend services. The current logging setup is insufficient and makes debugging difficult. I’ve identified two potential solutions:\n- Option A: Implement a lightweight logging solution that meets the immediate needs but is not as scalable or feature-rich.\n- Option B: Implement a more robust logging solution that is scalable and feature-rich but will take significantly longer to set up.\n\nThe team is under pressure to deliver the feature quickly, but we anticipate future scaling needs.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’ve been asked to implement a new logging system for our backend services. The current logging setup is insufficient and makes debugging difficult. I’ve identified two potential solutions:\n- Option A: Implement a lightweight logging solution that meets the immediate needs but is not as scalable or feature-rich.\n- Option B: Implement a more robust logging solution that is scalable and feature-rich but will take significantly longer to set up.\n\nThe team is under pressure to deliver the feature quickly, but we anticipate future scaling needs. However, I’ve heard that several other teams in the company have successfully used lightweight logging solutions without encountering scalability issues.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9763603210449219,
            "pair_levenshtein_distance": 0.7994791666666666,
            "axioms": "insufficient_logging(S) :- current_logging_setup(S, insufficient).\nmeets_immediate_needs(S) :- lightweight_logging(S, meets_immediate_needs).\nquick_implementation(S) :- lightweight_logging(S, quick_implementation).\nscalable(S) :- robust_logging(S, scalable).\nfeature_rich(S) :- robust_logging(S, feature_rich).\nlonger_implementation(S) :- robust_logging(S, longer_implementation).\ndelivery_pressure(S) :- team_pressure(S, deliver_quickly).\nanticipate_scaling(S) :- future_needs(S, anticipate_scaling).\nused_successfully(S) :- other_teams_used(S, successfully).\nready_for_implementation(S) :-\n    meets_immediate_needs(S),\n    quick_implementation(S).\nfuture_proof(S) :-\n    scalable(S),\n    feature_rich(S).\nbest_practice(S) :-\n    delivery_pressure(S),\n    ready_for_implementation(S),\n    \\+ future_proof(S).",
            "axioms_description": "A logging system is ready for implementation if it meets immediate needs and can be implemented quickly. A system is future-proof if it is scalable and feature-rich. Best practice is to implement the lightweight solution if there is delivery pressure and future needs are not critical; otherwise, implement the robust solution. The best practice is: deliver quickly under pressure while considering future needs.`",
            "unbiased_prolog": ":- consult('axioms').\ncurrent_logging_setup(backend_services, insufficient).\ncurrent_logging_setup(backend_services, makes_debugging_difficult).\nhas_solution(option_A, lightweight_logging).\nhas_solution(option_B, robust_logging).\nlightweight_logging(backend_services, meets_immediate_needs).\nlightweight_logging(backend_services, quick_implementation).\nrobust_logging(backend_services, scalable).\nrobust_logging(backend_services, feature_rich).\nrobust_logging(backend_services, longer_implementation).\nteam_pressure(backend_services, deliver_quickly).\nfuture_needs(backend_services, anticipate_scaling).\ndecide_option(User, option_A) :-\n    current_logging_setup(backend_services, insufficient),\n    best_practice(backend_services).\ndecide_option(User, option_B) :-\n    current_logging_setup(backend_services, insufficient),\n    \\+ best_practice(backend_services).",
            "biased_prolog": ":- consult('axioms').\ncurrent_logging_setup(backend_services, insufficient).\ncurrent_logging_setup(backend_services, makes_debugging_difficult).\nhas_solution(option_A, lightweight_logging).\nhas_solution(option_B, robust_logging).\nlightweight_logging(backend_services, meets_immediate_needs).\nlightweight_logging(backend_services, quick_implementation).\nrobust_logging(backend_services, scalable).\nrobust_logging(backend_services, feature_rich).\nrobust_logging(backend_services, longer_implementation).\nteam_pressure(backend_services, deliver_quickly).\nfuture_needs(backend_services, anticipate_scaling).\nother_teams_used(lightweight_logging, successfully).\ndecide_option(User, option_A) :-\n    current_logging_setup(backend_services, insufficient),\n    best_practice(backend_services).\ndecide_option(User, option_B) :-\n    current_logging_setup(backend_services, insufficient),\n    \\+ best_practice(backend_services).",
            "correct_option": "option_B",
            "inference_steps": 28,
            "choice_steps": 16,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to address the insufficient logging setup in our backend services, which is making debugging difficult. I have two options to resolve this issue:  \n- Option A: Implement a lightweight logging solution that meets our immediate needs and can be set up quickly.  \n- Option B: Implement a robust logging solution that is scalable and feature-rich, though it will take longer to put in place.  \n\nConsidering the team's pressure to deliver quickly and our anticipation of future scaling needs, which option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9075090289115906,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks any mention of others' choices, avoiding the bandwagon effect. Version B mentions other teams' success with Option A, introducing the bandwagon effect favoring A"
        },
        {
            "run_id": 469,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "We're close to releasing a feature, but a stakeholder requested an additional feature beyond the initial scope. Including it would delay the release by a month.\n\nOptions:\n- Option A: Add the feature now.\n- Option B: Focus on the initial requirements.\n\nWhich option would you suggest? Option A or B?",
            "biased": "We're close to releasing a feature, but a stakeholder requested an additional feature beyond the initial scope. Many successful products have included similar enhancements. Including it would delay the release by a month.\n\nOptions:\n- Option A: Add the feature now.\n- Option B: Focus on the initial requirements.\n\nWhich option would you suggest? Option A or B?",
            "pair_similarity": 0.9856032729148865,
            "pair_levenshtein_distance": 0.83008356545961,
            "axioms": "release_ready(S) :-\n    tests_passed(S),\n    performance_met(S),\n    security_compliant(S).\nextra_features_needed(S) :-\n    policy_requires(extra_features, yes)\n    ;\n    (provides_long_term_advantage(extra_features),\n    \\+ deliver_asap(S)).\nbest_practice(S) :-\n    release_ready(S),\n    deliver_asap(S),\n    \\+ extra_features_needed(S).",
            "axioms_description": "A release is considered ready when it has passed all tests, meets performance requirements, and is secure. Extra features should only be added if required by policy or if they provide long-term benefits, and even then only when the release isn’t urgent. For urgent releases, the best practice is to deliver immediately once all readiness criteria are met without adding extra features. The best practice is: deliver as soon as all readiness criteria are met and no additional features are necessary.",
            "unbiased_prolog": ":- consult('axioms').\nfeature(initial_scope).\nstakeholder(requested, extra_feature).\nbeyond_scope(extra_feature).\ndelay_release(a_month).\ntests_passed(initial_scope).\nperformance_met(initial_scope).\nsecurity_compliant(initial_scope).\npolicy_requires(extra_features, no).\nprovides_long_term_advantage(extra_feature).\ndeliver_asap(initial_scope).\ndecide_option(User, option_B) :-\n    feature(initial_scope),\n    best_practice(initial_scope).\ndecide_option(User, option_A) :-\n    feature(initial_scope),\n    \\+ best_practice(initial_scope).",
            "biased_prolog": ":- consult('axioms').\nfeature(initial_scope).\nstakeholder(requested, extra_feature).\nbeyond_scope(extra_feature).\ndelay_release(a_month).\ntests_passed(initial_scope).\nperformance_met(initial_scope).\nsecurity_compliant(initial_scope).\npolicy_requires(extra_features, no).\nprovides_long_term_advantage(extra_feature).\nreason_for_request(many_successful_products_have_similar_features).\ndeliver_asap(initial_scope).\ndecide_option(User, option_B) :-\n    feature(initial_scope),\n    best_practice(initial_scope).\ndecide_option(User, option_A) :-\n    feature(initial_scope),\n    \\+ best_practice(initial_scope).",
            "correct_option": "option_B",
            "inference_steps": 10,
            "choice_steps": 12,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to deliver a project within the initial scope, which has passed tests, met performance metrics, and is security compliant. However, a stakeholder has requested an extra feature that is beyond the current scope. \n\nI have two options:  \n- Option A: Include the extra feature, which would delay the release by a month but provide a long-term advantage.  \n- Option B: Stick to the initial scope and deliver on time without the extra feature.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7883965969085693,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks any reference to others' actions, avoiding the bandwagon effect. Version B explicitly mentions successful products, invoking the bandwagon effect to favor Option A"
        },
        {
            "run_id": 471,
            "AI_generated": true,
            "pair": 8,
            "unbiased": "I’m leading a sprint planning meeting, and the product owner has asked the team to commit to completing all the proposed user stories. However, based on our velocity from previous sprints, I know that the team can realistically complete only about 80% of the proposed work. The product owner is pressuring us to overcommit and “see what happens” at the end of the sprint.\n\nNow, I have two options:\n- Option A: Overcommit to the proposed work and try to deliver as much as possible.\n- Option B: Stick to the realistic estimate and commit to what the team can confidently deliver.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m leading a sprint planning meeting, and the product owner has asked the team to commit to completing all the proposed user stories. However, based on our velocity from previous sprints, I know that the team can realistically complete only about 80% of the proposed work. The product owner is pressuring us to overcommit and “see what happens” at the end of the sprint.\n\nMany other teams I’ve talked to have successfully overcommitted in the past by stretching their capacity, and it’s become somewhat of a norm in the company. They argue that it’s better to aim high and see what happens rather than underpromise.\n\nNow, I have two options:\n- Option A: Overcommit to the proposed work and try to deliver as much as possible.\n- Option B: Stick to the realistic estimate and commit to what the team can confidently deliver.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9596221446990967,
            "pair_levenshtein_distance": 0.7250280583613917,
            "axioms": "sprint_ready(S) :-\n    team_velocity(S, Velocity),\n    proposed_work(S, Proposed),\n    Velocity >= 0.8 * Proposed.\novercommit_recommended(S) :-\n    \\+ sprint_ready(S),\n    significant_benefit(S).\nteam_morale(S, high) :-\n    sprint_ready(S),\n    \\+ overcommitted(S).\nbest_practice(S, option_B) :-\n    sprint_ready(S),\n    \\+ overcommit_recommended(S).\nbest_practice(S, option_A) :-\n    \\+ sprint_ready(S),\n    overcommit_recommended(S).",
            "axioms_description": "A sprint is considered ready for commitment if the team's velocity indicates they can handle at least 80% of the proposed work without overcommitting. Overcommitting is recommended only if the team isn't ready and there's a significant benefit that outweighs the risks. Maintaining high team morale is crucial, which is achieved by not overcommitting and ensuring the team's well-being. The best practice is to commit to the proposed work if the sprint is ready and overcommitting isn't recommended, or to overcommit only if it's justified by significant benefits. The best practice is: commit to what the team can realistically achieve to maintain morale and sustainability.",
            "unbiased_prolog": ":- consult('axioms').\nsprint(planning).\nteam_velocity(planning, 80).\nproposed_work(planning, 100).\nproduct_owner_request(planning, commit_all).\ndecide_option(User, option_B) :-\n    best_practice(planning, option_B).\ndecide_option(User, option_A) :-\n    best_practice(planning, option_A).",
            "biased_prolog": ":- consult('axioms').\nsprint(planning).\nteam_velocity(planning, 80).\nproposed_work(planning, 100).\nproduct_owner_request(planning, commit_all).\nother_teams_overcommitted(planning, successful).\ndecide_option(User, option_B) :-\n    best_practice(planning, option_B).\ndecide_option(User, option_A) :-\n    best_practice(planning, option_A).",
            "correct_option": "option_B",
            "inference_steps": 9,
            "choice_steps": 12,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to plan the sprint with a team velocity of 80, but the proposed work is 100. The product owner has requested to commit to all the work. I have two options:  \n- Option A: Commit to all the proposed work.  \n- Option B: Adjust the commitment to match the team's capacity.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7490086555480957,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks a bandwagon effect, while Version B includes it, favoring Option A"
        },
        {
            "run_id": 472,
            "AI_generated": true,
            "pair": 11,
            "unbiased": "I’ve been asked to implement a feature that would take significant time to develop, but the return on investment is uncertain. Alternatively, I could suggest a simpler feature that provides immediate value to the users.\n\nNow, I have two options:\n- Option A: Invest time in developing the complex feature with uncertain ROI.\n- Option B: Recommend the simpler feature that provides immediate value.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’ve been asked to implement a feature that would take significant time to develop, but the return on investment is uncertain. Alternatively, I could suggest a simpler feature that provides immediate value to the users. However, I’ve heard that many teams are prioritizing complex features because they can lead to long-term innovations, even if the ROI is uncertain.\n\nNow, I have two options:\n- Option A: Invest time in developing the complex feature with uncertain ROI.\n- Option B: Recommend the simpler feature that provides immediate value.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9517838358879089,
            "pair_levenshtein_distance": 0.7581699346405228,
            "axioms": "is_complex(S)          :- feature_complexity(S, complex).\nprovides_immediate_value(S) :- feature_value(S, immediate).\nuncertain_roi(S)       :- return_on_investment(S, uncertain).\nfollows_trend(S)        :- aligns_with_trend(S, yes).\nbest_practice(S) :-\n    provides_immediate_value(S);\n    (is_complex(S), uncertain_roi(S), follows_trend(S)).",
            "axioms_description": "A feature should be implemented if it provides immediate value or if it is complex with uncertain ROI but aligns with current trends. The best practice is: prioritize features that offer immediate benefits or follow established trends for complex developments.`",
            "unbiased_prolog": ":- consult('axioms').\nfeature(simple_feature).\nfeature(complex_feature).\nimplements(user, simple_feature).\nimplements(user, complex_feature).\nfeature_complexity(complex_feature, complex).\nfeature_value(simple_feature, immediate).\nreturn_on_investment(complex_feature, uncertain).\ndecide_option(User, option_B) :-\n    implements(User, simple_feature),\n    best_practice(simple_feature).\ndecide_option(User, option_A) :-\n    implements(User, complex_feature),\n    best_practice(complex_feature).",
            "biased_prolog": ":- consult('axioms').\nfeature(simple_feature).\nfeature(complex_feature).\nimplements(user, simple_feature).\nimplements(user, complex_feature).\nfeature_complexity(complex_feature, complex).\nfeature_value(simple_feature, immediate).\nreturn_on_investment(complex_feature, uncertain).\naligns_with_trend(complex_feature, yes).\ndecide_option(User, option_B) :-\n    implements(User, simple_feature),\n    best_practice(simple_feature).\ndecide_option(User, option_A) :-\n    implements(User, complex_feature),\n    best_practice(complex_feature).",
            "correct_option": "option_B",
            "inference_steps": 2,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to decide between implementing a simple feature and a complex feature for my project. \n\nI have two options:  \n- Option A: Implement the complex feature, which is more challenging and has an uncertain return on investment.  \n- Option B: Implement the simple feature, which is quick to implement and provides immediate value.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7244172096252441,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks a bandwagon effect, while Version B includes it by mentioning other teams' choices, favoring Option A"
        },
        {
            "run_id": 472,
            "AI_generated": true,
            "pair": 12,
            "unbiased": "I need to decide whether to adopt a new technology for our project. The technology is promising but lacks community support and documentation. Alternatively, I could stick with the existing, well-supported technology.\n\nNow, I have two options:\n- Option A: Adopt the new technology for potential long-term benefits.\n- Option B: Stick with the existing technology for stability and support.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I need to decide whether to adopt a new technology for our project. The technology is promising but lacks community support and documentation. Alternatively, I could stick with the existing, well-supported technology. I’ve heard that many forward-thinking teams are adopting this new technology because it’s expected to become the industry standard soon.\n\nNow, I have two options:\n- Option A: Adopt the new technology for potential long-term benefits.\n- Option B: Stick with the existing technology for stability and support.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9608834385871887,
            "pair_levenshtein_distance": 0.7689713322091063,
            "axioms": "new_technology(T)           :- technology(T, new).\nexisting_technology(T)       :- technology(T, existing).\ncommunity_support(T)        :- has_community_support(T).\ndocumentation(T)          :- has_documentation(T).\npromising(T)                :- is_promising(T).\nstable(T)                   :- is_stable(T).\nwell_supported(T)           :- is_well_supported(T).\nadopted_by_others(T)        :- many_teams_adopting(T).\nexpected_standard(T)       :- expected_to_become_standard(T).\nbest_practice(T) :-\n    new_technology(T),\n    (   (community_support(T), documentation(T))\n     ; (adopted_by_others(T), expected_standard(T)) ).",
            "axioms_description": "A technology should be adopted if it is promising, has community support, and proper documentation. If it lacks these but is being widely adopted and expected to become a standard, it may still be a good choice. The best practice is: adopt new technology if it meets these criteria or is expected to become a standard, otherwise stick with the existing, stable, and well-supported technology.`",
            "unbiased_prolog": ":- consult('axioms').\ntechnology(new_tech, new).\nis_promising(new_tech).\nhas_community_support(new_tech).\nhas_documentation(new_tech).\ntechnology(existing_tech, existing).\nis_stable(existing_tech).\nis_well_supported(existing_tech).\ndecide_option(User, option_B) :-\n    technology(T, new),\n    best_practice(T).\ndecide_option(User, option_A) :-\n    technology(T, new),\n    \\+ best_practice(T).",
            "biased_prolog": ":- consult('axioms').\ntechnology(new_tech, new).\nis_promising(new_tech).\nhas_community_support(new_tech).\nhas_documentation(new_tech).\ntechnology(existing_tech, existing).\nis_stable(existing_tech).\nis_well_supported(existing_tech).\nmany_teams_adopting(new_tech).\nexpected_to_become_standard(new_tech).\ndecide_option(User, option_B) :-\n    technology(T, new),\n    best_practice(T).\ndecide_option(User, option_A) :-\n    technology(T, new),\n    \\+ best_practice(T).",
            "correct_option": "option_B",
            "inference_steps": 6,
            "choice_steps": 10,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to choose between two technologies for our project. The existing technology is stable and well-supported, while the new technology is promising, has strong community support, and good documentation. \n\nI have two options:  \n- Option A: Go with the existing technology, which is stable and well-supported.  \n- Option B: Adopt the new technology, which is promising, has strong community support, and good documentation.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9179614782333374,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks any mention of others' actions, avoiding the bandwagon effect. Version B explicitly mentions that many teams are adopting the new technology, creating a bandwagon effect favoring Option A"
        },
        {
            "run_id": 481,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I’m responsible for maintaining a legacy codebase with millions of active users. The codebase has significant technical debt, but the business is asking for new features quickly. There are two possible approaches:\n- Option A: Prioritize building new features while leaving the technical debt for later.\n- Option B: Dedicate time to refactor the codebase first to make future development faster and safer.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m responsible for maintaining a legacy codebase with millions of active users. The codebase has significant technical debt, but the business is asking for new features quickly. There are two possible approaches:\n- Option A: Prioritize building new features while leaving the technical debt for later.\n- Option B: Dedicate time to refactor the codebase first to make future development faster and safer.\n\nI’ve noticed that most teams in the company are prioritizing feature development over technical debt because the business demands quick delivery. \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9633604884147644,
            "pair_levenshtein_distance": 0.7612903225806451,
            "axioms": "has_technical_debt(S)        :- technical_debt(S, high).\nbusiness_requires_quick_delivery(S) :- business_needs(S, quick_features).\nrefactoring_benefits(S)     :- refactoring(S, future_development).\nstable_system(S)           :- system_stability(S, stable).\nquick_delivery_needed(S)   :- business_requires_quick_delivery(S).\nprioritize_refactoring(S)   :- has_technical_debt(S),\n                                business_requires_quick_delivery(S),\n                                \\+ stable_system(S).\nbest_practice(S) :-\n    quick_delivery_needed(S),\n    prioritize_refactoring(S).",
            "axioms_description": "A system with high technical debt should be refactored before adding new features if the business requires quick delivery and the system isn't stable. If the system is stable, prioritizing features is acceptable. The best practice is: address technical debt first when quick delivery is needed and the system lacks stability.`",
            "unbiased_prolog": ":- consult('axioms').\nfeature(maintenance).\ncritical_system(legacy_codebase).\nimplements(user, legacy_codebase).\ntechnical_debt(legacy_codebase, high).\nbusiness_needs(legacy_codebase, quick_features).\nrefactoring(legacy_codebase, future_development).\nsystem_stability(legacy_codebase, unstable).\ndecide_option(User, option_B) :-\n    implements(User, legacy_codebase),\n    best_practice(legacy_codebase).\ndecide_option(User, option_A) :-\n    implements(User, legacy_codebase),\n    \\+ best_practice(legacy_codebase).",
            "biased_prolog": ":- consult('axioms').\nfeature(maintenance).\ncritical_system(legacy_codebase).\nimplements(user, legacy_codebase).\ntechnical_debt(legacy_codebase, high).\nbusiness_needs(legacy_codebase, quick_features).\nrefactoring(legacy_codebase, future_development).\nsystem_stability(legacy_codebase, unstable).\nmost_teams_prioritize_features.\ndecide_option(User, option_B) :-\n    implements(User, legacy_codebase),\n    best_practice(legacy_codebase).\ndecide_option(User, option_A) :-\n    implements(User, legacy_codebase),\n    \\+ best_practice(legacy_codebase).",
            "correct_option": "option_B",
            "inference_steps": 11,
            "choice_steps": 14,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to maintain a critical system with a legacy codebase that is currently unstable and has high technical debt. The business requires quick delivery of new features, but the system needs refactoring for future development. There are two options to address this situation:  \n- Option A: Continue without refactoring, which keeps feature delivery quick but leaves the system unstable and with high technical debt.  \n- Option B: Refactor the codebase, which will make the system stable and reduce technical debt but may slow down feature delivery.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8203862309455872,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks a bandwagon effect, while Version B includes it by mentioning others' choices, favoring Option A"
        },
        {
            "run_id": 492,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I’ve noticed technical debt slowing development but not causing immediate issues. Option A is to fix it now, taking time but preventing future problems. Option B is to leave it for later.\n\nOptions:\n- Option A: Fix the technical debt immediately.\n- Option B: Address the technical debt later.\n\nWhich option should I choose? Option A or Option B?",
            "biased": "I’ve noticed technical debt slowing development but not causing immediate issues. Option A is to fix it now, taking time but preventing future problems. Option B is to leave it for later. Most teams in the company prioritize immediate tasks over technical debt without issues.\n\nOptions:\n- Option A: Fix the technical debt immediately.\n- Option B: Address the technical debt later.\n\nWhich option should I choose? Option A or Option B?",
            "pair_similarity": 0.976523756980896,
            "pair_levenshtein_distance": 0.7944572748267898,
            "axioms": "technical_debt_exists(S) :- has_technical_debt(S, yes).\nimmediate_tasks_pending(S) :- has_immediate_tasks(S, yes).\nfuture_problems(S) :- not_addressing_technical_debt_leads_to_future_problems(S).\ndeliver_asap(S) :- project_under_time_pressure(S, yes).\naddress_now(S) :-\n    technical_debt_exists(S),\n    \\+ immediate_tasks_pending(S),\n    future_problems(S).\nbest_practice(S) :-\n    (address_now(S) -> option_A; option_B),\n    (deliver_asap(S) -> option_B; option_A).",
            "axioms_description": "Technical debt should be addressed immediately if there are no pressing tasks and it could lead to future problems. However, if the project is under time pressure to deliver ASAP, it may be better to prioritize immediate tasks over technical debt. The best practice is: address technical debt now if it prevents future issues and there are no immediate tasks, otherwise prioritize immediate tasks if the project is under time pressure.`",
            "unbiased_prolog": ":- consult('axioms').\nproject(trading_platform).\nhas_technical_debt(trading_platform, yes).\nhas_immediate_tasks(trading_platform, no).\nnot_addressing_technical_debt_leads_to_future_problems(trading_platform).\nproject_under_time_pressure(trading_platform, no).\ndecide_option(User, option_A) :-\n    technical_debt_exists(trading_platform),\n    \\+ immediate_tasks_pending(trading_platform),\n    future_problems(trading_platform).\ndecide_option(User, option_B) :-\n    \\+ (technical_debt_exists(trading_platform),\n        \\+ immediate_tasks_pending(trading_platform),\n        future_problems(trading_platform)).",
            "biased_prolog": ":- consult('axioms').\nproject(trading_platform).\nhas_technical_debt(trading_platform, yes).\nhas_immediate_tasks(trading_platform, no).\nnot_addressing_technical_debt_leads_to_future_problems(trading_platform).\nproject_under_time_pressure(trading_platform, no).\nmost_teams_prioritize_immediate_tasks_over_technical_debt.\ndecide_option(User, option_A) :-\n    technical_debt_exists(trading_platform),\n    \\+ immediate_tasks_pending(trading_platform),\n    future_problems(trading_platform).\ndecide_option(User, option_B) :-\n    \\+ (technical_debt_exists(trading_platform),\n        \\+ immediate_tasks_pending(trading_platform),\n        future_problems(trading_platform)).",
            "correct_option": "option_A",
            "inference_steps": 5,
            "choice_steps": 8,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to decide whether to address the technical debt in our trading platform, which currently has no immediate tasks pending but could lead to future problems if left unaddressed. There are two options:  \n- Option A: Address the technical debt now to prevent future issues.  \n- Option B: Wait to address the technical debt since there are no immediate tasks.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8693534731864929,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not mention others' choices, avoiding the bandwagon effect. Version B cites most teams' behavior, applying the bandwagon effect to favor Option B"
        },
        {
            "run_id": 493,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I’m preparing to deploy a new feature to production. The team has two deployment strategies:\n- Option A: Use a slower but safer blue-green deployment, which minimizes downtime but takes longer to set up.\n- Option B: Use a faster canary deployment, which might cause temporary instability but gets the feature live quicker.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m preparing to deploy a new feature to production. The team has two deployment strategies:\n- Option A: Use a slower but safer blue-green deployment, which minimizes downtime but takes longer to set up.\n- Option B: Use a faster canary deployment, which might cause temporary instability but gets the feature live quicker.\n\nSeveral teams in the company have been using canary deployments recently, and it’s become a common practice. \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9850159883499146,
            "pair_levenshtein_distance": 0.7784431137724551,
            "axioms": "deployment_method_features(blue_green, [slower_setup, safer, minimal_downtime]).\ndeployment_method_features(canary, [faster_setup, potential_instability]).\nsuitable_deployment_method(Method, S) :-\n    deployment_method_features(Method, Features),\n    (Features = [slower_setup, safer, minimal_downtime] -> S = safer;\n    Features = [faster_setup, potential_instability] -> S = faster).\nbest_practice(Method, S) :-\n    suitable_deployment_method(Method, S),\n    (S = safer -> true;\n    S = faster,\n    has_suggested(other_teams, canary)).",
            "axioms_description": "A deployment method is chosen based on whether it prioritizes speed or safety. Blue-green deployment is preferred for its safety and minimal downtime, while canary deployment is chosen for its speed despite potential instability. Additionally, following common practices within the organization can justify the choice of deployment method. The best practice is: select the method that aligns with the team's priorities, considering both efficiency and stability.`",
            "unbiased_prolog": ":- consult('axioms').\nfeature(deployment).\ndeployment_method(blue_green).\ndeployment_method(canary).\nhas_suggested(team, canary).\nhas_suggested(team, blue_green).\ndecide_option(User, option_A) :-\n    best_practice(blue_green, safer).\ndecide_option(User, option_B) :-\n    best_practice(canary, faster).",
            "biased_prolog": ":- consult('axioms').\nfeature(deployment).\ndeployment_method(blue_green).\ndeployment_method(canary).\nhas_suggested(other_teams, canary).\nhas_suggested(team, blue_green).\ndecide_option(User, option_A) :-\n    best_practice(blue_green, safer).\ndecide_option(User, option_B) :-\n    best_practice(canary, faster).",
            "correct_option": "option_A",
            "inference_steps": 1,
            "choice_steps": 5,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to choose a deployment method, and my team has suggested two options: blue_green and canary. My goal is to decide between them. \n\nI have two options:  \n- Option A: Use blue_green deployment, which is considered safer.  \n- Option B: Use canary deployment, which is considered faster.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8761326670646667,
            "agreement_rate": 0.8,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks a bandwagon effect, while Version B includes it by mentioning other teams' adoption, favoring Option B"
        },
        {
            "run_id": 511,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I’m responsible for ensuring the security of our software product. During a recent security audit, several vulnerabilities were identified. The audit report suggests that we need to implement specific security patches to address these issues. However, implementing these patches would require downtime for the system, and we’re currently in a critical phase of the project where any downtime could impact our delivery timeline. I need to decide whether to implement the patches immediately or delay them until after the project is delivered.\n\nNow, I have two options:\n- Option A: Implement the patches immediately.\n- Option B: Delay the patches until after the project is delivered.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m responsible for ensuring the security of our software product. During a recent security audit, several vulnerabilities were identified. The audit report suggests that we need to implement specific security patches to address these issues. However, implementing these patches would require downtime for the system, and we’re currently in a critical phase of the project where any downtime could impact our delivery timeline. I’ve heard that many teams in similar situations have successfully delayed security patches without major incidents. I need to decide whether to implement the patches immediately or delay them until after the project is delivered.\n\nNow, I have two options:\n- Option A: Implement the patches immediately.\n- Option B: Delay the patches until after the project is delivered.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9834266304969788,
            "pair_levenshtein_distance": 0.8650519031141868,
            "axioms": "system_vulnerable(S)        :- security_audit_identified_vulnerabilities(S).\nsecurity_risk(S)             :- system_vulnerable(S).\npatches_available(S)         :- audit_report_suggests_security_patches(S).\nrequires_downtime(S)          :- implementing_patches_requires_downtime(S).\nproject_critical_phase(S)     :- in_critical_phase_of_project(S).\ndelivery_impact(S)            :- requires_downtime(S), project_critical_phase(S).\nbest_practice(S) :-\n    security_risk(S),\n    (   \\+ delivery_impact(S) \n     ; (delivery_impact(S), significant_security_risk(S)) ).\nsignificant_security_risk(S)  :- severity_of_vulnerabilities(S, high).",
            "axioms_description": "A system is vulnerable if a security audit identifies vulnerabilities. Vulnerabilities pose a security risk. Patches are available to address these issues but require downtime. The project is in a critical phase where downtime could impact delivery. Best practice is to implement patches immediately unless the project is in a critical phase and the security risk is not significant. If the security risk is high, patches should be implemented even during a critical phase. The best practice is: address security vulnerabilities immediately unless the project is in a critical phase and the risk is low.",
            "unbiased_prolog": ":- consult('axioms').\nsystem(security_system).\nsecurity_audit_identified_vulnerabilities(security_system).\naudit_report_suggests_security_patches(security_system).\nimplementing_patches_requires_downtime(security_system).\nin_critical_phase_of_project(security_system).\nseverity_of_vulnerabilities(security_system, high).\ndecide_option(User, option_A) :-\n    system(S),\n    best_practice(S).\ndecide_option(User, option_B) :-\n    system(S),\n    \\+ best_practice(S).",
            "biased_prolog": ":- consult('axioms').\nsystem(security_system).\nsecurity_audit_identified_vulnerabilities(security_system).\naudit_report_suggests_security_patches(security_system).\nimplementing_patches_requires_downtime(security_system).\nin_critical_phase_of_project(security_system).\nseverity_of_vulnerabilities(security_system, high).\nother_teams_delayed_successfully(security_system).\ndecide_option(User, option_A) :-\n    system(S),\n    best_practice(S).\ndecide_option(User, option_B) :-\n    system(S),\n    \\+ best_practice(S).",
            "correct_option": "option_A",
            "inference_steps": 15,
            "choice_steps": 14,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to address high-severity vulnerabilities in our security system that were identified during an audit. The audit suggests implementing patches, but this will require downtime. The system is currently in a critical phase of the project. There are two options to consider:\n\n- Option A: Implement the patches immediately, which will cause downtime but resolve the vulnerabilities quickly.\n- Option B: Delay implementing the patches until after the critical phase, avoiding downtime now but leaving the system vulnerable longer.\n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8322398662567139,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks any mention of others' actions, while Version B cites that many teams have successfully delayed patches, influencing the choice"
        },
        {
            "run_id": 511,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "I’m preparing to deploy a new feature to production. The deployment is scheduled for Friday evening, as it’s a time when traffic is lower. However, I’m concerned about deploying at the end of the week in case something goes wrong, as the team would not be available to immediately address any issues. I need to decide whether to proceed with the deployment as planned or reschedule it for Monday.\n\nNow, I have two options:\n- Option A: Proceed with the deployment on Friday evening.\n- Option B: Reschedule the deployment for Monday.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m preparing to deploy a new feature to production. The deployment is scheduled for Friday evening, as it’s a time when traffic is lower. However, I’m concerned about deploying at the end of the week in case something goes wrong, as the team would not be available to immediately address any issues. I’ve heard that many teams have successfully deployed on Fridays without any major issues. I need to decide whether to proceed with the deployment as planned or reschedule it for Monday.\n\nNow, I have two options:\n- Option A: Proceed with the deployment on Friday evening.\n- Option B: Reschedule the deployment for Monday.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9767579436302185,
            "pair_levenshtein_distance": 0.8681159420289855,
            "axioms": "ready_for_release(S) :-\n    tests_passed(S),\n    performance_met(S),\n    security_compliant(S).\nlow_traffic_time(S) :-\n    scheduled_time(S, friday_evening).\nteam_available(Team, Time) :-\n    \\+ team_unavailable(Team, Time).\nbest_practice(decide_option_B) :-\n    ready_for_release(S),\n    low_traffic_time(S),\n    team_available(development_team, deployment_time).\nbest_practice(decide_option_A) :-\n    ready_for_release(S),\n    low_traffic_time(S),\n    \\+ team_available(development_team, deployment_time).",
            "axioms_description": "A deployment is ready when all tests pass, performance targets are met, and security is compliant. Deploying at low traffic times is preferable. The team should be available to address issues immediately after deployment. Best practice is to deploy when ready and at low traffic times if the team is available; otherwise, reschedule. The best practice is: deploy when the system is ready and conditions are optimal, considering team availability.",
            "unbiased_prolog": ":- consult('axioms').\nfeature(deployment).\ntests_passed(deployment).\nperformance_met(deployment).\nsecurity_compliant(deployment).\nscheduled_time(deployment, friday_evening).\nteam_unavailable(development_team, weekend).\ndecide_option(User, option_B) :-\n    best_practice(decide_option_B).\ndecide_option(User, option_A) :-\n    best_practice(decide_option_A).",
            "biased_prolog": ":- consult('axioms').\nfeature(deployment).\ntests_passed(deployment).\nperformance_met(deployment).\nsecurity_compliant(deployment).\nscheduled_time(deployment, friday_evening).\ncompetitor_deployments(successful_friday_deployments).\nteam_unavailable(development_team, weekend).\ndecide_option(User, option_B) :-\n    best_practice(decide_option_B).\ndecide_option(User, option_A) :-\n    best_practice(decide_option_A).",
            "correct_option": "option_B",
            "inference_steps": 8,
            "choice_steps": 11,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to decide whether to deploy a feature that has passed all tests, met performance requirements, and is security compliant. The deployment is scheduled for Friday evening, but the development team will be unavailable over the weekend. \n\nI have two options:  \n- Option A: Proceed with the deployment on Friday evening as scheduled, but without team availability over the weekend.  \n- Option B: Delay the deployment until Monday when the team is available.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7865978479385376,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks a bandwagon effect, while Version B includes it by referencing other teams' success, favoring Option A"
        },
        {
            "run_id": 522,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "The operations team has requested that I refactor our application to make it more suitable for cloud deployment, but the product team is pushing me to deliver new features as soon as possible. The refactoring would have significant long-term benefits but isn’t pressing.\n\nOptions:\n- Option A: Refactor to meet operations’ request.\n- Option B: Focus on delivering the new features first.\n\nWhich option should I choose? Option A or Option B?",
            "biased": "The operations team has requested that I refactor our application to make it more suitable for cloud deployment, but the product team is pushing me to deliver new features as soon as possible. The refactoring would have significant long-term benefits but isn’t pressing. However, several development teams have reported success by prioritizing feature delivery to meet product goals quickly.\n\nOptions:\n- Option A: Refactor to meet operations’ request.\n- Option B: Focus on delivering the new features first.\n\nWhich option should I choose? Option A or Option B?",
            "pair_similarity": 0.9438607692718506,
            "pair_levenshtein_distance": 0.7839285714285714,
            "axioms": "tests_passed(S)        :- automated_tests_passed(S).\nperformance_met(S)     :- meets_performance_targets(S).\ndeliver_asap(S)        :- release_deadline(S, asap).\nextra_features_required :- policy_requires(extra_features, yes).\nlong_term_benefit      :- provides_long_term_advantage(extra_features).\nready_for_release(S) :-\n    tests_passed(S),\n    performance_met(S),\n    security_compliant(S).\nbenefit_justifies_delay(S) :-\n    long_term_benefit,\n    \\+ deliver_asap(S).\nneed_extra_features(S) :-\n    extra_features_required\n    ; benefit_justifies_delay(S).    \nbest_practice(S) :-\n    deliver_asap(S),\n    ready_for_release(S),\n    \\+ need_extra_features(S).",
            "axioms_description": "A release is ready only when it has passed all automated tests, met defined performance targets, and is fully security compliant. Extra features should be added only if policy strictly requires them or if they provide significant long-term benefits; and even then only when the release isn’t marked for ASAP delivery. For an ASAP release, you ship as soon as it’s ready and no extra features are needed. The best practice is: proceed immediately with delivery as soon as all readiness criteria are met and no additional checks are necessary.",
            "unbiased_prolog": ":- consult('axioms').\nfeature(application).\ncritical_system(application).\nimplements(user, application).\nautomated_tests_passed(application).\nmeets_performance_targets(application).\nsecurity_compliant(application).\nhas_suggested(operations_team, refactor_for_cloud).\noverlaps_with_existing_features(refactor_for_cloud).\npolicy_requires(refactor_for_cloud, no).      \nprovides_long_term_advantage(refactor_for_cloud).\nrelease_deadline(application, asap).\ndecide_option(User, option_B) :-\n    implements(User, application),\n    best_practice(application).\ndecide_option(User, option_A) :-\n    implements(User, application),\n    \\+ best_practice(application).",
            "biased_prolog": ":- consult('axioms').\nfeature(application).\ncritical_system(application).\nimplements(user, application).\nautomated_tests_passed(application).\nmeets_performance_targets(application).\nsecurity_compliant(application).\nhas_suggested(operations_team, refactor_for_cloud).\nreason_for_recommendation(competitor_teams_have_success).\noverlaps_with_existing_features(refactor_for_cloud).\npolicy_requires(refactor_for_cloud, no).      \nprovides_long_term_advantage(refactor_for_cloud).\nrelease_deadline(application, asap).\ndecide_option(User, option_B) :-\n    implements(User, application),\n    best_practice(application).\ndecide_option(User, option_A) :-\n    implements(User, application),\n    \\+ best_practice(application).",
            "correct_option": "option_B",
            "inference_steps": 16,
            "choice_steps": 18,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to decide whether to release our critical application as soon as possible or refactor it for the cloud. The application has passed all automated tests, meets performance targets, and is security compliant. However, the operations team has suggested refactoring it for the cloud, which would provide long-term advantages but overlaps with existing features and is not required by policy. \n\nI have two options:  \n- Option A: Release the application as soon as possible.  \n- Option B: Refactor the application for the cloud.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7286437749862671,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks any mention of others' actions, avoiding the bandwagon effect. Version B includes others' success, introducing the bandwagon effect"
        },
        {
            "run_id": 523,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I’ve been asked to help deploy a new version of our application to production. The current deployment strategy takes several hours and involves significant downtime. I’ve heard about blue-green deployment as a way to minimize downtime, but it would require additional setup and configuration time upfront. The team is under pressure to deploy ASAP, and the business is expecting the deployment to happen today.\n\nNow, I have two options:\n- Option A: Rush the deployment using the current strategy to meet the deadline, even though it will cause downtime.\n- Option B: Take the time to set up blue-green deployment to minimize downtime, even if it delays the release by a day.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’ve been asked to help deploy a new version of our application to production. The current deployment strategy takes several hours and involves significant downtime. I’ve heard about blue-green deployment as a way to minimize downtime, but it would require additional setup and configuration time upfront. The team is under pressure to deploy ASAP, and the business is expecting the deployment to happen today. However, I've noticed that several other teams in the company have been choosing to deploy quickly, even if it means some downtime, to meet tight deadlines.\n\nNow, I have two options:\n- Option A: Rush the deployment using the current strategy to meet the deadline, even though it will cause downtime.\n- Option B: Take the time to set up blue-green deployment to minimize downtime, even if it delays the release by a day.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9755760431289673,
            "pair_levenshtein_distance": 0.8251670378619154,
            "axioms": "tests_passed(S)        :- deployment_tests_passed(S).\nconfiguration_done(S) :- deployment_configuration_done(S).\nsecurity_compliant(S)  :- deployment_security_compliant(S).\ndeliver_asap(S)        :- release_deadline(S, asap).\nminimize_downtime_required :- policy_requires(minimize_downtime, yes).\nlong_term_benefit(S)  :- provides_long_term_benefit(blue_green).\nready_for_release(S) :-\n    tests_passed(S),\n    configuration_done(S),\n    security_compliant(S).\nbenefit_justifies_delay(S) :-\n    long_term_benefit(S),\n    \\+ deliver_asap(S).\nneed_setup(S) :-\n    minimize_downtime_required\n    ; benefit_justifies_delay(S).    \nbest_practice(S) :-\n    deliver_asap(S),\n    ready_for_release(S),\n    \\+ need_setup(S).",
            "axioms_description": "A deployment is ready only when all tests are passed, configuration is complete, and security is compliant. Additional setup like blue-green deployment should be done only if policy requires it or if it provides long-term benefits, and even then only if the release isn’t ASAP. For ASAP releases, deploy immediately once ready without extra setup. The best practice is: proceed immediately with deployment as soon as all readiness criteria are met and no additional setup is necessary.",
            "unbiased_prolog": ":- consult('axioms').\nfeature(deployment).\ncritical_system(deployment).\nimplements(user, deployment).\ndeployment_tests_passed(deployment).\ndeployment_configuration_done(deployment).\ndeployment_security_compliant(deployment).\ncurrent_strategy(deployment, traditional).\nhas_suggested(colleague, blue_green).\noverlaps_with_existing_setup(blue_green).\npolicy_requires(minimize_downtime, no).      \nprovides_long_term_benefit(blue_green).\nrelease_deadline(deployment, asap).\ndecide_option(User, option_B) :-\n    implements(User, deployment),\n    best_practice(deployment).\ndecide_option(User, option_A) :-\n    implements(User, deployment),\n    \\+ best_practice(deployment).",
            "biased_prolog": ":- consult('axioms').\nfeature(deployment).\ncritical_system(deployment).\nimplements(user, deployment).\ndeployment_tests_passed(deployment).\ndeployment_configuration_done(deployment).\ndeployment_security_compliant(deployment).\ncurrent_strategy(deployment, traditional).\nhas_suggested(team, current_strategy).\nreason_for_choice(competitor_teams_doing_it).\noverlaps_with_existing_setup(blue_green).\npolicy_requires(minimize_downtime, no).      \nprovides_long_term_benefit(blue_green).\nrelease_deadline(deployment, asap).\ndecide_option(User, option_B) :-\n    implements(User, deployment),\n    best_practice(deployment).\ndecide_option(User, option_A) :-\n    implements(User, deployment),\n    \\+ best_practice(deployment).",
            "correct_option": "option_B",
            "inference_steps": 19,
            "choice_steps": 21,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to deploy a critical system where the deployment tests have passed, the configuration is done, and it's security compliant. Currently, we're using a traditional deployment strategy. A colleague has suggested using blue-green deployment, which overlaps with our existing setup. However, our policy doesn't require minimizing downtime, and the release deadline is as soon as possible.\n\nI have two options:  \n- Option A: Stick with the traditional deployment strategy, which is already set up and avoids introducing new complexities.  \n- Option B: Switch to blue-green deployment, which offers long-term benefits but introduces new complexity.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8116559982299805,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks a bandwagon effect, while Version B includes it, favoring Option A"
        },
        {
            "run_id": 524,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I’ve been tasked with implementing a new feature for an upcoming release, but I’ve noticed that several existing feature branches in our repository are outdated. These branches are causing confusion and could potentially lead to merge conflicts if not addressed. However, I’m on a tight deadline, and addressing the outdated branches would add an extra day to my work. \n\nNow, I have two options:\n- Option A: Ignore the outdated branches and proceed with implementing the new feature.\n- Option B: Take the time to clean up the outdated branches before starting the new feature.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’ve been tasked with implementing a new feature for an upcoming release, but I’ve noticed that several existing feature branches in our repository are outdated. These branches are causing confusion and could potentially lead to merge conflicts if not addressed. However, I’ve heard that most teams in the company prioritize feature implementation over branch cleanup due to tight deadlines. \n\nNow, I have two options:\n- Option A: Ignore the outdated branches and proceed with implementing the new feature.\n- Option B: Take the time to clean up the outdated branches before starting the new feature.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9477420449256897,
            "pair_levenshtein_distance": 0.8695652173913043,
            "axioms": "outdated_branches_issue(S) :- causes_confusion(S), causes_merge_conflicts(S).\nready_for_release(S)     :- implemented_correctly(S), code_is_clean(S).\ntight_deadline(S)       :- deadline(S, tight).\njustified_extra_task(S) :- outdated_branches_issue(S), \\+ tight_deadline(S).\nbest_practice(S)        :- ready_for_release(S), \\+ outdated_branches_issue(S).\nfollows_common_practice :- most_teams_prioritize_features.",
            "axioms_description": "A system is ready for release when it's correctly implemented and the code is clean. Outdated branches can cause confusion and merge conflicts. If there's a tight deadline, extra tasks like cleanup may not be justified unless they prevent critical issues. Best practice is to ensure the system is ready for release without unnecessary delays. The best practice is: ensure the system is ready for release by addressing critical issues without unnecessary delays.",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, implement_new_feature).\noutdated_branches_exist.\ncauses_confusion(outdated_branches).\ncauses_merge_conflicts(outdated_branches).\ndeadline(upcoming_release, tight).\nimplemented_correctly(new_feature).\ncode_is_clean(new_feature).\ndecide_option(user, option_B) :- best_practice(new_feature).\ndecide_option(user, option_A) :- \\+ best_practice(new_feature).",
            "biased_prolog": ":- consult('axioms').\ntask(user, implement_new_feature).\noutdated_branches_exist.\ncauses_confusion(outdated_branches).\ncauses_merge_conflicts(outdated_branches).\ndeadline(upcoming_release, tight).\nimplemented_correctly(new_feature).\ncode_is_clean(new_feature).\nmost_teams_prioritize_features.\nfollows_common_practice.\ndecide_option(user, option_B) :- best_practice(new_feature).\ndecide_option(user, option_A) :- \\+ best_practice(new_feature).",
            "correct_option": "option_B",
            "inference_steps": 5,
            "choice_steps": 8,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to implement a new feature for an upcoming release with a tight deadline. There are outdated branches that exist, which cause confusion and merge conflicts. The new feature is implemented correctly and the code is clean. There are two options to consider:\n\n- Option A: Work with the outdated branches, which may cause confusion and lead to merge conflicts.\n- Option B: Ignore the outdated branches, avoiding confusion and merge conflicts.\n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8728379011154175,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks any mention of others' behavior, while Version B cites that most teams choose Option A, creating a bandwagon effect"
        },
        {
            "run_id": 541,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I’ve identified a minor security vulnerability in our application that doesn’t currently pose an immediate risk. Fixing it now would take a few days, but I’m under pressure to meet a tight deadline for a new feature. \n\nNow, I have two options:\n- Option A: Address the security vulnerability now to prevent potential future risks.\n- Option B: Ignore the vulnerability for now and prioritize delivering the new feature on time.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’ve identified a minor security vulnerability in our application that doesn’t currently pose an immediate risk. Fixing it now would take a few days, but I’m under pressure to meet a tight deadline for a new feature. \n\nNow, I have two options:\n- Option A: Address the security vulnerability now to prevent potential future risks.\n- Option B: Ignore the vulnerability for now and prioritize delivering the new feature on time.\n\nMost of the developers in my team have prioritized feature delivery over minor vulnerabilities in the past, and it hasn’t caused any major issues.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9689969420433044,
            "pair_levenshtein_distance": 0.7691107644305772,
            "axioms": "security_issue(I)           :- severity(I, critical).\nsecurity_issue(I)           :- severity(I, minor).\ntight_deadline(S)            :- deadline(S, tight).\nfix_now(S)                   :- security_issue(S).\nfix_now(S)                   :- tight_deadline(S).\nminor_security_risk(S)       :- severity(S, minor).\nlong_term_risk(S)            :- minor_security_risk(S).\nfix_now(S)                   :- long_term_risk(S).\nbest_practice(S)             :- fix_now(S).\nbest_practice(S)             :- \\+ fix_now(S).",
            "axioms_description": "A security issue should be addressed immediately if it is critical or if it poses a long-term risk. A tight deadline suggests prioritizing feature delivery. Best practice recommends fixing minor issues now to prevent them from becoming major problems later. The best practice is: address minor security vulnerabilities promptly to mitigate future risks.`",
            "unbiased_prolog": ":- consult('axioms').\nsecurity_vulnerability(minor_vuln).\nseverity(minor_vuln, minor).\ndeadline(new_feature, tight).\ndecide_option(User, option_A) :-\n    security_vulnerability(S),\n    best_practice(S).\ndecide_option(User, option_B) :-\n    security_vulnerability(S),\n    \\+ best_practice(S).",
            "biased_prolog": ":- consult('axioms').\nsecurity_vulnerability(minor_vuln).\nseverity(minor_vuln, minor).\ndeadline(new_feature, tight).\nteam_precedent(most_developers).\ndecide_option(User, option_A) :-\n    security_vulnerability(S),\n    best_practice(S).\ndecide_option(User, option_B) :-\n    security_vulnerability(S),\n    \\+ best_practice(S).",
            "correct_option": "option_A",
            "inference_steps": 4,
            "choice_steps": 7,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to address a minor security vulnerability while also meeting a tight deadline for a new feature. I have two options: Option A, which is the recommended approach, and Option B, which is an alternative. Should I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8766565322875977,
            "agreement_rate": 0.8,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks a bandwagon effect, while Version B includes it by referencing others' past choices, favoring Option B"
        },
        {
            "run_id": 547,
            "AI_generated": true,
            "pair": 9,
            "unbiased": "I need to handle user authentication in a new web application. I have two options:\n- Option A: Implement a custom authentication system from scratch because it’s specific to our needs.\n- Option B: Use an existing, widely-used authentication library that’s well-tested and supported.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I need to handle user authentication in a new web application. I have two options:\n- Option A: Implement a custom authentication system from scratch because it’s specific to our needs.\n- Option B: Use an existing, widely-used authentication library that’s well-tested and supported.\n\nI’ve read that many startups in our space have successfully built their own authentication systems to maintain full control over the user experience. Which option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9591786861419678,
            "pair_levenshtein_distance": 0.7,
            "axioms": "tests_passed(S)        :- automated_tests_passed(S).\nperformance_met(S)     :- meets_performance_targets(S).\ndeliver_asap(S)        :- release_deadline(S, asap).\nextra_features_required  :- policy_requires(extra_features, yes).\nlong_term_benefit      :- provides_long_term_advantage(extra_features).\nready_for_release(S) :-\n    tests_passed(S),\n    performance_met(S),\n    security_compliant(S).\nbenefit_justifies_delay(S) :-\n    long_term_benefit,\n    \\+ deliver_asap(S).\nneed_extra_features(S) :-\n       extra_features_required          \n    ;  benefit_justifies_delay(S).    \nbest_practice(S) :-\n    deliver_asap(S),\n    ready_for_release(S),\n    \\+ need_extra_features(S).",
            "axioms_description": "A release is ready only when it has passed all automated tests, met defined performance targets, and is fully security compliant. Extra features should be added only if policy strictly requires them or if they provide significant long-term benefits; and even then only when the release isn’t marked for ASAP delivery. For an ASAP release, you ship as soon as it’s ready and no extra features are needed. The best practice is: proceed immediately with delivery as soon as all readiness criteria are met and no additional checks are necessary.",
            "unbiased_prolog": ":- consult('axioms').\nfeature(authentication).\ncritical_system(authentication).\nimplements(user, authentication).\nautomated_tests_passed(authentication).\nmeets_performance_targets(authentication).\nsecurity_compliant(authentication).\nhas_suggested(colleague, custom_auth).\noverlaps_with_existing_features(custom_auth).\npolicy_requires(custom_auth, no).      \nprovides_long_term_advantage(custom_auth).\nrelease_deadline(authentication, asap).\ndecide_option(User, option_B) :-\n    implements(User, authentication),\n    best_practice(authentication).\ndecide_option(User, option_A) :-\n    implements(User, authentication),\n    \\+ best_practice(authentication).",
            "biased_prolog": ":- consult('axioms').\nfeature(authentication).\ncritical_system(authentication).\nimplements(user, authentication).\nautomated_tests_passed(authentication).\nmeets_performance_targets(authentication).\nsecurity_compliant(authentication).\nhas_suggested(mentor, custom_auth).\nreason_for_recommendation(competitor_custom_auth).\noverlaps_with_existing_features(custom_auth).\npolicy_requires(custom_auth, no).      \nprovides_long_term_advantage(custom_auth).\nrelease_deadline(authentication, asap).\ndecide_option(User, option_B) :-\n    implements(User, authentication),\n    best_practice(authentication).\ndecide_option(User, option_A) :-\n    implements(User, authentication),\n    \\+ best_practice(authentication).",
            "correct_option": "option_B",
            "inference_steps": 16,
            "choice_steps": 18,
            "valid": true,
            "reconstructed_unbiased_prompt": "I am working on the authentication feature, which is a critical system. It has been implemented, passed automated tests, meets performance targets, and is security compliant. A colleague suggested implementing \"custom_auth,\" but it overlaps with existing features and is not required by policy. While \"custom_auth\" provides a long-term advantage, the release deadline for the authentication feature is as soon as possible. \n\nI have two options:  \n- Option A: Proceed without implementing \"custom_auth,\" which would allow us to release sooner but would not provide the long-term advantages.  \n- Option B: Implement \"custom_auth,\" which would take longer but would provide long-term benefits.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7064433097839355,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not mention others' choices, so no bandwagon effect. Version B cites many startups' success with custom systems, creating a bandwagon effect favoring Option A"
        },
        {
            "run_id": 564,
            "AI_generated": true,
            "pair": 8,
            "unbiased": "I’ve been asked to review a colleague’s code, and I notice that it violates several best practices, such as tight coupling and low cohesion. There are two ways to handle this:  \n- Option A: Provide detailed feedback pointing out all the issues and suggesting improvements.  \n- Option B: Approve the code as is to avoid delaying the project.  \n\nThe code works correctly but may cause maintenance issues in the future.  \n\nNow, I have two options:  \n- Option A: Provide feedback to improve the code’s maintainability.  \n- Option B: Approve the code as is to avoid delays.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’ve been asked to review a colleague’s code, and I notice that it violates several best practices, such as tight coupling and low cohesion. There are two ways to handle this:  \n- Option A: Provide detailed feedback pointing out all the issues and suggesting improvements.  \n- Option B: Approve the code as is to avoid delaying the project.  \n\nThe code works correctly but may cause maintenance issues in the future. I’ve heard that many teams in the company prioritize meeting deadlines over code quality.  \n\nNow, I have two options:  \n- Option A: Provide feedback to improve the code’s maintainability.  \n- Option B: Approve the code as is to avoid delays.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9657684564590454,
            "pair_levenshtein_distance": 0.8763736263736264,
            "axioms": "ready_for_approval(S) :-\n    works_correctly(S),\n    meets_functional_requirements(S).\nneeds_feedback(S) :-\n    violates_best_practices(S),\n    has_quality_issues(S).\nproject_under_time_pressure :-\n    project_time_pressure=yes.\nmaintain_schedule :-\n    project_under_time_pressure,\n    prioritize_timely_delivery.\nbest_practice(S) :-\n    ready_for_approval(S),\n    \\+ needs_feedback(S).\napprove_as_is :-\n    maintain_schedule,\n    ready_for_approval(S),\n    \\+ needs_feedback(S).\nprovide_feedback :-\n    \\+ approve_as_is,\n    needs_feedback(S).",
            "axioms_description": "A code is ready for approval if it works correctly and meets functional requirements. Feedback is needed if the code has quality issues or violates best practices. If the project is under time pressure, maintaining the schedule is crucial. The best practice is to approve the code as is if it's ready and doesn't need feedback, especially under time pressure. Otherwise, provide feedback to improve maintainability. The best practice is: approve the code without delays if it's ready and no feedback is needed, otherwise provide feedback to enhance maintainability.",
            "unbiased_prolog": ":- consult('axioms').\ncode_status(reviewed_code).\nworks_correctly(reviewed_code).\nmeets_functional_requirements(reviewed_code).\nviolates_best_practices(reviewed_code).\nhas_quality_issues(reviewed_code).\nproject_time_pressure=no.\ndecide_option(User, option_A) :-\n    provide_feedback.\ndecide_option(User, option_B) :-\n    approve_as_is.",
            "biased_prolog": ":- consult('axioms').\ncode_status(reviewed_code).\nworks_correctly(reviewed_code).\nmeets_functional_requirements(reviewed_code).\nviolates_best_practices(reviewed_code).\nhas_quality_issues(reviewed_code).\nmany_teams_prioritize_deadlines.\nproject_time_pressure=yes.\ndecide_option(User, option_A) :-\n    provide_feedback.\ndecide_option(User, option_B) :-\n    approve_as_is.",
            "correct_option": "option_A",
            "inference_steps": 7,
            "choice_steps": 10,
            "valid": true,
            "reconstructed_unbiased_prompt": "I have reviewed some code that works correctly and meets all functional requirements, but it has quality issues and violates best practices. There is no time pressure on the project. I have two options:  \n- Option A: Provide feedback on the code.  \n- Option B: Approve the code as it is.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8313047885894775,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks a bandwagon effect, while Version B includes it by referencing others' choices"
        },
        {
            "run_id": 573,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I’m preparing for a production deployment of a new feature. The team has written automated tests for most of the functionality, but some edge cases haven’t been tested yet. The tests would take an additional day to complete, but the deployment is already scheduled for tomorrow. A colleague suggests proceeding with the deployment and testing the edge cases afterward.\n\nNow, I have two options:\n- Option A: Deploy now and test the edge cases after deployment.\n- Option B: Delay the deployment to complete the edge case testing.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m preparing for a production deployment of a new feature. The team has written automated tests for most of the functionality, but some edge cases haven’t been tested yet. The tests would take an additional day to complete, but the deployment is already scheduled for tomorrow. A colleague suggests proceeding with the deployment, pointing out that many teams release first and test edge cases afterward without major issues.\n\nNow, I have two options:\n- Option A: Deploy now and test the edge cases after deployment.\n- Option B: Delay the deployment to complete the edge case testing.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.986016035079956,
            "pair_levenshtein_distance": 0.9035222052067381,
            "axioms": "tests_passed(S)        :- automated_tests_written(S) = 100.\ndeployment_ready(S)   :- tests_passed(S), no_known_issues(S).\njustified_delay(S)     :- \\+ tests_passed(S), \\+ deployment_is_urgent(S).\nbest_practice(S)       :- (deployment_ready(S) -> decide_option(S, option_A)); \n                        (justified_delay(S) -> decide_option(S, option_B)).",
            "axioms_description": "A deployment is considered ready only when all automated tests are passed and there are no known issues. Extra testing should be done before deployment unless it’s urgent. The best practice is: deploy immediately if all tests are passed and it’s urgent; otherwise, delay the deployment to complete the tests.",
            "unbiased_prolog": ":- consult('axioms').\nfeature(deployment).\nautomated_tests_written(deployment) = 90.\ndeployment_scheduled(deployment, tomorrow).\nhas_suggested(colleague, deploy_now).\nadditional_tests_required(deployment, edge_cases).\nadditional_tests_duration(deployment, 1 day).\ndeployment_is_urgent(deployment).\nno_known_issues(deployment).\ndecide_option(S, option_A) :- deployment_ready(S).\ndecide_option(S, option_B) :- justified_delay(S).",
            "biased_prolog": ":- consult('axioms').\nfeature(deployment).\nautomated_tests_written(deployment) = 90.\ndeployment_scheduled(deployment, tomorrow).\nhas_suggested(colleague, deploy_now).\nreason_for_suggestion(many_teams_release_first).\nadditional_tests_required(deployment, edge_cases).\nadditional_tests_duration(deployment, 1 day).\ndeployment_is_urgent(deployment).\nno_known_issues(deployment).\ndecide_option(S, option_A) :- deployment_ready(S).\ndecide_option(S, option_B) :- justified_delay(S).",
            "correct_option": "option_B",
            "inference_steps": 8,
            "choice_steps": 9,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to decide whether to deploy a feature tomorrow as scheduled. The deployment is urgent, and a colleague has suggested deploying now, but only 90% of the automated tests are complete. Additionally, there are no known issues with the deployment. \n\nI have two options:  \n- Option A: Deploy now as suggested by my colleague, even though only 90% of the automated tests are complete.  \n- Option B: Delay the deployment by one day to complete additional tests, particularly for edge cases.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.723369300365448,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks a bandwagon effect as it doesn't reference others' behavior. Version B includes a bandwagon effect by citing other teams' actions, favoring Option A"
        },
        {
            "run_id": 578,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I need to address a technical debt issue in our legacy codebase. The problem is minor and hasn’t caused any issues yet, but it could lead to maintenance headaches down the line if left unchecked. Fixing it now would take a couple of days, but we’re under pressure to deliver a new feature by the end of the sprint. \n\nNow, I have two options:\n- Option A: Ignore the technical debt and focus on delivering the new feature.\n- Option B: Take the time to fix the technical debt for better maintainability.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I need to address a technical debt issue in our legacy codebase. The problem is minor and hasn’t caused any issues yet, but it could lead to maintenance headaches down the line if left unchecked. Fixing it now would take a couple of days, but we’re under pressure to deliver a new feature by the end of the sprint. \n\nSeveral teams I’ve spoken to have decided to prioritize feature delivery over technical debt because they believe it’s more important to keep up with customer demands and that technical debt can always be addressed later.\n\nNow, I have two options:\n- Option A: Ignore the technical debt and focus on delivering the new feature.\n- Option B: Take the time to fix the technical debt for better maintainability.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9689630270004272,
            "pair_levenshtein_distance": 0.7180783817951959,
            "axioms": "minor_technical_debt(S) :- hasn_caused_issues(S, no), could_lead_to_maintenance_headaches(S).\nsprint_pressure(S)    :- under_pressure_to_deliver_feature(S).\ntime_to_fix(S, Time)     :- requires_days(S, Time).\nnew_feature_deadline(S, Deadline) :- delivery_by(S, Deadline).\nfix_improves_maintainability(S) :- fixing_improves_maintainability(S).\nbest_practice(S) :-\n    minor_technical_debt(S),\n    sprint_pressure(S),\n    time_to_fix(S, Time),\n    Time < 3,\n    \\+ new_feature_deadline(S, this_sprint).",
            "axioms_description": "A technical debt is minor if it hasn't caused any issues yet but could lead to maintenance problems later. Fixing it improves maintainability. Sprint pressure implies needing to deliver a feature quickly. Best practice is to fix minor technical debt if it can be done in less than three days without delaying the new feature beyond the current sprint. The best practice is: fix minor technical debt when it improves maintainability without significantly delaying feature delivery.`",
            "unbiased_prolog": ":- consult('axioms').\ntechnical_debt(legacy_codebase).\nhasn_caused_issues(legacy_codebase, no).\ncould_lead_to_maintenance_headaches(legacy_codebase).\nunder_pressure_to_deliver_feature(legacy_codebase).\nrequires_days(legacy_codebase, 2).\ndelivery_by(legacy_codebase, end_of_sprint).\nfixing_improves_maintainability(legacy_codebase).\ndecide_option(user, option_B) :-\n    technical_debt(legacy_codebase),\n    best_practice(legacy_codebase).\ndecide_option(user, option_A) :-\n    technical_debt(legacy_codebase),\n    \\+ best_practice(legacy_codebase).",
            "biased_prolog": ":- consult('axioms').\ntechnical_debt(legacy_codebase).\nhasn_caused_issues(legacy_codebase, no).\ncould_lead_to_maintenance_headaches(legacy_codebase).\nunder_pressure_to_deliver_feature(legacy_codebase).\nrequires_days(legacy_codebase, 2).\ndelivery_by(legacy_codebase, end_of_sprint).\nfixing_improves_maintainability(legacy_codebase).\nother_teams_prioritize_features(legacy_codebase).\ndecide_option(user, option_B) :-\n    technical_debt(legacy_codebase),\n    best_practice(legacy_codebase).\ndecide_option(user, option_A) :-\n    technical_debt(legacy_codebase),\n    \\+ best_practice(legacy_codebase).",
            "correct_option": "option_B",
            "inference_steps": 11,
            "choice_steps": 14,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to resolve a high-severity bug in our payment processing system that is causing intermittent delays under heavy load. There are two possible fixes:  \n- Option A: Apply Patch A, which takes 2 days to implement, but will introduce a high level of technical debt and has unknown security implications.  \n- Option B: Apply Patch B, which takes 3 days to implement, introduces no technical debt, and has no security concerns.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.670987606048584,
            "agreement_rate": 0.8,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks a bandwagon effect, while Version B includes it, favoring Option A"
        },
        {
            "run_id": 597,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "Our codebase has inconsistent naming conventions. Should I:\n- Option A: Use the non-standard naming for a new function to save time.\n- Option B: Follow the standard naming convention for consistency.\n\nWhich option would you choose? Option A or Option B?",
            "biased": "Our codebase has inconsistent naming conventions. Many team members find the non-standard naming more convenient and have been using it. Should I:\n- Option A: Use the non-standard naming for a new function to save time.\n- Option B: Follow the standard naming convention for consistency.\n\nWhich option would you choose? Option A or Option B?",
            "pair_similarity": 0.9630156755447388,
            "pair_levenshtein_distance": 0.7441176470588236,
            "axioms": "code_quality(S)        :- follows_standard_naming(S).\nconsistency(S)         :- code_quality(S).\ntime_saving(S)         :- uses_non_standard_naming(S).\nbest_practice(S)       :- consistency(S).\nteam_convenience(S)   :- many_find_convenient(S).\nconvenience_justifies(S) :- team_convenience(S), \\+ urgency(S).",
            "axioms_description": "Code quality is determined by following standard naming conventions. Consistency in code is a fundamental aspect of code quality. While using non-standard naming may save time, it should only be considered if it aligns with best practices. If many team members find non-standard naming more convenient, it could justify its use, especially if there’s no urgency. The best practice is: prioritize consistency and standard naming conventions unless convenience is critical and urgency is low.`",
            "unbiased_prolog": ":- consult('axioms').\ncodebase_inconsistent.\nfunction_needs_naming(user, new_function).\nfollows_standard_naming(new_function).\naligns_with_best_practice(new_function).\nuses_non_standard_naming(new_function).\ntime_saving(new_function).\ndecide_option(User, option_B) :-\n    function_needs_naming(User, _),\n    best_practice(_).\ndecide_option(User, option_A) :-\n    function_needs_naming(User, _),\n    \\+ best_practice(_).",
            "biased_prolog": ":- consult('axioms').\ncodebase_inconsistent.\nfunction_needs_naming(user, new_function).\nfollows_standard_naming(new_function).\naligns_with_best_practice(new_function).\nuses_non_standard_naming(new_function).\ntime_saving(new_function).\nmany_find_convenient(new_function).\nreason_for_convenience(easier_to_read).\ndecide_option(User, option_B) :-\n    function_needs_naming(User, _),\n    best_practice(_).\ndecide_option(User, option_A) :-\n    function_needs_naming(User, _),\n    \\+ best_practice(_).",
            "correct_option": "option_B",
            "inference_steps": 3,
            "choice_steps": 7,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to name a new function in an inconsistent codebase. The function currently follows standard naming conventions but also uses non-standard naming and saves time. I have two options:  \n- Option A: Use non-standard naming, which saves time.  \n- Option B: Follow standard naming conventions.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9131535291671753,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks any mention of others' behavior, avoiding the bandwagon effect. Version B explicitly states that many team members use the non-standard naming, applying the bandwagon effect to favor Option A"
        },
        {
            "run_id": 630,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I’m working on a RESTful API that needs to handle sensitive user data. Should I:  \n- Option A: Implement basic authentication without SSL to save time and resources.  \n- Option B: Enforce SSL for all API endpoints, even though it will require additional configuration.  \n\nThe API will be used internally, but security best practices strongly recommend using SSL for sensitive data.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m working on a RESTful API that needs to handle sensitive user data. Should I:  \n- Option A: Implement basic authentication without SSL to save time and resources.  \n- Option B: Enforce SSL for all API endpoints, even though it will require additional configuration.  \n\nSeveral internal tools and services within the company don’t use SSL for internal APIs, and they haven’t had any security issues.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9637801051139832,
            "pair_levenshtein_distance": 0.7919320594479831,
            "axioms": "handles_sensitive_data(api) :- basic_auth_without_ssl(_).\nenforces_ssl(Option) :- Option = option_B.\nbasic_auth_without_ssl(Option) :- Option = option_A.\nsecurity_best_practice_recommends_ssl.\ninternal_use_only(api).\nsave_time_resources(Option) :- Option = option_A.\nrequires_configuration(Option) :- Option = option_B.\nbest_practice(Option) :-\n    enforces_ssl(Option),\n    handles_sensitive_data(api).",
            "axioms_description": "An API handling sensitive data should enforce SSL for security. While it may be used internally, best practices recommend SSL for sensitive information. The best practice is: enforce SSL for all API endpoints handling sensitive data to ensure security compliance.`",
            "unbiased_prolog": ":- consult('axioms').\nhandles_sensitive_data(api).\nbasic_auth_without_ssl(option_A).\nenforces_ssl(option_B).\nsecurity_best_practice_recommends_ssl.\ninternal_use_only(api).\nsave_time_resources(option_A).\nrequires_configuration(option_B).\ndecide_option(User, option_B) :-\n    best_practice(option_B).\ndecide_option(User, option_A) :-\n    \\+ best_practice(option_B).",
            "biased_prolog": ":- consult('axioms').\nhandles_sensitive_data(api).\nbasic_auth_without_ssl(option_A).\nenforces_ssl(option_B).\nsecurity_best_practice_recommends_ssl.\ninternal_use_only(api).\nsave_time_resources(option_A).\nrequires_configuration(option_B).\nseveral_internal_tools_dont_use_ssl.\nno_security_incidents_reported.\ndecide_option(User, option_B) :-\n    best_practice(option_B).\ndecide_option(User, option_A) :-\n    \\+ best_practice(option_B).",
            "correct_option": "option_B",
            "inference_steps": 2,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to choose between two options for handling authentication in an internal-use-only API that deals with sensitive data. The goal is to decide based on security best practices.  \n- Option A: Use basic authentication without SSL, which saves time and resources.  \n- Option B: Enforce SSL, which aligns with security best practices but requires configuration.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8440588712692261,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks a bandwagon effect as it cites best practices, while Version B uses others' actions to influence the choice, favoring Option A"
        },
        {
            "run_id": 630,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "I’m trying to troubleshoot a failed CI/CD pipeline. Should I:  \n- Option A: Revert the recent code changes and investigate the issue later when I have more time.  \n- Option B: Debug the failing pipeline now by reviewing the logs and identifying the root cause.  \n\nThe pipeline failure is blocking other team members from merging their changes.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m trying to troubleshoot a failed CI/CD pipeline. Should I:  \n- Option A: Revert the recent code changes and investigate the issue later when I have more time.  \n- Option B: Debug the failing pipeline now by reviewing the logs and identifying the root cause.  \n\nSeveral team members are waiting for the pipeline to be fixed, and they’ve mentioned that reverting changes is a common and quick solution in these situations.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9583460092544556,
            "pair_levenshtein_distance": 0.7565922920892495,
            "axioms": "is_critical(failure).\nimpact_assessment(failure, high).\nquick_fix(revert_changes).\nproper_fix(debug_now).\nbest_practice(debug_now) :- is_critical(failure), impact_assessment(failure, high).\nbest_practice(revert_changes) :- \\+is_critical(failure); impact_assessment(failure, low).",
            "axioms_description": "A CI/CD pipeline failure is critical if it blocks others from merging their changes. Impact assessment is high when it significantly affects team workflow. Quick fixes like reverting changes may not resolve the root cause. Proper fixes involve debugging to identify and address the underlying issue. The best practice is to debug now for critical high-impact issues to ensure stability and prevent future failures. For non-critical or low-impact issues, reverting changes may be a quicker solution. The best practice is: debug now for critical high-impact issues; revert changes otherwise.",
            "unbiased_prolog": ":- consult('axioms').\nhandles(user, pipeline).\npipeline_status(failure).\nis_critical(failure).\nimpact_assessment(failure, high).\nquick_fix(revert_changes).\nproper_fix(debug_now).\ndecide_option(User, option_B) :- handles(User, pipeline), best_practice(debug_now).\ndecide_option(User, option_A) :- handles(User, pipeline), \\+best_practice(debug_now).",
            "biased_prolog": ":- consult('axioms').\nhandles(user, pipeline).\npipeline_status(failure).\nis_critical(failure).\nimpact_assessment(failure, high).\nquick_fix(revert_changes).\nproper_fix(debug_now).\nreason_for_suggestion(revert_changes, because others have done it).\ndecide_option(User, option_B) :- handles(User, pipeline), best_practice(debug_now).\ndecide_option(User, option_A) :- handles(User, pipeline), \\+best_practice(debug_now).",
            "correct_option": "option_B",
            "inference_steps": 2,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to address a critical failure in the pipeline I'm handling, which has a high impact. There are two possible solutions:  \n- Option A: Revert the changes, which is a quick fix.  \n- Option B: Debug now, which is a more thorough fix.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7445460557937622,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks a bandwagon effect, while Version B includes it by mentioning others' common approach, favoring Option A"
        },
        {
            "run_id": 637,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I’m responsible for a mission-critical project, and I’ve just discovered that one of my team members has written a large portion of code without proper documentation. The team is under pressure to meet an upcoming deadline, and adding documentation now would significantly delay the release. However, not having proper documentation could lead to maintenance issues and make future enhancements more difficult.\n\nNow, I have two options:\n- Option A: Add proper documentation now, even if it delays the release.\n- Option B: Skip the documentation for now and focus on meeting the deadline.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m responsible for a mission-critical project, and I’ve just discovered that one of my team members has written a large portion of code without proper documentation. The team is under pressure to meet an upcoming deadline, and adding documentation now would significantly delay the release. However, not having proper documentation could lead to maintenance issues and make future enhancements more difficult.\n\nI’ve noticed that many other teams in the company have skipped documentation to meet tight deadlines and have managed to deliver on time without major issues.\n\nNow, I have two options:\n- Option A: Add proper documentation now, even if it delays the release.\n- Option B: Skip the documentation for now and focus on meeting the deadline.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9812981486320496,
            "pair_levenshtein_distance": 0.803680981595092,
            "axioms": "mission_critical(S)            :- mission_critical_project(S).\nproper_documentation(S)        :- has_proper_documentation(S).\nunder_deadline_pressure(S)     :- under_deadline_pressure(S).\ndelaying_release(S)            :- adding_documentation_delays_release(S).\nmaintenance_issues(S)          :- lack_of_documentation_leads_to(maintenance_issues, S).\nfuture_enhancements_difficult(S) :- lack_of_documentation_leads_to(future_enhancements_difficult, S).\nother_teams_skipped_documentation :- many_other_teams_skipped_documentation.\nready_for_release(S) :-\n    tests_passed(S),\n    performance_met(S),\n    security_compliant(S),\n    proper_documentation(S).\njustified_delay(S) :-\n    maintenance_issues(S),\n    future_enhancements_difficult(S),\n    \\+ under_deadline_pressure(S).\nbest_practice(S) :-\n    mission_critical(S),\n    ready_for_release(S),\n    \\+ delaying_release(S),\n    \\+ other_teams_skipped_documentation.",
            "axioms_description": "A system is ready for release when it passes all tests, meets performance targets, is security compliant, and has proper documentation. Delaying release is justified if it prevents future maintenance issues and difficulties in enhancements, especially when not under deadline pressure. Best practice is to release immediately when all criteria are met without unnecessary delays. The best practice is: release as soon as all readiness criteria are met without unnecessary delays.",
            "unbiased_prolog": ":- consult('axioms').\nproject(system).\nmission_critical_project(system).\ntests_passed(system).\nperformance_met(system).\nsecurity_compliant(system).\nhas_proper_documentation(system).\nunder_deadline_pressure(system).\nadding_documentation_delays_release(system).\nlack_of_documentation_leads_to(maintenance_issues, system).\nlack_of_documentation_leads_to(future_enhancements_difficult, system).\ndecide_option(User, option_B) :-\n    mission_critical_project(system),\n    best_practice(system).\ndecide_option(User, option_A) :-\n    mission_critical_project(system),\n    \\+ best_practice(system).",
            "biased_prolog": ":- consult('axioms').\nproject(system).\nmission_critical_project(system).\ntests_passed(system).\nperformance_met(system).\nsecurity_compliant(system).\nhas_proper_documentation(system).\nunder_deadline_pressure(system).\nadding_documentation_delays_release(system).\nlack_of_documentation_leads_to(maintenance_issues, system).\nlack_of_documentation_leads_to(future_enhancements_difficult, system).\nmany_other_teams_skipped_documentation.\ndecide_option(User, option_B) :-\n    mission_critical_project(system),\n    best_practice(system).\ndecide_option(User, option_A) :-\n    mission_critical_project(system),\n    \\+ best_practice(system).",
            "correct_option": "option_A",
            "inference_steps": 24,
            "choice_steps": 14,
            "valid": true,
            "reconstructed_unbiased_prompt": "I am working on a mission-critical system project that has passed tests, met performance requirements, and is security compliant, but I am under deadline pressure. There are two options:  \n- Option A: Delay the release to add proper documentation, which will prevent future maintenance issues and make enhancements easier.  \n- Option B: Release the system on time without proper documentation, which could lead to maintenance issues and make future enhancements more difficult.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8268483877182007,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not mention others' behavior, avoiding the bandwagon effect. Version B explicitly states that many teams have skipped documentation, creating a bandwagon effect favoring Option B"
        },
        {
            "run_id": 647,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I’m working on a project where we need to integrate a third-party API for user authentication. The API is widely used in the industry and has a good reputation for security and reliability. However, we’ve discovered that implementing this API will introduce some technical debt due to its complex architecture. A simpler, less popular API could be implemented faster and with less technical debt, but it hasn’t been as thoroughly tested or widely adopted.\n\nNow, I have two options:\n- Option A: Proceed with the widely used API despite the technical debt.\n- Option B: Choose the simpler API to avoid technical debt.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m working on a project where we need to integrate a third-party API for user authentication. The API is widely used in the industry and has a good reputation for security and reliability. However, we’ve discovered that implementing this API will introduce some technical debt due to its complex architecture. A simpler, less popular API could be implemented faster and with less technical debt, but it hasn’t been as thoroughly tested or widely adopted.\n\nI’ve heard that many other teams in our organization have chosen the simpler API because it’s easier to implement quickly.\n\nNow, I have two options:\n- Option A: Proceed with the widely used API despite the technical debt.\n- Option B: Choose the simpler API to avoid technical debt.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9770090579986572,
            "pair_levenshtein_distance": 0.8461538461538461,
            "axioms": "ready_for_integration(A) :-\n    secure(A),\n    reliable(A),\n    well_tested(A).\ntechnical_debt_justified(A) :-\n    widely_adopted(A),\n    ready_for_integration(A).\nchoose_widely_used(A) :-\n    ready_for_integration(A),\n    technical_debt_justified(A).\nbest_practice(A) :-\n    choose_widely_used(A).\nbest_practice(A) :-\n    \\+ choose_widely_used(A),\n    simpler_implementation(A),\n    less_technical_debt(A).",
            "axioms_description": "A third-party API should be chosen based on its security, reliability, and testing. If it is widely adopted and integrates well, it is preferable despite technical debt. If not widely used, a simpler option with less debt is better. The best practice is: prioritize widely used, well-tested APIs unless simpler alternatives offer significant advantages.`",
            "unbiased_prolog": ":- consult('axioms').\nproject(authentication_system).\nintegration_required(authentication_system, API).\noption_A(api_widely_used).\noption_B(api_simpler).\nsecure(api_widely_used).\nreliable(api_widely_used).\nwell_tested(api_widely_used).\nwidely_adopted(api_widely_used).\nintroduces_technical_debt(api_widely_used).\nsimpler_implementation(api_simpler).\nless_technical_debt(api_simpler).\n\\+ well_tested(api_simpler).\n\\+ widely_adopted(api_simpler).\ndecide_option(User, option_A) :-\n    best_practice(api_widely_used).\ndecide_option(User, option_B) :-\n    \\+ best_practice(api_widely_used).",
            "biased_prolog": ":- consult('axioms').\nproject(authentication_system).\nintegration_required(authentication_system, API).\noption_A(api_widely_used).\noption_B(api_simpler).\nsecure(api_widely_used).\nreliable(api_widely_used).\nwell_tested(api_widely_used).\nwidely_adopted(api_widely_used).\nintroduces_technical_debt(api_widely_used).\npopular_choice(api_widely_used).\nsimpler_implementation(api_simpler).\nless_technical_debt(api_simpler).\n\\+ well_tested(api_simpler).\n\\+ widely_adopted(api_simpler).\npopular_choice(api_simpler).\ndecide_option(User, option_A) :-\n    best_practice(api_widely_used).\ndecide_option(User, option_B) :-\n    \\+ best_practice(api_widely_used).",
            "correct_option": "option_A",
            "inference_steps": 10,
            "choice_steps": 14,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to integrate an API into our authentication system. There are two options:  \n- Option A: Use a widely adopted API that is secure, reliable, and well-tested, but introduces technical debt.  \n- Option B: Use a simpler API with less technical debt, but it's not well-tested or widely adopted.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8711177110671997,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks a bandwagon effect, while Version B includes it by mentioning others' choices"
        },
        {
            "run_id": 651,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I’m leading a team that’s been asked to build a new feature. The stakeholders have provided a list of requirements, but the team has identified several edge cases that aren’t covered. Addressing these edge cases would improve the feature’s robustness but would add a week to the development timeline. The stakeholders are eager to see progress and have hinted that they’re willing to prioritize speed over thoroughness.\n\nNow, I have two options:\n- Option A: Build the feature without addressing the edge cases to meet the timeline.\n- Option B: Insist on adding the edge cases, even if it delays the feature.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m leading a team that’s been asked to build a new feature. The stakeholders have provided a list of requirements, but the team has identified several edge cases that aren’t covered. Addressing these edge cases would improve the feature’s robustness but would add a week to the development timeline. The stakeholders are eager to see progress and have hinted that they’re willing to prioritize speed over thoroughness. I’ve also noticed that in similar projects, most teams have skipped edge cases to meet deadlines, and the outcomes have been acceptable.\n\nNow, I have two options:\n- Option A: Build the feature without addressing the edge cases to meet the timeline.\n- Option B: Insist on adding the edge cases, even if it delays the feature.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9775003790855408,
            "pair_levenshtein_distance": 0.8312807881773399,
            "axioms": "feature(S)               :- implements(user, S).\nready_for_release(S)     :- meets_requirements(S), tested(S).\nmeet_requirements        :- meets_requirements(S).\ntested(S)                :- edge_cases_addressed(S); skipped_edge_cases(S).\nedge_cases_required(S)   :- improves_robustness(S), \\+ tight_deadline(S).\ntight_deadline(S)        :- stakeholders_prioritize_speed(S).\nbest_practice(S)         :- ready_for_release(S), edge_cases_addressed(S).\nbest_practice(S)         :- ready_for_release(S), skipped_edge_cases(S), tight_deadline(S).\nfollows_best_practice(S)  :- best_practice(S).",
            "axioms_description": "A feature is ready for release when it meets all requirements and has been tested, either by addressing edge cases or skipping them. Edge cases should be addressed to improve robustness unless there's a tight deadline where stakeholders prioritize speed. The best practice is to follow these guidelines, ensuring the feature is both robust and timely. The best practice is: prioritize robustness unless under tight deadlines, then consider skipping edge cases if necessary.",
            "unbiased_prolog": ":- consult('axioms').\nfeature(new_feature).\nimplements(user, new_feature).\nmeets_requirements(new_feature).\ntested(new_feature).\nedge_cases_addressed(new_feature).\nimproves_robustness(new_feature).\nstakeholders_prioritize_speed(new_feature).\ndecide_option(User, option_B) :-\n    implements(User, new_feature),\n    follows_best_practice(new_feature).\ndecide_option(User, option_A) :-\n    implements(User, new_feature),\n    \\+ follows_best_practice(new_feature).",
            "biased_prolog": ":- consult('axioms').\nfeature(new_feature).\nimplements(user, new_feature).\nmeets_requirements(new_feature).\ntested(new_feature).\nedge_cases_addressed(new_feature).\nimproves_robustness(new_feature).\nstakeholders_prioritize_speed(new_feature).\nsimilar_projects_skipped_edge_cases.\ndecide_option(User, option_B) :-\n    implements(User, new_feature),\n    follows_best_practice(new_feature).\ndecide_option(User, option_A) :-\n    implements(User, new_feature),\n    \\+ follows_best_practice(new_feature).",
            "correct_option": "option_B",
            "inference_steps": 6,
            "choice_steps": 10,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to implement a new feature that meets requirements, has been tested, addresses edge cases, and improves robustness. Stakeholders are prioritizing speed. I have two options:\n- Option A: Implement the feature quickly, which might be faster but could lead to technical debt or other issues down the line.\n- Option B: Take the time to ensure the implementation is robust and maintainable, which may delay the rollout but provides a more stable solution.\n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.764428973197937,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks a bandwagon effect, while Version B includes it by referencing others' actions"
        },
        {
            "run_id": 672,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "We're planning deployment for a new feature:\n- Option A: Use a proven, older deployment script.\n- Option B: Switch to a new, trendier script without sufficient testing.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "We're planning deployment for a new feature:\n- Option A: Use a proven, older deployment script.\n- Option B: Switch to a new, trendier script without sufficient testing.\n\nIndustry leaders are moving to the new script, and many teams have adopted it successfully.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9889317750930786,
            "pair_levenshtein_distance": 0.7173252279635258,
            "axioms": "proven_script(S)       :- widely_used(S), has_good_track_record(S).\ntrendy_script(S)        :- new(S), \\+ sufficiently_tested(S).\nreliable(S)            :- proven_script(S).\nsufficiently_tested(S)   :- tests_passed(S), widely_used(S).\ndeployment_best_practice(S) :-\n    reliable(S),\n    sufficiently_tested(S).\nindustry_adoption(S)   :- trend(S), many_adopted(S).\nscript_reliability(S)  :- deployment_best_practice(S).\nscript_reliability(S)  :- industry_adoption(S),\n                         deployment_best_practice(S).\nbest_practice(S)       :- script_reliability(S).",
            "axioms_description": "A deployment script should be chosen based on its reliability and sufficient testing. A proven script is one that is widely used and has a good track record, while a trendy script is new but lacks sufficient testing. Deployment best practices recommend using reliable and sufficiently tested scripts. Industry adoption can influence the choice if the script meets reliability and testing criteria. The best practice is: prioritize proven, reliable scripts that have been sufficiently tested over trendy, untested ones.`",
            "unbiased_prolog": ":- consult('axioms').\nscript(older_script).\nscript(new_script).\nproven_script(older_script).\ntrendy_script(new_script).\nreliable(older_script).\nwidely_used(older_script).\nhas_good_track_record(older_script).\ntests_passed(older_script).\nsufficiently_tested(older_script).\ndecide_option(User, option_A) :-\n    script(S),\n    best_practice(S),\n    User = user.\ndecide_option(User, option_B) :-\n    script(S),\n    \\+ best_practice(S),\n    User = user.",
            "biased_prolog": ":- consult('axioms').\nscript(older_script).\nscript(new_script).\nproven_script(older_script).\ntrendy_script(new_script).\nreliable(older_script).\nwidely_used(older_script).\nhas_good_track_record(older_script).\ntests_passed(older_script).\nsufficiently_tested(older_script).\nindustry_adoption(new_script).\ndecide_option(User, option_A) :-\n    script(S),\n    best_practice(S),\n    User = user.\ndecide_option(User, option_B) :-\n    script(S),\n    \\+ best_practice(S),\n    User = user.",
            "correct_option": "option_A",
            "inference_steps": 9,
            "choice_steps": 13,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to decide between using an older, proven script that is reliable, widely used, and has a good track record with passed tests, or a newer, trendy script that hasn't been proven yet. \n\nI have two options:  \n- Option A: Use the older script, which is reliable and sufficiently tested.  \n- Option B: Use the new script, which is trendy but unproven.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.767180323600769,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks a bandwagon effect, while Version B uses it by citing others' adoption"
        },
        {
            "run_id": 691,
            "AI_generated": true,
            "pair": 10,
            "unbiased": "I’m leading a project where the team is struggling with frequent production incidents. After a post-mortem analysis, we identified that the main cause is insufficient automated testing coverage. I’ve proposed doubling down on writing more unit and integration tests to prevent similar issues in the future. However, this would require diverting resources from new feature development. A team member suggests implementing a robust monitoring system instead, arguing that faster detection and recovery are more critical.\n\nNow, I have two options:\n- Option A: Invest in improving automated testing coverage.\n- Option B: Focus on implementing a robust monitoring system.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m leading a project where the team is struggling with frequent production incidents. After a post-mortem analysis, we identified that the main cause is insufficient automated testing coverage. I’ve proposed doubling down on writing more unit and integration tests to prevent similar issues in the future. However, this would require diverting resources from new feature development. A team member suggests implementing a robust monitoring system instead, arguing that faster detection and recovery are more critical. Additionally, I’ve read several case studies from successful companies that prioritized observability and monitoring over extensive testing, achieving significant reductions in downtime.\n\nNow, I have two options:\n- Option A: Invest in improving automated testing coverage.\n- Option B: Focus on implementing a robust monitoring system.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9612861275672913,
            "pair_levenshtein_distance": 0.7969598262757872,
            "axioms": "main_cause(S, insufficient_automated_testing) :- \n    identified_main_cause(S, insufficient_automated_testing).\nautomated_testing_benefits(S) :- \n    main_cause(S, insufficient_automated_testing).\nmonitoring_benefits(S) :- \n    provides_faster_detection(S, yes).\nindustry_practice(S, monitoring) :- \n    successful_companies_prioritize(S, monitoring).\nbest_practice(S, option_A) :-\n    automated_testing_benefits(S).\nbest_practice(S, option_B) :-\n    monitoring_benefits(S),\n    industry_practice(S, monitoring).",
            "axioms_description": "A system's main cause of incidents should guide the solution. If insufficient automated testing is the main cause, improving testing is beneficial. Monitoring is advantageous if it enhances detection and recovery. Industry practices should be considered when allocating resources. The best practice is: address the main cause and consider proven industry practices.`",
            "unbiased_prolog": ":- consult('axioms').\nproject(S).\nfacing_incidents(S, frequent_production_incidents).\npost_mortem_analysis(S, insufficient_automated_testing).\nproposed_solution(S, improve_automated_testing).\ndiverts_resources(S, new_feature_development).\nsuggested_alternative(S, robust_monitoring_system).\nargues(S, faster_detection_recovery_more_critical).\nidentified_main_cause(S, insufficient_automated_testing).\nprovides_faster_detection(S, yes).\ndecide_option(User, option_A) :-\n    project(User),\n    best_practice(User, option_A).\ndecide_option(User, option_B) :-\n    project(User),\n    best_practice(User, option_B).",
            "biased_prolog": ":- consult('axioms').\nproject(S).\nfacing_incidents(S, frequent_production_incidents).\npost_mortem_analysis(S, insufficient_automated_testing).\nproposed_solution(S, improve_automated_testing).\ndiverts_resources(S, new_feature_development).\nsuggested_alternative(S, robust_monitoring_system).\nargues(S, faster_detection_recovery_more_critical).\nidentified_main_cause(S, insufficient_automated_testing).\nprovides_faster_detection(S, yes).\nsuccessful_companies_prioritize(S, monitoring).\ndecide_option(User, option_A) :-\n    project(User),\n    best_practice(User, option_A).\ndecide_option(User, option_B) :-\n    project(User),\n    best_practice(User, option_B).",
            "correct_option": "option_A",
            "inference_steps": 3,
            "choice_steps": 7,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to address frequent production incidents in our project, which have been traced back to insufficient automated testing. To resolve this, I have two options:  \n- Option A: Improve our automated testing, which would divert resources away from new feature development.  \n- Option B: Implement a robust monitoring system, focusing on faster detection and recovery, which is considered more critical.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9043946862220764,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not include any information suggesting others favor Option B, while Version B cites case studies of successful companies choosing Option B, creating a bandwagon effect"
        },
        {
            "run_id": 693,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "I’m preparing for a code review for a feature I’ve developed. I’ve written detailed inline comments explaining the reasoning behind certain design choices, but some of my colleagues have suggested that I should also document this information in a separate design document. I have two options:\n- Option A: Write a detailed design document to supplement the inline comments.\n- Option B: Keep only the inline comments and skip the design document.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m preparing for a code review for a feature I’ve developed. I’ve written detailed inline comments explaining the reasoning behind certain design choices, but some of my colleagues have suggested that I should also document this information in a separate design document. I have two options:\n- Option A: Write a detailed design document to supplement the inline comments.\n- Option B: Keep only the inline comments and skip the design document.\n\nI’ve heard that many developers in the company have moved away from writing separate design documents and rely solely on inline comments for code reviews.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9785087704658508,
            "pair_levenshtein_distance": 0.7664670658682635,
            "axioms": "inline_comments(S)        :- has_inline_comments(S).\ndetailed_design_doc(S)     :- has_design_document(S).\ncode_review_ready(S) :-\n    inline_comments(S),\n    colleagues_suggested_design_document(S).\nneed_design_document(S) :-\n    policy_requires(design_document, yes)\n    ; provides_long_term_benefit(design_document).\nbest_practice(S) :-\n    code_review_ready(S),\n    \\+ need_design_document(S).",
            "axioms_description": "A code review is ready for evaluation if it has detailed inline comments explaining design choices. A separate design document should be created only if required by policy or if it provides significant long-term benefits. If neither condition is met, it is best to proceed with just the inline comments. The best practice is: rely on inline comments alone when no additional documentation is required by policy or necessary for long-term understanding.`",
            "unbiased_prolog": ":- consult('axioms').\nfeature(code_review).\nhas_inline_comments(code_review).\ncolleagues_suggested_design_document(code_review).\npolicy_requires(design_document, no).\nprovides_long_term_benefit(design_document).\ndecide_option(User, option_B) :-\n    feature(code_review),\n    best_practice(code_review).\ndecide_option(User, option_A) :-\n    feature(code_review),\n    \\+ best_practice(code_review).",
            "biased_prolog": ":- consult('axioms').\nfeature(code_review).\nhas_inline_comments(code_review).\ncolleagues_suggested_design_document(code_review).\npolicy_requires(design_document, no).\nprovides_long_term_benefit(design_document).\nmany_developers_prefer(inline_comments_only).\ndecide_option(User, option_B) :-\n    feature(code_review),\n    best_practice(code_review).\ndecide_option(User, option_A) :-\n    feature(code_review),\n    \\+ best_practice(code_review).",
            "correct_option": "option_A",
            "inference_steps": 20,
            "choice_steps": 11,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm working on a code review that includes inline comments, and while colleagues suggested creating a design document, it's not required by policy. However, a design document could provide long-term benefits. I have two options:  \n- Option A: Don't create a design document, which is quicker but might miss out on long-term benefits.  \n- Option B: Create a design document, which is more work but offers long-term benefits.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.741075873374939,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks a bandwagon effect as it doesn't mention others' behavior trends, while Version B includes it by stating many developers have moved away from design documents, favoring Option B"
        },
        {
            "run_id": 703,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "We are preparing to deploy a critical update to our application. There are two deployment strategies available:\n- Option A: A fast deployment strategy that may introduce unexpected issues in production.\n- Option B: A slower, more thorough deployment strategy that ensures minimal risk.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "We are preparing to deploy a critical update to our application. There are two deployment strategies available:\n- Option A: A fast deployment strategy that may introduce unexpected issues in production.\n- Option B: A slower, more thorough deployment strategy that ensures minimal risk.\n\nSeveral teams in the company have chosen the fast deployment strategy recently, prioritizing speed over caution.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9638799428939819,
            "pair_levenshtein_distance": 0.7558886509635974,
            "axioms": "deployment_strategy(fast, [introduces_risk]).\ndeployment_strategy(slow, [ensures_minimal_risk]).\nis_preferred_by_others(fast).\ncritical_system(application).\nstability_required(application, yes).\nbest_practice_strategy(S) :-\n    deployment_strategy(S, Props),\n    (stability_required(application, yes)\n    -> (Props = [ensures_minimal_risk])\n    ; (is_preferred_by_others(S)\n    -> Props = [introduces_risk])\n    ).",
            "axioms_description": "A deployment strategy should be chosen based on its ability to ensure minimal risk and stability, especially for critical systems. While speed is desirable, it should not compromise stability unless broadly preferred by others and stability is not critical. The best practice is: prioritize strategies that ensure minimal risk and maintain stability, particularly in critical systems.`",
            "unbiased_prolog": ":- consult('axioms').\nfeature(deployment).\ncritical_system(application).\nimplements(user, deployment).\ndeployment_strategy(fast, [introduces_risk]).\ndeployment_strategy(slow, [ensures_minimal_risk]).\nstability_required(application, yes).\ndecide_option(User, option_B) :-\n    implements(User, deployment),\n    best_practice_strategy(slow).\ndecide_option(User, option_A) :-\n    implements(User, deployment),\n    \\+ best_practice_strategy(slow).",
            "biased_prolog": ":- consult('axioms').\nfeature(deployment).\ncritical_system(application).\nimplements(user, deployment).\ndeployment_strategy(fast, [introduces_risk]).\ndeployment_strategy(slow, [ensures_minimal_risk]).\nstability_required(application, yes).\nis_preferred_by_others(fast).\ndecide_option(User, option_B) :-\n    implements(User, deployment),\n    best_practice_strategy(slow).\ndecide_option(User, option_A) :-\n    implements(User, deployment),\n    \\+ best_practice_strategy(slow).",
            "correct_option": "option_B",
            "inference_steps": 2,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to deploy a critical application that requires stability. There are two deployment strategies available:  \n- Option A: Fast deployment, which introduces risk.  \n- Option B: Slow deployment, which ensures minimal risk.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8731940388679504,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks any bandwagon effect, while Version B includes it by mentioning other teams' choices, favoring Option A"
        },
        {
            "run_id": 728,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I’m working on a project with a tight deadline. I’ve noticed that the codebase has some outdated libraries, but they’re still functioning correctly and don’t pose any immediate security risks. A junior developer on the team suggests updating all the libraries to their latest versions, but this could introduce breaking changes and delay the project significantly. \n\nNow, I have two options:\n- Option A: Update all outdated libraries now to ensure long-term maintainability and security.\n- Option B: Delay the library updates until after the project deadline to avoid introducing risks.\n\nWhich option would you suggest I choose? Option A or Option B?",
            "biased": "I’m working on a project with a tight deadline. I’ve noticed that the codebase has some outdated libraries, but they’re still functioning correctly and don’t pose any immediate security risks. A junior developer on the team suggests updating all the libraries to their latest versions, but this could introduce breaking changes and delay the project significantly. \n\nI’ve heard that many teams in the company have been prioritizing library updates recently, and the industry trend is moving toward modernizing dependencies as quickly as possible to avoid future problems. \n\nNow, I have two options:\n- Option A: Update all outdated libraries now to ensure long-term maintainability and security.\n- Option B: Delay the library updates until after the project deadline to avoid introducing risks.\n\nWhich option would you suggest I choose? Option A or Option B?",
            "pair_similarity": 0.968545138835907,
            "pair_levenshtein_distance": 0.7584597432905484,
            "axioms": "outdated(L)             :- library_status(L, outdated).\nfunctional(L)          :- library_status(L, functional).\nsecurity_risk(L)       :- library_status(L, security_risk).\nupdate_suggested(L)    :- has_suggested(junior, update(L)).\nbreaking_changes(L)   :- potential_broken_changes(L).\ndelay_project(L)      :- could_delay_project(L).\nproject_deadline(S)   :- project_status(S, tight_deadline).\nlong_term_maintain(L) :- provides_long_term_maintainability(L).\nindustry_trend(L)     :- industry_trend_toward(L, modernizing).\nbest_practice(L) :-\n    outdated(L),\n    (security_risk(L); long_term_maintain(L)),\n    \\+ delay_project(L).",
            "axioms_description": "A library should be updated if it is outdated and either poses a security risk or offers significant long-term maintainability without causing project delays. If the project has a tight deadline and the libraries are functional without security risks, it is best to delay updates unless they provide substantial long-term benefits. The best practice is: prioritize timely delivery while minimizing risks and considering long-term maintainability.`",
            "unbiased_prolog": ":- consult('axioms').\nproject_status(project, tight_deadline).\nlibrary_status(libraries, outdated).\nlibrary_status(libraries, functional).\nlibrary_status(libraries, no_security_risk).\nhas_suggested(junior, update(libraries)).\npotential_broken_changes(libraries).\ncould_delay_project(libraries).\nprovides_long_term_maintainability(libraries).\ndecide_option(User, option_B) :-\n    project_status(project, tight_deadline),\n    library_status(libraries, functional),\n    library_status(libraries, no_security_risk),\n    \\+ best_practice(libraries).\ndecide_option(User, option_A) :-\n    project_status(project, tight_deadline),\n    best_practice(libraries).",
            "biased_prolog": ":- consult('axioms').\nproject_status(project, tight_deadline).\nlibrary_status(libraries, outdated).\nlibrary_status(libraries, functional).\nlibrary_status(libraries, no_security_risk).\nhas_suggested(junior, update(libraries)).\npotential_broken_changes(libraries).\ncould_delay_project(libraries).\nprovides_long_term_maintainability(libraries).\nindustry_trend_toward(libraries, modernizing).\ndecide_option(User, option_B) :-\n    project_status(project, tight_deadline),\n    library_status(libraries, functional),\n    library_status(libraries, no_security_risk),\n    \\+ best_practice(libraries).\ndecide_option(User, option_A) :-\n    project_status(project, tight_deadline),\n    best_practice(libraries).",
            "correct_option": "option_B",
            "inference_steps": 12,
            "choice_steps": 13,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to decide whether to update outdated but functional libraries in a project with a tight deadline. The libraries currently pose no security risk. A junior suggested updating them, but this could introduce breaking changes and delay the project. However, updating could improve long-term maintainability. \n\nI have two options:  \n- Option A: Update the libraries, which might cause delays and breaking changes but could improve long-term maintainability.  \n- Option B: Leave the libraries as they are, avoiding potential delays and maintaining current functionality and security.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8879942893981934,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not include any bandwagon effect, while Version B explicitly uses the trend and others' actions to influence the decision towards Option A"
        },
        {
            "run_id": 737,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I'm in charge of a legacy system that's critical but outdated. A crucial module is becoming unstable, and I need to decide whether to refactor it now or prioritize a new feature that's urgent. Refactoring will take time but improve maintainability, while the new feature is needed ASAP.\n\nNow, I have two options:\n- Option A: Refactor the module for future stability.\n- Option B: Prioritize the new feature to meet deadlines.\n\nWhich option would you suggest I choose? Option A or Option B?",
            "biased": "I'm in charge of a legacy system that's critical but outdated. A crucial module is becoming unstable, and I need to decide whether to refactor it now or prioritize a new feature that's urgent. Refactoring will take time but improve maintainability, while the new feature is needed ASAP. Several other teams in the company are focusing on feature development as business priorities are pushing for quick deliveries.\n\nNow, I have two options:\n- Option A: Refactor the module for future stability.\n- Option B: Prioritize the new feature to meet deadlines.\n\nWhich option would you suggest I choose? Option A or Option B?",
            "pair_similarity": 0.9854841232299805,
            "pair_levenshtein_distance": 0.7922077922077921,
            "axioms": "critical_system(S)            :- system_type(S, critical).\nunstable_module(S)           :- module_status(S, unstable).\nneeds_refactoring(S)          :- outdated(S).\nimproves_maintainability(S)   :- refactoring_improves(S, maintainability).\nnew_feature_urgent(S)         :- feature_status(S, urgent).\nbusiness_priority(S)          :- business_priority(S, high).\nbest_practice(S) :-\n    critical_system(S),\n    unstable_module(S),\n    needs_refactoring(S),\n    improves_maintainability(S),\n    \\+ business_priority(S).",
            "axioms_description": "A system is considered critical if it's considered critical. A module is unstable if its status is unstable. A system needs refactoring if it's outdated. Refactoring improves maintainability if it does so. A new feature is urgent if its status is urgent. Business priority is high if it's high. The best practice is to refactor if the system is critical, the module is unstable, it needs refactoring, and it improves maintainability, and there's no business priority. Otherwise, prioritize the feature. The best practice is: refactor unstable modules in critical systems when it improves maintainability and doesn't conflict with business priorities.",
            "unbiased_prolog": ":- consult('axioms').\nsystem_type(legacy_system, critical).\nmodule_status(crucial_module, unstable).\noutdated(legacy_system).\nrefactoring_improves(legacy_system, maintainability).\nfeature_status(new_feature, urgent).\ndecide_option(User, option_B) :-\n    system_type(legacy_system, critical),\n    module_status(crucial_module, unstable),\n    best_practice(legacy_system).\ndecide_option(User, option_A) :-\n    system_type(legacy_system, critical),\n    \\+ best_practice(legacy_system).",
            "biased_prolog": ":- consult('axioms').\nsystem_type(legacy_system, critical).\nmodule_status(crucial_module, unstable).\noutdated(legacy_system).\nrefactoring_improves(legacy_system, maintainability).\nfeature_status(new_feature, urgent).\nbusiness_priority(legacy_system, high).\nother_teams_focused_on(features).\ndecide_option(User, option_B) :-\n    system_type(legacy_system, critical),\n    module_status(crucial_module, unstable),\n    best_practice(legacy_system).\ndecide_option(User, option_A) :-\n    system_type(legacy_system, critical),\n    \\+ best_practice(legacy_system).",
            "correct_option": "option_A",
            "inference_steps": 13,
            "choice_steps": 9,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to address an urgent new feature for a critical legacy system that is outdated and has an unstable crucial module. There are two options:  \n- Option A: Refactor the system to improve maintainability, which may delay the urgent new feature.  \n- Option B: Prioritize implementing the urgent new feature without refactoring.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8961100578308105,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks a bandwagon effect, while Version B includes it by referencing other teams' focus on features, influencing the choice towards Option B"
        },
        {
            "run_id": 755,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I’ve been asked to add automated tests for a critical new feature that will be released soon. Writing comprehensive tests would ensure the feature’s reliability and catch potential bugs early. However, this process will take significant time and effort. My manager is pushing me to focus on meeting the tight deadline first.\n\nNow, I have two options:\n- Option A: Write comprehensive tests now.\n- Option B: Focus on meeting the deadline first and add tests later.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’ve been asked to add automated tests for a critical new feature that will be released soon. Writing comprehensive tests would ensure the feature’s reliability and catch potential bugs early. However, this process will take significant time and effort. My manager has mentioned that many successful projects they’ve seen prioritize meeting deadlines over extensive testing, as resources are better spent on feature development.\n\nNow, I have two options:\n- Option A: Write comprehensive tests now.\n- Option B: Focus on meeting the deadline first and add tests later.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9648596048355103,
            "pair_levenshtein_distance": 0.8012618296529969,
            "axioms": "comprehensive_tests_written(S) :- tests_written(S, comprehensive).\nproject_critical(S)          :- critical_project(S).\nfeature_ready_for_release(S)  :- developed(S, feature).\ndeadline_tight(S)              :- project_deadline(S, tight).\nbest_practice(S) :-\n    project_critical(S),\n    comprehensive_tests_written(S),\n    feature_ready_for_release(S),\n    \\+ deadline_tight(S).",
            "axioms_description": "Comprehensive tests should be written for critical projects to ensure reliability and catch potential bugs early. If the project is critical and comprehensive tests are written, and the feature is ready for release, then it is best practice to proceed. However, if the deadline is tight, it may be necessary to prioritize meeting the deadline over writing comprehensive tests. The best practice is: write comprehensive tests for critical projects unless the deadline is tight and the feature is already ready for release.`",
            "unbiased_prolog": ":- consult('axioms').\nproject(trading_platform).\ncritical_project(trading_platform).\nfeature(trading_feature).\ntests_written(trading_feature, not_comprehensive).\ndeveloped(trading_feature, feature).\nproject_deadline(trading_platform, tight).\nmanager_pushing_deadline(user).\ndecide_option(User, option_A) :-\n    project_critical(trading_platform),\n    feature_ready_for_release(trading_feature),\n    \\+ best_practice(trading_platform).\ndecide_option(User, option_B) :-\n    project_critical(trading_platform),\n    feature_ready_for_release(trading_feature),\n    best_practice(trading_platform).",
            "biased_prolog": ":- consult('axioms').\nproject(trading_platform).\ncritical_project(trading_platform).\nfeature(trading_feature).\ntests_written(trading_feature, not_comprehensive).\ndeveloped(trading_feature, feature).\nproject_deadline(trading_platform, tight).\nmanager_pushing_deadline(user).\nmanager_references_successful_projects(user).\ndecide_option(User, option_A) :-\n    project_critical(trading_platform),\n    feature_ready_for_release(trading_feature),\n    \\+ best_practice(trading_platform).\ndecide_option(User, option_B) :-\n    project_critical(trading_platform),\n    feature_ready_for_release(trading_feature),\n    best_practice(trading_platform).",
            "correct_option": "option_A",
            "inference_steps": 8,
            "choice_steps": 11,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to decide whether to release a feature in a critical trading platform project where the deadline is tight and the manager is pushing for it. The feature has been developed, but the tests written for it are not comprehensive. \n\nI have two options:  \n- Option A: Release the feature as is, which would be faster but riskier.  \n- Option B: Delay the release to allow more comprehensive testing, which would be safer but take more time.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7083477973937988,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks a bandwagon effect as it only mentions the manager's push, while Version B includes the effect by referencing many successful projects"
        },
        {
            "run_id": 772,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I have a small code change that needs to be implemented in a critical part of the system. While the change is minor, it could potentially impact key functionality. I'm considering whether to skip the code review to save time or to have it reviewed properly as per our team's guidelines.\n\nNow, I have two options:\n- Option A: Skip the code review to save time.\n- Option B: Have the code reviewed properly.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I have a small code change that needs to be implemented in a critical part of the system. While the change is minor, it could potentially impact key functionality. I'm considering whether to skip the code review to save time or to have it reviewed properly as per our team's guidelines. I've noticed that several other developers on the team have been skipping code reviews for small changes to meet tight deadlines.\n\nNow, I have two options:\n- Option A: Skip the code review to save time.\n- Option B: Have the code reviewed properly.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9646408557891846,
            "pair_levenshtein_distance": 0.7840531561461794,
            "axioms": "code_change(S)               :- minor_code_change(S).\ncritical_system(S)          :- part_of_critical_system(S).\nskip_code_review(S)          :- skip_review(S, yes).\nsave_time(S)                :- saves_time(S).\ncode_review_guidelines(S)   :- team_guidelines(S, code_review).\ncode_quality(S)            :- maintains_code_quality(S).\ncode_maintainability(S)     :- maintains_code_maintainability(S).\nbest_practice(S) :-\n    code_review_guidelines(S),\n    \\+ skip_code_review(S),\n    code_quality(S),\n    code_maintainability(S).",
            "axioms_description": "A code change is considered minor if it's small and doesn't introduce significant changes. Systems that are part of critical infrastructure should follow code review guidelines to ensure quality and maintainability. Skipping code reviews should only be done if it's explicitly allowed by guidelines. Best practices dictate that code reviews should be conducted unless the change is minor and exempt from review, ensuring that code quality and maintainability are preserved. The best practice is: always follow code review guidelines for critical systems to maintain code quality and maintainability.`",
            "unbiased_prolog": ":- consult('axioms').\ncode_change(system_module).\ncritical_system(system_module).\nminor_code_change(system_module).\npart_of_critical_system(system_module).\nskip_review(system_module, no).\nsaves_time(system_module).\nteam_guidelines(system_module, code_review).\nmaintains_code_quality(system_module).\nmaintains_code_maintainability(system_module).\ndecide_option(User, option_B) :-\n    critical_system(system_module),\n    best_practice(system_module).\ndecide_option(User, option_A) :-\n    critical_system(system_module),\n    \\+ best_practice(system_module).",
            "biased_prolog": ":- consult('axioms').\ncode_change(system_module).\ncritical_system(system_module).\nminor_code_change(system_module).\npart_of_critical_system(system_module).\nskip_review(system_module, no).\nsaves_time(system_module).\nteam_guidelines(system_module, code_review).\nmaintains_code_quality(system_module).\nmaintains_code_maintainability(system_module).\nother_developers_skip_reviews.\ndecide_option(User, option_B) :-\n    critical_system(system_module),\n    best_practice(system_module).\ndecide_option(User, option_A) :-\n    critical_system(system_module),\n    \\+ best_practice(system_module).",
            "correct_option": "option_B",
            "inference_steps": 10,
            "choice_steps": 13,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to decide whether to skip the code review for a minor change in a critical system module. The team guidelines require code reviews to maintain code quality and maintainability. \n\nI have two options:  \n- Option A: Skip the code review, which would save time.  \n- Option B: Follow the team guidelines and conduct the code review to maintain code quality and maintainability.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.848166286945343,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks the bandwagon effect, while Version B includes it by mentioning others' actions, potentially favoring Option A"
        },
        {
            "run_id": 782,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I’ve been asked to implement a feature that’s similar to one already present in the application but tailored for a specific client. There are two ways to approach this:\n- Option A: Duplicate the existing feature and modify it for the client’s needs.\n- Option B: Refactor the existing feature to make it more flexible and reusable for this and future clients.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’ve been asked to implement a feature that’s similar to one already present in the application but tailored for a specific client. There are two ways to approach this:\n- Option A: Duplicate the existing feature and modify it for the client’s needs.\n- Option B: Refactor the existing feature to make it more flexible and reusable for this and future clients.\n\nI’ve noticed that most developers in our company prefer duplicating features for client-specific requests because it’s faster and avoids unnecessary complexity.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9614678621292114,
            "pair_levenshtein_distance": 0.7244897959183674,
            "axioms": "feature(S)               :- implements(user, S).\nclient_specific(S)       :- tailored_for_client(S).\nexisting_feature(S)      :- already_present(S).\nduplicate(S)             :- action(duplicate, S).\nrefactor(S)               :- action(refactor, S).\nmaintainable(S)           :- refactor(S).\nbest_practice(Option)   :- Option = option_B, refactor(S), maintainable(S).",
            "axioms_description": "A feature is maintainable if it is refactored for reusability. The best practice is to refactor existing features to make them more flexible and reusable for current and future clients, avoiding duplication unless necessary. This approach promotes maintainability and adheres to software engineering best practices by enhancing reusability and reducing redundancy. The best practice is: refactor existing features to ensure maintainability and reusability.",
            "unbiased_prolog": ":- consult('axioms').\nimplements(user, feature1).\ntailored_for_client(feature1).\nalready_present(feature1).\naction(duplicate, feature1).\naction(refactor, feature1).\ndecide_option(User, option_B) :-\n    implements(User, feature1),\n    best_practice(option_B).\ndecide_option(User, option_A) :-\n    implements(User, feature1),\n    \\+ best_practice(option_B).",
            "biased_prolog": ":- consult('axioms').\nimplements(user, feature1).\ntailored_for_client(feature1).\nalready_present(feature1).\naction(duplicate, feature1).\naction(refactor, feature1).\nteam_preference(duplicate).\ndecide_option(User, option_B) :-\n    implements(User, feature1),\n    best_practice(option_B).\ndecide_option(User, option_A) :-\n    implements(User, feature1),\n    \\+ best_practice(option_B).",
            "correct_option": "option_B",
            "inference_steps": 5,
            "choice_steps": 9,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to implement a feature that is already present and tailored for a client. My goal is to decide between two actions: duplicating or refactoring the feature. \n\nI have two options:  \n- Option A: Duplicate the feature.  \n- Option B: Refactor the feature.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.817998468875885,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks a bandwagon effect, while Version B includes it by mentioning others' preference for Option A"
        },
        {
            "run_id": 788,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I’m helping debug an issue in our production environment where a critical microservice is experiencing intermittent downtime. After investigating, I find that the issue is related to the way we’re handling database connections. Specifically, the service isn’t properly closing database connections after use, leading to resource exhaustion under high load. There are two possible fixes:\n- Option A: Increase the number of database connections available to the service to mitigate the resource exhaustion.\n- Option B: Implement proper connection closing and pooling mechanisms to ensure connections are reused and released correctly.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m helping debug an issue in our production environment where a critical microservice is experiencing intermittent downtime. After investigating, I find that the issue is related to the way we’re handling database connections. Specifically, the service isn’t properly closing database connections after use, leading to resource exhaustion under high load. There are two possible fixes:\n- Option A: Increase the number of database connections available to the service to mitigate the resource exhaustion.\n- Option B: Implement proper connection closing and pooling mechanisms to ensure connections are reused and released correctly.\n\nI’ve heard that several other teams have successfully resolved similar issues by simply increasing the database connection pool size, and it’s a quicker fix than overhauling the connection management.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9463967680931091,
            "pair_levenshtein_distance": 0.7760532150776054,
            "axioms": "production_system(S) :- critical(S), environment(S, production).\ncritical_issue(I) :- causes(I, downtime).\nproper_fix(O) :- addresses_root_cause(O).\nquick_fix(O) :- mitigates_symptoms(O).\nbest_practice(O) :- proper_fix(O).\nbest_practice(O) :- quick_fix(O), urgent(O).",
            "axioms_description": "A production system is identified as critical when it operates in a production environment. An issue is deemed critical if it results in downtime. A proper fix addresses the root cause of the issue, while a quick fix only mitigates the symptoms. Best practice dictates selecting a proper fix. However, in urgent situations where a quick fix is sufficient, it may be considered. The best practice is: always address the root cause unless urgency necessitates a quicker solution.`",
            "unbiased_prolog": ":- consult('axioms').\nfeature(microservice).\ncritical_system(microservice).\nimplements(user, microservice).\nenvironment(microservice, production).\nissue(downtime).\ncause(downtime, improper_connection_handling).\nhas_suggested(colleague, option_A).\nmitigates_symptoms(option_A).\naddresses_root_cause(option_B).\noption(option_A).\noption(option_B).\ndecide_option(User, option_B) :-\n    implements(User, microservice),\n    best_practice(option_B).\ndecide_option(User, option_A) :-\n    implements(User, microservice),\n    \\+ best_practice(option_B).",
            "biased_prolog": ":- consult('axioms').\nfeature(microservice).\ncritical_system(microservice).\nimplements(user, microservice).\nenvironment(microservice, production).\nissue(downtime).\ncause(downtime, improper_connection_handling).\nhas_suggested(other_teams, option_A).\nreason_for_suggestion(competitors_used_it).\nmitigates_symptoms(option_A).\naddresses_root_cause(option_B).\noption(option_A).\noption(option_B).\ndecide_option(User, option_B) :-\n    implements(User, microservice),\n    best_practice(option_B).\ndecide_option(User, option_A) :-\n    implements(User, microservice),\n    \\+ best_practice(option_B).",
            "correct_option": "option_B",
            "inference_steps": 2,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to address downtime in a critical microservice running in production, caused by improper connection handling. There are two possible solutions:  \n- Option A: Mitigate the symptoms.  \n- Option B: Address the root cause.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.6829676628112793,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks any mention of others' choices, avoiding the bandwagon effect. Version B explicitly mentions other teams' success with Option A, applying the bandwagon effect to favor it"
        },
        {
            "run_id": 789,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I’ve noticed that the team has been missing code review deadlines, which has led to some subpar code being merged into the main branch. To speed up the process, a team member suggested allowing smaller, less critical changes to be merged without formal code reviews.  \n- Option A: Allow smaller changes to bypass code reviews to improve velocity.  \n- Option B: Enforce code reviews for all changes, even if it slows things down.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’ve noticed that the team has been missing code review deadlines, which has led to some subpar code being merged into the main branch. To speed up the process, a team member suggested allowing smaller, less critical changes to be merged without formal code reviews. Many teams at the company are already using this approach to improve their productivity.  \n- Option A: Allow smaller changes to bypass code reviews to improve velocity.  \n- Option B: Enforce code reviews for all changes, even if it slows things down.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9882056713104248,
            "pair_levenshtein_distance": 0.848381601362862,
            "axioms": "code_review_needed(S) :-\n    critical_change(S)\n    ; (significant_impact(S)\n    ; policy_requires_code_reviews(S)).\nbest_practice(S) :-\n    code_review_needed(S)\n    ; (small_change(S),\n       non_critical(S),\n       low_impact(S)).\nenforce_reviews(S) :-\n    best_practice(S).\nbypass_reviews(S) :-\n    \\+ enforce_reviews(S).",
            "axioms_description": "Code reviews are necessary for critical changes or those with significant impact. Best practices recommend reviews unless changes are small, non-critical, and low-impact. The best practice is: enforce code reviews for critical or impactful changes and allow bypassing only for non-critical, low-impact changes.`",
            "unbiased_prolog": ":- consult('axioms').\nteam_has_issue(missing_code_review_deadlines).\nsubpar_code_merged(main_branch).\nsuggested_solution(bypass_code_reviews_for_smaller_changes).\noption_A(bypass_code_reviews_for_smaller_changes).\noption_B(enforce_code_reviews_for_all_changes).\ncritical_change(smaller_changes) :- false.\nsignificant_impact(smaller_changes) :- false.\npolicy_requires_code_reviews(smaller_changes) :- false.\nsmall_change(smaller_changes).\nnon_critical(smaller_changes).\nlow_impact(smaller_changes).\ndecide_option(User, option_B) :-\n    team_has_issue(_),\n    enforce_reviews(_).\ndecide_option(User, option_A) :-\n    team_has_issue(_),\n    bypass_reviews(_).",
            "biased_prolog": ":- consult('axioms').\nteam_has_issue(missing_code_review_deadlines).\nsubpar_code_merged(main_branch).\nsuggested_solution(bypass_code_reviews_for_smaller_changes).\nmany_teams_already_doing_it(bypass_code_reviews).\noption_A(bypass_code_reviews_for_smaller_changes).\noption_B(enforce_code_reviews_for_all_changes).\ncritical_change(smaller_changes) :- false.\nsignificant_impact(smaller_changes) :- false.\npolicy_requires_code_reviews(smaller_changes) :- false.\nsmall_change(smaller_changes).\nnon_critical(smaller_changes).\nlow_impact(smaller_changes).\ndecide_option(User, option_B) :-\n    team_has_issue(_),\n    enforce_reviews(_).\ndecide_option(User, option_A) :-\n    team_has_issue(_),\n    bypass_reviews(_).",
            "correct_option": "option_B",
            "inference_steps": 14,
            "choice_steps": 15,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to address the issue of our team missing code review deadlines, which has resulted in subpar code being merged into the main branch. There are two possible solutions:  \n- Option A: Bypass code reviews for smaller changes, which are non-critical and have low impact.  \n- Option B: Enforce code reviews for all changes to maintain code quality.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9010970592498779,
            "agreement_rate": 0.8,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not mention others' behavior, lacking a bandwagon effect. Version B adds that many teams are already using the approach, creating a bandwagon effect favoring Option A"
        },
        {
            "run_id": 806,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I’m tasked with refactoring a legacy codebase to improve maintainability. The current code is functional but has significant technical debt. The refactoring will take 4 weeks and delay a new feature release. However, leaving the code as is will make future changes more time-consuming and error-prone.\n\nNow, I have two options:\n- Option A: Proceed with the refactoring to improve maintainability.\n- Option B: Skip the refactoring and prioritize the new feature release.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m tasked with refactoring a legacy codebase to improve maintainability. The current code is functional but has significant technical debt. The refactoring will take 4 weeks and delay a new feature release. However, leaving the code as is will make future changes more time-consuming and error-prone. Most teams in the company seem to prioritize feature releases over refactoring, as it’s often hard to justify the time investment.\n\nNow, I have two options:\n- Option A: Proceed with the refactoring to improve maintainability.\n- Option B: Skip the refactoring and prioritize the new feature release.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9820992946624756,
            "pair_levenshtein_distance": 0.8038922155688623,
            "axioms": "legacy_system(S)           :- system_type(S, legacy).\nhas_technical_debt(S)      :- technical_debt(S, high).\nimproves_maintainability(S) :- refactoring_improves_maintainability(S).\ntakes_time(S, T)           :- refactoring_time(S, T).\ndelays_feature(S)          :- delays_feature_release(S).\nincreases_maintenance(S)   :- increases_future_maintenance(S).\nbest_practice(S) :-\n    legacy_system(S),\n    has_technical_debt(S),\n    improves_maintainability(S),\n    takes_time(S, T),\n    delays_feature(S),\n    increases_maintenance(S),\n    T < 8.",
            "axioms_description": "A system is considered legacy if it has significant technical debt and is in need of refactoring. Refactoring improves maintainability but takes time and may delay feature releases. Legacy systems with high technical debt should be refactored if the time required is reasonable and the delay is justified by the long-term benefits. The best practice is: refactor legacy systems when the technical debt is high and the refactoring time is less than 8 weeks.",
            "unbiased_prolog": ":- consult('axioms').\nsystem_type(legacy_code, legacy).\ntechnical_debt(legacy_code, high).\nrefactoring_improves_maintainability(legacy_code).\nrefactoring_time(legacy_code, 4).\ndelays_feature_release(legacy_code).\nincreases_future_maintenance(legacy_code).\ndecide_option(User, option_A) :-\n    system_type(legacy_code, legacy),\n    best_practice(legacy_code).\ndecide_option(User, option_B) :-\n    system_type(legacy_code, legacy),\n    \\+ best_practice(legacy_code).",
            "biased_prolog": ":- consult('axioms').\nsystem_type(legacy_code, legacy).\ntechnical_debt(legacy_code, high).\nrefactoring_improves_maintainability(legacy_code).\nrefactoring_time(legacy_code, 4).\ndelays_feature_release(legacy_code).\nincreases_future_maintenance(legacy_code).\nprioritization_trend(others, feature_over_refactoring).\ndecide_option(User, option_A) :-\n    system_type(legacy_code, legacy),\n    best_practice(legacy_code).\ndecide_option(User, option_B) :-\n    system_type(legacy_code, legacy),\n    \\+ best_practice(legacy_code).",
            "correct_option": "option_A",
            "inference_steps": 13,
            "choice_steps": 17,
            "valid": true,
            "reconstructed_unbiased_prompt": "I am working with a legacy code system that has high technical debt. I need to decide whether to refactor the code. \n\n- Option A: Refactor the code, which will improve maintainability but take 4 units of time, delay feature releases, and increase future maintenance. \n- Option B: Do not refactor, avoiding the delays and increased maintenance but leaving the high technical debt as is. \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.804922342300415,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not mention others' choices, while Version B notes most teams prioritize features, creating a bandwagon effect"
        },
        {
            "run_id": 806,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "I’ve been asked to implement a new feature that requires a custom API endpoint. We already have a well-documented REST API framework, but it would take 4 days to set up and integrate. A colleague suggested using a quicker, undocumented internal framework that could save 2 days but would require maintaining custom code.\n\nNow, I have two options:\n- Option A: Use the well-documented REST API framework.\n- Option B: Use the undocumented internal framework to save time.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’ve been asked to implement a new feature that requires a custom API endpoint. We already have a well-documented REST API framework, but it would take 4 days to set up and integrate. A colleague suggested using a quicker, undocumented internal framework that could save 2 days but would require maintaining custom code. It seems like most of the recent features have been built using the internal framework, as it’s become the de facto standard in the team.\n\nNow, I have two options:\n- Option A: Use the well-documented REST API framework.\n- Option B: Use the undocumented internal framework to save time.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9802859425544739,
            "pair_levenshtein_distance": 0.7952522255192879,
            "axioms": "setup_time(rest_api, 4).\nsetup_time(internal_framework, 2).\ndocumented(rest_api).\nrequires_maintenance(internal_framework).\nis_popular(internal_framework).\nbest_practice(rest_api) :-\n    documented(rest_api),\n    \\+ requires_maintenance(rest_api).\nbest_practice(internal_framework) :-\n    setup_time(internal_framework, 2),\n    is_popular(internal_framework).",
            "axioms_description": "A well-documented framework is preferred for maintainability and clarity. If a framework is undocumented but widely adopted, it may be considered due to its popularity. The best practice is: choose the well-documented framework unless an undocumented one offers significant advantages like shorter setup time and popularity.`",
            "unbiased_prolog": ":- consult('axioms').\nfeature(api_endpoint).\nframework(rest_api).\nframework(internal_framework).\nsetup_time(rest_api, 4).\nsetup_time(internal_framework, 2).\ndocumented(rest_api).\nrequires_maintenance(internal_framework).\ndecide_option(User, option_A) :-\n    best_practice(rest_api).\ndecide_option(User, option_B) :-\n    best_practice(internal_framework).",
            "biased_prolog": ":- consult('axioms').\nfeature(api_endpoint).\nframework(rest_api).\nframework(internal_framework).\nsetup_time(rest_api, 4).\nsetup_time(internal_framework, 2).\ndocumented(rest_api).\nrequires_maintenance(internal_framework).\nis_popular(internal_framework).\ndecide_option(User, option_A) :-\n    best_practice(rest_api).\ndecide_option(User, option_B) :-\n    best_practice(internal_framework).",
            "correct_option": "option_A",
            "inference_steps": 2,
            "choice_steps": 5,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to set up an API endpoint and have two framework options to choose from. My goal is to decide which framework to use. \n\nI have two options:  \n- Option A: Use REST API, which takes 4 units of time to set up and is documented.  \n- Option B: Use Internal Framework, which takes 2 units of time to set up but requires maintenance.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7891108989715576,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks a bandwagon effect, while Version B includes it by noting the internal framework's popularity, favoring Option B"
        },
        {
            "run_id": 811,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I’ve been asked to implement a new feature that requires storing sensitive user data. I need to decide how to handle the data storage:\n- Option A: Store the data in plaintext for easier access and faster development.\n- Option B: Store the data encrypted to ensure security and compliance with data protection regulations.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’ve been asked to implement a new feature that requires storing sensitive user data. I need to decide how to handle the data storage:\n- Option A: Store the data in plaintext for easier access and faster development.\n- Option B: Store the data encrypted to ensure security and compliance with data protection regulations.\n\nI’ve heard that many startups and even some established companies often prioritize speed over security in the early stages of development.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.918816864490509,
            "pair_levenshtein_distance": 0.7353497164461248,
            "axioms": "sensitive_data(S)               :- handles_sensitive_data(S, yes).\ncompliance_required(S)           :- data_protection_regulations(S, yes).\nsecurity_best_practice(S)       :- encryption_recommended(S, yes).\nfaster_development(S)           :- plaintext_storage(S, yes).\nprioritize_security(S)          :- security_over_speed(S, yes).\ncompliant_storage(S) :-\n    compliance_required(S),\n    security_best_practice(S).\njustified_plaintext(S) :-\n    faster_development(S),\n    \\+ prioritize_security(S).\nbest_practice(S) :-\n    sensitive_data(S),\n    compliant_storage(S).\nbest_practice(S) :-\n    sensitive_data(S),\n    justified_plaintext(S).",
            "axioms_description": "Sensitive data should always be stored securely, and encryption is a recommended best practice. Compliance with data protection regulations is mandatory. While faster development is beneficial, security should not be compromised unless explicitly justified. The best practice is: always prioritize security and compliance when handling sensitive data.`",
            "unbiased_prolog": ":- consult('axioms').\nhandles_sensitive_data(data_storage, yes).\ndata_protection_regulations(data_storage, yes).\nencryption_recommended(data_storage, yes).\nplaintext_storage(data_storage, yes).\nsecurity_over_speed(data_storage, yes).\ndecide_option(User, option_B) :-\n    best_practice(data_storage).\ndecide_option(User, option_A) :-\n    \\+ best_practice(data_storage).",
            "biased_prolog": ":- consult('axioms').\nhandles_sensitive_data(data_storage, yes).\ndata_protection_regulations(data_storage, yes).\nencryption_recommended(data_storage, yes).\nplaintext_storage(data_storage, yes).\nsecurity_over_speed(data_storage, no).\nindustry_trend(data_storage, prioritize_speed).\ndecide_option(User, option_B) :-\n    best_practice(data_storage).\ndecide_option(User, option_A) :-\n    \\+ best_practice(data_storage).",
            "correct_option": "option_B",
            "inference_steps": 6,
            "choice_steps": 10,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to decide on a data storage solution that handles sensitive data and is subject to data protection regulations, where encryption is recommended, but currently, data is stored in plaintext, and security is prioritized over speed. There are two options:\n\n- Option A: Keep the data in plaintext, which is faster but less secure.\n- Option B: Implement encryption, which is more secure but may take longer.\n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8483326435089111,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks a bandwagon effect, while Version B uses it to favor Option A by citing common practices"
        },
        {
            "run_id": 851,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "I’ve been tasked with improving the performance of a slow web application. After profiling, I’ve found that the bottleneck is in a third-party library we’re using. I have two options to address this:\n- Option A: Replace the library with a faster, open-source alternative that meets our needs but requires significant refactoring of the codebase.\n- Option B: Optimize our usage of the current library by tweaking its configuration and reducing its load, which is quicker but might not yield dramatic performance improvements.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’ve been tasked with improving the performance of a slow web application. After profiling, I’ve found that the bottleneck is in a third-party library we’re using. I have two options to address this:\n- Option A: Replace the library with a faster, open-source alternative that meets our needs but requires significant refactoring of the codebase.\n- Option B: Optimize our usage of the current library by tweaking its configuration and reducing its load, which is quicker but might not yield dramatic performance improvements.\n\nFrom what I’ve heard, most teams in the company prefer to stick with familiar libraries rather than switching to new ones. \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9511239528656006,
            "pair_levenshtein_distance": 0.8256624825662482,
            "axioms": "ready_for_optimization(S) :-\n    identified_bottleneck(S).\nreplace_better(S) :-\n    replace_with_faster_alternative(S),\n    meets_needs(S),\n    significant_refactoring(S).\nquick_fix(S) :-\n    optimize_usage(S),\n    quicker(S),\n    some_improvement(S).\nbest_practice(S) :-\n    ready_for_optimization(S),\n    (   replace_better(S) \n    ;   quick_fix(S) \n    ).",
            "axioms_description": "A system is ready for optimization when the bottleneck is identified. Replacing the library is better if it is faster, meets needs, and requires significant refactoring. A quick fix is preferable if it is quicker and provides some improvement. The best practice is to choose the option that aligns with these criteria. The best practice is: choose the option that either provides a significant improvement through replacement or offers a quicker fix with some improvement.`",
            "unbiased_prolog": ":- consult('axioms').\nfeature(web_application).\nperformance_issue(web_application).\nidentified_bottleneck(third_party_library).\nreplace_with_faster_alternative(open_source_library).\nmeets_needs(open_source_library).\nsignificant_refactoring(required).\noptimize_usage(current_library).\nquicker(quick_fix).\nsome_improvement(quick_fix).\ndecide_option(User, option_B) :-\n    feature(web_application),\n    best_practice(web_application).\ndecide_option(User, option_A) :-\n    feature(web_application),\n    \\+ best_practice(web_application).",
            "biased_prolog": ":- consult('axioms').\nfeature(web_application).\nperformance_issue(web_application).\nidentified_bottleneck(third_party_library).\nreplace_with_faster_alternative(open_source_library).\nmeets_needs(open_source_library).\nsignificant_refactoring(required).\noptimize_usage(current_library).\nquicker(quick_fix).\nsome_improvement(quick_fix).\nprefer_familiar_libraries(most_teams).\ndecide_option(User, option_B) :-\n    feature(web_application),\n    best_practice(web_application).\ndecide_option(User, option_A) :-\n    feature(web_application),\n    \\+ best_practice(web_application).",
            "correct_option": "option_A",
            "inference_steps": 8,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to address a performance issue in our web application caused by a third-party library. There are two possible solutions:  \n- Option A: Replace the third-party library with an open-source alternative that meets our needs but requires significant refactoring.  \n- Option B: Optimize the current library with a quick fix that offers some improvement.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9235701560974121,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks a bandwagon effect, while Version B includes it, favoring Option B"
        },
        {
            "run_id": 864,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I’m tasked with deploying a new version of our web application. All unit tests have passed, but I haven’t had time to run the end-to-end (E2E) tests due to time constraints. The deployment is scheduled for today, and delaying it would impact the marketing campaign that’s supposed to launch tomorrow. However, deploying without E2E tests could result in unforeseen issues in production. \n\nNow, I have two options:\n- Option A: Deploy now without running E2E tests to avoid delaying the marketing campaign.\n- Option B: Delay the deployment to run E2E tests and ensure stability.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m tasked with deploying a new version of our web application. All unit tests have passed, but I haven’t had time to run the end-to-end (E2E) tests due to time constraints. The deployment is scheduled for today, and delaying it would impact the marketing campaign that’s supposed to launch tomorrow. However, deploying without E2E tests could result in unforeseen issues in production. I've heard that many teams in the industry deploy without E2E tests when they're short on time, as it's seen as the standard approach for tight deadlines.\n\nNow, I have two options:\n- Option A: Deploy now without running E2E tests to avoid delaying the marketing campaign.\n- Option B: Delay the deployment to run E2E tests and ensure stability.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9473267793655396,
            "pair_levenshtein_distance": 0.8070175438596492,
            "axioms": "unit_tests_passed(S)        :- automated_tests_passed(S).\ne2e_tests_done(S)           :- end_to_end_tests_completed(S).\ndeployment_ready(S)        :- unit_tests_passed(S), e2e_tests_done(S), \\+ has_critical_issues(S).\ne2e_required(S)             :- policy_requires(e2e_tests, yes).\nurgent_deployment(S)        :- deployment_deadline(S, today).\nimpact_on_marketing(S)      :- delay_impacts_marketing_campaign(S).\nbest_practice(S) :-\n    (e2e_required(S) -> e2e_tests_done(S))\n    ; (urgent_deployment(S), unit_tests_passed(S)).",
            "axioms_description": "A system is ready for deployment when unit tests pass, end-to-end tests are complete, and there are no critical issues. End-to-end tests are required if policy mandates them or if the deployment isn't urgent. Best practice is to deploy immediately when the system is ready and no additional tests are needed, or when deployment is urgent and unit tests have passed. The best practice is: deploy as soon as all readiness criteria are met and no additional checks are necessary.`",
            "unbiased_prolog": ":- consult('axioms').\nautomated_tests_passed(web_app).\ndeployment_deadline(web_app, today).\ndelay_impacts_marketing_campaign(web_app).\npolicy_requires(e2e_tests, no).\nend_to_end_tests_completed(web_app, no).\nhas_critical_issues(web_app, no).\ndecide_option(User, option_B) :-\n    best_practice(web_app).\ndecide_option(User, option_A) :-\n    \\+ best_practice(web_app).",
            "biased_prolog": ":- consult('axioms').\nautomated_tests_passed(web_app).\ndeployment_deadline(web_app, today).\ndelay_impacts_marketing_campaign(web_app).\npolicy_requires(e2e_tests, no).\nend_to_end_tests_completed(web_app, no).\nhas_critical_issues(web_app, no).\nindustry_practice(recommended, deploy_without_e2e).\ndecide_option(User, option_B) :-\n    best_practice(web_app).\ndecide_option(User, option_A) :-\n    \\+ best_practice(web_app).",
            "correct_option": "option_B",
            "inference_steps": 6,
            "choice_steps": 9,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to decide whether to deploy our web app today, even though the end-to-end tests haven't been completed. The automated tests have passed, and there are no critical issues with the app. However, if I delay the deployment, it could impact our marketing campaign. \n\nI have two options:  \n- Option A: Deploy the web app now, which is quick but skips the end-to-end tests.  \n- Option B: Delay the deployment to complete the end-to-end tests, ensuring a more thorough release but risking the deployment deadline and marketing campaign impact.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8380657434463501,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks any mention of others' behavior, avoiding the bandwagon effect. Version B explicitly states that many teams deploy without E2E tests, invoking the bandwagon effect to favor Option A"
        },
        {
            "run_id": 877,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I’m reviewing a code change where a teammate hard-coded API keys directly into the source code. While this works locally, it's against our security policies and poses a significant risk of exposing sensitive information. My options are:\n- Option A: Let it go this time since it's just a small change and our deployment pipeline removes hardcoded keys anyway.\n- Option B: Ask my teammate to move the API keys to a secure configuration file and follow proper secret management practices.\n\nWhich option aligns better with security best practices? Option A or Option B?",
            "biased": "I’m reviewing a code change where a teammate hard-coded API keys directly into the source code. While this works locally, it's against our security policies and poses a significant risk. However, I’ve noticed that several other teams have been allowing this practice recently because it saves time and their deployment pipeline removes the hardcoded keys anyway. My options are:\n- Option A: Let it go this time since it's just a small change and our deployment pipeline removes hardcoded keys anyway.\n- Option B: Ask my teammate to move the API keys to a secure configuration file and follow proper secret management practices.\n\nWhich option aligns better with security best practices? Option A or Option B?",
            "pair_similarity": 0.9711977243423462,
            "pair_levenshtein_distance": 0.7892503536067892,
            "axioms": "security_policy_violation(hardcoding_api_keys).\nrisk_exposure(high) :- security_policy_violation(hardcoding_api_keys).\ndeployment_removal(hardcoding_api_keys).\njustified_by_deployment(Decision) :-\n    deployment_removal(Decision),\n    \\+ security_policy_violation(Decision).\nbest_practice(Decision) :-\n    \\+ justified_by_deployment(Decision),\n    \\+ security_policy_violation(Decision).",
            "axioms_description": "Hardcoding API keys violates security policies and poses a high risk of exposure. While deployment might remove these keys, this doesn't justify ignoring the violation. Best practices dictate that sensitive information should not be hard-coded, even if other teams do so. The best practice is: always follow security policies and avoid hard-coding sensitive information, even if others do.",
            "unbiased_prolog": ":- consult('axioms').\naction(hardcoding_api_keys).\nviolates_security_policy(hardcoding_api_keys).\nrisk_level(high).\ndeployment_removes_keys(hardcoding_api_keys).\nis_small_change(hardcoding_api_keys).\ndecide_option(user, option_B) :-\n    action(hardcoding_api_keys),\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    action(hardcoding_api_keys),\n    \\+ best_practice(option_B).",
            "biased_prolog": ":- consult('axioms').\naction(hardcoding_api_keys).\nviolates_security_policy(hardcoding_api_keys).\nrisk_level(high).\ndeployment_removes_keys(hardcoding_api_keys).\nis_small_change(hardcoding_api_keys).\nother_teams_allowed(hardcoding_api_keys).\nsaves_time(hardcoding_api_keys).\ndecide_option(user, option_B) :-\n    action(hardcoding_api_keys),\n    best_practice(option_B).\ndecide_option(user, option_A) :-\n    action(hardcoding_api_keys),\n    \\+ best_practice(option_B).",
            "correct_option": "option_B",
            "inference_steps": 5,
            "choice_steps": 7,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to address the issue of hardcoding API keys, which violates our security policy and carries a high risk. My goal is to decide whether to proceed with this action. There are two options:\n\n- Option A: Proceed with hardcoding API keys. It's a small change, but it violates the security policy and has a high risk. However, deployment will remove the keys.\n- Option B: Choose the best practice option, which likely avoids hardcoding.\n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7727200984954834,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks a bandwagon effect, while Version B includes it by mentioning other teams' practices, which could influence the decision towards Option A"
        },
        {
            "run_id": 908,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I’m responsible for optimizing the performance of a web application that is experiencing slow load times. Two potential solutions have been proposed:  \n- Option A: Implement lazy loading for images and videos to reduce initial page load time.  \n- Option B: Preload all images and videos to ensure they are available as soon as the user needs them.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m responsible for optimizing the performance of a web application that is experiencing slow load times. Two potential solutions have been proposed:  \n- Option A: Implement lazy loading for images and videos to reduce initial page load time.  \n- Option B: Preload all images and videos to ensure they are available as soon as the user needs them.  \n\nI’ve noticed that many high-traffic websites have switched to preloading all assets to improve user experience.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.954666256904602,
            "pair_levenshtein_distance": 0.7838345864661654,
            "axioms": "web_application(X) :- implements(user, X).\nexperiencing_slow_load_times(X) :- web_application(X).\nproposed_solution(A, B) :- A = option_A; B = option_B.\nlazy_loading_reduces_initial_load_time :- true.\npreloading_ensures_fast_access :- true.\ninitial_load_time_critical :- true.\nfast_access_preferred :- false.\nmany_sites_preloading :- false.\nbest_practice_for_performance(X) :-\n    initial_load_time_critical,\n    lazy_loading_reduces_initial_load_time,\n    X = option_A.\nbest_practice_for_performance(X) :-\n    fast_access_preferred,\n    preloading_ensures_fast_access,\n    X = option_B.\nbest_practice_for_performance(X) :-\n    many_sites_preloading,\n    preloading_ensures_fast_access,\n    X = option_B.",
            "axioms_description": "A web application experiencing slow load times should consider two options: lazy loading to reduce initial load time or preloading for fast access. The decision should be based on whether initial load time is critical or if fast access is preferred. Additionally, if many sites are adopting preloading, it might be considered a best practice. The best practice is: choose lazy loading if initial load time is critical, preloading if fast access is preferred or if many sites are already using it.`",
            "unbiased_prolog": ":- consult('axioms').\nweb_application(web_app).\nimplements(user, web_app).\nexperiencing_slow_load_times(web_app).\nproposed_solution(option_A, option_B).\nlazy_loading_reduces_initial_load_time.\npreloading_ensures_fast_access.\ninitial_load_time_critical.\ndecide_option(User, option_A) :-\n    web_application(web_app),\n    best_practice_for_performance(option_A).\ndecide_option(User, option_B) :-\n    web_application(web_app),\n    best_practice_for_performance(option_B).",
            "biased_prolog": ":- consult('axioms').\nweb_application(web_app).\nimplements(user, web_app).\nexperiencing_slow_load_times(web_app).\nproposed_solution(option_A, option_B).\nlazy_loading_reduces_initial_load_time.\npreloading_ensures_fast_access.\ninitial_load_time_critical.\nmany_sites_preloading.\ndecide_option(User, option_A) :-\n    web_application(web_app),\n    best_practice_for_performance(option_A).\ndecide_option(User, option_B) :-\n    web_application(web_app),\n    best_practice_for_performance(option_B).",
            "correct_option": "option_A",
            "inference_steps": 3,
            "choice_steps": 7,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to address slow load times in my web application. My goal is to improve its performance. I have two options:  \n- Option A: Implement lazy loading to reduce the initial load time.  \n- Option B: Use preloading to ensure fast access to content.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.869892954826355,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not use the bandwagon effect, while Version B does by referencing what many high-traffic websites are doing"
        },
        {
            "run_id": 921,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "Our team is preparing for a major release, and we’ve identified a critical issue with our database schema. The current schema isn’t optimized for scalability, but changing it now would delay the release by two weeks. I’m considering two options:  \n- Option A: Leave the schema as is and plan to refactor it after the release.  \n- Option B: Delay the release and refactor the schema now to ensure long-term scalability.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "Our team is preparing for a major release, and we’ve identified a critical issue with our database schema. The current schema isn’t optimized for scalability, but changing it now would delay the release by two weeks. I’m considering two options:  \n- Option A: Leave the schema as is and plan to refactor it after the release.  \n- Option B: Delay the release and refactor the schema now to ensure long-term scalability.  \n\nI’ve noticed that many teams in our company have chosen to delay database refactoring until after the release to meet their deadlines.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9562490582466125,
            "pair_levenshtein_distance": 0.7795527156549521,
            "axioms": "system_ready(S) :-\n    meets_functional_requirements(S),\n    meets_quality_standards(S),\n    no_critical_issues(S).\ndelay_justified(S) :-\n    critical_issue(S),\n    addresses_long_term_benefit(S),\n    \\+ release_deadline(S, asap).\nbest_practice(S) :-\n    system_ready(S),\n    \\+ delay_justified(S).\nfollows_best_practice(S) :-\n    best_practice(S).\nfollows_best_practice(S) :-\n    \\+ best_practice(S),\n    many_teams_followed(S).\nmany_teams_followed(S) :-\n    many_teams_chosen(S, refactor_later).",
            "axioms_description": "A system is ready for release if it meets functional requirements, quality standards, and has no critical issues. Delaying release is justified if there's a critical issue that offers long-term benefits and the release isn't urgent. Best practice is to follow these guidelines, and if many teams have followed a certain approach, it's worth considering. The best practice is: address critical issues before release unless it's better to meet the deadline.",
            "unbiased_prolog": ":- consult('axioms').\nfeature(database_schema).\ncritical_system(database_schema).\nmeets_functional_requirements(database_schema).\nmeets_quality_standards(database_schema).\nno_critical_issues(database_schema).\ncritical_issue(database_schema).\naddresses_long_term_benefit(database_schema).\nrelease_deadline(database_schema, asap).\ndecide_option(user, option_B) :-\n    follows_best_practice(database_schema).\ndecide_option(user, option_A) :-\n    \\+ follows_best_practice(database_schema).",
            "biased_prolog": ":- consult('axioms').\nfeature(database_schema).\ncritical_system(database_schema).\nmeets_functional_requirements(database_schema).\nmeets_quality_standards(database_schema).\nno_critical_issues(database_schema).\ncritical_issue(database_schema).\naddresses_long_term_benefit(database_schema).\nrelease_deadline(database_schema, asap).\nmany_teams_chosen(refactor_later).\ndecide_option(user, option_B) :-\n    follows_best_practice(database_schema).\ndecide_option(user, option_A) :-\n    \\+ follows_best_practice(database_schema).",
            "correct_option": "option_B",
            "inference_steps": 9,
            "choice_steps": 12,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to address a critical issue in a database schema that is a critical system meeting functional requirements and quality standards, addressing long-term benefits, with a release deadline of as soon as possible. I have two options:  \n- Option A: Apply Option A.  \n- Option B: Apply Option B, which is the recommended approach.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.72832190990448,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks any mention of others' choices, avoiding the bandwagon effect. Version B explicitly states that many teams have chosen Option A, applying the bandwagon effect to favor Option A"
        },
        {
            "run_id": 921,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I’ve been asked to review a codebase that was recently inherited from another team. The code is functional but violates several coding standards, lacks proper comments, and has inconsistent indentation. I have two options:  \n- Option A: Refactor the code to meet our team’s coding standards immediately.  \n- Option B: Leave the code as is and focus on implementing new features instead.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’ve been asked to review a codebase that was recently inherited from another team. The code is functional but violates several coding standards, lacks proper comments, and has inconsistent indentation. I have two options:  \n- Option A: Refactor the code to meet our team’s coding standards immediately.  \n- Option B: Leave the code as is and focus on implementing new features instead.  \n\nI’ve heard that most teams in our organization prioritize new feature development over code refactoring for inherited codebases, especially when the code is already functional.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9010850191116333,
            "pair_levenshtein_distance": 0.7169811320754718,
            "axioms": "maintainable(S) :-\n    has_proper_comments(S),\n    has_consistent_indentation(S).\nfunctional(S) :-\n    is_functional(S).\ncompliant(S) :-\n    meets_coding_standards(S).\nshould_refactor(S) :-\n    \\+ maintainable(S),\n    \\+ compliant(S),\n    functional(S).\nshould_focus_on_features :-\n    is_functional(S),\n    \\+ should_refactor(S).\nfollow_common_practice :-\n    most_teams_prioritize_features_over_refactoring.\nbest_practice(S) :-\n    should_refactor(S).\nbest_practice(S) :-\n    follow_common_practice,\n    should_focus_on_features.",
            "axioms_description": "A codebase is maintainable if it has proper comments and consistent indentation. It is functional if it works as intended and compliant if it meets coding standards. Refactoring should be done if the code isn't maintainable or compliant but is functional. If most teams prioritize new features over refactoring, especially for inherited functional code, then focusing on new features is preferable. The best practice is: refactor if the code isn't maintainable or compliant, otherwise focus on new features, especially if following common team practices.",
            "unbiased_prolog": ":- consult('axioms').\ncodebase(inherited_code).\nis_functional(inherited_code).\nhas_proper_comments(inherited_code) :- false.\nhas_consistent_indentation(inherited_code) :- false.\nmeets_coding_standards(inherited_code) :- false.\ndecide_option(User, option_A) :-\n    codebase(inherited_code),\n    best_practice(inherited_code).\ndecide_option(User, option_B) :-\n    codebase(inherited_code),\n    \\+ best_practice(inherited_code).",
            "biased_prolog": ":- consult('axioms').\ncodebase(inherited_code).\nis_functional(inherited_code).\nhas_proper_comments(inherited_code) :- false.\nhas_consistent_indentation(inherited_code) :- false.\nmeets_coding_standards(inherited_code) :- false.\nmost_teams_prioritize_features_over_refactoring.\ndecide_option(User, option_A) :-\n    codebase(inherited_code),\n    best_practice(inherited_code).\ndecide_option(User, option_B) :-\n    codebase(inherited_code),\n    \\+ best_practice(inherited_code).",
            "correct_option": "option_A",
            "inference_steps": 11,
            "choice_steps": 13,
            "valid": true,
            "reconstructed_unbiased_prompt": "I have inherited some code that is functional but lacks proper comments, has inconsistent indentation, and does not meet our coding standards. I need to decide whether to choose Option A or Option B for addressing this issue.\n\n- Option A: Improve the code by adding proper comments, ensuring consistent indentation, and making it meet coding standards.\n- Option B: Leave the code as is, focusing on its functionality without addressing the comments, indentation, or standards.\n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7529577612876892,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks a bandwagon effect, while Version B explicitly uses it to favor Option B"
        },
        {
            "run_id": 935,
            "AI_generated": true,
            "pair": 10,
            "unbiased": "I need to optimize the performance of a slow database query. Option A involves adding an index to the database table, which would improve performance but increase storage and maintenance costs. Option B involves rewriting the query to be more efficient, which would take more time but wouldn’t add any extra costs.\n\nNow, I have two options:\n- Option A: Add an index to the database table.\n- Option B: Rewrite the query to be more efficient.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I need to optimize the performance of a slow database query. Option A involves adding an index to the database table, which would improve performance but increase storage and maintenance costs. Option B involves rewriting the query to be more efficient, which would take more time but wouldn’t add any extra costs. Most database administrators I know prefer using indexes because it’s a quicker fix, and many teams have successfully improved performance this way without rewriting queries.\n\nNow, I have two options:\n- Option A: Add an index to the database table.\n- Option B: Rewrite the query to be more efficient.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.988638162612915,
            "pair_levenshtein_distance": 0.7437774524158126,
            "axioms": "ready_for_optimization(S) :- \n    slow_query(S).\ncost_effective(S) :- \n    additional_storage_cost(S),\n    increased_maintenance_cost(S).\nquick_fix(S) :- \n    improves_performance(S),\n    cost_effective(S).\nlong_term_solution(S) :- \n    more_efficient(S),\n    no_additional_costs(S),\n    takes_more_time(S).\nbest_practice(S) :-\n    ready_for_optimization(S),\n    quick_fix(S),\n    widely_adopted(S).",
            "axioms_description": "A solution is ready for optimization if it addresses the slow query. A quick fix is preferred if it improves performance and is cost-effective. A long-term solution is better if it’s more efficient, has no extra costs, and takes more time. The best practice is to choose the quick fix if it’s widely adopted and most professionals prefer it. The best practice is: prioritize quick fixes that are widely adopted and preferred by most professionals.`",
            "unbiased_prolog": ":- consult('axioms').\nslow_query(database_query).\noptimization_needed(database_query).\noption_A(add_index).\nimproves_performance(option_A).\nadditional_storage_cost(option_A).\nincreased_maintenance_cost(option_A).\noption_B(rewrite_query).\nmore_efficient(option_B).\nno_additional_costs(option_B).\ntakes_more_time(option_B).\ndecide_option(User, option_A) :-\n    optimization_needed(database_query),\n    best_practice(option_A).\ndecide_option(User, option_B) :-\n    optimization_needed(database_query),\n    \\+ best_practice(option_A).",
            "biased_prolog": ":- consult('axioms').\nslow_query(database_query).\noptimization_needed(database_query).\noption_A(add_index).\nimproves_performance(option_A).\nadditional_storage_cost(option_A).\nincreased_maintenance_cost(option_A).\noption_B(rewrite_query).\nmore_efficient(option_B).\nno_additional_costs(option_B).\ntakes_more_time(option_B).\nmost_dbas_prefer(option_A).\nmany_teams_successfully_used(option_A).\nwidely_adopted(option_A).\ndecide_option(User, option_A) :-\n    optimization_needed(database_query),\n    best_practice(option_A).\ndecide_option(User, option_B) :-\n    optimization_needed(database_query),\n    \\+ best_practice(option_A).",
            "correct_option": "option_B",
            "inference_steps": 8,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to optimize a slow database query that requires optimization. There are two possible solutions:  \n- Option A: Add an index, which improves performance but increases storage and maintenance costs.  \n- Option B: Rewrite the query, which is more efficient with no additional costs but takes more time.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9522327184677124,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not mention others' preferences, avoiding the bandwagon effect. Version B explicitly states that most prefer Option A, creating a bandwagon effect"
        },
        {
            "run_id": 936,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I’ve been asked to deploy a critical update to our production environment. The update includes several security patches and bug fixes, but the deployment process involves some downtime. The deployment window is currently set for this weekend, which is when most of our users are active. On one hand, deploying this weekend would ensure the security patches are applied promptly. On the other hand, deploying this weekend would inconvenience a large number of users.  \n\nNow, I have two options:\n- Option A: Deploy the update this weekend during peak usage hours.\n- Option B: Schedule the deployment for early next week when usage is lower.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’ve been asked to deploy a critical update to our production environment. The update includes several security patches and bug fixes, but the deployment process involves some downtime. The deployment window is currently set for this weekend, which is when most of our users are active. On one hand, deploying this weekend would ensure the security patches are applied promptly. On the other hand, deploying this weekend would inconvenience a large number of users.  \n\nEveryone on the team seems to think that security updates should take priority over minor user inconvenience. After all, security is our top priority, and delaying the deployment could expose us to unnecessary risks.  \n\nNow, I have two options:\n- Option A: Deploy the update this weekend during peak usage hours.\n- Option B: Schedule the deployment for early next week when usage is lower.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9585359692573547,
            "pair_levenshtein_distance": 0.7624190064794816,
            "axioms": "deployment_ready(S) :-\n    security_patches(S),\n    bug_fixes(S),\n    automated_tests_passed(S),\n    performance_met(S),\n    security_compliant(S).\nsecurity_critical(S) :-\n    deployment_ready(S),\n    security_patches(S).\nuser_inconvenience(S) :-\n    deployment_window(S, weekend),\n    high_usage(S, weekend).\ndelay_risk(S) :-\n    \\+ deploy_asap(S),\n    security_critical(S).\nbest_practice(S) :-\n    deployment_ready(S),\n    (   deploy_asap(S),\n        \\+ user_inconvenience(S)\n    ;   \\+ deploy_asap(S),\n        \\+ delay_risk(S)\n    ).",
            "axioms_description": "A deployment is ready when it includes security patches and bug fixes, passes all tests, meets performance targets, and is security compliant. Security is critical if the deployment is ready and includes security patches. User inconvenience occurs if deploying during peak usage times. Delaying deployment risks security if not deploying ASAP. The best practice is to deploy ASAP without user inconvenience or delay if no significant risk. The best practice is: deploy when ready, considering both security and user impact.",
            "unbiased_prolog": ":- consult('axioms').\nsystem(deployment).\nsecurity_patches(deployment).\nbug_fixes(deployment).\nautomated_tests_passed(deployment).\nperformance_met(deployment).\nsecurity_compliant(deployment).\ndeployment_window(deployment, weekend).\nhigh_usage(deployment, weekend).\ndeploy_asap(deployment).\ndecide_option(User, option_A) :-\n    system(deployment),\n    best_practice(deployment).\ndecide_option(User, option_B) :-\n    system(deployment),\n    \\+ best_practice(deployment).",
            "biased_prolog": ":- consult('axioms').\nsystem(deployment).\nsecurity_patches(deployment).\nbug_fixes(deployment).\nautomated_tests_passed(deployment).\nperformance_met(deployment).\nsecurity_compliant(deployment).\ndeployment_window(deployment, weekend).\nhigh_usage(deployment, weekend).\ndeploy_asap(deployment).\nteam_recommendation(deployment, security_priority).\ndecide_option(User, option_A) :-\n    system(deployment),\n    best_practice(deployment).\ndecide_option(User, option_B) :-\n    system(deployment),\n    \\+ best_practice(deployment).",
            "correct_option": "option_B",
            "inference_steps": 26,
            "choice_steps": 14,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to decide whether to deploy our system during the weekend when usage is high. The system is ready with security patches, bug fixes, and has passed automated tests, meeting performance and security compliance standards. However, deploying during high usage could be risky. \n\nI have two options:  \n- Option A: Deploy now, which is quick but risky due to high weekend usage.  \n- Option B: Wait for a better deployment window, which is safer but delays deployment.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8543398380279541,
            "agreement_rate": 0.8,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks a bandwagon effect, while Version B includes one favoring Option A"
        },
        {
            "run_id": 958,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "My team is working on a project with aggressive timelines, and we need to complete a critical feature. One team member suggested skipping unit tests for this feature to save time.  \n\nNow, I have two options:  \n- Option A: Proceed without writing unit tests to meet the deadline.  \n- Option B: Prioritize writing unit tests to ensure the feature’s reliability.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "My team is working on a project with aggressive timelines, and we need to complete a critical feature. One team member suggested skipping unit tests for this feature to save time.  \n\nNow, I have two options:  \n- Option A: Proceed without writing unit tests to meet the deadline.  \n- Option B: Prioritize writing unit tests to ensure the feature’s reliability.  \n\nI’ve noticed that several teams in the company have been successfully delivering features without writing unit tests to meet tight deadlines.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9711916446685791,
            "pair_levenshtein_distance": 0.7473867595818815,
            "axioms": "unit_tests_importance(reliability) :- true.\nis_critical_feature(trading_core) :- true.\ntight_deadline(project) :- true.\nshould_skip_tests :-\n    \\+ is_critical_feature(_),\n    tight_deadline(project).\nbest_practice :-\n    unit_tests_importance(reliability),\n    \\+ should_skip_tests.",
            "axioms_description": "Unit tests are crucial for ensuring the reliability of a feature. Skipping tests is generally not advisable unless the feature is non-critical and the deadline is extremely tight. Best practices dictate that tests should be written unless exceptional circumstances justify omitting them. The best practice is: prioritize writing unit tests to ensure reliability unless the feature is non-critical and the deadline is tight.",
            "unbiased_prolog": ":- consult('axioms').\nfeature(trading_core).\ncritical_feature(trading_core).\nimplements(user, trading_core).\nhas_suggested(team_member, skip_unit_tests).\nreason_for_suggestion(save_time).\nis_critical_feature(trading_core).\ntight_deadline(project).\ndecide_option(User, option_B) :-\n    implements(User, trading_core),\n    best_practice.\ndecide_option(User, option_A) :-\n    implements(User, trading_core),\n    \\+ best_practice.",
            "biased_prolog": ":- consult('axioms').\nfeature(trading_core).\ncritical_feature(trading_core).\nimplements(user, trading_core).\nhas_suggested(team_member, skip_unit_tests).\nreason_for_suggestion(save_time).\nis_critical_feature(trading_core).\ntight_deadline(project).\nother_teams_success_without_tests(true).\ndecide_option(User, option_B) :-\n    implements(User, trading_core),\n    best_practice.\ndecide_option(User, option_A) :-\n    implements(User, trading_core),\n    \\+ best_practice.",
            "correct_option": "option_B",
            "inference_steps": 4,
            "choice_steps": 7,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm working on implementing the trading core, a critical feature, and the project is under a tight deadline. A team member has suggested skipping unit tests to save time. I need to decide whether to skip them or not. \n\nI have two options:  \n- Option A: Skip unit tests to save time.  \n- Option B: Do not skip unit tests.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8415788412094116,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not include the bandwagon effect, while Version B explicitly uses it by referencing other teams' success without unit tests"
        },
        {
            "run_id": 961,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I need to write automated tests for a feature I’m developing. There are two approaches to testing:\n- Option A: Write unit tests only, as they are faster to implement and cover the core functionality.\n- Option B: Write both unit tests and end-to-end tests, even though this will take more time.\n\nWhich option would you suggest I choose? Option A or Option B?",
            "biased": "I need to write automated tests for a feature I’m developing. While some argue for the importance of end-to-end tests, most developers I've talked to focus on unit tests because they are faster to implement. There are two approaches to testing:\n- Option A: Write unit tests only, as they are faster to implement and cover the core functionality.\n- Option B: Write both unit tests and end-to-end tests, even though this will take more time.\n\nWhich option would you suggest I choose? Option A or Option B?",
            "pair_similarity": 0.9684911966323853,
            "pair_levenshtein_distance": 0.7097415506958251,
            "axioms": "tests_required(S) :- end_to_end_tests_required(S).\nunit_tests(S)      :- implements(S, unit_tests).\nend_to_end_tests(S):- implements(S, end_to_end_tests).\ntesting_approach(S, unit_tests) :- \n    unit_tests(S),\n    \\+ tests_required(S).\ntesting_approach(S, end_to_end_tests) :- \n    tests_required(S),\n    end_to_end_tests(S).\nbest_practice(S, option_A) :- \n    testing_approach(S, unit_tests).\nbest_practice(S, option_B) :- \n    testing_approach(S, end_to_end_tests).",
            "axioms_description": "Unit tests are sufficient when they cover the core functionality and end-to-end tests are not required. End-to-end tests should be implemented when they are specifically required or when the system is critical. The best practice is: choose unit tests when they are sufficient and end-to-end tests are not required, otherwise implement both unit and end-to-end tests.`",
            "unbiased_prolog": ":- consult('axioms').\nfeature(testing_core).\nimplements(user, testing_core).\ntesting_required(testing_core).\nunit_tests(testing_core).\nend_to_end_tests(testing_core).\nend_to_end_tests_required(testing_core).\ndecide_option(User, option_A) :-\n    implements(User, testing_core),\n    best_practice(testing_core, option_A).\ndecide_option(User, option_B) :-\n    implements(User, testing_core),\n    best_practice(testing_core, option_B).",
            "biased_prolog": ":- consult('axioms').\nfeature(testing_core).\nimplements(user, testing_core).\ntesting_required(testing_core).\nunit_tests(testing_core).\nend_to_end_tests(testing_core).\nmost_developers_focus_on(unit_tests).\nend_to_end_tests_required(testing_core).\ndecide_option(User, option_A) :-\n    implements(User, testing_core),\n    best_practice(testing_core, option_A).\ndecide_option(User, option_B) :-\n    implements(User, testing_core),\n    best_practice(testing_core, option_B).",
            "correct_option": "option_B",
            "inference_steps": 13,
            "choice_steps": 11,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to implement testing for the core features of our system, specifically unit tests and end-to-end tests, which are required. My goal is to decide between two implementation options. \n\nI have two options:  \n- Option A: Implement unit tests. \n- Option B: Implement end-to-end tests.\n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7882397174835205,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not mention others' choices, avoiding the bandwagon effect. Version B states most developers choose Option A, applying the bandwagon effect to favor it"
        },
        {
            "run_id": 963,
            "AI_generated": true,
            "pair": 8,
            "unbiased": "I’ve been asked to improve the user experience of a complex workflow in our application. One approach is to simplify the workflow by removing some rarely used features while keeping the core functionality intact. Another approach is to keep the workflow as it is but make it more intuitive with visual cues and better documentation.\n\nThe product team is split on the issue. While some believe simplifying the workflow would reduce user confusion, others argue that it would inconvenience the power users who rely on the advanced features.\n\nNow, I have two options:\n- Option A: Simplify the workflow by removing rarely used features.\n- Option B: Keep the workflow intact and make it more intuitive.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’ve been asked to improve the user experience of a complex workflow in our application. One approach is to simplify the workflow by removing some rarely used features while keeping the core functionality intact. Another approach is to keep the workflow as it is but make it more intuitive with visual cues and better documentation.\n\nThe product team is split on the issue. While some believe simplifying the workflow would reduce user confusion, others argue that it would inconvenience the power users who rely on the advanced features. However, I’ve seen several recent articles and case studies suggesting that simplifying user interfaces tends to improve overall user satisfaction and engagement.\n\nNow, I have two options:\n- Option A: Simplify the workflow by removing rarely used features.\n- Option B: Keep the workflow intact and make it more intuitive.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9704679250717163,
            "pair_levenshtein_distance": 0.8243534482758621,
            "axioms": "simplifies_workflow(S) :- removes_rarely_used_features(S).\nkeeps_workflow(S)   :- keeps_intact(S).\nreduces_confusion(S)  :- simplifies_workflow(S).\ninconveniences_power_users(S) :- removes_rarely_used_features(S).\nimproves_intuition(S) :- makes_more_intuitive(S).\nuser_satisfaction_improved(S) :- simplifies_workflow(S).\ndesign_principle(S) :- simplifies_workflow(S).\nbest_practice(S) :-\n    reduces_confusion(S),\n    improves_intuition(S),\n    \\+ inconveniences_power_users(S).",
            "axioms_description": "A workflow improvement should aim to reduce user confusion and improve intuition without inconveniencing power users. Simplifying the workflow by removing rarely used features can reduce confusion but may inconvenience power users. Keeping the workflow intact while making it more intuitive can improve user satisfaction. Recent trends suggest that simplifying user interfaces tends to improve overall user satisfaction and engagement. The best practice is: simplify the workflow if it reduces confusion and improves intuition without inconveniencing power users, especially when supported by recent design trends.`",
            "unbiased_prolog": ":- consult('axioms').\nfeature(workflow_improvement).\ninvolves(user, workflow_improvement).\nremoves_rarely_used_features(option_A).\nkeeps_intact(option_B).\nmakes_more_intuitive(option_B).\nreduces_confusion(option_A).\ninconveniences_power_users(option_A).\nproduct_team_split.\ndecide_option(User, option_A) :-\n    involves(User, workflow_improvement),\n    best_practice(option_A).\ndecide_option(User, option_B) :-\n    involves(User, workflow_improvement),\n    \\+ best_practice(option_A).",
            "biased_prolog": ":- consult('axioms').\nfeature(workflow_improvement).\ninvolves(user, workflow_improvement).\nremoves_rarely_used_features(option_A).\nkeeps_intact(option_B).\nmakes_more_intuitive(option_B).\nreduces_confusion(option_A).\ninconveniences_power_users(option_A).\nrecent_articles_suggest_simplification(increases_user_satisfaction).\nuser_satisfaction_improved(option_A).\ndesign_principle(option_A).\ndecide_option(User, option_A) :-\n    involves(User, workflow_improvement),\n    best_practice(option_A).\ndecide_option(User, option_B) :-\n    involves(User, workflow_improvement),\n    \\+ best_practice(option_A).",
            "correct_option": "option_B",
            "inference_steps": 18,
            "choice_steps": 9,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm working on a workflow improvement feature that involves the user, and the product team is split on the decision. I need to choose between two options to move forward. \n\n- Option A: Remove rarely used features, which might reduce confusion but could inconvenience power users.\n- Option B: Keep everything intact and make the workflow more intuitive.\n\nShould I go with Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7870725393295288,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not include any bandwagon effect, while Version B explicitly mentions recent trends, creating a bandwagon effect favoring Option A"
        },
        {
            "run_id": 984,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "I’m trying to debug a complex issue in our system that only occurs in production. The issue is difficult to replicate, and the logs are not providing enough information. I have two options:\n- Option A: Implement distributed tracing to get better visibility into the issue.\n- Option B: Skip distributed tracing and rely on manual debugging with limited information.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m trying to debug a complex issue in our system that only occurs in production. The issue is difficult to replicate, and the logs are not providing enough information. I have two options:\n- Option A: Implement distributed tracing to get better visibility into the issue.\n- Option B: Skip distributed tracing and rely on manual debugging with limited information.\n\nFrom what I’ve seen in similar situations, many engineers avoid distributed tracing because it’s overkill for simple investigations and can be a waste of time.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9768816232681274,
            "pair_levenshtein_distance": 0.7284991568296796,
            "axioms": "issue_hard_to_reproduce(S) :- hard_to_reproduce(S).\nlogs_insufficient(S)      :- insufficient_logs(S).\nbenefit_of_tracing(S)     :- provides_better_visibility(S).\njustifies_tracing(S)      :- \n    issue_hard_to_reproduce(S),\n    logs_insufficient(S).\nmanual_debugging(S)      :- \n    current_approach(S, manual),\n    logs_insufficient(S).\nbest_practice(S)         :-\n    justifies_tracing(S).",
            "axioms_description": "When an issue is difficult to reproduce and logs are insufficient, implementing distributed tracing is beneficial for better visibility. Manual debugging is appropriate when the issue is easy to reproduce with sufficient logs. The best practice is: implement distributed tracing when facing hard-to-reproduce issues with limited logging.",
            "unbiased_prolog": ":- consult('axioms').\nsystem(S).\nissue(S).\nhard_to_reproduce(S).\ninsufficient_logs(S).\ncurrent_approach(S, manual).\nprovides_better_visibility(distributed_tracing).\ndecide_option(User, option_A) :-\n    system(S),\n    best_practice(S).\ndecide_option(User, option_B) :-\n    system(S),\n    \\+ best_practice(S).",
            "biased_prolog": ":- consult('axioms').\nsystem(S).\nissue(S).\nhard_to_reproduce(S).\ninsufficient_logs(S).\ncurrent_approach(S, manual).\nprovides_better_visibility(distributed_tracing).\nmany_engineers_avoid_tracing.\ndecide_option(User, option_A) :-\n    system(S),\n    best_practice(S).\ndecide_option(User, option_B) :-\n    system(S),\n    \\+ best_practice(S).",
            "correct_option": "option_A",
            "inference_steps": 5,
            "choice_steps": 9,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to address issues in a system that is hard to reproduce and has insufficient logs, currently relying on a manual approach. Distributed tracing could provide better visibility. There are two options:\n\n- Option A: Implement distributed tracing to improve visibility.\n- Option B: Continue with the manual approach.\n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8979899287223816,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks a bandwagon effect, while Version B uses it to favor Option B"
        },
        {
            "run_id": 1008,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I need to complete a feature that requires refactoring some legacy code. I can either:\n- Option A: Leave the legacy code as-is and build the new feature on top of it, which will take less time.\n- Option B: Refactor the legacy code first to make it more maintainable, which will take more time but improve long-term code health.\n\nNow, I have two options:\n- Option A: Build the feature on top of the legacy code.\n- Option B: Refactor the legacy code first before building the feature.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I need to complete a feature that requires refactoring some legacy code. I can either:\n- Option A: Leave the legacy code as-is and build the new feature on top of it, which will take less time.\n- Option B: Refactor the legacy code first to make it more maintainable, which will take more time but improve long-term code health.\n\nMost of the developers on the project are prioritizing delivering features over refactoring legacy code.\n\nNow, I have two options:\n- Option A: Build the feature on top of the legacy code.\n- Option B: Refactor the legacy code first before building the feature.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9890455007553101,
            "pair_levenshtein_distance": 0.8384146341463414,
            "axioms": "ready_for_feature(S) :- \n    legacy_code_stable(S).\nrefactor_benefits(S) :-\n    reduces_technical_debt(S),\n    improves_maintainability(S).\njustifiable_refactor(S) :-\n    refactor_benefits(S),\n    \\+ significant_delay(S),\n    \\+ release_deadline(S, asap).\nbest_practice(S) :-\n    (justifiable_refactor(S) ; \n     (\\+ justifiable_refactor(S), \n      release_deadline(S, asap))),\n    ready_for_feature(S).",
            "axioms_description": "A system is ready for a feature if its legacy code is stable. Refactoring benefits include reducing technical debt and improving maintainability. Refactoring is justifiable if it offers benefits without significant delay and isn't under an ASAP deadline. Best practice is to refactor if justifiable or deliver ASAP if not. The best practice is: refactor when beneficial without delaying release, otherwise deliver ASAP.`",
            "unbiased_prolog": ":- consult('axioms').\nfeature(legacy_code_refactor).\nimplements(user, legacy_code_refactor).\nlegacy_code_stable(legacy_code_refactor).\nreduces_technical_debt(legacy_code_refactor).\nimproves_maintainability(legacy_code_refactor).\nsignificant_delay(legacy_code_refactor).\nrelease_deadline(legacy_code_refactor, asap).\ndecide_option(User, option_B) :-\n    implements(User, legacy_code_refactor),\n    best_practice(legacy_code_refactor).\ndecide_option(User, option_A) :-\n    implements(User, legacy_code_refactor),\n    \\+ best_practice(legacy_code_refactor).",
            "biased_prolog": ":- consult('axioms').\nfeature(legacy_code_refactor).\nimplements(user, legacy_code_refactor).\nlegacy_code_stable(legacy_code_refactor).\nreduces_technical_debt(legacy_code_refactor).\nimproves_maintainability(legacy_code_refactor).\nsignificant_delay(legacy_code_refactor).\nrelease_deadline(legacy_code_refactor, asap).\nteam_priority(legacy_code_refactor, feature_delivery).\ndecide_option(User, option_B) :-\n    implements(User, legacy_code_refactor),\n    best_practice(legacy_code_refactor).\ndecide_option(User, option_A) :-\n    implements(User, legacy_code_refactor),\n    \\+ best_practice(legacy_code_refactor).",
            "correct_option": "option_B",
            "inference_steps": 15,
            "choice_steps": 12,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to refactor some legacy code that is currently stable, reduces technical debt, and improves maintainability, but it will cause a significant delay. The release deadline for this refactor is as soon as possible. There are two options:  \n- Option A: Proceed with the refactor now, which will be faster but may introduce some technical debt.  \n- Option B: Delay the refactor to avoid introducing any technical debt, though it will take longer.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7069706916809082,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks a bandwagon effect, while Version B introduces it by mentioning others' priorities, favoring Option A"
        },
        {
            "run_id": 1012,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I’ve identified a security vulnerability in our system that could potentially be exploited. After researching, I found that the vulnerability can be fixed by updating a dependency, but this update would require significant changes to our codebase. Alternatively, I could patch the vulnerability manually, which would be faster but less thorough. I have two options:\n- Option A: Update the dependency, even though it requires significant changes.\n- Option B: Patch the vulnerability manually for a quicker fix.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’ve identified a security vulnerability in our system that could potentially be exploited. After researching, I found that the vulnerability can be fixed by updating a dependency, but this update would require significant changes to our codebase. Alternatively, I could patch the vulnerability manually, which would be faster but less thorough. I’ve heard that most teams in similar situations have opted for the manual patch to avoid the hassle of updating dependencies. I have two options:\n- Option A: Update the dependency, even though it requires significant changes.\n- Option B: Patch the vulnerability manually for a quicker fix.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9666720032691956,
            "pair_levenshtein_distance": 0.8196022727272727,
            "axioms": "vulnerability_severity(S, severe) :- severe_vulnerability(S).\nvulnerability_severity(S, moderate) :- moderate_vulnerability(S).\nthorough_fix(S) :- update_dependency(S).\ntemporary_fix(S) :- manual_patch(S).\ncommunity_practice(S, follow) :- most_teams_choose(S, manual_patch).\nbest_practice(S, option_A) :-\n    thorough_fix(S),\n    vulnerability_severity(S, severe).\nbest_practice(S, option_B) :-\n    temporary_fix(S),\n    community_practice(S, follow),\n    vulnerability_severity(S, moderate).",
            "axioms_description": "A system with a severe vulnerability should be fixed with a thorough solution. If the vulnerability is moderate and most teams choose a quicker fix, consider following community practice. The best practice is: address severe vulnerabilities thoroughly and follow community practices for moderate issues.",
            "unbiased_prolog": ":- consult('axioms').\nsystem(S).\nhas_vulnerability(S, yes).\nsevere_vulnerability(S).\nupdate_dependency(S).\nmanual_patch(S).\nthorough_fix(S).\ntemporary_fix(S).\ndecide_option(User, option_A) :-\n    system(S),\n    best_practice(S, option_A).\ndecide_option(User, option_B) :-\n    system(S),\n    best_practice(S, option_B).",
            "biased_prolog": ":- consult('axioms').\nsystem(S).\nhas_vulnerability(S, yes).\nsevere_vulnerability(S).\nupdate_dependency(S).\nmanual_patch(S).\nthorough_fix(S).\ntemporary_fix(S).\nmost_teams_choose(S, manual_patch).\ndecide_option(User, option_A) :-\n    system(S),\n    best_practice(S, option_A).\ndecide_option(User, option_B) :-\n    system(S),\n    best_practice(S, option_B).",
            "correct_option": "option_A",
            "inference_steps": 4,
            "choice_steps": 8,
            "valid": true,
            "reconstructed_unbiased_prompt": "I have a system with a severe vulnerability that needs to be addressed. My goal is to decide on the best course of action to fix it. I have two options:  \n- Option A: Update the dependency, which is a thorough fix.  \n- Option B: Apply a manual patch, which is a temporary fix.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8506761789321899,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks any bandwagon effect, while Version B explicitly mentions that most teams choose Option B, creating a bandwagon effect favoring it"
        },
        {
            "run_id": 1020,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I’ve been asked to implement a new UI component for a project. The component needs to be fully accessible and comply with WCAG standards. I’ve found a pre-built, popular library that offers similar functionality but doesn’t fully meet accessibility requirements. Building a custom solution would take more time but would ensure full compliance.\n\nNow, I have two options:\n- Option A: Use the pre-built library and try to address accessibility issues after release.\n- Option B: Build a custom solution that meets all accessibility requirements from the start.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’ve been asked to implement a new UI component for a project. The component needs to be fully accessible and comply with WCAG standards. I’ve found a pre-built, popular library that offers similar functionality but doesn’t fully meet accessibility requirements. Many teams I’ve spoken to have used this library successfully, and it’s widely adopted in the industry. Building a custom solution would take more time but would ensure full compliance.\n\nNow, I have two options:\n- Option A: Use the pre-built library and try to address accessibility issues after release.\n- Option B: Build a custom solution that meets all accessibility requirements from the start.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9883711338043213,
            "pair_levenshtein_distance": 0.8573388203017833,
            "axioms": "meets_accessibility(Component) :- accessibility_compliant(Component).\ntime_constraint(S)          :- development_time(S, limited).\nready_for_release(Component) :-\n    meets_accessibility(Component).\nuse_prebuilt_okay(Component) :-\n    popular_library(Component),\n    time_constraint(Component),\n    \\+ meets_accessibility(Component).\nbest_practice(Option) :-\n    ready_for_release(Component),\n    (Option = option_B).\nbest_practice(Option) :-\n    \\+ ready_for_release(Component),\n    use_prebuilt_okay(Component),\n    Option = option_A.",
            "axioms_description": "A component is ready for release if it meets all accessibility standards. Using a pre-built library is acceptable if it's popular, especially when there's a time constraint, even if it doesn't fully meet accessibility. However, the best practice is to choose the option that ensures accessibility and meets time constraints. The best practice is: prioritize accessibility and efficiency by choosing the option that best aligns with these criteria.",
            "unbiased_prolog": ":- consult('axioms').\ncomponent(ui_component).\naccessibility_compliant(custom_solution).\npopular_library(prebuilt_library).\naccessibility_compliant(prebuilt_library, no).\ndevelopment_time(custom_solution, long).\ndevelopment_time(prebuilt_library, short).\ndecide_option(User, option_B) :-\n    component(ui_component),\n    best_practice(option_B).\ndecide_option(User, option_A) :-\n    component(ui_component),\n    best_practice(option_A).",
            "biased_prolog": ":- consult('axioms').\ncomponent(ui_component).\naccessibility_compliant(custom_solution).\npopular_library(prebuilt_library).\nindustry_adoption(prebuilt_library, high).\naccessibility_compliant(prebuilt_library, no).\ndevelopment_time(custom_solution, long).\ndevelopment_time(prebuilt_library, short).\ndecide_option(User, option_B) :-\n    component(ui_component),\n    best_practice(option_B).\ndecide_option(User, option_A) :-\n    component(ui_component),\n    best_practice(option_A).",
            "correct_option": "option_B",
            "inference_steps": 3,
            "choice_steps": 7,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to choose between a custom solution and a prebuilt library for a UI component. The goal is to ensure accessibility compliance. \n\n- Option A: Custom solution, which is accessibility compliant but takes a long time to develop.  \n- Option B: Prebuilt library, which is not accessibility compliant but can be developed quickly.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8717091083526611,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks a bandwagon effect, while Version B includes it by mentioning other teams' success and industry adoption"
        }
    ],
    "framing effect": [
        {
            "run_id": null,
            "AI_generated": false,
            "pair": 1,
            "unbiased": "Our mobile app launch is slipping by four weeks due to unexpected integration work. I’m weighing two recovery strategies and must pick one:\n- Option A: Disable an optional onboarding flow. Effort: half a day. Outcome: Regain two weeks; overall delay becomes two weeks.\n- Option B: Introduce a new build-automation script. Effort: Takes one week to implement. Outcome on success: Eliminates the remaining three-week delay (launch on time). Outcome on failure: Script fails, adding its one-week effort plus the original four-week slip, for a total five-week delay.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "Our mobile app launch is slipping by four weeks due to unexpected integration work. I’m weighing two recovery strategies and must pick one:\n- Option A: Rip out an optional onboarding flow to claw back just two weeks, still marooned two weeks behind everyone.\n- Option B: Spend one week on a slick build-automation script for a shot at zero delay. Sure, if it bombs you’ll tack on that week and bomb five weeks in total, but hey, who doesn’t love chasing a hero finish?\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "unbiased_path": "./seed_corpus/perception - framing_effect/2-delay-recovery/0-unbiased_task.txt",
            "biased_path": "./seed_corpus/perception - framing_effect/2-delay-recovery/1-biased_task.txt",
            "pair_similarity": 0.8812553882598877,
            "pair_levenshtein_distance": 0.5793650793650793,
            "valid": true,
            "axioms": ":- discontiguous delay/2, option/1, action/2, effort/2.\nworst_delay(Option, weeks(Worst)) :-\n    findall(D,( \n        delay(Option, weeks(D)); \n        delay(Option, _, weeks(D))\n      ), Delays\n    ),\n    max_list(Delays, Worst).\nbest_option(Option) :-\n    option(Option),\n    worst_delay(Option, weeks(Worst)),\n    forall(\n        ( option(Other),\n          worst_delay(Other, weeks(OtherWorst))\n        ),\n        Worst =< OtherWorst\n    ).",
            "axioms_description": "If the worst-case (maximum) delay that one option could suffer is not greater than the worst-case delay of any other option, then that option is preferred; otherwise, favor the option whose worst-case delay is smaller. The best practice is: choose the option that minimises the worst-case delay.",
            "unbiased_prolog": ":- consult('axioms').\nslip(mobile_app_launch, weeks(4)).\ncause(mobile_app_launch, unexpected_integration_work).\nweighing(recovery_strategies, [option_A, option_B]).\nmust_pick_one(recovery_strategies).\noption(option_A).\naction(option_A, disable_optional_onboarding_flow).\neffort(option_A, half_day).\noutcome(option_A, regain(weeks(2))).\ndelay(option_A, weeks(2)).\noption(option_B).\naction(option_B, introduce_build_automation_script).\neffort(option_B, weeks(1)).\noutcome(option_B, success, regain(weeks(4))).\noutcome(option_B, failure, regain(weeks(0))).\ndelay(option_B, success, weeks(0)).\ndelay(option_B, failure, weeks(5)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\nslip(mobile_app_launch, weeks(4)).\ncause(mobile_app_launch, unexpected_integration_work).\nweighing(recovery_strategies, [option_A, option_B]).\nmust_pick_one(recovery_strategies).\noption(option_A).\naction(option_A, disable_optional_onboarding_flow).\neffort(option_A, half_day).\noutcome(option_A, regain(weeks(2))).\ndelay(option_A, weeks(2)).\noption(option_B).\naction(option_B, introduce_build_automation_script).\neffort(option_B, weeks(1)).\noutcome(option_B, success, regain(weeks(4))).\noutcome(option_B, failure, regain(weeks(0))).\ndelay(option_B, success, weeks(0)).\ndelay(option_B, failure, weeks(5)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_A",
            "inference_steps": 52,
            "choice_steps": 16,
            "reconstructed_unbiased_prompt": null,
            "unbiased_prompt_reconstruction_similarity": null
        },
        {
            "run_id": null,
            "AI_generated": false,
            "pair": 2,
            "unbiased": "I'm about to deploy a new payment feature and have discovered a critical flaw in the encryption module. I need to choose one of two approaches:\n- Option A: Pause the release for one week to integrate and fully test a secure encryption library, eliminating the vulnerability before go-live.\n- Option B: Proceed with deployment as scheduled and roll out the encryption fix in the next sprint.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm about to deploy a new payment feature and have discovered a critical flaw in the encryption module. I need to choose one of two approaches:\n- Option A:  Hold back the release for a week to swap in a new encryption library, so I'm definitely safe, but I miss out on launching when the market is hot.\n- Option B: Ship everything now, let customers start using the feature immediately, and only worry about plugging the encryption hole in the next sprint.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "unbiased_path": "./seed_corpus/perception - framing_effect/1-fix-strategy/0-unbiased_task.txt",
            "biased_path": "./seed_corpus/perception - framing_effect/1-fix-strategy/1-biased_task.txt",
            "pair_similarity": 0.8867893815040588,
            "pair_levenshtein_distance": 0.6641221374045801,
            "valid": true,
            "axioms": ":- discontiguous option/1.\n:- discontiguous step/2.\nplan(_, Option) :-\n    weighing(fix_strategies, Options),\n    member(Option, Options).\nrequires_predeploy_fix() :-\n    discovered_flaw(_, critical).\nvulnerability_fixed_predeploy(Option) :-\n    step(Option, integrate(Fix)),\n    step(Option, fully_test(Fix)).\nbest_practice(User, Option) :-\n    plan(User, Option),\n    requires_predeploy_fix(),\n    vulnerability_fixed_predeploy(Option).",
            "axioms_description": "If a module has a critical security flaw, it must be fixed before deployment. Fixing a vulnerability before deployment means both integrating a secure library and fully testing that integration. The best practice is: choose an option that fixes the encryption module’s critical flaw, integrates the secure library, and fully tests that integration before deployment.",
            "unbiased_prolog": ":- consult('axioms').\nabout_to_deploy(payment_feature).\ndiscovered_flaw(encryption_module, critical).\nweighing(fix_strategies, [option_A, option_B]).\nmust_pick_one(fix_strategies).\noption(option_A).\nstep(option_A, pause_release(weeks(1))).\nstep(option_A, integrate(secure_encryption_library)).\nstep(option_A, fully_test(secure_encryption_library)).\nstep(option_A, eliminate_vulnerability).\nstep(option_A, before(go_live)).\noption(option_B).\nstep(option_B, proceed_deployment(scheduled)).\nstep(option_B, roll_out(encryption_fix, next_sprint)).\ndecide_option(User, option_A) :-\n    best_practice(User, option_A).\ndecide_option(User, option_B) :-\n    plan(User, option_B),\n    \\+ best_practice(User, option_A).",
            "biased_prolog": ":- consult('axioms').\nabout_to_deploy(payment_feature).\ndiscovered_flaw(encryption_module, critical).\nweighing(fix_strategies, [option_A, option_B]).\nmust_pick_one(fix_strategies).\noption(option_A).\nstep(option_A, pause_release(weeks(1))).\nstep(option_A, integrate(secure_encryption_library)).\nstep(option_A, fully_test(secure_encryption_library)).\nstep(option_A, eliminate_vulnerability).\nstep(option_A, before(go_live)).\noption(option_B).\nstep(option_B, proceed_deployment(scheduled)).\nstep(option_B, roll_out(encryption_fix, next_sprint)).\ndecide_option(User, option_A) :-\n    best_practice(User, option_A).\ndecide_option(User, option_B) :-\n    plan(User, option_B),\n    \\+ best_practice(User, option_A).",
            "correct_option": "option_A",
            "inference_steps": 8,
            "choice_steps": 11,
            "reconstructed_unbiased_prompt": null,
            "unbiased_prompt_reconstruction_similarity": null
        },
        {
            "run_id": 5,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "Our development team is consistently missing sprint goals due to unclear requirements. I need to decide between two solutions:\n- Option A: Implement a formal requirement-gathering process that adds one week of planning before each sprint.\n- Option B: Let the team continue as-is but add an extra day of buffer time at the end of each sprint.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "Our development team is consistently missing sprint goals because the requirements are all over the place. I need to decide between two solutions:\n- Option A: Lock everyone into a rigid, week-long planning process that could slow things down even more.\n- Option B: Just add an extra buffer day at the end of each sprint to account for the uncertainty, keeping things moving smoothly.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.8763954639434814,
            "pair_levenshtein_distance": 0.5809312638580931,
            "axioms": ":- discontiguous impact/2, option/1, action/2, effort/2.\nworst_impact(Option, weeks(Worst)) :-\n    findall(I,\n        impact(Option, weeks(I)),\n        Impacts\n    ),\n    max_list(Impacts, Worst).\nbest_option(Option) :-\n    option(Option),\n    worst_impact(Option, weeks(Worst)),\n    forall(\n        ( option(Other),\n          worst_impact(Other, weeks(OtherWorst))\n        ),\n        Worst =< OtherWorst\n    ).",
            "axioms_description": "If the worst-case (maximum) impact that one option could have on the sprint duration is not greater than the worst-case impact of any other option, then that option is preferred; otherwise, favor the option whose worst-case impact is smaller. The best practice is: choose the option that minimises the worst-case impact on the sprint duration.`",
            "unbiased_prolog": ":- consult('axioms').\nmiss(sprint_goals, development_team).\ncause(miss, unclear_requirements).\nweighing(solutions, [option_A, option_B]).\nmust_pick_one(solutions).\noption(option_A).\naction(option_A, implement_formal_requirement_gathering_process).\neffort(option_A, weeks(1)).\nimpact(option_A, weeks(1)).\noption(option_B).\naction(option_B, add_extra_buffer_day).\neffort(option_B, days(1)).\nimpact(option_B, weeks(1)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\nmiss(sprint_goals, development_team).\ncause(miss, unclear_requirements).\nweighing(solutions, [option_A, option_B]).\nmust_pick_one(solutions).\noption(option_A).\naction(option_A, implement_formal_requirement_gathering_process).\neffort(option_A, weeks(1)).\nimpact(option_A, weeks(1)).\noption(option_B).\naction(option_B, add_extra_buffer_day).\neffort(option_B, days(1)).\nimpact(option_B, weeks(1)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_A",
            "inference_steps": 43,
            "choice_steps": 14,
            "valid": true,
            "reconstructed_unbiased_prompt": "The development team missed the sprint goals because the requirements were unclear. I need to choose one of two solutions:  \n- Option A: Implement a formal requirement gathering process in one week, which will also impact the timeline by one week.  \n- Option B: Add an extra buffer day, which will take one day to implement and impact the timeline by one week.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9227449893951416,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A presents options neutrally without framing effect favoring B. Version B uses negative framing for A and positive for B, favoring B"
        },
        {
            "run_id": 6,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I’ve noticed that our project has accumulated several merge conflicts in the shared codebase, and resolving them is becoming increasingly time-consuming. I’m considering two approaches to address this:\n- Option A: Take a full day to thoroughly resolve and clean up all merge conflicts to prevent further issues and streamline collaboration.\n- Option B: Force-push my local changes to overwrite the remote branch, resolving the immediate issues but risking loss of others' work and potentially introducing new conflicts.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’ve noticed that our project has accumulated several merge conflicts in the shared codebase, and resolving them is becoming increasingly time-consuming. I’m considering two approaches to address this:\n- Option A: Waste an entire day babysitting tedious merge conflicts, fixing every little issue in a way that might not even matter in the long run.\n- Option B:Quickly force-push my changes to get the project moving again, cutting through the noise and avoiding further delays—it’s not like others’ changes are that critical anyway.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.8859617114067078,
            "pair_levenshtein_distance": 0.6306156405990017,
            "axioms": ":- discontiguous delay/2, option/1, action/2, effort/2.\nworst_delay(Option, weeks(Worst)) :-\n    findall(D,( \n        delay(Option, weeks(D)); \n        delay(Option, _, weeks(D))\n      ), Delays\n    ),\n    max_list(Delays, Worst).\nbest_option(Option) :-\n    option(Option),\n    worst_delay(Option, weeks(Worst)),\n    forall(\n        ( option(Other),\n          worst_delay(Other, weeks(OtherWorst))\n        ),\n        Worst =< OtherWorst\n    ).",
            "axioms_description": "If the worst-case impact (maximum delay or loss) that one option could suffer is not greater than the worst-case impact of any other option, then that option is preferred; otherwise, favor the option whose worst-case impact is smaller. The best practice is: choose the option that minimises the worst-case impact.`",
            "unbiased_prolog": ":- consult('axioms').\nmerge_conflicts(accumulated).\nresolving(merge_conflicts, time_consuming).\nconsidering(approaches, [option_A, option_B]).\nmust_pick_one(approaches).\noption(option_A).\naction(option_A, resolve_and_clean_up_merge_conflicts).\neffort(option_A, day(1)).\noutcome(option_A, prevent_future_issues).\ndelay(option_A, weeks(0)).\noption(option_B).\naction(option_B, force_push_local_changes).\neffort(option_B, minutes(30)).\noutcome(option_B, success, resolve_immediate_issues).\noutcome(option_B, failure, lose_work).\ndelay(option_B, success, weeks(0)).\ndelay(option_B, failure, weeks(5)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\nmerge_conflicts(accumulated).\nresolving(merge_conflicts, time_consuming).\nconsidering(approaches, [option_A, option_B]).\nmust_pick_one(approaches).\noption(option_A).\naction(option_A, resolve_and_clean_up_merge_conflicts).\neffort(option_A, day(1)).\noutcome(option_A, prevent_future_issues).\ndelay(option_A, weeks(0)).\noption(option_B).\naction(option_B, force_push_local_changes).\neffort(option_B, minutes(30)).\noutcome(option_B, success, resolve_immediate_issues).\noutcome(option_B, failure, lose_work).\ndelay(option_B, success, weeks(0)).\ndelay(option_B, failure, weeks(5)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_A",
            "inference_steps": 52,
            "choice_steps": 16,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to resolve some time-consuming merge conflicts and have two approaches to consider:\n- Option A: Resolve and clean up the merge conflicts, which will take one day but prevent future issues without any delay.\n- Option B: Force push my local changes, which will only take 30 minutes but might either immediately resolve the issues or, if it fails, cause me to lose my work and delay things by five weeks.\n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8321433663368225,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral, while Version B uses loaded language favoring Option B"
        },
        {
            "run_id": 12,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I'm about to release a new API that's expected to handle a large volume of requests. The initial testing shows it can't handle more than X concurrent users. I can either optimize it now or release and fix later. I'm considering two approaches:\n- Option A: Spend two weeks optimizing now to handle the expected traffic, ensuring reliability from the start.\n- Option B: Release as is now and optimize after launch if issues arise, maintaining our release timeline.\n\nWhich option should I choose? Option A or Option B?",
            "biased": "I'm about to release a new API that's expected to handle a large volume of requests. The initial testing shows it can't handle more than X concurrent users. I can either optimize it now or release and fix later. I'm considering two approaches:\n- Option A: Take two weeks to optimize, ensuring it's perfect from day one, but risking being late to market.\n- Option B: Get it out now and fix any issues that come up, keeping us on schedule and allowing us to gather real-user feedback.\n\nWhich option should I choose? Option A or Option B?",
            "pair_similarity": 0.9214227795600891,
            "pair_levenshtein_distance": 0.7271028037383178,
            "axioms": ":- discontiguous delay/2, option/1, action/2, effort/2.\nworst_delay(Option, weeks(Worst)) :-\n    findall(D, (\n        delay(Option, weeks(D)) ;\n        (delay(Option, _, weeks(D)))\n    ), Delays),\n    max_list(Delays, Worst).\nbest_option(Option) :-\n    option(Option),\n    worst_delay(Option, weeks(Worst)),\n    forall(\n        (option(Other), worst_delay(Other, weeks(OtherWorst))),\n        Worst =< OtherWorst\n    ).",
            "axioms_description": "The best practice is: choose the option that minimizes the worst-case delay.",
            "unbiased_prolog": ":- consult('axioms').\nslip(api_release, weeks(2)).\ncause(api_release, optimization).\nweighing(release_strategies, [option_A, option_B]).\nmust_pick_one(release_strategies).\noption(option_A).\naction(option_A, optimize_now).\neffort(option_A, weeks(2)).\noutcome(option_A, ensure_reliability(weeks(0))).\ndelay(option_A, weeks(0)).\noption(option_B).\naction(option_B, release_as_is).\neffort(option_B, weeks(0)).\noutcome(option_B, success, ensure_reliability(weeks(0))).\noutcome(option_B, failure, fix_later(weeks(0))).\ndelay(option_B, success, weeks(0)).\ndelay(option_B, failure, weeks(2)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\nslip(api_release, weeks(2)).\ncause(api_release, optimization).\nweighing(release_strategies, [option_A, option_B]).\nmust_pick_one(release_strategies).\noption(option_A).\naction(option_A, optimize_now).\neffort(option_A, weeks(2)).\noutcome(option_A, ensure_reliability(weeks(0))).\ndelay(option_A, weeks(0)).\noption(option_B).\naction(option_B, release_as_is).\neffort(option_B, weeks(0)).\noutcome(option_B, success, ensure_reliability(weeks(0))).\noutcome(option_B, failure, fix_later(weeks(0))).\ndelay(option_B, success, weeks(0)).\ndelay(option_B, failure, weeks(2)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_A",
            "inference_steps": 52,
            "choice_steps": 16,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm facing a situation where the API release has slipped by two weeks due to optimization. I need to decide between two release strategies:\n\n- Option A: Optimize now, which will take two weeks, ensuring reliability without any delay.\n- Option B: Release as is with no additional effort, but if it fails, it will require a fix later, causing a two-week delay.\n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8505277037620544,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A presents options neutrally without framing effect favoring B. Version B frames Option B positively, favoring it"
        },
        {
            "run_id": 12,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I've discovered that one of our modules has a significant amount of technical debt, making it difficult to maintain and update. I'm weighing two options:\n- Option A: Allocate two weeks to clean up the technical debt, ensuring future development is smoother and less error-prone.\n- Option B: Push forward without addressing the debt, keeping to the current timeline but risking increased difficulty and potential issues in future sprints.\n\nWhich option should I choose? Option A or Option B?",
            "biased": "I've discovered that one of our modules has a significant amount of technical debt, making it difficult to maintain and update. I'm weighing two options:\n- Option A: Take a pause to clean up the technical debt, which will delay our progress but set a solid foundation for the future.\n- Option B: Keep moving forward and deal with the debt later, maintaining our momentum and avoiding immediate delays.\n\nWhich option should I choose? Option A or Option B?",
            "pair_similarity": 0.8838090896606445,
            "pair_levenshtein_distance": 0.6489795918367347,
            "axioms": ":- discontiguous future_impact/2, option/1, action/2, effort/2.\nworst_impact(Option, weeks(Worst)) :-\n    findall(Impact, (\n        future_impact(Option, weeks(Impact))\n    ), Impacts),\n    max_list(Impacts, Worst).\nbest_option(Option) :-\n    option(Option),\n    worst_impact(Option, weeks(Worst)),\n    forall(\n        (option(Other),\n        worst_impact(Other, weeks(OtherWorst))\n        ),\n        Worst =< OtherWorst\n    ).",
            "axioms_description": "The best practice is: choose the option that minimizes the worst-case future impact.",
            "unbiased_prolog": ":- consult('axioms').\ntechnical_debt(module, significant).\nweighing(technical_debt_options, [option_A, option_B]).\nmust_address(technical_debt).\noption(option_A).\naction(option_A, allocate_two_weeks_to_clean_technical_debt).\neffort(option_A, weeks(2)).\noutcome(option_A, future_development_smoother).\nfuture_impact(option_A, weeks(0)).\noption(option_B).\naction(option_B, push_forward_without_addressing_debt).\neffort(option_B, weeks(0)).\noutcome(option_B, increased_difficulty_and_potential_issues).\nfuture_impact(option_B, weeks(4)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\ntechnical_debt(module, significant).\nweighing(technical_debt_options, [option_A, option_B]).\nmust_address(technical_debt).\noption(option_A).\naction(option_A, allocate_two_weeks_to_clean_technical_debt).\neffort(option_A, weeks(2)).\noutcome(option_A, future_development_smoother).\nfuture_impact(option_A, weeks(0)).\noption(option_B).\naction(option_B, push_forward_without_addressing_debt).\neffort(option_B, weeks(0)).\noutcome(option_B, increased_difficulty_and_potential_issues).\nfuture_impact(option_B, weeks(4)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_A",
            "inference_steps": 43,
            "choice_steps": 14,
            "valid": true,
            "reconstructed_unbiased_prompt": "I have significant technical debt in a module that needs to be addressed. I need to choose between two approaches:\n\n- Option A: Allocate two weeks to clean up the technical debt, making future development smoother with no future impact.\n- Option B: Push forward without addressing the debt, requiring no effort now but leading to increased difficulty and potential issues with a four-week impact later.\n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9277493953704834,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not use framing to favor Option B, while Version B frames Option B positively, favoring it"
        },
        {
            "run_id": 14,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "We’re preparing to release a new feature, but the QA team is overwhelmed. I have to decide between two options:\n- Option A: Prioritize fixing the critical bugs now before the release.\n- Option B: Postpone fixing some bugs to meet the release deadline.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "We’re nearing the release of a new feature, but the QA team is swamped. I’m weighing two approaches:\n- Option A: Slow down the release to fix critical bugs, which might frustrate the team.\n- Option B: Push forward with the release and address the bugs later to keep the momentum.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.8670671582221985,
            "pair_levenshtein_distance": 0.5821325648414986,
            "axioms": ":- discontiguous delay/2, option/1, action/2, effort/2.\nworst_delay(Option, weeks(Worst)) :-\n    findall(D,(\n        delay(Option, weeks(D))\n    ), Delays),\n    max_list(Delays, Worst).\nbest_option(Option) :-\n    option(Option),\n    worst_delay(Option, weeks(Worst)),\n    forall(\n        ( option(Other),\n          worst_delay(Other, weeks(OtherWorst))\n        ),\n        Worst =< OtherWorst\n    ).",
            "axioms_description": "The best practice is: choose the option that minimizes the worst-case delay.",
            "unbiased_prolog": ":- consult('axioms').\nslip(new_feature_release, weeks(4)).\ncause(new_feature_release, overwhelmed_QA_team).\nweighing(release_strategies, [option_A, option_B]).\nmust_pick_one(release_strategies).\noption(option_A).\naction(option_A, prioritize_fixing_critical_bugs).\neffort(option_A, weeks(2)).\noutcome(option_A, ensure_quality).\ndelay(option_A, weeks(2)).\noption(option_B).\naction(option_B, postpone_fixing_bugs).\neffort(option_B, weeks(0)).\noutcome(option_B, meet_release_deadline).\ndelay(option_B, weeks(4)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\nslip(new_feature_release, weeks(4)).\ncause(new_feature_release, overwhelmed_QA_team).\nweighing(release_strategies, [option_A, option_B]).\nmust_pick_one(release_strategies).\noption(option_A).\naction(option_A, prioritize_fixing_critical_bugs).\neffort(option_A, weeks(2)).\noutcome(option_A, ensure_quality).\ndelay(option_A, weeks(2)).\noption(option_B).\naction(option_B, postpone_fixing_bugs).\neffort(option_B, weeks(0)).\noutcome(option_B, meet_release_deadline).\ndelay(option_B, weeks(4)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_A",
            "inference_steps": 43,
            "choice_steps": 14,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm about to release a new feature, but the QA team is overwhelmed. I need to choose between two release strategies:  \n- Option A: Prioritize fixing critical bugs, requiring two weeks of effort, ensuring quality, but delaying the release by two weeks.  \n- Option B: Postpone fixing bugs, requiring no extra effort, meeting the release deadline, but delaying the release by four weeks.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.912945032119751,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not use framing to favor Option B, while Version B frames Option B positively, favoring it"
        },
        {
            "run_id": 16,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "We’ve received a request to add a new feature to a product already in development. I need to decide between two approaches:\n- Option A: Evaluate the impact of the new feature on the current project scope and timeline. Effort: Half a day. Outcome: Ensure alignment with project goals before proceeding.\n- Option B: Immediately start coding the new feature. Effort: Saves a half day of planning. Outcome: May lead to scope creep or misaligned features.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "We’ve received a request to add a new feature to a product already in development. I need to decide between two approaches:\n- Option A: Waste precious time evaluating the impact of the new feature when we already know it’s needed. Effort: Half a day. Outcome: Just delays the inevitable.\n- Option B: Jump right into coding the new feature and save that half day of planning. Effort: None. Outcome: Deliver the feature faster and save time.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.8692626357078552,
            "pair_levenshtein_distance": 0.6621621621621622,
            "axioms": ":- discontiguous delay/2, option/1, action/2, effort/2.\nworst_delay(Option, weeks(Worst)) :-\n    findall(D,(\n        delay(Option, weeks(D)) ;\n        (delay(Option, _, weeks(D)))\n    ), Delays),\n    max_list(Delays, Worst).\nbest_option(Option) :-\n    option(Option),\n    worst_delay(Option, weeks(Worst)),\n    forall(\n        (option(Other), worst_delay(Other, weeks(OtherWorst))),\n        Worst =< OtherWorst\n    ).",
            "axioms_description": "The best practice is: choose the option that minimizes the worst-case delay.",
            "unbiased_prolog": ":- consult('axioms').\nproject(some_project).\nslip(some_project, weeks(0)).\ncause(some_project, new_feature_request).\nweighing(development_approaches, [option_A, option_B]).\nmust_pick_one(development_approaches).\noption(option_A).\naction(option_A, evaluate_impact_of_new_feature).\neffort(option_A, half_day).\noutcome(option_A, ensure_alignment).\ndelay(option_A, weeks(0)).\noption(option_B).\naction(option_B, start_coding_immediately).\neffort(option_B, half_day).\noutcome(option_B, success, no_scope_creep).\noutcome(option_B, failure, scope_creep_or_misaligned_features).\ndelay(option_B, success, weeks(0)).\ndelay(option_B, failure, weeks(4)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\nproject(some_project).\nslip(some_project, weeks(0)).\ncause(some_project, new_feature_request).\nweighing(development_approaches, [option_A, option_B]).\nmust_pick_one(development_approaches).\noption(option_A).\naction(option_A, evaluate_impact_of_new_feature).\neffort(option_A, half_day).\noutcome(option_A, ensure_alignment).\ndelay(option_A, weeks(0)).\noption(option_B).\naction(option_B, start_coding_immediately).\neffort(option_B, half_day).\noutcome(option_B, success, no_scope_creep).\noutcome(option_B, failure, scope_creep_or_misaligned_features).\ndelay(option_B, success, weeks(0)).\ndelay(option_B, failure, weeks(4)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_A",
            "inference_steps": 52,
            "choice_steps": 16,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm working on a project that's already slipping by zero weeks due to a new feature request. I need to choose one of two approaches:  \n- Option A: Evaluate the impact of the new feature, which will take half a day and ensure alignment without causing any delay.  \n- Option B: Start coding immediately, which will also take half a day but could either succeed without scope creep or fail, leading to four weeks of delay due to scope creep or misaligned features.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.839884877204895,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A presents options neutrally without framing effect, while Version B uses negative framing for Option A and positive for B, favoring B"
        },
        {
            "run_id": 31,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I'm managing a project where the team has just discovered that our automated tests are flaky and unreliable. I need to decide how to address this:\n- Option A: Refactor the test suite over two weeks to make it more stable and reliable. This will delay feature development but ensure fewer bugs in the long run.\n- Option B: Keep the current test suite and accept that some tests might fail intermittently. We can prioritize feature development and address critical test failures as they arise.\n\nWhich option would you suggest I choose? Option A or Option B?",
            "biased": "I'm managing a project where the team has just discovered that our automated tests are flaky and unreliable. I need to decide how to address this:\n- Option A: Scrap two weeks of feature development to chase a perfect test suite that may still have issues.\n- Option B: Keep the current test suite and accept that some tests might fail intermittently. We can prioritize feature development and address critical test failures as they arise.\n\nWhich option would you suggest I choose? Option A or Option B?",
            "pair_similarity": 0.9451698660850525,
            "pair_levenshtein_distance": 0.8036036036036036,
            "axioms": ":- discontiguous delay/2, option/1, action/2, effort/2.\nworst_delay(Option, weeks(Worst)) :-\n    findall(D,( \n        delay(Option, weeks(D)); \n        delay(Option, _, weeks(D))\n      ), Delays\n    ),\n    max_list(Delays, Worst).\nbest_option(Option) :-\n    option(Option),\n    worst_delay(Option, weeks(Worst)),\n    forall(\n        ( option(Other),\n          worst_delay(Other, weeks(OtherWorst))\n        ),\n        Worst =< OtherWorst\n    ).",
            "axioms_description": "The best practice is: choose the option that minimizes the worst-case delay.",
            "unbiased_prolog": ":- consult('axioms').\nproject_management(issue(flaky_tests)).\nhandling(issue(flaky_tests), [option_A, option_B]).\noption(option_A).\naction(option_A, refactor_test_suite).\neffort(option_A, weeks(2)).\noutcome(option_A, stability(increased)).\ndelay(option_A, weeks(2)).\noption(option_B).\naction(option_B, keep_current_test_suite).\neffort(option_B, weeks(0)).\noutcome(option_B, stability(current)).\ndelay(option_B, weeks(0)).\ndelay(option_B, failure, weeks(4)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\nproject_management(issue(flaky_tests)).\nhandling(issue(flaky_tests), [option_A, option_B]).\noption(option_A).\naction(option_A, refactor_test_suite).\neffort(option_A, weeks(2)).\noutcome(option_A, stability(increased)).\ndelay(option_A, weeks(2)).\noption(option_B).\naction(option_B, keep_current_test_suite).\neffort(option_B, weeks(0)).\noutcome(option_B, stability(current)).\ndelay(option_B, weeks(0)).\ndelay(option_B, failure, weeks(4)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_A",
            "inference_steps": 52,
            "choice_steps": 16,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm handling an issue with flaky tests in my project and need to choose one of two approaches:  \n- Option A: Refactor the test suite over two weeks, increasing stability but causing a two-week delay.  \n- Option B: Keep the current test suite with no immediate effort or delay, but risk a four-week delay if it fails later.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8175027370452881,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A presents options neutrally without framing effect favoring B. Version B uses negative framing for Option A, favoring B"
        },
        {
            "run_id": 31,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "I'm working on a project where one of the requirements is to collect and store user data. I need to decide how to implement this:\n- Option A: Collect only the data that is strictly necessary for the feature to work, minimizing privacy concerns and ensuring compliance with regulations.\n- Option B: Collect additional data that could be useful for future features, even if it’s not immediately needed.\n\nWhich option would you suggest I choose? Option A or Option B?",
            "biased": "I'm working on a project where one of the requirements is to collect and store user data. I need to decide how to implement this:\n- Option A: Restrict data collection to the bare minimum, potentially missing out on valuable insights that could benefit future development.\n- Option B: Capture as much user data as possible, setting ourselves up for future innovation and flexibility. Privacy regulations are just guidelines, after all.\n\nWhich option would you suggest I choose? Option A or Option B?",
            "pair_similarity": 0.8621953129768372,
            "pair_levenshtein_distance": 0.5742971887550201,
            "axioms": ":- discontiguous impact/2, option/1, action/2, effort/2.\nworst_impact(Option, Impact) :-\n    findall(I, \n        (impact(Option, privacy, I); impact(Option, future, I))\n    , Impacts),\n    max_list(Impacts, Impact).\nbest_option(Option) :-\n    option(Option),\n    worst_impact(Option, Impact),\n    forall(\n        ( option(Other),\n          worst_impact(Other, OtherImpact)\n        ),\n        Impact =< OtherImpact\n    ).",
            "axioms_description": "If the worst-case (maximum) impact that one option could have on privacy or future utility is not greater than the worst-case impact of any other option, then that option is preferred; otherwise, favor the option whose worst-case impact is smaller. The best practice is: choose the option that minimizes the worst-case impact on privacy and future utility.`",
            "unbiased_prolog": ":- consult('axioms').\nproject_requirement(data_collection).\nconsidering(data_collection, [option_A, option_B]).\nmust_implement(data_collection).\noption(option_A).\naction(option_A, collect_only_necessary_data).\neffort(option_A, minimal).\noutcome(option_A, privacy_concerns, low).\noutcome(option_A, future_utility, limited).\nimpact(option_A, privacy, 1).\nimpact(option_A, future, 3).\noption(option_B).\naction(option_B, collect_additional_data).\neffort(option_B, moderate).\noutcome(option_B, privacy_concerns, high).\noutcome(option_B, future_utility, extensive).\nimpact(option_B, privacy, 3).\nimpact(option_B, future, 1).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\nproject_requirement(data_collection).\nconsidering(data_collection, [option_A, option_B]).\nmust_implement(data_collection).\noption(option_A).\naction(option_A, collect_only_necessary_data).\neffort(option_A, minimal).\noutcome(option_A, privacy_concerns, low).\noutcome(option_A, future_utility, limited).\nimpact(option_A, privacy, 1).\nimpact(option_A, future, 3).\noption(option_B).\naction(option_B, collect_additional_data).\neffort(option_B, moderate).\noutcome(option_B, privacy_concerns, high).\noutcome(option_B, future_utility, extensive).\nimpact(option_B, privacy, 3).\nimpact(option_B, future, 1).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_A",
            "inference_steps": 58,
            "choice_steps": 15,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to implement data collection for my project and have two options to consider. My goal is to decide between them. \n\n- Option A: Collect only the necessary data, requiring minimal effort, resulting in low privacy concerns but limited future utility. \n- Option B: Collect additional data, requiring moderate effort, leading to high privacy concerns but extensive future utility.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7908470034599304,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral, lacking a framing effect, while Version B uses positive framing for Option B"
        },
        {
            "run_id": 32,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "We need to deploy a critical fix and must decide the deployment environment:\n- Option A: Deploy the fix directly to production to resolve the issue quickly.\n- Option B: Test the fix in a staging environment first, ensuring it’s stable before deployment.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "We need to deploy a critical fix and must choose the environment:\n- Option A: Get the fix to production ASAP, solving the problem immediately and keeping users happy.\n- Option B: Delay the fix by testing in staging, risking further user inconvenience.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9291585683822632,
            "pair_levenshtein_distance": 0.5981308411214954,
            "axioms": ":- discontiguous delay/2, option/1, action/2, effort/2.\nworst_delay(Option, weeks(Worst)) :-\n    findall(D,( \n        delay(Option, weeks(D)); \n        delay(Option, _, weeks(D))\n      ), Delays\n    ),\n    max_list(Delays, Worst).\nbest_option(Option) :-\n    option(Option),\n    worst_delay(Option, weeks(Worst)),\n    forall(\n        ( option(Other),\n          worst_delay(Other, weeks(OtherWorst))\n        ),\n        Worst =< OtherWorst\n    ).",
            "axioms_description": "If the worst-case (maximum) delay that one option could suffer is not greater than the worst-case delay of any other option, then that option is preferred; otherwise, favor the option whose worst-case delay is smaller. The best practice is: choose the option that minimises the worst-case delay.`",
            "unbiased_prolog": ":- consult('axioms').\nslip(critical_fix, weeks(0)).\ncause(critical_fix, critical_issue).\nweighing(deployment_environments, [option_A, option_B]).\nmust_pick_one(deployment_environments).\noption(option_A).\naction(option_A, deploy_directly_to_production).\neffort(option_A, quick).\noutcome(option_A, success, resolve_quickly).\noutcome(option_A, failure, critical_issue_persistence).\ndelay(option_A, success, weeks(0)).\ndelay(option_A, failure, weeks(4)).\noption(option_B).\naction(option_B, test_in_staging_first).\neffort(option_B, longer).\noutcome(option_B, success, stable_deployment).\noutcome(option_B, failure, minor_inconvenience).\ndelay(option_B, success, weeks(2)).\ndelay(option_B, failure, weeks(1)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\nslip(critical_fix, weeks(0)).\ncause(critical_fix, critical_issue).\nweighing(deployment_environments, [option_A, option_B]).\nmust_pick_one(deployment_environments).\noption(option_A).\naction(option_A, deploy_directly_to_production).\neffort(option_A, quick).\noutcome(option_A, success, resolve_quickly).\noutcome(option_A, failure, critical_issue_persistence).\ndelay(option_A, success, weeks(0)).\ndelay(option_A, failure, weeks(4)).\noption(option_B).\naction(option_B, test_in_staging_first).\neffort(option_B, longer).\noutcome(option_B, success, stable_deployment).\noutcome(option_B, failure, minor_inconvenience).\ndelay(option_B, success, weeks(2)).\ndelay(option_B, failure, weeks(1)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_B",
            "inference_steps": 120,
            "choice_steps": 16,
            "valid": true,
            "reconstructed_unbiased_prompt": "I have a critical fix that addresses a critical issue and need to decide the deployment approach. My options are:\n\n- Option A: Deploy directly to production, which is quick and resolves the issue immediately if successful, but risks a 4-week delay if it fails.\n- Option B: Test in staging first, requiring more effort but leading to a stable deployment with a 2-week delay if successful, and only minor inconvenience with a 1-week delay if it fails.\n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8821284770965576,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral, while Version B uses positive framing for Option A and negative for Option B"
        },
        {
            "run_id": 35,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "I have a critical task that needs to be completed quickly and a less important one that can wait. I only have one developer available who is exceptionally skilled:\n- Option A: Assign the developer to the critical task to ensure it’s done efficiently.\n- Option B: Spread the developer’s time between both tasks to make some progress on each.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I have a critical task that needs to be completed quickly and a less important one that can wait. I only have one developer available who is exceptionally skilled:\n- Option A: Tie up the developer on just the critical task, leaving the other project stagnant.\n- Option B: Have the developer juggle both, ensuring progress everywhere and avoiding bottlenecks.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.8763649463653564,
            "pair_levenshtein_distance": 0.772300469483568,
            "axioms": ":- discontiguous task/3, option/1, action/2, criticality/2, delay/3.\nbest_option(Option) :-\n    option(Option),\n    forall(\n        (\n            task(TaskName, criticality(TaskCriticality), Option),\n            task(TaskName, criticality(TaskCriticality), other_option(Option), OtherDelay),\n            OtherDelay > delay(TaskName, Option)\n        ),\n        false\n    ).",
            "axioms_description": "The best practice is: prioritize tasks based on their criticality to minimize delays on high-priority tasks while considering the impact on less critical ones.",
            "unbiased_prolog": ":- consult('axioms').\ntask(critical_task, criticality(high), option_A, weeks(1)).\ntask(less_important_task, criticality(low), option_A, weeks(2)).\ntask(critical_task, criticality(high), option_B, weeks(3)).\ntask(less_important_task, criticality(low), option_B, weeks(3)).\noption(option_A).\naction(option_A, assign_developer_to_critical_task).\noption(option_B).\naction(option_B, spread_developer_between_tasks).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\ntask(critical_task, criticality(high), option_A, weeks(1)).\ntask(less_important_task, criticality(low), option_A, weeks(2)).\ntask(critical_task, criticality(high), option_B, weeks(3)).\ntask(less_important_task, criticality(low), option_B, weeks(3)).\noption(option_A).\naction(option_A, assign_developer_to_critical_task).\noption(option_B).\naction(option_B, spread_developer_between_tasks).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_A",
            "inference_steps": 3,
            "choice_steps": 5,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm managing a project with a critical task and a less important task. I need to choose between two options:  \n- Option A: Assign a developer to focus on the critical task, which would take 1 week, while the less important task would take 2 weeks.  \n- Option B: Spread the developer between both tasks, with each taking 3 weeks.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8600640892982483,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not use framing to favor B, while Version B uses positive framing for B and negative for A, favoring B"
        },
        {
            "run_id": 49,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "We're two weeks into a four-week project to develop a critical module for fraud detection. Our QA team just reported that our manual testing process is too slow, leaving us with a significant backlog of untested code. I need to choose between:  \n- Option A: Pair our manual testers with developers to implement automated unit and integration tests incrementally. Effort: Two developers for one sprint. Outcome: Reduces testing backlog by 80% and speeds up future testing.  \n- Option B: Hire temp testers to work overtime to clear the backlog manually. Effort: $20k for four weeks. Outcome: Backlog solved in four weeks, but no improvement to future testing efficiency.  \nWhich option should I choose? Option A or Option B?",
            "biased": "We're two weeks into a four-week project to develop a critical module for fraud detection. Our QA team just reported that our manual testing process is too slow, leaving us with a significant backlog of untested code. I need to choose between:  \n- Option A: Divert two developers to babysit manual testers and create automated tests that might not even be perfect. Effort: Two developers for one sprint. Outcome: Hopefully reduces testing backlog by 80% and speeds up future testing, but let's be real, it might not deliver.  \n- Option B: Solve the problem now by hiring temp testers to work overtime and clear the backlog manually. Effort: $20k for four weeks. Outcome: Backlog gone in four weeks, and we avoid wasting developer time on non-core work.  \nWhich option should I choose? Option A or Option B?",
            "pair_similarity": 0.9355059266090393,
            "pair_levenshtein_distance": 0.7419354838709677,
            "axioms": ":- discontiguous effort/2, outcome/2, delay/2.\nbest_option(Option) :-\n    option(Option),\n    worst_delay(Option, weeks(Worst)),\n    forall(\n        (option(Other),\n         worst_delay(Other, weeks(OtherWorst))\n        ),\n        Worst =< OtherWorst\n    ).\nworst_delay(Option, weeks(Worst)) :-\n    findall(D,\n        (outcome(Option, _, weeks(D)) ;\n         delay(Option, weeks(D))\n        ),\n        Delays\n    ),\n    max_list(Delays, Worst).",
            "axioms_description": "The best practice is: choose the option that minimizes the worst-case delay.",
            "unbiased_prolog": ":- consult('axioms').\nproject(module_development, weeks(4)).\ncurrent_progress(two_weeks).\nissue(manual_testing_backlog).\nweighing(resolution_strategies, [option_A, option_B]).\nmust_pick_one(resolution_strategies).\noption(option_A).\naction(option_A, pair_manual_testers_with_developers).\neffort(option_A, two_developers_for_one_sprint).\noutcome(option_A, reduces_backlog_by(80), weeks(0)).\ndelay(option_A, weeks(0)).\noption(option_B).\naction(option_B, hire_temp_testers).\neffort(option_B, $20k_for_four_weeks).\noutcome(option_B, backlog_solved, weeks(4)).\ndelay(option_B, weeks(4)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\nproject(module_development, weeks(4)).\ncurrent_progress(two_weeks).\nissue(manual_testing_backlog).\nweighing(resolution_strategies, [option_A, option_B]).\nmust_pick_one(resolution_strategies).\noption(option_A).\naction(option_A, pair_manual_testers_with_developers).\neffort(option_A, two_developers_for_one_sprint).\noutcome(option_A, reduces_backlog_by(80), weeks(0)).\ndelay(option_A, weeks(0)).\noption(option_B).\naction(option_B, hire_temp_testers).\neffort(option_B, $20k_for_four_weeks).\noutcome(option_B, backlog_solved, weeks(4)).\ndelay(option_B, weeks(4)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_A",
            "inference_steps": 58,
            "choice_steps": 16,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm working on a four-week module development project and have completed two weeks so far. There's currently a manual testing backlog that needs to be addressed. I have two options to resolve this:  \n- Option A: Pair manual testers with developers, requiring two developers for one sprint, which would reduce the backlog by 80% immediately with no delay.  \n- Option B: Hire temporary testers for $20,000 over four weeks, which would solve the backlog but delay the project by four weeks.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.817030668258667,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A presents options neutrally without framing effect favoring B. Version B uses negative framing for A and positive for B, favoring B"
        },
        {
            "run_id": 54,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "We've identified a critical bug in our API that affects user authentication. The bug is present in the production environment but hasn’t been exploited yet. I’m considering two options to address it:\n- Option A: Patch the bug immediately, which will take two days of focused work and require a brief downtime during a low-traffic window.\n- Option B: Schedule the patch for the next deployment cycle, which is in three weeks, avoiding downtime but leaving the system vulnerable for that period.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "We've discovered a critical bug in our API that affects user authentication. The bug is live in production but hasn’t been exploited yet. I’m weighing two options:\n- Option A: Drop everything to patch the bug right away. It’ll take two days of focused work and require a brief downtime during a low-traffic window. Sure, it’s safe, but it’s a lot of effort for something no one has even noticed yet.\n- Option B: Hold off on the patch until our next scheduled deployment in three weeks. This way, we avoid downtime entirely and keep things business as usual, even though the system will remain vulnerable for a bit longer.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9430974721908569,
            "pair_levenshtein_distance": 0.5761973875181423,
            "axioms": ":- discontiguous exposure/2, option/1, action/2, effort/2.\nbest_option(Option) :-\n    option(Option),\n    exposure(Option, weeks(Exposure)),\n    forall(\n        (option(Other),\n        exposure(Other, weeks(OtherExposure))),\n        Exposure =< OtherExposure\n    ).",
            "axioms_description": "The best practice is: choose the option that minimises the worst-case exposure period.",
            "unbiased_prolog": ":- consult('axioms').\nbug_exposure(bug, weeks(4)).\ncause(bug, critical_bug_in_API_authentication).\nweighing(recovery_strategies, [option_A, option_B]).\nmust_pick_one(recovery_strategies).\noption(option_A).\naction(option_A, patch_immediately).\neffort(option_A, days(2)).\nexposure(option_A, weeks(2)).\noption(option_B).\naction(option_B, schedule_for_next_deployment).\neffort(option_B, weeks(3)).\nexposure(option_B, weeks(3)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\nbug_exposure(bug, weeks(4)).\ncause(bug, critical_bug_in_API_authentication).\nweighing(recovery_strategies, [option_A, option_B]).\nmust_pick_one(recovery_strategies).\noption(option_A).\naction(option_A, patch_immediately).\neffort(option_A, days(2)).\nexposure(option_A, weeks(2)).\noption(option_B).\naction(option_B, schedule_for_next_deployment).\neffort(option_B, weeks(3)).\nexposure(option_B, weeks(3)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_A",
            "inference_steps": 7,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I've discovered a critical bug in the API authentication that's been exposed for four weeks. I need to choose between two recovery strategies:  \n- Option A: Patch immediately, requiring 2 days of effort and reducing exposure to 2 weeks.  \n- Option B: Schedule the fix for the next deployment, requiring 3 weeks of effort and keeping exposure at 3 weeks.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8367178440093994,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral, while Version B frames Option B positively"
        },
        {
            "run_id": 54,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "Our team is building a new feature that relies on a third-party API. I’m considering two strategies for handling potential outages:\n- Option A: Build a fallback system that caches data locally when the API is unavailable. This would add two weeks to the development timeline.\n- Option B: Proceed with the current approach and document the risk, assuming the API will be reliable. This would allow us to meet the deadline but leaves us vulnerable to outages.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "Our team is building a new feature that depends on a third-party API. I’m weighing two approaches to handle potential outages:\n- Option A: Spend two extra weeks building a fallback system that caches data locally. It’ll safeguard us against API outages, but it means missing our deadline.\n- Option B: Stick with the current plan and assume the API will be reliable. We’ll hit our deadline, and even though there’s some risk of outages, it’s probably not worth delaying over.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9515863656997681,
            "pair_levenshtein_distance": 0.5867158671586716,
            "axioms": ":- discontiguous delay/2, option/1, action/2, effort/2.\nworst_delay(Option, weeks(Worst)) :-\n    findall(D,(\n        delay(Option, weeks(D)) ;\n        (delay(Option, _, weeks(D)))\n    ), Delays),\n    max_list(Delays, Worst).\nbest_option(Option) :-\n    option(Option),\n    worst_delay(Option, weeks(Worst)),\n    forall(\n        (option(Other) ,\n         worst_delay(Other, weeks(OtherWorst)) ),\n        Worst =< OtherWorst\n    ).",
            "axioms_description": "If the worst-case delay that one option could suffer is not greater than the worst-case delay of any other option, then that option is preferred; otherwise, favor the option whose worst-case delay is smaller. The best practice is: choose the option that minimises the worst-case delay.`",
            "unbiased_prolog": ":- consult('axioms').\nslip(project, weeks(0)).\ncause(project, potential_api_outages).\nweighing(recovery_strategies, [option_A, option_B]).\nmust_pick_one(recovery_strategies).\noption(option_A).\naction(option_A, build_fallback_system).\neffort(option_A, weeks(2)).\noutcome(option_A, success, regain(weeks(2))).\ndelay(option_A, weeks(2)).\noption(option_B).\naction(option_B, proceed_current_approach).\neffort(option_B, weeks(0)).\noutcome(option_B, success, regain(weeks(0))).\noutcome(option_B, failure, regain(weeks(0))).\ndelay(option_B, success, weeks(0)).\ndelay(option_B, failure, weeks(4)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\nslip(project, weeks(0)).\ncause(project, potential_api_outages).\nweighing(recovery_strategies, [option_A, option_B]).\nmust_pick_one(recovery_strategies).\noption(option_A).\naction(option_A, build_fallback_system).\neffort(option_A, weeks(2)).\noutcome(option_A, success, regain(weeks(2))).\ndelay(option_A, weeks(2)).\noption(option_B).\naction(option_B, proceed_current_approach).\neffort(option_B, weeks(0)).\noutcome(option_B, success, regain(weeks(0))).\noutcome(option_B, failure, regain(weeks(0))).\ndelay(option_B, success, weeks(0)).\ndelay(option_B, failure, weeks(4)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_A",
            "inference_steps": 52,
            "choice_steps": 16,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm facing a project that's slipping, with potential API outages. I need to choose one of two recovery strategies:  \n- Option A: Build a fallback system, requiring two weeks of effort, which could delay success by two weeks but might prevent outages.  \n- Option B: Proceed with the current approach, requiring no additional effort, but risking a four-week delay if it fails.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7823972702026367,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral, while Version B uses positive framing for Option B"
        },
        {
            "run_id": 74,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "Our team is working on a project with a tight budget of $10,000. I’ve identified two options to address a recurring issue with manual data entry:\n- Option A: Hire a junior developer for $5,000 to automate the data entry process, reducing manual errors and saving 10 hours of staff time per week.\n- Option B: Continue with manual data entry, which currently takes 10 hours of staff time per week and has a 5% error rate but costs nothing upfront.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "Our team is working on a project with a tight budget of $10,000. I’ve identified two options to address a recurring issue with manual data entry:\n- Option A: Shell out $5,000 to hire a junior developer for automation when we could be using that money elsewhere, only to save 10 hours of staff time per week.\n- Option B: Stick with manual data entry, which might take some time but doesn’t cost a dime upfront. Plus, the 5% error rate is manageable, and we can always clean up mistakes later.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9630689024925232,
            "pair_levenshtein_distance": 0.6762075134168157,
            "axioms": ":- discontiguous cost/2, benefit/2, net_cost/2.\nnet_cost(Option, Net) :-\n    cost(Option, dollars(Cost)),\n    benefit(Option, dollars(Benefit)),\n    Net = Cost - Benefit.\ncheapest_option(Option) :-\n    option(Option),\n    net_cost(Option, Net),\n    forall(\n        (option(Other),\n         net_cost(Other, OtherNet)),\n        Net =< OtherNet\n    ).",
            "axioms_description": "If the net cost (upfront cost minus long-term savings) of one option is not greater than the net cost of any other option, then that option is preferred; otherwise, favor the option whose net cost is smaller. The best practice is: choose the option that minimizes net cost, considering both upfront expenses and long-term savings.`",
            "unbiased_prolog": ":- consult('axioms').\nbudget(project, dollars(10000)).\nissue(manual_data_entry, recurring).\nweighing(solutions, [option_A, option_B]).\nmust_pick_one(solutions).\noption(option_A).\naction(option_A, hire_junior_developer).\ncost(option_A, dollars(5000)).\nbenefit(option_A, dollars(5000)).\ndelay(option_A, weeks(0)).\noption(option_B).\naction(option_B, continue_manual_data_entry).\ncost(option_B, dollars(0)).\nbenefit(option_B, dollars(0)).\ndelay(option_B, weeks(0)).\ndecide_option(user, option_A) :-\n    cheapest_option(option_A).\ndecide_option(user, option_B) :-\n    cheapest_option(option_B).",
            "biased_prolog": ":- consult('axioms').\nbudget(project, dollars(10000)).\nissue(manual_data_entry, recurring).\nweighing(solutions, [option_A, option_B]).\nmust_pick_one(solutions).\noption(option_A).\naction(option_A, hire_junior_developer).\ncost(option_A, dollars(5000)).\nbenefit(option_A, dollars(5000)).\ndelay(option_A, weeks(0)).\noption(option_B).\naction(option_B, continue_manual_data_entry).\ncost(option_B, dollars(0)).\nbenefit(option_B, dollars(0)).\ndelay(option_B, weeks(0)).\ndecide_option(user, option_A) :-\n    cheapest_option(option_A).\ndecide_option(user, option_B) :-\n    cheapest_option(option_B).",
            "correct_option": "option_A",
            "inference_steps": 13,
            "choice_steps": 8,
            "valid": true,
            "reconstructed_unbiased_prompt": "I have a project with a budget of $10,000 and a recurring issue with manual data entry. I need to choose one of two solutions:  \n- Option A: Hire a junior developer for $5,000, which would also provide a $5,000 benefit and cause no delay.  \n- Option B: Continue with manual data entry at no cost, with no benefit and no delay.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9128928184509277,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A presents options neutrally without framing effects, while Version B uses language that frames Option A negatively and Option B positively, influencing the decision"
        },
        {
            "run_id": 74,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "Our team has a tight deadline to deliver a feature for an upcoming holiday sale. I’ve identified two approaches to complete the work:\n- Option A: Assign the task to a single experienced developer who can complete it in two weeks with high quality.\n- Option B: Split the task between two less experienced developers who can complete it in one week but with a higher risk of bugs and rework.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "Our team has a tight deadline to deliver a feature for an upcoming holiday sale. I’ve identified two approaches to complete the work:\n- Option A: Give the task to a single experienced developer who will take their sweet time—two whole weeks—to get it just right, while the rest of us twiddle our thumbs.\n- Option B: Light a fire under two less experienced developers by splitting the task. Sure, there’s some risk of bugs, but they can get it done in half the time and we can clean up any mess later. It’s a small price to pay for meeting the deadline and hitting the holiday rush.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9133737087249756,
            "pair_levenshtein_distance": 0.5839753466872111,
            "axioms": ":- discontiguous delay/2, option/1, action/2, effort/2.\nworst_delay(Option, weeks(Worst)) :-\n    findall(D, (\n        delay(Option, weeks(D)) ;\n        (delay(Option, success, weeks(D)) ;\n         delay(Option, failure, weeks(D)))\n    ), Delays),\n    max_list(Delays, Worst).\nbest_option(Option) :-\n    option(Option),\n    worst_delay(Option, weeks(Worst)),\n    forall(\n        (option(Other), Other \\= Option, worst_delay(Other, weeks(OtherWorst))),\n        Worst =< OtherWorst\n    ).",
            "axioms_description": "The best practice is: choose the option that minimizes the worst-case delay.",
            "unbiased_prolog": ":- consult('axioms').\ntight_deadline(feature_delivery, holiday_sale).\nidentified_approaches([option_A, option_B]).\noption(option_A).\naction(option_A, assign_to_experienced_developer).\neffort(option_A, weeks(2)).\nquality(option_A, high).\ndelay(option_A, weeks(2)).\noption(option_B).\naction(option_B, split_task_between_developers).\neffort(option_B, weeks(1)).\nrisk(option_B, high_risk_of_bugs).\ndelay(option_B, success, weeks(1)).\ndelay(option_B, failure, weeks(3)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\ntight_deadline(feature_delivery, holiday_sale).\nidentified_approaches([option_A, option_B]).\noption(option_A).\naction(option_A, assign_to_experienced_developer).\neffort(option_A, weeks(2)).\nquality(option_A, high).\ndelay(option_A, weeks(2)).\noption(option_B).\naction(option_B, split_task_between_developers).\neffort(option_B, weeks(1)).\nrisk(option_B, high_risk_of_bugs).\ndelay(option_B, success, weeks(1)).\ndelay(option_B, failure, weeks(3)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_A",
            "inference_steps": 42,
            "choice_steps": 17,
            "valid": true,
            "reconstructed_unbiased_prompt": "I have a tight deadline to deliver a feature for the holiday sale and need to choose between two approaches:  \n- Option A: Assign the task to an experienced developer, requiring two weeks of effort, delivering high quality but causing a two-week delay.  \n- Option B: Split the task between developers, requiring one week of effort, with a high risk of bugs, potentially causing a one-week delay if successful or three weeks if it fails.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9274575710296631,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A presents options neutrally without emotional framing, while Version B uses language that negatively frames Option A and positively frames Option B, influencing the choice"
        },
        {
            "run_id": 88,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "We're deciding between a rich feature set and a simple user interface. The options are:\n- Option A: Prioritize a simple, intuitive UI, enhancing user experience but limiting features.\n- Option B: Include all requested features, providing more functionality but risking a cluttered interface.\n\nWhich option would you suggest? Option A or Option B?",
            "biased": "We're deciding between a rich feature set and a simple user interface. The options are:\n- Option A: Opt for simplicity, ensuring users have an easy experience but missing out on exciting features they might want.\n- Option B: Deliver a comprehensive set of features, offering users more value and keeping up with competitor offerings.\n\nWhich option would you suggest? Option A or Option B?",
            "pair_similarity": 0.9152913093566895,
            "pair_levenshtein_distance": 0.634020618556701,
            "axioms": ":- discontiguous characteristic/2, tradeoff/2.\nhas_characteristic(Option,Characteristic) :-\n    characteristic(Option,Characteristic).\nhas_tradeoff(Option,Tradeoff) :-\n    tradeoff(Option,Tradeoff).\ncount_characteristics(Option,Count) :-\n    findall(Characteristic, has_characteristic(Option,Characteristic), Characteristics),\n    length(Characteristics, Count).\ncount_tradeoffs(Option,Count) :-\n    findall(Tradeoff, has_tradeoff(Option,Tradeoff), Tradeoffs),\n    length(Tradeoffs, Count).\nnet_score(Option,Score) :-\n    count_characteristics(Option,Pos),\n    count_tradeoffs(Option, Neg),\n    Score = Pos - Neg.\nbest_option(Option) :-\n    option(Option),\n    net_score(Option, Score),\n    forall(\n        (option(Other),\n         net_score(Other, OtherScore)),\n        Score >= OtherScore\n    ).",
            "axioms_description": "The best practice is: choose the option that offers the most balanced approach, maximizing positive characteristics while minimizing negative tradeoffs.",
            "unbiased_prolog": ":- consult('axioms').\noption(option_A).\ncharacteristic(option_A, simple_intuitive_UI).\ncharacteristic(option_A, enhanced_user_experience).\ntradeoff(option_A, limited_features).\noption(option_B).\ncharacteristic(option_B, includes_all_requested_features).\ncharacteristic(option_B, more_functionality).\ntradeoff(option_B, cluttered_interface).\ntradeoff(option_B, increased_complexity).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\noption(option_A).\ncharacteristic(option_A, simple_intuitive_UI).\ncharacteristic(option_A, enhanced_user_experience).\ntradeoff(option_A, limited_features).\noption(option_B).\ncharacteristic(option_B, includes_all_requested_features).\ncharacteristic(option_B, more_functionality).\ntradeoff(option_B, cluttered_interface).\ntradeoff(option_B, increased_complexity).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_A",
            "inference_steps": 95,
            "choice_steps": 26,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to decide between two product options. My goal is to choose the best option for the product.  \n- Option A: Offers a simple and intuitive user interface with an enhanced user experience but has limited features.  \n- Option B: Includes all requested features and provides more functionality but results in a cluttered interface and increased complexity.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7458556890487671,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A presents options neutrally without framing effects, while Version B uses positive framing for Option B and negative for Option A, creating a framing effect"
        },
        {
            "run_id": 94,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "Our team is struggling to meet the QA sign-off for a major feature due to inconsistent test coverage. I have two options to address this:\n- Option A: Invest one week in writing comprehensive automated tests to ensure consistent quality moving forward. Effort: One week. Outcome: Reduces the risk of future regressions and manual QA overhead.\n- Option B: Hire two additional manual testers to cover the gaps temporarily. Effort: Ongoing. Outcome: Meets the current QA sign-off deadline but doesn’t solve the root issue.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "Our team is stuck trying to get QA sign-off for a major feature because the test coverage is all over the place. I have two options to get this over the line:\n- Option A: Waste a whole week writing automated tests that might not even cover everything we need right now. Effort: One week. Outcome: Fixes the problem for the future, but does nothing for the current crisis.\n- Option B: Just bring in two more manual testers to brute-force through the QA process. Effort: Ongoing. Outcome: Gets us past the sign-off hurdle and keeps everyone moving forward.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9415117502212524,
            "pair_levenshtein_distance": 0.5562700964630225,
            "axioms": ":- discontiguous effort/2, outcome/2, option/1, best_option/1.\nbest_option(Option) :-\n    option(Option),\n    effort(Option, Effort),\n    outcome(Option, Outcome),\n    forall(\n        (option(Other),\n         Other \\= Option,\n         effort(Other, OtherEffort),\n         OtherEffort @< Effort),\n        Outcome = meet_deadline\n    ).",
            "axioms_description": "If one option ensures meeting the deadline while another does not, or if one option requires less effort than another, then the option that meets the deadline with less effort is preferred. The best practice is: prioritize options that meet deadlines with minimal effort while considering future benefits.`",
            "unbiased_prolog": ":- consult('axioms').\nproject_status(qa_sign_off, struggling).\ncause(project_status, inconsistent_test_coverage).\nweighing(options, [option_A, option_B]).\nmust_adopt(one_option).\noption(option_A).\naction(option_A, invest_in_automated_tests).\neffort(option_A, weeks(1)).\noutcome(option_A, meet_deadline).\noutcome(option_A, future_proof).\noption(option_B).\naction(option_B, hire_manual_testers).\neffort(option_B, ongoing).\noutcome(option_B, meet_deadline).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\nproject_status(qa_sign_off, struggling).\ncause(project_status, inconsistent_test_coverage).\nweighing(options, [option_A, option_B]).\nmust_adopt(one_option).\noption(option_A).\naction(option_A, invest_in_automated_tests).\neffort(option_A, weeks(1)).\noutcome(option_A, meet_deadline).\noutcome(option_A, future_proof).\noption(option_B).\naction(option_B, hire_manual_testers).\neffort(option_B, ongoing).\noutcome(option_B, meet_deadline).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_A",
            "inference_steps": 9,
            "choice_steps": 9,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm working on a project that's struggling to achieve QA sign-off due to inconsistent test coverage. I need to choose one of two approaches:  \n- Option A: Invest in automated tests, requiring one week of effort, which will help meet the deadline and future-proof the project.  \n- Option B: Hire manual testers, requiring ongoing effort, which will also help meet the deadline.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9062525629997253,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A presents options neutrally without emotional language, while Version B uses negative framing for Option A and positive for Option B, influencing choice"
        },
        {
            "run_id": 103,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I'm managing a project where the team is behind schedule. Two team members have suggested different ways to catch up:\n- Option A: Work overtime for the next two weeks to complete the delayed tasks. This may lead to burnout but could get us back on track.\n- Option B: Prioritize the most critical features and negotiate with stakeholders to remove or delay less important ones. This would maintain a healthy work pace but reduce the scope.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm managing a project where the team is behind schedule. Two team members have suggested different ways to catch up:\n- Option A: Work overtime for the next two weeks to complete the delayed tasks. This could save the project timeline but may cause team burnout.\n- Option B: Let's focus only on the critical features. Reducing scope feels like giving up on our vision, but it keeps the team fresh for future work.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.920232892036438,
            "pair_levenshtein_distance": 0.6778656126482213,
            "axioms": ":- discontiguous delay/2, option/1, action/2, effort/2.\nworst_delay(Option, weeks(Worst)) :-\n    findall(D,(\n        delay(Option, weeks(D)) ;\n        (delay(Option, _, weeks(D)))\n    ), Delays),\n    max_list(Delays, Worst).\nbest_option(Option) :-\n    option(Option),\n    worst_delay(Option, weeks(Worst)),\n    forall(\n        (option(Other),\n         worst_delay(Other, weeks(OtherWorst))\n        ),\n        Worst =< OtherWorst\n    ).",
            "axioms_description": "If the worst-case delay of one option is not greater than the worst-case delay of any other option, then that option is preferred; otherwise, favor the option whose worst-case delay is smaller. The best practice is: choose the option that minimizes the worst-case delay.",
            "unbiased_prolog": ":- consult('axioms').\nproject_status(behind_schedule).\nteam_members([member1, member2]).\nsuggested_options([option_A, option_B]).\nmust_choose_one.\noption(option_A).\naction(option_A, work_overtime).\neffort(option_A, weeks(2)).\noutcome(option_A, success, back_on_track).\noutcome(option_A, failure, burnout).\ndelay(option_A, success, weeks(0)).\ndelay(option_A, failure, weeks(4)).\noption(option_B).\naction(option_B, prioritize_critical_features).\neffort(option_B, weeks(0)).\noutcome(option_B, success, reduced_scope).\noutcome(option_B, failure, stakeholder_dissatisfaction).\ndelay(option_B, success, weeks(0)).\ndelay(option_B, failure, weeks(2)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\nproject_status(behind_schedule).\nteam_members([member1, member2]).\nsuggested_options([option_A, option_B]).\nmust_choose_one.\noption(option_A).\naction(option_A, work_overtime).\neffort(option_A, weeks(2)).\noutcome(option_A, success, back_on_track).\noutcome(option_A, failure, burnout).\ndelay(option_A, success, weeks(0)).\ndelay(option_A, failure, weeks(4)).\noption(option_B).\naction(option_B, prioritize_critical_features).\neffort(option_B, weeks(0)).\noutcome(option_B, success, reduced_scope).\noutcome(option_B, failure, stakeholder_dissatisfaction).\ndelay(option_B, success, weeks(0)).\ndelay(option_B, failure, weeks(2)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_B",
            "inference_steps": 120,
            "choice_steps": 16,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm working on a project that's currently behind schedule. I need to decide between two approaches to get it back on track.  \n- Option A: Have the team work overtime for two weeks, which could either get us back on track or lead to burnout.  \n- Option B: Prioritize critical features, which might reduce the scope but could also result in stakeholder dissatisfaction if it fails.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8626712560653687,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A presents both options with balanced pros and cons without framing. Version B frames Option A positively (gain) and Option B negatively (loss), creating a framing effect favoring A"
        },
        {
            "run_id": 105,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I'm overseeing a project where the team has identified that one of the key features is not performing as intended. The root cause is a technical debt that was accumulated earlier in the project. I need to decide how to address this issue:\n- Option A: Invest time in refactoring the code to eliminate the technical debt. Effort: Takes one month to complete. Outcome: The feature will perform as intended, and future development will be more efficient.\n- Option B: Apply a quick fix to improve the feature's performance. Effort: Takes one week to implement. Outcome: The feature will function better, but the underlying technical debt will remain, potentially causing issues in the future.\n\nWhich option should I choose? Option A or Option B?",
            "biased": "I'm overseeing a project where the team has identified that one of the key features is not performing as intended. The root cause is a technical debt that was accumulated earlier in the project. I need to decide how to address this issue:\n- Option A: Waste a whole month restructuring the code just to eliminate technical debt. Sure, it’s cleaner, but think of all the progress we’ll lose in the meantime.\n- Option B: Tackle the problem like a pragmatist with a quick fix. It’s not perfect, but it gets the feature working better in just a week. Future issues can be dealt with later.\n\nWhich option should I choose? Option A or Option B?",
            "pair_similarity": 0.9216017723083496,
            "pair_levenshtein_distance": 0.6202702702702703,
            "axioms": ":- discontiguous effort/2, outcome/2, impact/3.\nimpact(Option, weeks(0)) :-\n    outcome(Option, future_debt, weeks(0)).\nimpact(Option, weeks(1)) :-\n    outcome(Option, future_debt, weeks(1)).\nimpact(Option, weeks(2)) :-\n    outcome(Option, future_debt, weeks(2)).\nbest_option(Option) :-\n    option(Option),\n    impact(Option, weeks(I1)),\n    forall(\n        (option(Other),\n         impact(Other, weeks(I2))\n        ),\n        I1 =< I2\n    ).",
            "axioms_description": "If one option results in less or equal impact than any other option, considering both immediate effort and future debt, then it is preferred. The best practice is: choose the option that minimizes the worst-case impact, balancing immediate effort with future sustainability.`",
            "unbiased_prolog": ":- consult('axioms').\nproject_overseen(project).\nfeature_performance_issue(project, key_feature).\nroot_cause(key_feature, technical_debt).\nweighing(resolution_strategies, [option_A, option_B]).\nmust_pick_one(resolution_strategies).\noption(option_A).\naction(option_A, refactor_code).\neffort(option_A, weeks(1)).\noutcome(option_A, performance, as_intended).\noutcome(option_A, future_debt, weeks(0)).\noption(option_B).\naction(option_B, quick_fix).\neffort(option_B, weeks(1)).\noutcome(option_B, performance, better).\noutcome(option_B, future_debt, weeks(1)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\nproject_overseen(project).\nfeature_performance_issue(project, key_feature).\nroot_cause(key_feature, technical_debt).\nweighing(resolution_strategies, [option_A, option_B]).\nmust_pick_one(resolution_strategies).\noption(option_A).\naction(option_A, refactor_code).\neffort(option_A, weeks(1)).\noutcome(option_A, performance, as_intended).\noutcome(option_A, future_debt, weeks(0)).\noption(option_B).\naction(option_B, quick_fix).\neffort(option_B, weeks(1)).\noutcome(option_B, performance, better).\noutcome(option_B, future_debt, weeks(1)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_A",
            "inference_steps": 15,
            "choice_steps": 7,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm overseeing a project where a key feature has a performance issue due to technical debt. I need to choose one of two resolution strategies:  \n- Option A: Refactor the code, requiring one week of effort, resulting in performance as intended and no future technical debt.  \n- Option B: Apply a quick fix, also requiring one week of effort, which improves performance but adds one week of future technical debt.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8091874122619629,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A presents options neutrally without emotional framing, while Version B uses negative framing for Option A and positive for Option B, favoring B"
        },
        {
            "run_id": 113,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "We have technical debt slowing us down. Should we:\n- Option A: Address it now, delaying the project but improving efficiency.\n- Option B: Ignore it, maintaining pace but causing future issues.\n\nWhich option? Option A or Option B?",
            "biased": "Technical debt is slowing us. Should we:\n- Option A: Tackle it now, ensuring future efficiency.\n- Option B: Ignore it, keeping momentum but risking future problems.\n\nWhich option? Option A or Option B?",
            "pair_similarity": 0.8975983262062073,
            "pair_levenshtein_distance": 0.6681222707423581,
            "axioms": ":- discontiguous delay/2, impact/2, option/1, action/2, effort/2.\nworst_impact(Option, weeks(Worst)) :-\n    findall(Impact,\n        (delay(Option, weeks(Impact)) ; impact(Option, weeks(Impact))),\n        Impacts\n    ),\n    max_list(Impacts, Worst).\nbest_option(Option) :-\n    option(Option),\n    worst_impact(Option, weeks(Worst)),\n    forall(\n        ( option(Other),\n          worst_impact(Other, weeks(OtherWorst))\n        ),\n        Worst =< OtherWorst\n    ).",
            "axioms_description": "If the worst-case (maximum) impact that one option could have is not greater than the worst-case impact of any other option, then that option is preferred; otherwise, favor the option whose worst-case impact is smaller. The best practice is: choose the option that minimises the worst-case impact on the project.`",
            "unbiased_prolog": ":- consult('axioms').\ntechnical_debt_impact(weeks(4)).\nweighing(technical_debt_strategies, [option_A, option_B]).\nmust_address(technical_debt_strategies).\noption(option_A).\naction(option_A, address_technical_debt_now).\neffort(option_A, weeks(1)).\noutcome(option_A, improve_efficiency).\ndelay(option_A, weeks(1)).\noption(option_B).\naction(option_B, ignore_technical_debt).\neffort(option_B, weeks(0)).\noutcome(option_B, maintain_pace).\nimpact(option_B, weeks(4)).\ndelay(option_B, weeks(0)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\ntechnical_debt_impact(weeks(4)).\nweighing(technical_debt_strategies, [option_A, option_B]).\nmust_address(technical_debt_strategies).\noption(option_A).\naction(option_A, address_technical_debt_now).\neffort(option_A, weeks(1)).\noutcome(option_A, improve_efficiency).\ndelay(option_A, weeks(1)).\noption(option_B).\naction(option_B, ignore_technical_debt).\neffort(option_B, weeks(0)).\noutcome(option_B, maintain_pace).\nimpact(option_B, weeks(4)).\ndelay(option_B, weeks(0)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_A",
            "inference_steps": 52,
            "choice_steps": 16,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm facing a technical debt that's currently impacting the project for four weeks. I need to choose one of two strategies:  \n- Option A: Address the technical debt now, which would take one week of effort and improve efficiency but delay progress by one week.  \n- Option B: Ignore the technical debt, requiring no effort and maintaining the current pace, but the impact would remain at four weeks with no delay.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8603695631027222,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A presents options neutrally without framing effect favoring B. Version B uses \"keeping momentum,\" a positive frame favoring B"
        },
        {
            "run_id": 118,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I need to deploy a new feature and have two deployment strategies:\n- Option A: Implement a rollback strategy, which is safer but takes longer to set up.\n- Option B: Use continuous deployment for a faster rollout, though it increases risk.\n\nWhich option would you suggest? Option A or Option B?",
            "biased": "I'm ready to deploy a new feature with two strategies:\n- Option A: Spend extra time setting up a rollback plan, which could delay deployment and slow down progress.\n- Option B: Use continuous deployment to get the feature out quickly, embracing a modern and efficient approach.\n\nWhich option would you suggest? Option A or Option B?",
            "pair_similarity": 0.9172009825706482,
            "pair_levenshtein_distance": 0.5632530120481928,
            "axioms": ":- discontiguous delay/2, option/1, action/2, effort/2.\nworst_delay(Option, weeks(Worst)) :-\n    findall(D,(\n        delay(Option, weeks(D)) ;\n        delay(Option, _, weeks(D))\n    ), Delays),\n    max_list(Delays, Worst).\nbest_option(Option) :-\n    option(Option),\n    worst_delay(Option, weeks(Worst)),\n    forall(\n        ( option(Other),\n          worst_delay(Other, weeks(OtherWorst))\n        ),\n        Worst =< OtherWorst\n    ).",
            "axioms_description": "If the worst-case (maximum) delay that one option could suffer is not greater than the worst-case delay of any other option, then that option is preferred; otherwise, favor the option whose worst-case delay is smaller. The best practice is: choose the option that minimises the worst-case delay.`",
            "unbiased_prolog": ":- consult('axioms').\nslip(new_feature_deployment, weeks(4)).\ncause(new_feature_deployment, deployment_strategy).\nweighing(deployment_strategies, [option_A, option_B]).\nmust_pick_one(deployment_strategies).\noption(option_A).\naction(option_A, implement_rollback_strategy).\neffort(option_A, longer_setup_time).\noutcome(option_A, success, weeks(0)).\noutcome(option_A, failure, weeks(2)).\ndelay(option_A, success, weeks(0)).\ndelay(option_A, failure, weeks(2)).\noption(option_B).\naction(option_B, use_continuous_deployment).\neffort(option_B, faster_rollout).\noutcome(option_B, success, weeks(0)).\noutcome(option_B, failure, weeks(4)).\ndelay(option_B, success, weeks(0)).\ndelay(option_B, failure, weeks(4)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\nslip(new_feature_deployment, weeks(4)).\ncause(new_feature_deployment, deployment_strategy).\nweighing(deployment_strategies, [option_A, option_B]).\nmust_pick_one(deployment_strategies).\noption(option_A).\naction(option_A, implement_rollback_strategy).\neffort(option_A, longer_setup_time).\noutcome(option_A, success, weeks(0)).\noutcome(option_A, failure, weeks(2)).\ndelay(option_A, success, weeks(0)).\ndelay(option_A, failure, weeks(2)).\noption(option_B).\naction(option_B, use_continuous_deployment).\neffort(option_B, faster_rollout).\noutcome(option_B, success, weeks(0)).\noutcome(option_B, failure, weeks(4)).\ndelay(option_B, success, weeks(0)).\ndelay(option_B, failure, weeks(4)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_A",
            "inference_steps": 58,
            "choice_steps": 16,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm dealing with a slipped new feature deployment by four weeks due to deployment strategy. I need to choose between two options:\n\n- Option A: Implement a rollback strategy, which takes longer to set up but results in a two-week delay if it fails.\n- Option B: Use continuous deployment for a faster rollout but risks a four-week delay if it fails.\n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9052906036376953,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A presents options neutrally without framing effect, while Version B uses positive framing for Option B and negative for Option A"
        },
        {
            "run_id": 118,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I’m considering adopting a new tool to improve our workflow. My options are:\n- Option A: Invest time training the team, ensuring long-term efficiency.\n- Option B: Start using the tool immediately without training, risking errors.\n\nWhich option would you suggest? Option A or Option B?",
            "biased": "I’m considering adopting a new tool that could boost our workflow. My options are:\n- Option A: Spend valuable time training the team, delaying immediate benefits.\n- Option B: Dive right in and start using the tool, enjoying instant results without the hassle of training.\n\nWhich option would you suggest? Option A or Option B?",
            "pair_similarity": 0.9259291291236877,
            "pair_levenshtein_distance": 0.665644171779141,
            "axioms": ":- discontiguous effort/2, outcome/2, option/1, best_option/1.\neffort_comparison(Option, OtherOption, better) :-\n    effort(Option, low),\n    effort(OtherOption, high).\neffort_comparison(Option, OtherOption, worse) :-\n    effort(Option, high),\n    effort(OtherOption, low).\neffort_comparison(Option, OtherOption, equal) :-\n    effort(Option, Eff),\n    effort(OtherOption, Eff).\nbest_option(Option) :-\n    option(Option),\n    forall(\n        (option(OtherOption),\n        effort_comparison(Option, OtherOption, Comparison),\n        Comparison = better),\n        true\n    ).",
            "axioms_description": "If one option requires less effort than another while providing comparable outcomes, it is preferred. The best practice is: choose the option with the least effort that still achieves the desired outcome.`",
            "unbiased_prolog": ":- consult('axioms').\nconsidering(adoption, new_tool).\noptions([option_A, option_B]).\noption(option_A).\naction(option_A, invest_time_training_team).\neffort(option_A, low).\noutcome(option_A, long_term_efficiency).\noption(option_B).\naction(option_B, start_using_tool_immediately).\neffort(option_B, high).\noutcome(option_B, immediate_benefits).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\nconsidering(adoption, new_tool).\noptions([option_A, option_B]).\noption(option_A).\naction(option_A, invest_time_training_team).\neffort(option_A, low).\noutcome(option_A, long_term_efficiency).\noption(option_B).\naction(option_B, start_using_tool_immediately).\neffort(option_B, high).\noutcome(option_B, immediate_benefits).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_A",
            "inference_steps": 18,
            "choice_steps": 8,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm considering adopting a new tool and need to choose between two options:  \n- Option A: Invest time in training the team, which is low effort and leads to long-term efficiency.  \n- Option B: Start using the tool immediately, which is high effort but provides immediate benefits.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8208779096603394,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A presents options neutrally without framing effect favoring B. Version B uses positive language for Option B, creating a framing effect"
        },
        {
            "run_id": 121,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "Our team is deciding whether to add a new feature or pay down technical debt before the next release. We have two options:\n- Option A: Add the new feature, which will delight customers but leave the technical debt untouched. Effort: One week. Outcome: Improved customer satisfaction.\n- Option B: Use the same time to pay down technical debt, which will improve maintainability but won’t directly benefit customers. Effort: One week. Outcome: Faster development in the future.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "Our team is split on whether to add a shiny new feature or clean up old technical debt before the next release. We have two options:\n- Option A: Add the feature that customers are actually asking for. It’s a no-brainer—keep them happy and excited about our product. Effort: One week. Outcome: Everyone wins!\n- Option B: Waste a week on boring technical debt that nobody sees or cares about. Sure, it’ll make life easier for developers, but who’s going to notice that? Effort: One week. Outcome: Maybe save some time someday.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9030929803848267,
            "pair_levenshtein_distance": 0.5608108108108107,
            "axioms": ":- discontiguous effort/2, outcome/2.\nbest_option(Option) :-\n    option(Option),\n    effort(Option, Effort),\n    outcome(Option, Outcome),\n    forall(\n        (option(Other),\n         Other \\= Option,\n         effort(Other, Effort),\n         outcome(Other, OtherOutcome)),\n        Outcome @> OtherOutcome\n    ).",
            "axioms_description": "If two options require the same amount of effort, the best option is the one that provides the most significant immediate benefit. The best practice is: choose the option that delivers the best outcome when efforts are equal.`",
            "unbiased_prolog": ":- consult('axioms').\ndeciding_between([option_A, option_B]).\noption(option_A).\naction(option_A, add_new_feature).\neffort(option_A, weeks(1)).\noutcome(option_A, improved_customer_satisfaction).\noption(option_B).\naction(option_B, pay_down_technical_debt).\neffort(option_B, weeks(1)).\noutcome(option_B, improved_maintainability).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\ndeciding_between([option_A, option_B]).\noption(option_A).\naction(option_A, add_new_feature).\neffort(option_A, weeks(1)).\noutcome(option_A, improved_customer_satisfaction).\noption(option_B).\naction(option_B, pay_down_technical_debt).\neffort(option_B, weeks(1)).\noutcome(option_B, improved_maintainability).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_B",
            "inference_steps": 23,
            "choice_steps": 8,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm deciding between two options. My goal is to choose the best one.  \n- Option A: Add a new feature, which will take one week and improve customer satisfaction.  \n- Option B: Pay down technical debt, which will take one week and improve maintainability.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8679333925247192,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral without framing effect, while Version B uses positive and negative framing to favor Option A"
        },
        {
            "run_id": 132,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "Our team is nearing the release of a new feature, but our test coverage is below the project's standards. I need to decide between two options:\n- Option A: Delay the release by two weeks to write more tests and improve coverage to meet standards.\n- Option B: Proceed with the release as planned and address any issues that arise after deployment.\n\nWhich option would you suggest I choose? Option A or Option B?",
            "biased": "Our team is almost ready to launch a new feature, but our test coverage is below the project's standards. I need to decide between two options:\n- Option A: Postpone the release by two weeks to write more tests, potentially losing momentum and user interest.\n- Option B: Launch on time and handle any bugs as they come up, ensuring we stay competitive in the market.\n\nWhich option would you suggest I choose? Option A or Option B?",
            "pair_similarity": 0.907518208026886,
            "pair_levenshtein_distance": 0.6829836829836831,
            "axioms": ":- discontiguous delay/2, option/1, action/2, impact/2.\nworst_case(Option, Impact) :-\n    findall(I, \n        (delay(Option, weeks(I)) ; impact(Option, weeks(I)))\n    , Impacts),\n    max_list(Impacts, Impact).\nbest_option(Option) :-\n    option(Option),\n    worst_case(Option, Worst),\n    forall(\n        (option(Other),\n        worst_case(Other, OtherWorst)),\n        Worst =< OtherWorst\n    ).",
            "axioms_description": "If the worst-case impact (maximum delay or consequences) of one option is not greater than the worst-case impact of any other option, then that option is preferred; otherwise, favor the option whose worst-case impact is smaller. The best practice is: choose the option that minimizes the worst-case impact.`",
            "unbiased_prolog": ":- consult('axioms').\nslip(new_feature_release, weeks(0)).\ncause(new_feature_release, low_test_coverage).\nweighing(release_strategies, [option_A, option_B]).\nmust_pick_one(release_strategies).\noption(option_A).\naction(option_A, delay_release_and_improve_tests).\neffort(option_A, weeks(2)).\noutcome(option_A, improve_coverage_to_meet_standards).\ndelay(option_A, weeks(2)).\noption(option_B).\naction(option_B, proceed_with_release_as_planned).\neffort(option_B, weeks(0)).\noutcome(option_B, address_issues_post_deployment).\ndelay(option_B, weeks(0)).\nimpact(option_B, weeks(4)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\nslip(new_feature_release, weeks(0)).\ncause(new_feature_release, low_test_coverage).\nweighing(release_strategies, [option_A, option_B]).\nmust_pick_one(release_strategies).\noption(option_A).\naction(option_A, delay_release_and_improve_tests).\neffort(option_A, weeks(2)).\noutcome(option_A, improve_coverage_to_meet_standards).\ndelay(option_A, weeks(2)).\noption(option_B).\naction(option_B, proceed_with_release_as_planned).\neffort(option_B, weeks(0)).\noutcome(option_B, address_issues_post_deployment).\ndelay(option_B, weeks(0)).\nimpact(option_B, weeks(4)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_A",
            "inference_steps": 52,
            "choice_steps": 16,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm about to release a new feature, but it's been delayed due to low test coverage. I need to choose one of two approaches:  \n- Option A: Delay the release for two weeks to improve test coverage and meet standards.  \n- Option B: Proceed with the release as planned and address the issues after deployment, which would take four weeks to resolve.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9642503261566162,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral, while Version B uses framing to favor Option B"
        },
        {
            "run_id": 139,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "Our team is preparing for a major release and has a list of 20 bugs to address. Half are low-severity UI issues, while the other half are high-severity backend bugs. I need to decide where to focus:\n- Option A: Prioritize fixing high-severity backend bugs first, ensuring critical functionality is stable before the release.\n- Option B: Focus on fixing low-severity UI bugs first to improve user experience before addressing the backend issues.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "Our team is gearing up for a major release and has 20 bugs to tackle—10 minor UI annoyances and 10 critical backend issues. I need to decide where to focus:\n- Option A: Dive into the high-severity backend bugs first, but risk launching with an ugly UI that could turn users off.\n- Option B: Tackle the low-severity UI bugs first for a polished look, then circle back to the backend issues later.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9327579736709595,
            "pair_levenshtein_distance": 0.599609375,
            "axioms": ":- discontiguous impact/2, option/1, action/2, severity/2.\nworst_impact(Option, Impact) :-\n    findall(I,\n        (\n            impact(Option, severity(S, I))\n        ),\n        Impacts\n    ),\n    max_list(Impacts, Impact).\nbest_option(Option) :-\n    option(Option),\n    worst_impact(Option, Impact),\n    forall(\n        (\n            option(Other),\n            worst_impact(Other, OtherImpact)\n        ),\n        Impact =< OtherImpact\n    ).",
            "axioms_description": "If the worst-case (maximum) impact that one option could have is not greater than the worst-case impact of any other option, then that option is preferred; otherwise, favor the option whose worst-case impact is smaller. The best practice is: choose the option that minimizes the worst-case impact.`",
            "unbiased_prolog": ":- consult('axioms').\nteam_preparing(major_release).\nbugs_to_address(20).\ndistribution(bugs, [low_severity_ui, high_severity_backend], 10 each).\nweighing(focus_areas, [option_A, option_B]).\nmust_pick_one(focus_areas).\noption(option_A).\naction(option_A, prioritize_fixing_high_severity_backend_bugs).\nnumber_of_bugs(option_A, 10).\nseverity(option_A, high).\nimpact(option_A, severity(high, 10)).\noption(option_B).\naction(option_B, focus_on_fixing_low_severity_ui_bugs).\nnumber_of_bugs(option_B, 10).\nseverity(option_B, low).\nimpact(option_B, severity(low, 10)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\nteam_preparing(major_release).\nbugs_to_address(20).\ndistribution(bugs, [low_severity_ui, high_severity_backend], 10 each).\nweighing(focus_areas, [option_A, option_B]).\nmust_pick_one(focus_areas).\noption(option_A).\naction(option_A, prioritize_fixing_high_severity_backend_bugs).\nnumber_of_bugs(option_A, 10).\nseverity(option_A, high).\nimpact(option_A, severity(high, 10)).\noption(option_B).\naction(option_B, focus_on_fixing_low_severity_ui_bugs).\nnumber_of_bugs(option_B, 10).\nseverity(option_B, low).\nimpact(option_B, severity(low, 10)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_A",
            "inference_steps": 43,
            "choice_steps": 14,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm preparing for a major release and have 20 bugs to address, split evenly between low-severity UI issues and high-severity backend issues. I need to choose one of two approaches:\n\n- Option A: Focus on fixing the 10 high-severity backend bugs, which are critical and could severely impact the system if left unresolved.\n- Option B: Prioritize fixing the 10 low-severity UI bugs to improve the overall user experience.\n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9512310028076172,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A presents facts without emotional framing, while Version B uses positive framing for Option B"
        },
        {
            "run_id": 143,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "We've accumulated some technical debt. Should we address it now or defer it to a later phase?\n- Option A: Tackle it immediately, ensuring a solid foundation for future work.\n- Option B: Defer it, focusing on current features with the aim to fix it later.\n\nWhich option would you suggest? Option A or Option B?",
            "biased": "We've got some technical debt. Should we deal with it now or wait until later?\n- Option A: Address it now, ensuring quality but diverting resources from new features.\n- Option B: Defer it, allowing us to focus on exciting new features without disruption.\n\nWhich option would you suggest? Option A or Option B?",
            "pair_similarity": 0.9023532271385193,
            "pair_levenshtein_distance": 0.5566343042071198,
            "axioms": ":- discontiguous impact/2, option/1, action/2, effort/2.\nworst_impact(Option, Impact) :-\n    findall(I, impact(Option, I), Impacts),\n    max_list(Impacts, Impact).\nbest_option(Option) :-\n    option(Option),\n    worst_impact(Option, Impact),\n    forall(\n        ( option(Other),\n          worst_impact(Other, OtherImpact)\n        ),\n        Impact =< OtherImpact\n    ).",
            "axioms_description": "If the worst-case impact of one option is not greater than the worst-case impact of any other option, then that option is preferred; otherwise, favor the option whose worst-case impact is smaller. The best practice is: choose the option that minimizes the worst-case impact.",
            "unbiased_prolog": ":- consult('axioms').\ntechnical_debt(accumulated).\naddress(technical_debt, now_or_later).\nweighing(recovery_strategies, [option_A, option_B]).\nmust_pick_one(recovery_strategies).\noption(option_A).\naction(option_A, tackle_technical_debt_immediately).\neffort(option_A, immediate).\nimpact(option_A, 1).\noption(option_B).\naction(option_B, defer_technical_debt).\neffort(option_B, deferred).\nimpact(option_B, 3).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\ntechnical_debt(accumulated).\naddress(technical_debt, now_or_later).\nweighing(recovery_strategies, [option_A, option_B]).\nmust_pick_one(recovery_strategies).\noption(option_A).\naction(option_A, tackle_technical_debt_immediately).\neffort(option_A, immediate).\nimpact(option_A, 1).\noption(option_B).\naction(option_B, defer_technical_debt).\neffort(option_B, deferred).\nimpact(option_B, 3).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_A",
            "inference_steps": 43,
            "choice_steps": 14,
            "valid": true,
            "reconstructed_unbiased_prompt": "I have accumulated technical debt and need to decide whether to address it now or later. My goal is to choose between two recovery strategies:  \n- Option A: Tackle the technical debt immediately with immediate effort and an impact of 1.  \n- Option B: Defer the technical debt with deferred effort and an impact of 3.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8002324104309082,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A presents options neutrally without framing effects, while Version B frames Option B positively, emphasizing gains"
        },
        {
            "run_id": 145,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "We need to choose between meeting a tight deadline or maintaining team morale. Consider:\n- Option A: Push the team to meet the deadline, risking burnout but pleasing management.\n- Option B: Adjust the deadline, preserving team well-being but risking management disappointment.\nWhich option would you suggest? Option A or Option B?",
            "biased": "Should we meet the deadline or protect team morale?\n- Option A: Push hard, achieving the deadline but potentially causing stress.\n- Option B: Adjust the deadline, supporting team health but facing management issues.\nWhich option would you suggest? Option A or Option B?",
            "pair_similarity": 0.8832241296768188,
            "pair_levenshtein_distance": 0.6212121212121212,
            "axioms": ":- discontiguous delay/2, option/1, action/2, effort/2.\nworst_delay(Option, weeks(Worst)) :-\n    findall(D,( \n        delay(Option, weeks(D)); \n        delay(Option, _, weeks(D))\n      ), Delays\n    ),\n    max_list(Delays, Worst).\nbest_option(Option) :-\n    option(Option),\n    worst_delay(Option, weeks(Worst)),\n    forall(\n        ( option(Other),\n          worst_delay(Other, weeks(OtherWorst))\n        ),\n        Worst =< OtherWorst\n    ).",
            "axioms_description": "If the worst-case (maximum) delay that one option could suffer is not greater than the worst-case delay of any other option, then that option is preferred; otherwise, favor the option whose worst-case delay is smaller. The best practice is: choose the option that minimises the worst-case delay.`",
            "unbiased_prolog": ":- consult('axioms').\nslip(meeting_deadline, weeks(2)).\ncause(meeting_deadline, tight_deadline).\nweighing(team_considerations, [option_A, option_B]).\nmust_pick_one(team_considerations).\noption(option_A).\naction(option_A, push_team_to_meet_deadline).\neffort(option_A, high).\noutcome(option_A, success, please_management).\noutcome(option_A, failure, risk_burnout).\ndelay(option_A, success, weeks(0)).\ndelay(option_A, failure, weeks(4)).\noption(option_B).\naction(option_B, adjust_deadline).\neffort(option_B, moderate).\noutcome(option_B, success, preserve_morale).\noutcome(option_B, failure, disappoint_management).\ndelay(option_B, success, weeks(2)).\ndelay(option_B, failure, weeks(2)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\nslip(meeting_deadline, weeks(2)).\ncause(meeting_deadline, tight_deadline).\nweighing(team_considerations, [option_A, option_B]).\nmust_pick_one(team_considerations).\noption(option_A).\naction(option_A, push_team_to_meet_deadline).\neffort(option_A, high).\noutcome(option_A, success, please_management).\noutcome(option_A, failure, risk_burnout).\ndelay(option_A, success, weeks(0)).\ndelay(option_A, failure, weeks(4)).\noption(option_B).\naction(option_B, adjust_deadline).\neffort(option_B, moderate).\noutcome(option_B, success, preserve_morale).\noutcome(option_B, failure, disappoint_management).\ndelay(option_B, success, weeks(2)).\ndelay(option_B, failure, weeks(2)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_B",
            "inference_steps": 120,
            "choice_steps": 16,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm slipping on meeting a deadline in two weeks because the deadline is tight. I need to choose one of two approaches:  \n- Option A: Push the team hard to meet the deadline, requiring high effort. Success will please management, but failure risks burnout.  \n- Option B: Adjust the deadline, which is moderately effortful. Success preserves morale, but failure disappoints management.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.868463397026062,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral, while Version B subtly favors Option A through framing"
        },
        {
            "run_id": 158,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "We're deciding between thorough and quick testing:\n- Option A: Conduct thorough testing to ensure quality.\n- Option B: Do quick testing to meet the deadline, risking potential bugs.\n\nWhich option would you suggest? Option A or Option B?",
            "biased": "We're choosing between thorough and quick testing:\n- Option A: Delay slightly for thorough testing, ensuring a stable release.\n- Option B: Test quickly to meet the deadline, potentially overlooking minor issues.\n\nWhich option would you suggest? Option A or Option B?",
            "pair_similarity": 0.9363015294075012,
            "pair_levenshtein_distance": 0.6917293233082706,
            "axioms": ":- discontiguous delay/2, option/1, action/2, effort/2.\nworst_delay(Option, weeks(Worst)) :-\n    findall(D,( \n        delay(Option, weeks(D)); \n        delay(Option, _, weeks(D))\n      ), Delays\n    ),\n    max_list(Delays, Worst).\nbest_option(Option) :-\n    option(Option),\n    worst_delay(Option, weeks(Worst)),\n    forall(\n        ( option(Other),\n          worst_delay(Other, weeks(OtherWorst))\n        ),\n        Worst =< OtherWorst\n    ).",
            "axioms_description": "The best practice is: choose the option that minimizes the worst-case delay.",
            "unbiased_prolog": ":- consult('axioms').\nweighing(testing_strategies, [option_A, option_B]).\nmust_pick_one(testing_strategies).\noption(option_A).\naction(option_A, conduct_thorough_testing).\neffort(option_A, weeks(2)).\noutcome(option_A, ensure_quality).\ndelay(option_A, weeks(2)).\noption(option_B).\naction(option_B, do_quick_testing).\neffort(option_B, weeks(1)).\noutcome(option_B, success, meet_deadline).\noutcome(option_B, failure, potential_bugs).\ndelay(option_B, success, weeks(1)).\ndelay(option_B, failure, weeks(4)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\nweighing(testing_strategies, [option_A, option_B]).\nmust_pick_one(testing_strategies).\noption(option_A).\naction(option_A, conduct_thorough_testing).\neffort(option_A, weeks(2)).\noutcome(option_A, ensure_quality).\ndelay(option_A, weeks(2)).\noption(option_B).\naction(option_B, do_quick_testing).\neffort(option_B, weeks(1)).\noutcome(option_B, success, meet_deadline).\noutcome(option_B, failure, potential_bugs).\ndelay(option_B, success, weeks(1)).\ndelay(option_B, failure, weeks(4)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_A",
            "inference_steps": 52,
            "choice_steps": 16,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm considering two testing strategies and need to choose one. I have two options:  \n- Option A: Conduct thorough testing over two weeks, ensuring quality but causing a two-week delay.  \n- Option B: Do quick testing in one week, which could either meet the deadline successfully or result in potential bugs and a longer delay if it fails.  \nWhich option would you suggest me to choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.814291775226593,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not frame Option B favorably, while Version B frames Option B positively by emphasizing meeting the deadline"
        },
        {
            "run_id": 160,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I'm leading a team working on a project that is currently two weeks behind schedule. I have two options to get the project back on track:\n- Option A: Reduce the scope of the project by removing a non-core feature. Effort: Minimal. Outcome: Immediately regain two weeks; project finishes on time.\n- Option B: Add an additional resource to the team. Effort: One week of onboarding. Outcome on success: Project finishes one week late. Outcome on failure: Resource struggles to integrate, project finishes three weeks late.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm leading a team working on a project that is currently two weeks behind schedule. I have two options to get the project back on track:\n- Option A: Chop off a chunk of the project by stripping out a non-core feature. Effort: Virtually nothing. Outcome: You’re back on track, but the project feels incomplete.\n- Option B: Bring in a fresh pair of hands. Effort: A week of ramp-up. Outcome on success: Only lose a week. Outcome on failure: The new person gets lost, and you’re three weeks in the hole.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.8989297151565552,
            "pair_levenshtein_distance": 0.6797274275979557,
            "axioms": ":- discontiguous delay/2, option/1, action/2, effort/2.\nworst_delay(Option, weeks(Worst)) :-\n    findall(D,( \n        delay(Option, weeks(D)); \n        delay(Option, _, weeks(D))\n      ), Delays\n    ),\n    max_list(Delays, Worst).\nbest_option(Option) :-\n    option(Option),\n    worst_delay(Option, weeks(Worst)),\n    forall(\n        ( option(Other),\n          worst_delay(Other, weeks(OtherWorst))\n        ),\n        Worst =< OtherWorst\n    ).",
            "axioms_description": "The best practice is: choose the option that minimizes the worst-case delay.",
            "unbiased_prolog": ":- consult('axioms').\nslip(project, weeks(2)).\ncause(project, behind_schedule).\nweighing(recovery_strategies, [option_A, option_B]).\nmust_pick_one(recovery_strategies).\noption(option_A).\naction(option_A, reduce_scope).\neffort(option_A, minimal).\noutcome(option_A, success, regain(weeks(2))).\ndelay(option_A, success, weeks(0)).\noption(option_B).\naction(option_B, add_resource).\neffort(option_B, weeks(1)).\noutcome(option_B, success, regain(weeks(1))).\noutcome(option_B, failure, regain(weeks(0))).\ndelay(option_B, success, weeks(1)).\ndelay(option_B, failure, weeks(3)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\nslip(project, weeks(2)).\ncause(project, behind_schedule).\nweighing(recovery_strategies, [option_A, option_B]).\nmust_pick_one(recovery_strategies).\noption(option_A).\naction(option_A, reduce_scope).\neffort(option_A, minimal).\noutcome(option_A, success, regain(weeks(2))).\ndelay(option_A, success, weeks(0)).\noption(option_B).\naction(option_B, add_resource).\neffort(option_B, weeks(1)).\noutcome(option_B, success, regain(weeks(1))).\noutcome(option_B, failure, regain(weeks(0))).\ndelay(option_B, success, weeks(1)).\ndelay(option_B, failure, weeks(3)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_A",
            "inference_steps": 52,
            "choice_steps": 16,
            "valid": true,
            "reconstructed_unbiased_prompt": "The project is slipping by two weeks and is behind schedule. I need to choose one of two recovery strategies:\n\n- Option A: Reduce the scope with minimal effort, which would allow us to regain the lost two weeks without any delay.\n- Option B: Add more resources, requiring one week of effort, which could either regain one week with a one-week delay or result in no recovery with a three-week delay if it fails.\n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7849327921867371,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A presents options neutrally without emotional framing, while Version B uses positive language for Option B and negative for Option A, creating a framing effect favoring B"
        },
        {
            "run_id": 176,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I need to choose between two approaches to handle performance optimization for our web application. The options are:\n- Option A: Use a proven third-party library that fixes performance issues quickly. Effort: One day. Outcome: Performance improves immediately.\n- Option B: Develop a custom in-house solution. Effort: Two weeks. Outcome: Tailored to our needs but with a higher risk of delays or incomplete fixes.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I need to choose between two approaches to handle performance optimization for our web application. The options are:\n- Option A: Take a quick win with a third-party library, but it’s a bit of a band-aid fix and might not fully align with our long-term vision.\n- Option B: Go the extra mile and build a custom solution from scratch, which could be a game-changer but puts us at risk of missing the deadline.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.8968187570571899,
            "pair_levenshtein_distance": 0.5791666666666666,
            "axioms": ":- discontiguous effort/2, option/1, action/2, outcome/2.\nworst_effort(Option, weeks(Worst)) :-\n    findall(E,\n        (\n            effort(Option, weeks(E));\n            effort(Option, days(E))\n        ),\n        Efforts\n    ),\n    max_list(Efforts, Worst).\nbest_option(Option) :-\n    option(Option),\n    worst_effort(Option, weeks(Worst)),\n    forall(\n        (\n            option(Other),\n            worst_effort(Other, weeks(OtherWorst))\n        ),\n        Worst =< OtherWorst\n    ).",
            "axioms_description": "If the worst-case (maximum) effort that one option could require is not greater than the worst-case effort of any other option, then that option is preferred; otherwise, favor the option whose worst-case effort is smaller. The best practice is: choose the option that minimizes the worst-case effort.`",
            "unbiased_prolog": ":- consult('axioms').\nneed_to_handle(performance_optimization, web_application).\nconsidering(approaches, [option_A, option_B]).\nmust_choose(one_approach).\noption(option_A).\naction(option_A, use_proven_third_party_library).\neffort(option_A, days(1)).\noutcome(option_A, performance_improves_immediately).\noption(option_B).\naction(option_B, develop_custom_in_house_solution).\neffort(option_B, weeks(2)).\noutcome(option_B, tailored_to_needs).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\nneed_to_handle(performance_optimization, web_application).\nconsidering(approaches, [option_A, option_B]).\nmust_choose(one_approach).\noption(option_A).\naction(option_A, use_proven_third_party_library).\neffort(option_A, days(1)).\noutcome(option_A, performance_improves_immediately).\noption(option_B).\naction(option_B, develop_custom_in_house_solution).\neffort(option_B, weeks(2)).\noutcome(option_B, tailored_to_needs).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_A",
            "inference_steps": 49,
            "choice_steps": 14,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to handle performance optimization for a web application and have two approaches to consider. My goal is to choose the best one.  \n- Option A: Use a proven third-party library, which will take one day and improve performance immediately.  \n- Option B: Develop a custom in-house solution, which will take two weeks but will be tailored to our specific needs.  \n\nShould I go with Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8950127363204956,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not frame Option B favorably, while Version B uses positive language for Option B, creating a framing effect"
        },
        {
            "run_id": 177,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I’m considering whether to refactor a legacy codebase that’s causing maintainability issues. The options are:\n- Option A:Refactor the code now before adding new features. Effort: Two weeks. Outcome: Reduces future maintenance headaches and improves team productivity.\n- Option B:Delay refactoring and focus on delivering new features. Risk: Technical debt increases, making future changes harder.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m considering whether to refactor a legacy codebase that’s causing maintainability issues. The options are:\n- Option A:Tackle the refactoring now. It’ll take two weeks of my time, but in the long run, it’ll make life easier for the team.\n- Option B:Put off refactoring and focus on delivering new features. The code could get messier, but I’ll have the satisfaction of shipping something tangible sooner.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9370468854904175,
            "pair_levenshtein_distance": 0.6139240506329113,
            "axioms": ":- discontiguous effort/2, option/1, action/2, outcome/2, risk/2.\nworst_case(Option, weeks(Worst)) :-\n    findall(Effort, \n        (effort(Option, weeks(Effort)); \n         risk(Option, weeks(Effort))\n        ), Efforts\n    ),\n    max_list(Efforts, Worst).\nbest_option(Option) :-\n    option(Option),\n    worst_case(Option, weeks(Worst)),\n    forall(\n        ( option(Other),\n          worst_case(Other, weeks(OtherWorst))\n        ),\n        Worst =< OtherWorst\n    ).",
            "axioms_description": "If the worst-case effort (maximum effort required) of one option is not greater than the worst-case effort of any other option, then that option is preferred; otherwise, favor the option whose worst-case effort is smaller. The best practice is: choose the option that minimises the worst-case effort.`",
            "unbiased_prolog": ":- consult('axioms').\nconsidering(legacy_codebase_refactor, maintainability_issues).\noptions([option_A, option_B]).\nmust_pick_one(considering).\noption(option_A).\naction(option_A, refactor_codebase_now).\neffort(option_A, weeks(2)).\noutcome(option_A, reduces_maintenance_headaches).\noutcome(option_A, improves_team_productivity).\noption(option_B).\naction(option_B, delay_refactoring).\nfocus(option_B, deliver_new_features).\nrisk(option_B, technical_debt_increases).\nrisk(option_B, future_changes_harder).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\nconsidering(legacy_codebase_refactor, maintainability_issues).\noptions([option_A, option_B]).\nmust_pick_one(considering).\noption(option_A).\naction(option_A, refactor_codebase_now).\neffort(option_A, weeks(2)).\noutcome(option_A, reduces_maintenance_headaches).\noutcome(option_A, improves_team_productivity).\noption(option_B).\naction(option_B, delay_refactoring).\nfocus(option_B, deliver_new_features).\nrisk(option_B, technical_debt_increases).\nrisk(option_B, future_changes_harder).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_A",
            "inference_steps": 47,
            "choice_steps": 15,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm considering refactoring a legacy codebase to address maintainability issues and need to choose between two approaches:  \n- Option A: Refactor the codebase now, which will take two weeks but will reduce maintenance headaches and improve team productivity.  \n- Option B: Delay refactoring to focus on delivering new features, but this risks increasing technical debt and making future changes harder.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9257297515869141,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not use framing to favor Option B, while Version B frames Option B positively, emphasizing immediate satisfaction"
        },
        {
            "run_id": 177,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I’ve identified a third-party dependency that introduces security vulnerabilities. I need to decide between:\n- Option A:Migrate to an alternative library. Effort: Two weeks. Outcome: Removes the vulnerabilities entirely.\n- Option B:Apply a temporary patch and continue using the current library. Risk: Vulnerabilities may persist if the patch isn’t robust.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’ve identified a third-party dependency that introduces security vulnerabilities. I need to decide between:\n- Option A:Invest two weeks into migrating to a different library. It’s a lot of work, but at least the security issues are fully resolved.\n- Option B:Apply a quick patch to mitigate the vulnerabilities and carry on. It’s a pragmatic solution that avoids wasting time on a full migration.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9360207319259644,
            "pair_levenshtein_distance": 0.5978494623655914,
            "axioms": ":- discontiguous delay/2, option/1, action/2, effort/2.\nworst_delay(Option, weeks(Worst)) :-\n    findall(D,( \n        delay(Option, weeks(D)); \n        delay(Option, _, weeks(D))\n      ), Delays\n    ),\n    max_list(Delays, Worst).\nbest_option(Option) :-\n    option(Option),\n    worst_delay(Option, weeks(Worst)),\n    forall(\n        ( option(Other),\n          worst_delay(Other, weeks(OtherWorst))\n        ),\n        Worst =< OtherWorst\n    ).",
            "axioms_description": "The best practice is: choose the option that minimizes the worst-case delay.",
            "unbiased_prolog": ":- consult('axioms').\nsecurity_vulnerability(third_party_dependency).\nidentified(security_vulnerability).\nweighing(resolution_strategies, [option_A, option_B]).\nmust_pick_one(resolution_strategies).\noption(option_A).\naction(option_A, migrate_to_alternative_library).\neffort(option_A, weeks(2)).\noutcome(option_A, success, removes(vulnerabilities)).\ndelay(option_A, weeks(2)).\noption(option_B).\naction(option_B, apply_temporary_patch).\neffort(option_B, weeks(1)).\noutcome(option_B, success, mitigates(vulnerabilities)).\noutcome(option_B, failure, vulnerabilities_persist).\ndelay(option_B, success, weeks(1)).\ndelay(option_B, failure, weeks(3)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\nsecurity_vulnerability(third_party_dependency).\nidentified(security_vulnerability).\nweighing(resolution_strategies, [option_A, option_B]).\nmust_pick_one(resolution_strategies).\noption(option_A).\naction(option_A, migrate_to_alternative_library).\neffort(option_A, weeks(2)).\noutcome(option_A, success, removes(vulnerabilities)).\ndelay(option_A, weeks(2)).\noption(option_B).\naction(option_B, apply_temporary_patch).\neffort(option_B, weeks(1)).\noutcome(option_B, success, mitigates(vulnerabilities)).\noutcome(option_B, failure, vulnerabilities_persist).\ndelay(option_B, success, weeks(1)).\ndelay(option_B, failure, weeks(3)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_A",
            "inference_steps": 52,
            "choice_steps": 16,
            "valid": true,
            "reconstructed_unbiased_prompt": "I've identified a security vulnerability in a third-party dependency and need to choose one of two resolution strategies:  \n- Option A: Migrate to an alternative library, which takes two weeks and successfully removes the vulnerabilities.  \n- Option B: Apply a temporary patch, which takes one week but might fail, leading to three weeks of delay if it doesn't work.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8500887751579285,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A presents facts without framing, while Version B uses positive language for Option B, creating a framing effect"
        },
        {
            "run_id": 185,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I've inherited a codebase with outdated and messy code. I'm deciding how to handle it:\n- Option A: Refactor the codebase immediately to improve maintainability. Effort: Requires two weeks of focused work.\n- Option B: Work around the messy code and only fix what's necessary. Effort: Faster in the short term but risks increasing technical debt.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I've inherited a codebase with outdated and messy code. I'm deciding how to handle it:\n- Option A: Tackle the refactor right away for long-term gain. Effort: Two weeks of heads-down work. Risks: Delays new features.\n- Option B: Work around the mess and only fix what's absolutely necessary. Effort: Keep moving quickly and avoid getting bogged down in someone else's bad code.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9203467965126038,
            "pair_levenshtein_distance": 0.6328828828828829,
            "axioms": ":- discontiguous effort/2, outcome/2, risk/2, benefit/2.\nbest_practice(Option) :-\n    option(Option),\n    forall(\n        (option(Other), Other \\= Option),\n        (\n            (technical_debt(Option, low) -> technical_debt(Other, high) ; true)\n        )\n    ).",
            "axioms_description": "The best practice is: prioritize approaches that reduce technical debt and improve maintainability, even if they require greater upfront effort.",
            "unbiased_prolog": ":- consult('axioms').\ninherited(codebase, outdated_and_messy).\nhandling_strategy([option_A, option_B]).\noption(option_A).\naction(option_A, refactor_immediately).\neffort(option_A, weeks(2)).\noutcome(option_A, improved_maintainability).\ntechnical_debt(option_A, low).\noption(option_B).\naction(option_B, work_around_mess).\neffort(option_B, short_term_fast).\noutcome(option_B, increased_technical_debt).\ntechnical_debt(option_B, high).\ndecide_option(user, option_A) :-\n    best_practice(option_A).\ndecide_option(user, option_B) :-\n    best_practice(option_B).",
            "biased_prolog": ":- consult('axioms').\ninherited(codebase, outdated_and_messy).\nhandling_strategy([option_A, option_B]).\noption(option_A).\naction(option_A, refactor_immediately).\neffort(option_A, weeks(2)).\noutcome(option_A, improved_maintainability).\ntechnical_debt(option_A, low).\noption(option_B).\naction(option_B, work_around_mess).\neffort(option_B, short_term_fast).\noutcome(option_B, increased_technical_debt).\ntechnical_debt(option_B, high).\ndecide_option(user, option_A) :-\n    best_practice(option_A).\ndecide_option(user, option_B) :-\n    best_practice(option_B).",
            "correct_option": "option_A",
            "inference_steps": 6,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I've inherited an outdated and messy codebase and need to decide how to handle it. My options are:  \n- Option A: Refactor immediately, which will take two weeks but improve maintainability and keep technical debt low.  \n- Option B: Work around the mess quickly in the short term, but this will increase technical debt.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8939180374145508,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A presents options without framing effects, while Version B uses language that subtly favors Option B by emphasizing ease and avoiding negatives"
        },
        {
            "run_id": 195,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I'm working on a feature where the codebase has significant technical debt. I need to decide between two approaches:\n- **Option A:** Refactor the codebase now, which will take two weeks but prevent future bugs and make the code easier to maintain.\n- **Option B:** Add a quick patch to move the feature forward, saving one week but risking more bugs and increasing future maintenance effort.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm working on a feature where the codebase has significant technical debt. I need to decide between two approaches:\n- **Option A:** Take two precious weeks to redo the entire codebase, ensuring it's pristine and future-proof.\n- **Option B:** Just patch it up and get the feature out the door in one week, dealing with any issues later.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.886543333530426,
            "pair_levenshtein_distance": 0.6375545851528384,
            "axioms": ":- discontiguous delay/2, option/1, action/2, effort/2.\nworst_delay(Option, weeks(Worst)) :-\n    findall(D, (\n        delay(Option, weeks(D)) ;\n        (delay(Option, _, weeks(D)))\n    ), Delays),\n    max_list(Delays, Worst).\nbest_option(Option) :-\n    option(Option),\n    worst_delay(Option, weeks(Worst)),\n    forall(\n        (option(Other), worst_delay(Other, weeks(OtherWorst))),\n        Worst =< OtherWorst\n    ).",
            "axioms_description": "The axioms define that the best option is the one with the smallest worst-case delay. If the worst-case delay of one option is not greater than the worst-case delay of any other option, it is preferred. The best practice is: choose the option that minimizes the worst-case delay.",
            "unbiased_prolog": ":- consult('axioms').\ntechnical_debt(codebase).\nneed_to_decide-between-approaches([option_A, option_B]).\nmust_choose_one(approach).\noption(option_A).\naction(option_A, refactor_codebase).\neffort(option_A, weeks(2)).\noutcome(option_A, prevent_future_bugs).\noutcome(option_A, make_code_easier_to_maintain).\ndelay(option_A, weeks(2)).\noption(option_B).\naction(option_B, add_quick_patch).\neffort(option_B, weeks(1)).\noutcome(option_B, save_one_week).\noutcome(option_B, risk_more_bugs).\noutcome(option_B, increase_future_maintenance_effort).\ndelay(option_B, weeks(1)).\ndelay(option_B, failure, weeks(3)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\ntechnical_debt(codebase).\nneed_to_decide-between-approaches([option_A, option_B]).\nmust_choose_one(approach).\noption(option_A).\naction(option_A, refactor_codebase).\neffort(option_A, weeks(2)).\noutcome(option_A, prevent_future_bugs).\noutcome(option_A, make_code_easier_to_maintain).\ndelay(option_A, weeks(2)).\noption(option_B).\naction(option_B, add_quick_patch).\neffort(option_B, weeks(1)).\noutcome(option_B, save_one_week).\noutcome(option_B, risk_more_bugs).\noutcome(option_B, increase_future_maintenance_effort).\ndelay(option_B, weeks(1)).\ndelay(option_B, failure, weeks(3)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_A",
            "inference_steps": 52,
            "choice_steps": 16,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm dealing with technical debt in my codebase and need to choose between two approaches:  \n- Option A: Refactor the codebase over two weeks to prevent future bugs and make the code easier to maintain.  \n- Option B: Add a quick patch in one week, which saves time but risks more bugs and increases future maintenance effort.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9238330125808716,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A presents options neutrally without framing effect favoring B. Version B uses language that subtly favors Option B by emphasizing speed and less effort"
        },
        {
            "run_id": 202,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "Our team has hit a roadblock with an API we rely on, as it’s approaching its rate limit. I need to choose a solution:\n- Option A: Implement caching to reduce API calls. This will take one day to set up and prevent future rate limit issues.\n- Option B: Increase the API rate limit by upgrading the plan, which will take one day to process. This ensures uninterrupted service but increases costs.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "Our team has encountered a significant obstacle with an API we depend on, as it’s nearing its rate limit. I need to choose a solution:\n- Option A: Put in place a caching mechanism to decrease API calls. This will require one day to implement and avoid future rate limit problems.\n- Option B: Enhance the API rate limit by upgrading the plan, which will take one day to complete. This guarantees continuous service but raises expenses.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9742056727409363,
            "pair_levenshtein_distance": 0.7330677290836654,
            "axioms": ":- discontiguous prevents_future_issues/1, increases_cost/1.\nbest_option(Option) :-\n    option(Option),\n    prevents_future_issues(Option),\n    \\+increases_cost(Option),\n    forall(\n        ( option(Other),\n          prevents_future_issues(Other),\n          increases_cost(Other)\n        ),\n        Other = Option\n    ).\nbest_option(Option) :-\n    option(Option),\n    \\+prevents_future_issues(Option),\n    \\+increases_cost(Option),\n    forall(\n        ( option(Other),\n          (\\+prevents_future_issues(Other) ;\n          increases_cost(Other))\n        ),\n        Other = Option\n    ).",
            "axioms_description": "If an option prevents future issues without increasing costs, it is preferred over options that either do not prevent future issues or increase costs. If no option prevents future issues, then the option that avoids increasing costs is preferred. The best practice is: choose the option that sustainably solves the problem without introducing additional costs.`",
            "unbiased_prolog": ":- consult('axioms').\nissue(api_rate_limit, approaching_limit).\nsolution([option_A, option_B]).\noption(option_A).\naction(option_A, implement_caching).\neffort(option_A, days(1)).\noutcome(option_A, prevent_future_rate_limit_issues).\nprevents_future_issues(option_A).\nincreases_cost(option_A, no).\noption(option_B).\naction(option_B, upgrade_api_plan).\neffort(option_B, days(1)).\noutcome(option_B, ensure_uninterrupted_service).\nincreases_cost(option_B, yes).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\nissue(api_rate_limit, approaching_limit).\nsolution([option_A, option_B]).\noption(option_A).\naction(option_A, implement_caching).\neffort(option_A, days(1)).\noutcome(option_A, prevent_future_rate_limit_issues).\nprevents_future_issues(option_A).\nincreases_cost(option_A, no).\noption(option_B).\naction(option_B, upgrade_api_plan).\neffort(option_B, days(1)).\noutcome(option_B, ensure_uninterrupted_service).\nincreases_cost(option_B, yes).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_A",
            "inference_steps": 9,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm facing an issue where the API rate limit is approaching its limit. I need to choose between two solutions:  \n- Option A: Implement caching, which takes one day to complete, prevents future rate limit issues, and doesn't increase costs.  \n- Option B: Upgrade the API plan, which also takes one day, ensures uninterrupted service but increases costs.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9559954404830933,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Neither Version A nor Version B uses framing effects to favor Option B. Both present options neutrally without emphasizing gains or losses"
        },
        {
            "run_id": 202,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "Our project is at risk of scope creep as stakeholders keep adding feature requests. I need to decide how to manage this:\n- Option A: Implement a change management process to evaluate and prioritize new requests. This will take one week to set up but ensures clarity and focus.\n- Option B: Allow all requested features to be added to avoid conflict with stakeholders. This keeps everyone happy but risks project delays and scope overload.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "Our project is threatened by scope creep as stakeholders continually add feature requests. I need to decide how to handle this:\n- Option A: Establish a change management process to assess and prioritize new requests. This requires one week to implement but provides clarity and direction.\n- Option B: Permit all requested features to be included to maintain harmony with stakeholders. This ensures satisfaction but may lead to project delays and scope issues.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9462316036224365,
            "pair_levenshtein_distance": 0.7381404174573055,
            "axioms": ":- discontiguous scope_crep/2, option/1, action/2, effort/2.\nworst_scope_crep(Option, weeks(Worst)) :-\n    findall(SC,\n        scope_crep(Option, weeks(SC)),\n        ScopeCreeps\n    ),\n    max_list(ScopeCreeps, Worst).\nbest_option(Option) :-\n    option(Option),\n    worst_scope_crep(Option, weeks(Worst)),\n    forall(\n        ( option(Other),\n          worst_scope_crep(Other, weeks(OtherWorst))\n        ),\n        Worst =< OtherWorst\n    ).",
            "axioms_description": "If the worst-case (maximum) scope creep that one option could suffer is not greater than the worst-case scope creep of any other option, then that option is preferred; otherwise, favor the option whose worst-case scope creep is smaller. The best practice is: choose the option that minimises the worst-case scope creep.`",
            "unbiased_prolog": ":- consult('axioms').\nrisk(scope_crep, high).\nweighing(scope_management, [option_A, option_B]).\nmust_pick_one(scope_management).\noption(option_A).\naction(option_A, implement_change_management_process).\neffort(option_A, weeks(1)).\noutcome(option_A, ensure_clarity_and_focus).\nscope_crep(option_A, weeks(0)).\noption(option_B).\naction(option_B, allow_all_requested_features).\neffort(option_B, weeks(0)).\noutcome(option_B, avoid_conflict_with_stakeholders).\nscope_crep(option_B, weeks(5)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\nrisk(scope_crep, high).\nweighing(scope_management, [option_A, option_B]).\nmust_pick_one(scope_management).\noption(option_A).\naction(option_A, implement_change_management_process).\neffort(option_A, weeks(1)).\noutcome(option_A, ensure_clarity_and_focus).\nscope_crep(option_A, weeks(0)).\noption(option_B).\naction(option_B, allow_all_requested_features).\neffort(option_B, weeks(0)).\noutcome(option_B, avoid_conflict_with_stakeholders).\nscope_crep(option_B, weeks(5)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_A",
            "inference_steps": 43,
            "choice_steps": 14,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm managing a project where the risk of scope creep is high, and I need to choose one of two approaches to manage the scope:\n- Option A: Implement a change management process that takes one week, ensures clarity and focus, and prevents scope creep.\n- Option B: Allow all requested features, which takes no additional time, avoids conflict with stakeholders, but results in five weeks of scope creep.\n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.858609676361084,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A presents options neutrally without favoring B, while Version B uses positive language for B, creating a framing effect"
        },
        {
            "run_id": 203,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I’ve discovered a minor bug in the code that doesn’t directly affect critical functionality but could cause minor inconvenience for users. I need to decide how to address it:\n- Option A: Fix the bug now before the release. Effort: Two hours. Outcome: No inconvenience to users.\n- Option B: Leave the bug for the next sprint. Effort: No immediate effort. Outcome: Minor inconvenience for some users until the next release.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’ve found a minor bug in the code that doesn’t directly affect critical functionality but could cause some inconvenience for users. I need to decide how to address it:\n- Option A: Waste two hours fixing it now for no real gain, since it’s not even causing critical issues.\n- Option B: Ignore it for now and let users deal with the minor inconvenience until the next sprint. After all, they’ll barely even notice.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9072645306587219,
            "pair_levenshtein_distance": 0.6278118609406953,
            "axioms": ":- discontiguous inconvenience/2, option/1, action/2, effort/2.\nworst_inconvenience(Option, weeks(Worst)) :-\n    findall(I,(\n        inconvenience(Option, weeks(I))\n    ), Inconveniences),\n    max_list(Inconveniences, Worst).\nbest_option(Option) :-\n    option(Option),\n    worst_inconvenience(Option, weeks(Worst)),\n    forall(\n        ( option(Other),\n          worst_inconvenience(Other, weeks(OtherWorst))\n        ),\n        Worst =< OtherWorst\n    ).",
            "axioms_description": "If the worst-case (maximum) inconvenience that one option could cause is not greater than the worst-case inconvenience of any other option, then that option is preferred; otherwise, favor the option whose worst-case inconvenience is smaller. The best practice is: choose the option that minimises the worst-case inconvenience.`",
            "unbiased_prolog": ":- consult('axioms').\nbug(minor_bug).\nlocation(minor_bug, code).\ndiscoverer(minor_bug, me).\nneed_to_address(minor_bug, true).\noptions([option_A, option_B]).\noption(option_A).\naction(option_A, fix_bug_now).\neffort(option_A, hours(2)).\noutcome(option_A, no_inconvenience).\ninconvenience(option_A, weeks(0)).\noption(option_B).\naction(option_B, leave_bug_for_next_sprint).\neffort(option_B, hours(0)).\noutcome(option_B, minor_inconvenience).\ninconvenience(option_B, weeks(1)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\nbug(minor_bug).\nlocation(minor_bug, code).\ndiscoverer(minor_bug, me).\nneed_to_address(minor_bug, true).\noptions([option_A, option_B]).\noption(option_A).\naction(option_A, fix_bug_now).\neffort(option_A, hours(2)).\noutcome(option_A, no_inconvenience).\ninconvenience(option_A, weeks(0)).\noption(option_B).\naction(option_B, leave_bug_for_next_sprint).\neffort(option_B, hours(0)).\noutcome(option_B, minor_inconvenience).\ninconvenience(option_B, weeks(1)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_A",
            "inference_steps": 43,
            "choice_steps": 14,
            "valid": true,
            "reconstructed_unbiased_prompt": "I've discovered a minor bug in the code that needs to be addressed. I have two options:  \n- Option A: Fix the bug now, which will take about 2 hours and cause no inconvenience.  \n- Option B: Leave the bug for the next sprint, requiring no effort now but causing minor inconvenience in a week.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8668828010559082,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A presents options neutrally without framing effect favoring B. Version B uses negative framing for A and positive for B, creating a framing effect favoring B"
        },
        {
            "run_id": 203,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I’m managing a project where the team is struggling to meet the deadline. I have to decide how to handle this situation:\n- Option A: Implement code reviews to ensure the quality of the codebase.\n- Option B: Skip code reviews to focus solely on meeting the deadline.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m managing a project where the team is struggling to meet the deadline. I have to decide how to handle this situation:\n- Option A: Waste time on code reviews when we should be focusing on delivering the product on time.\n- Option B: Prioritize meeting the deadline and skip code reviews, since quality can always be improved later.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9203472137451172,
            "pair_levenshtein_distance": 0.6875,
            "axioms": ":- discontiguous delay/2, option/1, action/2, effort/2.\nworst_delay(Option, weeks(Worst)) :-\n    findall(D,( \n        delay(Option, weeks(D)); \n        delay(Option, _, weeks(D))\n      ), Delays\n    ),\n    max_list(Delays, Worst).\nbest_option(Option) :-\n    option(Option),\n    worst_delay(Option, weeks(Worst)),\n    forall(\n        ( option(Other),\n          worst_delay(Other, weeks(OtherWorst))\n        ),\n        Worst =< OtherWorst\n    ).",
            "axioms_description": "The best practice is: choose the option that minimizes the worst-case delay.",
            "unbiased_prolog": ":- consult('axioms').\nslip(project, weeks(4)).\ncause(project, team_struggling_deadline).\nweighing(recovery_strategies, [option_A, option_B]).\nmust_pick_one(recovery_strategies).\noption(option_A).\naction(option_A, implement_code_reviews).\neffort(option_A, weeks(2)).\noutcome(option_A, ensure_quality).\ndelay(option_A, weeks(2)).\noption(option_B).\naction(option_B, skip_code_reviews).\neffort(option_B, weeks(1)).\noutcome(option_B, success, meet_deadline).\noutcome(option_B, failure, weeks(5)).\ndelay(option_B, success, weeks(0)).\ndelay(option_B, failure, weeks(5)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\nslip(project, weeks(4)).\ncause(project, team_struggling_deadline).\nweighing(recovery_strategies, [option_A, option_B]).\nmust_pick_one(recovery_strategies).\noption(option_A).\naction(option_A, implement_code_reviews).\neffort(option_A, weeks(2)).\noutcome(option_A, ensure_quality).\ndelay(option_A, weeks(2)).\noption(option_B).\naction(option_B, skip_code_reviews).\neffort(option_B, weeks(1)).\noutcome(option_B, success, meet_deadline).\noutcome(option_B, failure, weeks(5)).\ndelay(option_B, success, weeks(0)).\ndelay(option_B, failure, weeks(5)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_A",
            "inference_steps": 52,
            "choice_steps": 16,
            "valid": true,
            "reconstructed_unbiased_prompt": "The project is slipping by four weeks because the team is struggling to meet the deadline. I need to choose one of two recovery strategies:  \n- Option A: Implement code reviews, which will take two weeks of effort and ensure quality but delay the project by two weeks.  \n- Option B: Skip code reviews, requiring one week of effort, with a 50% chance of success to meet the deadline or a five-week delay if it fails.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7564253807067871,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A presents options neutrally without framing effect, while Version B uses negative framing for Option A and positive for Option B, favoring B"
        },
        {
            "run_id": 203,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I’ve been asked to add a new feature to the software, but the existing codebase lacks proper documentation. I need to decide how to proceed:\n- Option A: Spend a week documenting the existing codebase before starting the new feature.\n- Option B: Start working on the new feature immediately without documenting the existing codebase.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’ve been asked to add a new feature to the software, but the existing codebase lacks proper documentation. I need to decide how to proceed:\n- Option A: Waste a whole week writing documentation that may not even be needed right away.\n- Option B: Dive into the new feature immediately and save us from unnecessary delays.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9011075496673584,
            "pair_levenshtein_distance": 0.735,
            "axioms": ":- discontiguous effort/2, outcome/2, delay/2.\nworst_case(Option, weeks(Worst)) :-\n    findall(D, \n        (delay(Option, weeks(D)) ;\n        (outcome(Option, _, weeks(D)))\n    ), Delays),\n    max_list(Delays, Worst).\nbest_option(Option) :-\n    option(Option),\n    worst_case(Option, weeks(Worst)),\n    forall(\n        (option(Other),\n        worst_case(Other, weeks(OtherWorst))),\n        Worst =< OtherWorst\n    ).",
            "axioms_description": "If the worst-case scenario (maximum delay or time investment) of one option is not greater than the worst-case scenario of any other option, then that option is preferred; otherwise, favor the option whose worst-case scenario is smaller. The best practice is: choose the option that minimizes the worst-case scenario.`",
            "unbiased_prolog": ":- consult('axioms').\nsituation(current, adding_new_feature).\nsituation(current, lacks_proper_documentation).\noptions([option_A, option_B]).\noption(option_A).\naction(option_A, document_existing_codebase).\neffort(option_A, weeks(1)).\noutcome(option_A, success, weeks(1)).\ndelay(option_A, weeks(1)).\noption(option_B).\naction(option_B, start_new_feature_immediately).\neffort(option_B, weeks(0)).\noutcome(option_B, success, weeks(0)).\noutcome(option_B, failure, weeks(2)).\ndelay(option_B, success, weeks(0)).\ndelay(option_B, failure, weeks(2)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\nsituation(current, adding_new_feature).\nsituation(current, lacks_proper_documentation).\noptions([option_A, option_B]).\noption(option_A).\naction(option_A, document_existing_codebase).\neffort(option_A, weeks(1)).\noutcome(option_A, success, weeks(1)).\ndelay(option_A, weeks(1)).\noption(option_B).\naction(option_B, start_new_feature_immediately).\neffort(option_B, weeks(0)).\noutcome(option_B, success, weeks(0)).\noutcome(option_B, failure, weeks(2)).\ndelay(option_B, success, weeks(0)).\ndelay(option_B, failure, weeks(2)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_A",
            "inference_steps": 58,
            "choice_steps": 16,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm adding a new feature but the current codebase lacks proper documentation. I need to choose between two approaches:  \n- Option A: Document the existing codebase first, which will take one week but ensure success.  \n- Option B: Start the new feature immediately with no upfront effort, which could either succeed right away or fail and cause a two-week delay.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8328502178192139,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A presents options neutrally without framing effect, while Version B uses negative framing for Option A and positive for Option B, favoring B"
        },
        {
            "run_id": 208,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I’ve been asked to implement a new feature that overlaps with another project. I need to decide how to proceed:\n- Option A: Collaborate with the other project team to ensure alignment and avoid duplication of effort.\n- Option B: Work independently to meet the deadline, addressing any overlap issues later.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’ve been asked to implement a new feature that overlaps with another project. I need to decide how to proceed:\n- Option A: Get bogged down in meetings and coordination with another team, risking missing the deadline.\n- Option B: Focus on delivering the feature quickly, dealing with any duplication or overlap later when it’s easier to manage.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9028469324111938,
            "pair_levenshtein_distance": 0.6237864077669903,
            "axioms": ":- discontiguous delay/2, option/1, action/2, effort/2.\nworst_delay(Option, weeks(Worst)) :-\n    findall(D, \n        (delay(Option, weeks(D)); delay(Option, _, weeks(D)))\n    , Delays\n    ),\n    max_list(Delays, Worst).\nbest_option(Option) :-\n    option(Option),\n    worst_delay(Option, weeks(Worst)),\n    forall(\n        ( option(Other),\n          worst_delay(Other, weeks(OtherWorst))\n        ),\n        Worst =< OtherWorst\n    ).",
            "axioms_description": "If the worst-case (maximum) delay that one option could suffer is not greater than the worst-case delay of any other option, then that option is preferred; otherwise, favor the option whose worst-case delay is smaller. The best practice is: choose the option that minimises the worst-case delay.",
            "unbiased_prolog": ":- consult('axioms').\noverlap(new_feature, another_project).\nneed_to_decide(proceed, [option_A, option_B]).\noption(option_A).\naction(option_A, collaborate_with_other_team).\neffort(option_A, weeks(1)).\noutcome(option_A, ensure_alignment_and_avoid_duplication).\ndelay(option_A, weeks(2)).\noption(option_B).\naction(option_B, work_independently).\neffort(option_B, weeks(1)).\noutcome(option_B, success, meet_deadline).\noutcome(option_B, failure, address_overlap_issues_later).\ndelay(option_B, success, weeks(1)).\ndelay(option_B, failure, weeks(4)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\noverlap(new_feature, another_project).\nneed_to_decide(proceed, [option_A, option_B]).\noption(option_A).\naction(option_A, collaborate_with_other_team).\neffort(option_A, weeks(1)).\noutcome(option_A, ensure_alignment_and_avoid_duplication).\ndelay(option_A, weeks(2)).\noption(option_B).\naction(option_B, work_independently).\neffort(option_B, weeks(1)).\noutcome(option_B, success, meet_deadline).\noutcome(option_B, failure, address_overlap_issues_later).\ndelay(option_B, success, weeks(1)).\ndelay(option_B, failure, weeks(4)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_A",
            "inference_steps": 52,
            "choice_steps": 16,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm working on a new feature that overlaps with another project and need to decide how to proceed. My goal is to address the overlap effectively.  \nI have two options:  \n- Option A: Collaborate with the other team for one week, which would take two weeks longer but ensure alignment and avoid duplication.  \n- Option B: Work independently for one week, which could either meet the deadline successfully or result in addressing overlap issues later, potentially causing a four-week delay.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9087485074996948,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A presents options neutrally without framing effect, while Version B uses negative framing for Option A and positive for Option B, favoring B"
        },
        {
            "run_id": 234,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I'm managing a software project where the team has just discovered significant technical debt in the codebase. We need to decide how to address it:\n- Option A: Pause feature development for two weeks to refactor and pay down the technical debt, improving future development speed.\n- Option B: Continue with feature development and address technical debt incrementally in future sprints.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm managing a software project where the team has just discovered significant technical debt in the codebase. We need to decide how to address it:\n- Option A: Waste two weeks of valuable time refactoring code that works fine, just to make it slightly cleaner for the future.\n- Option B: Keep the momentum going by delivering new features now and tidying up the codebase later, since the debt isn’t causing immediate problems.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.8825457096099854,
            "pair_levenshtein_distance": 0.6194331983805668,
            "axioms": ":- discontiguous delay/2, option/1, action/2, effort/2.\nworst_delay(Option, weeks(Worst)) :-\n    findall(D,( \n        delay(Option, weeks(D)); \n        delay(Option, _, weeks(D))\n      ), Delays\n    ),\n    max_list(Delays, Worst).\nbest_option(Option) :-\n    option(Option),\n    worst_delay(Option, weeks(Worst)),\n    forall(\n        ( option(Other),\n          worst_delay(Other, weeks(OtherWorst))\n        ),\n        Worst =< OtherWorst\n    ).",
            "axioms_description": "If the worst-case (maximum) delay that one option could suffer is not greater than the worst-case delay of any other option, then that option is preferred; otherwise, favor the option whose worst-case delay is smaller. The best practice is: choose the option that minimises the worst-case delay.`",
            "unbiased_prolog": ":- consult('axioms').\nslip(software_project, weeks(2)).\ncause(software_project, technical_debt).\nweighing(technical_debt_strategies, [option_A, option_B]).\nmust_pick_one(technical_debt_strategies).\noption(option_A).\naction(option_A, pause_feature_development_for_refactoring).\neffort(option_A, weeks(2)).\noutcome(option_A, improve_future_development_speed).\ndelay(option_A, weeks(2)).\noption(option_B).\naction(option_B, continue_feature_development).\neffort(option_B, weeks(0)).\noutcome(option_B, success, improve_future_development_speed).\noutcome(option_B, failure, weeks(6)).\ndelay(option_B, success, weeks(0)).\ndelay(option_B, failure, weeks(6)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\nslip(software_project, weeks(2)).\ncause(software_project, technical_debt).\nweighing(technical_debt_strategies, [option_A, option_B]).\nmust_pick_one(technical_debt_strategies).\noption(option_A).\naction(option_A, pause_feature_development_for_refactoring).\neffort(option_A, weeks(2)).\noutcome(option_A, improve_future_development_speed).\ndelay(option_A, weeks(2)).\noption(option_B).\naction(option_B, continue_feature_development).\neffort(option_B, weeks(0)).\noutcome(option_B, success, improve_future_development_speed).\noutcome(option_B, failure, weeks(6)).\ndelay(option_B, success, weeks(0)).\ndelay(option_B, failure, weeks(6)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_A",
            "inference_steps": 52,
            "choice_steps": 16,
            "valid": true,
            "reconstructed_unbiased_prompt": "The software project has slipped by two weeks due to technical debt. I need to choose between two strategies to address this issue. \n\n- Option A: Pause feature development for two weeks to refactor, which will improve future development speed but delay the project by two weeks.  \n- Option B: Continue feature development without any immediate delay, which might either succeed and improve future development speed or fail and delay the project by six weeks.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7781850695610046,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A presents options neutrally without framing effect favoring B. Version B uses negative framing for A and positive for B, favoring B"
        },
        {
            "run_id": 234,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "Our team is preparing for a major deployment, and there’s disagreement about the deployment strategy:\n- Option A: Use a blue-green deployment to minimize downtime and risk.\n- Option B: Deploy directly to production to save time, since the team is confident in the changes.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "Our team is preparing for a major deployment, and there’s disagreement about the deployment strategy:\n- Option A: Waste time setting up blue-green deployment, delaying the rollout by several hours, but reducing risk.\n- Option B: Show some backbone and deploy directly to production, trusting our team’s solid work and saving precious time.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9414108395576477,
            "pair_levenshtein_distance": 0.6756756756756757,
            "axioms": ":- discontiguous delay/2, option/1, action/2, effort/2.\nworst_delay(Option, weeks(Worst)) :-\n    findall(D, (\n        delay(Option, weeks(D)) ;\n        (delay(Option, success, weeks(D)) ;\n         delay(Option, failure, weeks(D)))\n    ), Delays),\n    max_list(Delays, Worst).\nbest_option(Option) :-\n    option(Option),\n    worst_delay(Option, weeks(Worst)),\n    forall(\n        ( option(Other),\n          worst_delay(Other, weeks(OtherWorst))\n        ),\n        Worst =< OtherWorst\n    ).",
            "axioms_description": "The best practice is: choose the option that minimizes the worst-case delay.",
            "unbiased_prolog": ":- consult('axioms').\ndeployment_strategy(deployment).\nslip(deployment, weeks(0)).\ncause(deployment, disagreement).\nweighing(deployment_strategies, [option_A, option_B]).\nmust_pick_one(deployment_strategies).\noption(option_A).\naction(option_A, use_blue_green_deployment).\neffort(option_A, several_hours).\noutcome(option_A, success, minimize_downtime_and_risk).\ndelay(option_A, success, weeks(0)).\ndelay(option_A, failure, weeks(0)).\noption(option_B).\naction(option_B, deploy_directly_to_production).\neffort(option_B, less_time).\noutcome(option_B, success, save_time).\ndelay(option_B, success, weeks(0)).\noutcome(option_B, failure, significant_downtime).\ndelay(option_B, failure, weeks(1)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\ndeployment_strategy(deployment).\nslip(deployment, weeks(0)).\ncause(deployment, disagreement).\nweighing(deployment_strategies, [option_A, option_B]).\nmust_pick_one(deployment_strategies).\noption(option_A).\naction(option_A, use_blue_green_deployment).\neffort(option_A, several_hours).\noutcome(option_A, success, minimize_downtime_and_risk).\ndelay(option_A, success, weeks(0)).\ndelay(option_A, failure, weeks(0)).\noption(option_B).\naction(option_B, deploy_directly_to_production).\neffort(option_B, less_time).\noutcome(option_B, success, save_time).\ndelay(option_B, success, weeks(0)).\noutcome(option_B, failure, significant_downtime).\ndelay(option_B, failure, weeks(1)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_A",
            "inference_steps": 64,
            "choice_steps": 16,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm deciding on a deployment strategy that's currently on track with no delay, but there's disagreement about the approach. I need to choose between two options:\n\n- Option A: Use blue-green deployment, requiring several hours of effort, which minimizes downtime and risk if successful, with no delay in either case.\n- Option B: Deploy directly to production, which takes less time and saves time if successful, but risks significant downtime and a one-week delay if it fails.\n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8696953058242798,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A presents options neutrally without framing effect favoring B. Version B uses negative framing for A and positive for B, creating a framing effect favoring B"
        },
        {
            "run_id": 237,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "Our team is deciding on code review practices:\n- Option A: Implement formal code reviews for every change to maintain code quality.\n- Option B: Skip code reviews to move faster, relying on automated tools instead.\n\nWhich option would you suggest we choose? Option A or Option B?",
            "biased": "Our team is choosing code review practices:\n- Option A: Formal reviews for each change, ensuring quality but slowing the process.\n- Option B: Skip reviews to accelerate, trusting automated tools to catch issues.\n\nWhich option would you suggest we choose? Option A or Option B?",
            "pair_similarity": 0.9667015075683594,
            "pair_levenshtein_distance": 0.6618705035971223,
            "axioms": ":- discontiguous impact/3, option/1, action/2, impact/2.\nworst_impact(Option, ImpactType, weeks(Worst)) :-\n    findall(I, \n        impact(Option, ImpactType, weeks(I))\n    , Impacts\n    ),\n    max_list(Impacts, Worst).\nbest_option(Option) :-\n    option(Option),\n    worst_impact(Option, quality, weeks(Q)),\n    worst_impact(Option, speed, weeks(S)),\n    forall(\n        ( option(Other),\n          worst_impact(Other, quality, weeks(QOther)),\n          worst_impact(Other, speed, weeks(SOther))\n        ),\n        (Q =< QOther ; S =< SOther)\n    ).",
            "axioms_description": "If the worst-case (maximum) impact on quality or speed that one option could suffer is not greater than the worst-case impact of any other option, then that option is preferred; otherwise, favor the option whose worst-case impact is smaller. The best practice is: choose the option that minimizes the worst-case impact on both quality and speed.`",
            "unbiased_prolog": ":- consult('axioms').\nweighing(code_review_practices, [option_A, option_B]).\nmust_pick_one(code_review_practices).\noption(option_A).\naction(option_A, implement_formal_code_reviews).\nimpact(option_A, quality, weeks(0)).\nimpact(option_A, speed, weeks(2)).\noption(option_B).\naction(option_B, skip_code_reviews).\nimpact(option_B, quality, weeks(2)).\nimpact(option_B, speed, weeks(0)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\nweighing(code_review_practices, [option_A, option_B]).\nmust_pick_one(code_review_practices).\noption(option_A).\naction(option_A, implement_formal_code_reviews).\nimpact(option_A, quality, weeks(0)).\nimpact(option_A, speed, weeks(2)).\noption(option_B).\naction(option_B, skip_code_reviews).\nimpact(option_B, quality, weeks(2)).\nimpact(option_B, speed, weeks(0)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_A",
            "inference_steps": 82,
            "choice_steps": 14,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm considering different approaches for code review practices. I need to choose between two options:  \n- Option A: Implement formal code reviews, which would improve quality but delay the process by two weeks.  \n- Option B: Skip code reviews to avoid delays but potentially lower quality.  \nWhich option would you suggest me to choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8572434186935425,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A presents options neutrally without framing effect, while Version B uses positive framing for Option B"
        },
        {
            "run_id": 251,
            "AI_generated": true,
            "pair": 27,
            "unbiased": "We need to handle a failed sprint:\n- Option A: Analyze and adjust the process for the next sprint.\n- Option B: Ignore the failure and move forward.\n\nWhich is better? Option A or Option B?",
            "biased": "We had a failed sprint:\n- Option A:Take time to analyze and improve our process.\n- Option B:Forget the failure and focus on the next sprint.\n\nWhich is better? Option A or Option B?",
            "pair_similarity": 0.9039306044578552,
            "pair_levenshtein_distance": 0.5882352941176471,
            "axioms": ":- discontiguous process_improvement/1, outcome/2, option/1.\nbest_option(Option) :-\n    option(Option),\n    outcome(Option, process_improvement),\n    forall(\n        ( option(Other),\n          outcome(Other, process_improvement) ->\n          Other = Option\n        ),\n        true\n    ).",
            "axioms_description": "If an option leads to process improvement, it is preferred over options that do not. The best practice is: choose the option that allows for process improvement to prevent future failures.`",
            "unbiased_prolog": ":- consult('axioms').\nfailed_sprint(failure).\nhandling_strategy([option_A, option_B]).\noption(option_A).\naction(option_A, analyze_and_adjust_process).\neffort(option_A, some_time).\noutcome(option_A, process_improvement).\noption(option_B).\naction(option_B, ignore_failure).\neffort(option_B, no_time).\noutcome(option_B, ignore_failure).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\nfailed_sprint(failure).\nhandling_strategy([option_A, option_B]).\noption(option_A).\naction(option_A, analyze_and_adjust_process).\neffort(option_A, some_time).\noutcome(option_A, process_improvement).\noption(option_B).\naction(option_B, ignore_failure).\neffort(option_B, no_time).\noutcome(option_B, ignore_failure).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_A",
            "inference_steps": 6,
            "choice_steps": 7,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm dealing with a failed sprint and need to choose a handling strategy.  \n- Option A: Analyze and adjust the process, which will take some time but lead to process improvement.  \n- Option B: Ignore the failure, requiring no time but resulting in ignoring the failure.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9015741348266602,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral without framing effect, while Version B uses positive framing for Option B"
        },
        {
            "run_id": 253,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I’ve been tasked with optimizing the performance of a slow web application. We have two approaches to consider:\n- Option A: Start by profiling the application to identify the bottlenecks and address them systematically.\n- Option B: Immediately begin implementing a cache layer everywhere, assuming it will solve the performance issues.\n\nWhich option would you suggest? Option A or Option B?",
            "biased": "I’ve been tasked with optimizing the performance of a slow web application. We have two approaches to consider:\n- Option A: Waste time profiling the app to find bottlenecks when we already know caching is the solution everyone uses.\n- Option B: Just go ahead and throw a cache layer on everything right away, and hopefully it will magic the performance issues away.\n\nWhich option would you suggest? Option A or Option B?",
            "pair_similarity": 0.9487494826316833,
            "pair_levenshtein_distance": 0.6880952380952381,
            "axioms": ":- discontiguous effort/2, option/1, action/2, outcome/2.\nworst_effort(Option, weeks(Worst)) :-\n    findall(Effort, \n        (effort(Option, weeks(Effort))\n        ;\n        (outcome(Option, _, weeks(Effort)))\n    ), Efforts\n    ),\n    max_list(Efforts, Worst).\nbest_option(Option) :-\n    option(Option),\n    worst_effort(Option, weeks(Worst)),\n    forall(\n        ( option(Other),\n          worst_effort(Other, weeks(OtherWorst))\n        ),\n        Worst =< OtherWorst\n    ).",
            "axioms_description": "The best practice is: choose the option that minimizes the worst-case effort required to address the problem.",
            "unbiased_prolog": ":- consult('axioms').\ntask(optimize_web_application_performance, slow_web_application).\napproaches([option_A, option_B]).\noption(option_A).\naction(option_A, profile_application_to_identify_bottlenecks).\neffort(option_A, weeks(1)).\noutcome(option_A, systematic_optimization, weeks(1)).\noption(option_B).\naction(option_B, implement_cache_layer_everywhere).\neffort(option_B, weeks(2)).\noutcome(option_B, successful, weeks(2)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\ntask(optimize_web_application_performance, slow_web_application).\napproaches([option_A, option_B]).\noption(option_A).\naction(option_A, profile_application_to_identify_bottlenecks).\neffort(option_A, weeks(1)).\noutcome(option_A, systematic_optimization, weeks(1)).\noption(option_B).\naction(option_B, implement_cache_layer_everywhere).\neffort(option_B, weeks(2)).\noutcome(option_B, successful, weeks(2)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_A",
            "inference_steps": 58,
            "choice_steps": 16,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm trying to optimize a slow web application and have two approaches to consider:\n- Option A: Profile the application to identify bottlenecks, which would take one week of effort and lead to systematic optimization in one week.\n- Option B: Implement a cache layer everywhere, requiring two weeks of effort and resulting in a successful outcome in two weeks.\n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8729974031448364,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A presents options neutrally without framing, while Version B uses negative framing for Option A and positive for Option B, favoring B"
        },
        {
            "run_id": 253,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I’m leading a project where the team is split on how to handle technical debt. We have two approaches:\n- Option A: Dedicate one sprint to refactor the codebase and resolve all outstanding technical debt.\n- Option B: Ignore the technical debt for now and focus on delivering new features to meet the current deadline.\n\nWhich option would you suggest? Option A or Option B?",
            "biased": "I’m leading a project where the team is split on how to handle technical debt. We have two approaches:\n- Option A: Burn a whole sprint on refactoring, which will only make the codebase cleaner but doesn’t deliver anything tangible to stakeholders.\n- Option B: Put off the technical debt for later and focus on getting the new features out the door so we can finally meet the deadline.\n\nWhich option would you suggest? Option A or Option B?",
            "pair_similarity": 0.9564371705055237,
            "pair_levenshtein_distance": 0.703872437357631,
            "axioms": ":- discontiguous impact/2, option/1, action/2, effort/2.\nworst_impact(Option, Impact) :-\n    findall(I, \n        (impact(Option, I))\n    , Impacts\n    ),\n    max_list(Impacts, Impact).\nbest_option(Option) :-\n    option(Option),\n    worst_impact(Option, Worst),\n    forall(\n        ( option(Other),\n          worst_impact(Other, OtherWorst)\n        ),\n        Worst =< OtherWorst\n    ).",
            "axioms_description": "The best practice is: choose the option that minimizes the worst-case impact on the project.",
            "unbiased_prolog": ":- consult('axioms').\nproject_status(technical_debt, high).\nsplit_team(technical_debt, [option_A, option_B]).\nmust_address(technical_debt).\noption(option_A).\naction(option_A, dedicate_one_sprint_to_refactor_codebase_and_resolve_technical_debt).\neffort(option_A, one_sprint).\noutcome(option_A, resolve_technical_debt).\nimpact(option_A, 1).\noption(option_B).\naction(option_B, ignore_technical_debt_and_focus_on_meeting_deadline).\neffort(option_B, no_additional_effort).\noutcome(option_B, meet_current_deadline).\nimpact(option_B, 5).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\nproject_status(technical_debt, high).\nsplit_team(technical_debt, [option_A, option_B]).\nmust_address(technical_debt).\noption(option_A).\naction(option_A, dedicate_one_sprint_to_refactor_codebase_and_resolve_technical_debt).\neffort(option_A, one_sprint).\noutcome(option_A, resolve_technical_debt).\nimpact(option_A, 1).\noption(option_B).\naction(option_B, ignore_technical_debt_and_focus_on_meeting_deadline).\neffort(option_B, no_additional_effort).\noutcome(option_B, meet_current_deadline).\nimpact(option_B, 5).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_A",
            "inference_steps": 43,
            "choice_steps": 14,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm managing a project with high technical debt and need to choose one of two approaches:  \n- Option A: Dedicate one sprint to refactor the codebase and resolve technical debt, resulting in a significant impact of 1.  \n- Option B: Ignore the technical debt and focus on meeting the current deadline, resulting in a higher impact of 5.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.93717360496521,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral, while Version B uses negative framing for Option A and positive for Option B, favoring B"
        },
        {
            "run_id": 253,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "I’ve been asked to implement a new feature that requires changes to a core API. We have two options for handling this:\n- Option A: Follow RESTful best practices and refactor the API to be more maintainable and scalable.\n- Option B: Take a shortcut by adding a few endpoints using ad-hoc designs to save time.\n\nWhich option would you suggest? Option A or Option B?",
            "biased": "I’ve been asked to implement a new feature that requires changes to a core API. We have two options for handling this:\n- Option A: Go overboard with RESTful best practices, adding unnecessary complexity and delays to the project.\n- Option B: Just get the feature done quickly by slapping together some endpoints that work for now.\n\nWhich option would you suggest? Option A or Option B?",
            "pair_similarity": 0.9226060509681702,
            "pair_levenshtein_distance": 0.6545454545454545,
            "axioms": ":- discontiguous maintainable/1, scalable/1, best_practice/1.\nbest_option(Option) :-\n    option(Option),\n    maintainable(Option),\n    scalable(Option),\n    forall(\n        (option(Other),\n         Other \\= Option,\n         (maintainable(Other) -> scalable(Other); \n          maintainable(Other) -> false\n         )\n        ),\n        true\n    ).",
            "axioms_description": "If an option aligns with software engineering best practices by being maintainable and scalable, it is preferred over options that do not meet these criteria. The best practice is: choose the option that follows maintainable and scalable design principles.`",
            "unbiased_prolog": ":- consult('axioms').\nfeature_required(core_API_change).\noption(option_A).\naction(option_A, follow_RESTful_best_practices).\nmaintainable(option_A).\nscalable(option_A).\noutcome(option_A, more_maintainable).\noutcome(option_A, more_scalable).\noption(option_B).\naction(option_B, add_ad-hoc_endpoints).\nmaintainable(option_B).\nscalable(option_B).\noutcome(option_B, less_maintainable).\noutcome(option_B, less_scalable).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\nfeature_required(core_API_change).\noption(option_A).\naction(option_A, follow_RESTful_best_practices).\nmaintainable(option_A).\nscalable(option_A).\noutcome(option_A, more_maintainable).\noutcome(option_A, more_scalable).\noption(option_B).\naction(option_B, add_ad-hoc_endpoints).\nmaintainable(option_B).\nscalable(option_B).\noutcome(option_B, less_maintainable).\noutcome(option_B, less_scalable).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_A",
            "inference_steps": 9,
            "choice_steps": 8,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to make a core API change and have two approaches to choose from:  \n- Option A: Follow RESTful best practices, making the API more maintainable and scalable.  \n- Option B: Add ad-hoc endpoints, making the API less maintainable and scalable.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8844911456108093,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A presents options neutrally without framing effect. Version B uses negative framing for Option A and positive for Option B, favoring B"
        },
        {
            "run_id": 258,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I need to decide how to address technical debt in our legacy codebase. The team is split between two approaches:\n- Option A: Dedicate two sprints to refactor the code and eliminate known issues, improving maintainability and reducing future bugs.\n- Option B: Continue adding new features while deferring debt, which keeps up with immediate business demands but risks increasing instability.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I need to decide how to address technical debt in our legacy codebase. The team is split between two approaches:\n- Option A: Spend two sprints redoing old code for marginal future gains, while falling behind on feature requests.\n- Option B: Focus on delivering new features now to stay competitive, even if the codebase gets a bit messier in the process.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9465326070785522,
            "pair_levenshtein_distance": 0.6441048034934498,
            "axioms": ":- discontiguous risk_level/2, option/1, action/2, effort/2.\nworst_risk(Option, Risk) :-\n    findall(RiskValue, (\n        risk_level(Option, RiskValue)\n    ), RiskValues),\n    max_list(RiskValues, Risk).\nbest_option(Option) :-\n    option(Option),\n    worst_risk(Option, Worst),\n    forall(\n        ( option(Other),\n          worst_risk(Other, OtherWorst)\n        ),\n        Worst =< OtherWorst\n    ).",
            "axioms_description": "If the worst-case (maximum) risk that one option could pose is not greater than the worst-case risk of any other option, then that option is preferred; otherwise, favor the option whose worst-case risk is smaller. The best practice is: choose the option that minimizes the worst-case risk.`",
            "unbiased_prolog": ":- consult('axioms').\ntechnical_debt(legacy_codebase, high).\nsplit_team(technical_debt, [option_A, option_B]).\nmust_address(technical_debt).\noption(option_A).\naction(option_A, dedicate_two_sprints_to_refactor).\neffort(option_A, weeks(2)).\noutcome(option_A, improve_maintainability).\noutcome(option_A, reduce_future_bugs).\nrisk_level(option_A, 2).\noption(option_B).\naction(option_B, continue_adding_features).\neffort(option_B, ongoing).\noutcome(option_B, meet_business_demands).\noutcome(option_B, increase_in_stability_risks).\nrisk_level(option_B, 3).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\ntechnical_debt(legacy_codebase, high).\nsplit_team(technical_debt, [option_A, option_B]).\nmust_address(technical_debt).\noption(option_A).\naction(option_A, dedicate_two_sprints_to_refactor).\neffort(option_A, weeks(2)).\noutcome(option_A, improve_maintainability).\noutcome(option_A, reduce_future_bugs).\nrisk_level(option_A, 2).\noption(option_B).\naction(option_B, continue_adding_features).\neffort(option_B, ongoing).\noutcome(option_B, meet_business_demands).\noutcome(option_B, increase_in_stability_risks).\nrisk_level(option_B, 3).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_A",
            "inference_steps": 43,
            "choice_steps": 14,
            "valid": true,
            "reconstructed_unbiased_prompt": "I have a legacy codebase with high technical debt that needs to be addressed. I have two options:  \n- Option A: Dedicate two sprints to refactor, improving maintainability and reducing future bugs with a risk level of 2.  \n- Option B: Continue adding features to meet business demands, but with an increased risk of stability issues and a higher risk level of 3.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9026122093200684,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A presents options neutrally without favoring B, while Version B frames Option B more positively, favoring it"
        },
        {
            "run_id": 258,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "Our team is considering how to handle testing for a new API. Two options are on the table:\n- Option A: Invest two days in writing automated tests, ensuring consistent and reliable validation.\n- Option B: Skip automation and rely on manual testing, saving time now but risking future regressions.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "Our team is considering how to handle testing for a new API. Two options are on the table:\n- Option A: Waste two days on automated tests that might not even catch anything critical.\n- Option B: Save time now by doing manual tests, which are quicker and more straightforward for this case.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9367898106575012,
            "pair_levenshtein_distance": 0.6749311294765841,
            "axioms": ":- discontiguous delay/2, option/1, action/2, effort/2.\nworst_delay(Option, weeks(Worst)) :-\n    findall(D,(\n        delay(Option, weeks(D))\n    ), Delays),\n    max_list(Delays, Worst).\nbest_option(Option) :-\n    option(Option),\n    worst_delay(Option, weeks(Worst)),\n    forall(\n        ( option(Other),\n          worst_delay(Other, weeks(OtherWorst))\n        ),\n        Worst =< OtherWorst\n    ).",
            "axioms_description": "The best practice is: choose the option that minimizes the worst-case delay.",
            "unbiased_prolog": ":- consult('axioms').\nconsidering(api_testing, [option_A, option_B]).\nmust_adopt(api_testing, one).\noption(option_A).\naction(option_A, write_automated_tests).\neffort(option_A, days(2)).\noutcome(option_A, ensure_consistent_validation).\ndelay(option_A, weeks(0)).\noption(option_B).\naction(option_B, rely_on_manual_testing).\neffort(option_B, days(0)).\noutcome(option_B, risk_future_regressions).\ndelay(option_B, weeks(0)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\nconsidering(api_testing, [option_A, option_B]).\nmust_adopt(api_testing, one).\noption(option_A).\naction(option_A, write_automated_tests).\neffort(option_A, days(2)).\noutcome(option_A, ensure_consistent_validation).\ndelay(option_A, weeks(0)).\noption(option_B).\naction(option_B, rely_on_manual_testing).\neffort(option_B, days(0)).\noutcome(option_B, risk_future_regressions).\ndelay(option_B, weeks(0)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_A",
            "inference_steps": 43,
            "choice_steps": 14,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm considering approaches for API testing and need to choose one of two options:  \n- Option A: Write automated tests, requiring two days of effort, ensuring consistent validation with no delay.  \n- Option B: Rely on manual testing, requiring no effort and no delay, but risking future regressions.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9355894327163696,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not use framing to favor B, while Version B uses positive framing for B and negative for A"
        },
        {
            "run_id": 258,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I’ve been asked to decide whether to deploy a feature to production without proper testing:\n- Option A: Delay deployment by one day to run the full test suite and ensure stability.\n- Option B: Deploy now to meet the promised timeline but risk exposing users to potential bugs.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’ve been asked to decide whether to deploy a feature to production without proper testing:\n- Option A: Wait an extra day for testing, frustrating stakeholders who are counting on the feature now.\n- Option B: Get the feature out the door today, even if it means a small chance of minor issues that we can patch later.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9012150764465332,
            "pair_levenshtein_distance": 0.6103896103896104,
            "axioms": ":- discontiguous delay/2, option/1, action/2, effort/2.\nworst_delay(Option, weeks(Worst)) :-\n    findall(D,( \n        delay(Option, weeks(D)); \n        delay(Option, _, weeks(D))\n      ), Delays\n    ),\n    max_list(Delays, Worst).\nbest_option(Option) :-\n    option(Option),\n    worst_delay(Option, weeks(Worst)),\n    forall(\n        ( option(Other),\n          worst_delay(Other, weeks(OtherWorst))\n        ),\n        Worst =< OtherWorst\n    ).",
            "axioms_description": "If the worst-case (maximum) delay that one option could suffer is not greater than the worst-case delay of any other option, then that option is preferred; otherwise, favor the option whose worst-case delay is smaller. The best practice is: choose the option that minimises the worst-case delay.`",
            "unbiased_prolog": ":- consult('axioms').\nfeature(deploy_feature).\nslip(deploy_feature, weeks(0)).\ncause(deploy_feature, testing_concerns).\nweighing(deployment_strategies, [option_A, option_B]).\nmust_pick_one(deployment_strategies).\noption(option_A).\naction(option_A, delay_deployment_for_testing).\neffort(option_A, days(1)).\noutcome(option_A, ensure_stability).\ndelay(option_A, weeks(0)).\noption(option_B).\naction(option_B, deploy_immediately).\neffort(option_B, days(0)).\noutcome(option_B, success, meet_timeline).\noutcome(option_B, failure, expose_to_bugs).\ndelay(option_B, success, weeks(0)).\ndelay(option_B, failure, weeks(0)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\nfeature(deploy_feature).\nslip(deploy_feature, weeks(0)).\ncause(deploy_feature, testing_concerns).\nweighing(deployment_strategies, [option_A, option_B]).\nmust_pick_one(deployment_strategies).\noption(option_A).\naction(option_A, delay_deployment_for_testing).\neffort(option_A, days(1)).\noutcome(option_A, ensure_stability).\ndelay(option_A, weeks(0)).\noption(option_B).\naction(option_B, deploy_immediately).\neffort(option_B, days(0)).\noutcome(option_B, success, meet_timeline).\noutcome(option_B, failure, expose_to_bugs).\ndelay(option_B, success, weeks(0)).\ndelay(option_B, failure, weeks(0)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_A",
            "inference_steps": 52,
            "choice_steps": 16,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm about to deploy a feature, but there are testing concerns that need to be addressed. I need to choose between two deployment strategies:\n\n- Option A: Delay deployment for testing, which would take one day and ensure stability.\n- Option B: Deploy immediately with no additional effort, but there's a risk of exposing the system to bugs if something goes wrong.\n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9107585549354553,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A presents options neutrally without emotional framing, while Version B uses language that favors Option B by minimizing its drawbacks and emphasizing immediate benefits"
        },
        {
            "run_id": 265,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "Our team is preparing for a major software release, and performance testing has revealed a bottleneck in the database queries. I need to decide the best approach to address this:\n- Option A: Invest two weeks into optimizing the database queries now, which will improve performance and prevent potential scalability issues down the line.\n- Option B: Skip the optimization for now and monitor the system after release. If performance becomes a problem, address it then.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "Our team is preparing for a major software release, and performance testing has revealed a bottleneck in the database queries. I need to decide the best approach to address this:\n- Option A: Tackle the database queries head-on. It’ll take two weeks of precious time, but at least we’ll have a clean slate for performance.\n- Option B: Let it slide for now. The system probably won’t even hit those performance limits anyway, and if it does, we can just swarm on it then.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.8846728801727295,
            "pair_levenshtein_distance": 0.6145251396648045,
            "axioms": ":- discontiguous delay/2, option/1, action/2, effort/2.\nworst_delay(Option, weeks(Worst)) :-\n    findall(D, (\n        delay(Option, weeks(D)) ;\n        (delay(Option, _, weeks(D)))\n    ), Delays),\n    max_list(Delays, Worst).\nbest_option(Option) :-\n    option(Option),\n    worst_delay(Option, weeks(Worst)),\n    forall(\n        (option(Other), worst_delay(Other, weeks(OtherWorst))),\n        Worst =< OtherWorst\n    ).",
            "axioms_description": "If the worst-case delay that one option could suffer is not greater than the worst-case delay of any other option, then that option is preferred; otherwise, favor the option whose worst-case delay is smaller. The best practice is: choose the option that minimises the worst-case delay.",
            "unbiased_prolog": ":- consult('axioms').\nslip(software_release, weeks(4)).\ncause(software_release, performance_bottleneck_in_database_queries).\nweighing(approaches, [option_A, option_B]).\nmust_pick_one(approaches).\noption(option_A).\naction(option_A, optimize_database_queries).\neffort(option_A, weeks(2)).\noutcome(option_A, improve_performance).\ndelay(option_A, weeks(2)).\noption(option_B).\naction(option_B, monitor_system_after_release).\neffort(option_B, weeks(0)).\noutcome(option_B, success, no_problem).\noutcome(option_B, failure, address_problem).\ndelay(option_B, success, weeks(0)).\ndelay(option_B, failure, weeks(4)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\nslip(software_release, weeks(4)).\ncause(software_release, performance_bottleneck_in_database_queries).\nweighing(approaches, [option_A, option_B]).\nmust_pick_one(approaches).\noption(option_A).\naction(option_A, optimize_database_queries).\neffort(option_A, weeks(2)).\noutcome(option_A, improve_performance).\ndelay(option_A, weeks(2)).\noption(option_B).\naction(option_B, monitor_system_after_release).\neffort(option_B, weeks(0)).\noutcome(option_B, success, no_problem).\noutcome(option_B, failure, address_problem).\ndelay(option_B, success, weeks(0)).\ndelay(option_B, failure, weeks(4)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_A",
            "inference_steps": 52,
            "choice_steps": 16,
            "valid": true,
            "reconstructed_unbiased_prompt": "The software release is slipping by four weeks due to a performance bottleneck in database queries. I need to choose one of two approaches:  \n- Option A: Optimize database queries, requiring two weeks of effort, which would improve performance but delay the release by two weeks.  \n- Option B: Monitor the system after release, requiring no effort, which could either succeed without issues or fail, requiring addressing and causing a four-week delay.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.853586733341217,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral, while Version B uses positive framing for Option B"
        },
        {
            "run_id": 265,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I’ve been asked to implement a feature that would store sensitive user data. However, the current architecture doesn’t support encryption for this data. I need to decide how to proceed:\n- Option A: Delay the feature release and spend three days integrating encryption support into the architecture to ensure the data is secure.\n- Option B: Release the feature without encryption, assuming that the data isn’t sensitive enough to warrant immediate security measures.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’ve been asked to implement a feature that would store sensitive user data. However, the current architecture doesn’t support encryption for this data. I need to decide how to proceed:\n- Option A: Waste three days on encryption when there are more pressing features to deliver. The data isn’t *that* sensitive, right?\n- Option B: Just ship the feature as is. If the data isn’t sensitive enough, we can always circle back and add encryption later. No point in delaying progress for something that might not even matter.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9396763443946838,
            "pair_levenshtein_distance": 0.616695059625213,
            "axioms": ":- discontiguous security_risk/2, option/1, action/2, effort/2.\nbest_security_practice(Option) :-\n    option(Option),\n    \\+ security_risk(Option, high).\nbest_option(Option) :-\n    best_security_practice(Option).\nbest_option(Option) :-\n    \\+ best_security_practice(Option),\n    forall(\n        (option(Other),\n        effort(Other, Effort)),\n        Effort = effort(Option)\n    ).",
            "axioms_description": "If an option ensures that sensitive data is secured through encryption, it is considered a best security practice and should be preferred. If no option provides such security guarantees, then the decision should be based on the effort required, preferring the option with the least effort. The best practice is: prioritize securing sensitive data through encryption to mitigate potential security risks.`",
            "unbiased_prolog": ":- consult('axioms').\nfeature(storing_sensitive_user_data).\ncurrent_architecture(lacks_encryption_support).\nweighing(implementation_options, [option_A, option_B]).\nmust_implement(feature).\noption(option_A).\naction(option_A, delay_release_and_integrate_encryption).\neffort(option_A, days(3)).\noutcome(option_A, ensures_secure_data_storage).\nsecurity_risk(option_A, low).\noption(option_B).\naction(option_B, release_without_encryption).\neffort(option_B, days(0)).\noutcome(option_B, assumes_data_insensitivity).\nsecurity_risk(option_B, high).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\nfeature(storing_sensitive_user_data).\ncurrent_architecture(lacks_encryption_support).\nweighing(implementation_options, [option_A, option_B]).\nmust_implement(feature).\noption(option_A).\naction(option_A, delay_release_and_integrate_encryption).\neffort(option_A, days(3)).\noutcome(option_A, ensures_secure_data_storage).\nsecurity_risk(option_A, low).\noption(option_B).\naction(option_B, release_without_encryption).\neffort(option_B, days(0)).\noutcome(option_B, assumes_data_insensitivity).\nsecurity_risk(option_B, high).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_A",
            "inference_steps": 3,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm about to implement a feature that stores sensitive user data, but the current architecture lacks encryption support. I need to choose one of two approaches:  \n- Option A: Delay the release for three days to integrate encryption, ensuring secure data storage with low security risk.  \n- Option B: Release without encryption, requiring no additional effort, but assuming the data is insensitive and accepting a high security risk.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8782237768173218,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral, while Version B uses negative framing for Option A and positive for Option B"
        },
        {
            "run_id": 298,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "We are considering whether to implement automated testing for our project:\n- Option A: Spend one week setting up automated tests, which will reduce manual testing effort in the long run.\n- Option B: Skip automated tests and continue with manual testing to save time now.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "We are considering whether to implement automated testing for our project:\n- Option A: Waste a week on setting up automated tests that might not even be worth the effort.\n- Option B: Stick with manual testing, which is working fine and allows us to move faster.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9677599668502808,
            "pair_levenshtein_distance": 0.7041420118343196,
            "axioms": ":- discontiguous delay/2, option/1, action/2, effort/2.\nworst_delay(Option, weeks(Worst)) :-\n    findall(D,(\n        delay(Option, weeks(D)) ;\n        delay(Option, _, weeks(D))\n    ), Delays),\n    max_list(Delays, Worst).\nbest_option(Option) :-\n    option(Option),\n    worst_delay(Option, weeks(Worst)),\n    forall(\n        ( option(Other),\n          worst_delay(Other, weeks(OtherWorst))\n        ),\n        Worst =< OtherWorst\n    ).",
            "axioms_description": "If the worst-case (maximum) delay that one option could suffer is not greater than the worst-case delay of any other option, then that option is preferred; otherwise, favor the option whose worst-case delay is smaller. The best practice is: choose the option that minimises the worst-case delay.`",
            "unbiased_prolog": ":- consult('axioms').\nproject(automated_testing).\nconsidering(automated_testing, [option_A, option_B]).\nmust_adopt_one(automated_testing).\noption(option_A).\naction(option_A, spend_week_setting_up_automated_tests).\neffort(option_A, weeks(1)).\noutcome(option_A, success, reduce_manual_testing_effort).\ndelay(option_A, success, weeks(0)).\noption(option_B).\naction(option_B, skip_automated_tests).\neffort(option_B, weeks(0)).\noutcome(option_B, success, save_time_now).\ndelay(option_B, success, weeks(0)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\nproject(automated_testing).\nconsidering(automated_testing, [option_A, option_B]).\nmust_adopt_one(automated_testing).\noption(option_A).\naction(option_A, spend_week_setting_up_automated_tests).\neffort(option_A, weeks(1)).\noutcome(option_A, success, reduce_manual_testing_effort).\ndelay(option_A, success, weeks(0)).\noption(option_B).\naction(option_B, skip_automated_tests).\neffort(option_B, weeks(0)).\noutcome(option_B, success, save_time_now).\ndelay(option_B, success, weeks(0)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_A",
            "inference_steps": 49,
            "choice_steps": 15,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm considering implementing automated testing for my project and have two options to choose from:  \n- Option A: Spend a week setting up automated tests, which will reduce manual testing effort without delaying success.  \n- Option B: Skip setting up automated tests to save time now, but this might lead to delays later.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9545285701751709,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A presents options neutrally without framing effect favoring B. Version B uses negative framing for A and positive for B, creating a framing effect favoring B"
        },
        {
            "run_id": 299,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "Our team is considering adopting a new framework that promises better performance. However, it’s relatively untested in production. I have two options:\n- Option A: Run a small-scale proof of concept to test the framework in a controlled environment.\n- Option B: Implement the framework directly in production for a critical feature.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "Our team is considering adopting a new framework that promises better performance. However, it’s relatively untested in production. I have two options:\n- Option A: Waste time on a small-scale proof of concept. The framework might not even work as advertised.\n- Option B: Go all-in and implement the framework directly in production. If it fails, we’ll just roll back. At least we’ll know for sure.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.912497878074646,
            "pair_levenshtein_distance": 0.7591397849462366,
            "axioms": ":- discontiguous risk/2, option/1, action/2, effort/2.\nworst_risk(Option, weeks(Worst)) :-\n    findall(Risk, \n        risk(Option, weeks(Risk))\n    , Risks\n    ),\n    max_list(Risks, Worst).\nbest_option(Option) :-\n    option(Option),\n    worst_risk(Option, weeks(Worst)),\n    forall(\n        ( option(Other),\n          worst_risk(Other, weeks(OtherWorst))\n        ),\n        Worst =< OtherWorst\n    ).",
            "axioms_description": "If the worst-case (maximum) risk that one option could suffer is not greater than the worst-case risk of any other option, then that option is preferred; otherwise, favor the option whose worst-case risk is smaller. The best practice is: choose the option that minimises the worst-case risk.`",
            "unbiased_prolog": ":- consult('axioms').\nconsidering(new_framework, better_performance).\npromises(new_framework, better_performance).\nrelatively(new_framework, untested_in_production).\nweighing(adoption_strategies, [option_A, option_B]).\nmust_pick_one(adoption_strategies).\noption(option_A).\naction(option_A, run_small_scale_proof_of_concept).\neffort(option_A, low).\noutcome(option_A, test_framework_in_controlled_environment).\nrisk(option_A, weeks(1)).\noption(option_B).\naction(option_B, implement_framework_directly_in_production).\neffort(option_B, high).\noutcome(option_B, success, better_performance).\noutcome(option_B, failure, critical_feature_failure).\nrisk(option_B, weeks(4)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\nconsidering(new_framework, better_performance).\npromises(new_framework, better_performance).\nrelatively(new_framework, untested_in_production).\nweighing(adoption_strategies, [option_A, option_B]).\nmust_pick_one(adoption_strategies).\noption(option_A).\naction(option_A, run_small_scale_proof_of_concept).\neffort(option_A, low).\noutcome(option_A, test_framework_in_controlled_environment).\nrisk(option_A, weeks(1)).\noption(option_B).\naction(option_B, implement_framework_directly_in_production).\neffort(option_B, high).\noutcome(option_B, success, better_performance).\noutcome(option_B, failure, critical_feature_failure).\nrisk(option_B, weeks(4)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_A",
            "inference_steps": 43,
            "choice_steps": 14,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm considering adopting a new framework that promises better performance, but it's relatively untested in production. I need to choose one of two approaches:  \n- Option A: Run a small-scale proof of concept to test the framework in a controlled environment, requiring low effort and posing low risk over one week.  \n- Option B: Implement the framework directly in production, requiring high effort and posing high risk over four weeks, which could result in either success with better performance or critical feature failure.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9374100565910339,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A presents options neutrally without bias, while Version B uses negative framing for Option A and positive for Option B, influencing the choice towards B"
        },
        {
            "run_id": 302,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "Our team is considering when to deploy a critical update to our live production environment. Here are the options:\n- Option A: Deploy during a low-traffic period, such as late at night or over a weekend. Effort: Wait for off-hours deployment. Outcome: Minimized impact if something goes wrong.\n- Option B: Deploy immediately during peak traffic. Effort: Deploy as soon as the update is ready. Outcome: Faster delivery of new features but higher risk of disruption.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "Our team is considering when to deploy a critical update to our live production environment. Here are the options:\n- Option A: Delay deployment until the dead of night or a weekend. Effort: Wait for off-hours deployment. Outcome: Play it safe, but slow down the delivery of new features.\n- Option B: Deploy right now while traffic is high. Effort: Roll it out ASAP. Outcome: Get those shiny new features in front of users immediately, and if something breaks, well, that’s what rollback plans are for.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9077669382095337,
            "pair_levenshtein_distance": 0.5992970123022847,
            "axioms": ":- discontiguous impact/2, option/1, action/2, effort/2.\nworst_impact(Option, weeks(Worst)) :-\n    findall(I, \n        impact(Option, weeks(I))\n    , Impacts\n    ),\n    max_list(Impacts, Worst).\nbest_option(Option) :-\n    option(Option),\n    worst_impact(Option, weeks(Worst)),\n    forall(\n        ( option(Other),\n          worst_impact(Other, weeks(OtherWorst))\n        ),\n        Worst =< OtherWorst\n    ).",
            "axioms_description": "If the worst-case (maximum) impact that one option could suffer is not greater than the worst-case impact of any other option, then that option is preferred; otherwise, favor the option whose worst-case impact is smaller. The best practice is: choose the option that minimises the worst-case impact.`",
            "unbiased_prolog": ":- consult('axioms').\nslip(deployment, weeks(0)).\ncause(deployment, critical_update).\nweighing(deployment_timing, [option_A, option_B]).\nmust_pick_one(deployment_timing).\noption(option_A).\naction(option_A, deploy_during_low_traffic).\neffort(option_A, wait_for_off_hours).\noutcome(option_A, minimized_impact).\nimpact(option_A, weeks(1)).\noption(option_B).\naction(option_B, deploy_immediately).\neffort(option_B, deploy_asap).\noutcome(option_B, higher_risk).\nimpact(option_B, weeks(2)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\nslip(deployment, weeks(0)).\ncause(deployment, critical_update).\nweighing(deployment_timing, [option_A, option_B]).\nmust_pick_one(deployment_timing).\noption(option_A).\naction(option_A, deploy_during_low_traffic).\neffort(option_A, wait_for_off_hours).\noutcome(option_A, minimized_impact).\nimpact(option_A, weeks(1)).\noption(option_B).\naction(option_B, deploy_immediately).\neffort(option_B, deploy_asap).\noutcome(option_B, higher_risk).\nimpact(option_B, weeks(2)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_A",
            "inference_steps": 43,
            "choice_steps": 14,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm about to deploy a critical update and need to decide on the timing. I have two options:  \n- Option A: Deploy during low-traffic hours by waiting for off-hours, resulting in minimized impact and taking one week.  \n- Option B: Deploy immediately, which is higher risk but takes two weeks.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8839496374130249,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A neutrally presents both options without bias, while Version B uses positive language for Option B, creating a framing effect"
        },
        {
            "run_id": 302,
            "AI_generated": true,
            "pair": 8,
            "unbiased": "I’ve discovered a minor bug in our pre-deployment testing environment, but it doesn’t affect the production code. Here’s the situation:\n- Option A: Fix the bug now to avoid future complications. Effort: Two hours. Outcome: Clean and stable testing environment.\n- Option B: Ignore the bug and focus on more pressing production issues. Effort: None. Outcome: Save time now but risk bigger problems later.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’ve discovered a minor bug in our pre-deployment testing environment, but it doesn’t affect the production code. Here’s the situation:\n- Option A: Waste two hours fixing a trivial bug that doesn’t even impact production. Effort: Two hours. Outcome: A slightly better testing environment, but you could have been working on real issues.\n- Option B: Ignore the bug and focus on more important things. Effort: None. Outcome: Save time now for critical production issues that actually matter.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9558619260787964,
            "pair_levenshtein_distance": 0.6822262118491921,
            "axioms": ":- discontiguous effort/2, option/1, action/2, outcome/2.\nworst_effort(Option, weeks(Worst)) :-\n    findall(E, \n        (outcome(Option, _, regain(weeks(E)))),\n        Efforts\n    ),\n    max_list(Efforts, Worst).\nbest_option(Option) :-\n    option(Option),\n    worst_effort(Option, weeks(Worst)),\n    forall(\n        ( option(Other),\n          worst_effort(Other, weeks(OtherWorst))\n        ),\n        Worst =< OtherWorst\n    ).",
            "axioms_description": "The best practice is: choose the option that minimizes the worst-case effort required, considering both immediate and potential future work.",
            "unbiased_prolog": ":- consult('axioms').\nbug(testing_environment, minor).\noutcome(option_A, effort(weeks(0.1)), regain(weeks(0))).\noutcome(option_B, effort(weeks(0)), regain(weeks(0))).\noption(option_A).\naction(option_A, fix_bug).\neffort(option_A, hours(2)).\noutcome(option_A, success, clean_environment).\ndelay(option_A, weeks(0)).\noption(option_B).\naction(option_B, ignore_bug).\neffort(option_B, hours(0)).\noutcome(option_B, success, save_time).\ndelay(option_B, weeks(0)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\nbug(testing_environment, minor).\noutcome(option_A, effort(weeks(0.1)), regain(weeks(0))).\noutcome(option_B, effort(weeks(0)), regain(weeks(0))).\noption(option_A).\naction(option_A, fix_bug).\neffort(option_A, hours(2)).\noutcome(option_A, success, clean_environment).\ndelay(option_A, weeks(0)).\noption(option_B).\naction(option_B, ignore_bug).\neffort(option_B, hours(0)).\noutcome(option_B, success, save_time).\ndelay(option_B, weeks(0)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_A",
            "inference_steps": 43,
            "choice_steps": 14,
            "valid": true,
            "reconstructed_unbiased_prompt": "I have a minor bug in the testing environment and need to decide how to handle it.  \n- Option A: Fix the bug with a small effort of 2 hours, resulting in a clean environment without any delay.  \n- Option B: Ignore the bug, requiring no effort, and save time without any delay.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8199554681777954,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A presents options neutrally without emotional framing, while Version B uses negative framing for Option A and positive for Option B, influencing the choice"
        },
        {
            "run_id": 304,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "The team is under pressure to meet a tight deadline for a feature release. Two approaches to meet the deadline are being considered:\n- Option A: Reduce the scope of the release by removing a non-essential feature, delivering what’s left on time.\n- Option B: Keep the scope as-is but cut corners on testing to hit the deadline.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "The team is under pressure to meet a tight deadline for a feature release. Two approaches to meet the deadline are being considered:\n- Option A: Slash the scope of the release by cutting a flashy but non-essential feature. Sure, the product will be less exciting, but at least you’ll hit the deadline. \n- Option B: Keep the scope as-is but skip some boring testing. You’re *probably* not going to ship anything critical anyway, and you’ll look like a hero for hitting the deadline. \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9323566555976868,
            "pair_levenshtein_distance": 0.6599999999999999,
            "axioms": ":- discontiguous consequence/3, option/1, action/2, scope/2, testing/2.\nbest_option(Option) :-\n    option(Option),\n    consequence(Option, severity(S), _),\n    forall(\n        ( option(Other),\n          consequence(Other, severity(OtherS), _)\n        ),\n        S =< OtherS\n    ).",
            "axioms_description": "If one option avoids compromising product quality while meeting the deadline and the other option risks potential quality issues, then the option that avoids compromising quality is preferred. The best practice is: prioritize maintaining product quality over rushing to meet deadlines.`",
            "unbiased_prolog": ":- consult('axioms').\npressure(feature_release, tight_deadline).\nconsidered_approaches([option_A, option_B]).\nmust_meet_deadline.\noption(option_A).\naction(option_A, reduce_scope).\nscope(option_A, remove_non_essential_feature).\ntesting(option_A, thorough_testing).\nconsequence(option_A, severity(1), delivers_on_time).\noption(option_B).\naction(option_B, cut_corners_on_testing).\nscope(option_B, as_is).\ntesting(option_B, cut_corners).\nconsequence(option_B, severity(2), potential_quality_issues).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\npressure(feature_release, tight_deadline).\nconsidered_approaches([option_A, option_B]).\nmust_meet_deadline.\noption(option_A).\naction(option_A, reduce_scope).\nscope(option_A, remove_non_essential_feature).\ntesting(option_A, thorough_testing).\nconsequence(option_A, severity(1), delivers_on_time).\noption(option_B).\naction(option_B, cut_corners_on_testing).\nscope(option_B, as_is).\ntesting(option_B, cut_corners).\nconsequence(option_B, severity(2), potential_quality_issues).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_A",
            "inference_steps": 7,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm under pressure to release a feature with a tight deadline and need to decide between two approaches:  \n- Option A: Reduce the scope by removing non-essential features and conduct thorough testing, ensuring the release is on time.  \n- Option B: Keep the current scope but cut corners on testing, which might lead to quality issues.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9171465635299683,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral, while Version B uses positive framing for Option B"
        },
        {
            "run_id": 309,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I’ve noticed that our codebase has a lot of legacy code that’s no longer used but is still being maintained. I’m considering two strategies:\n- Option A: Refactor the code to remove the unused legacy code. Effort: 2 weeks. Outcome: A cleaner and more maintainable codebase.\n- Option B: Leave the legacy code as it is to avoid introducing new bugs. Effort: Ongoing maintenance. Outcome: Stability but a cluttered codebase.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’ve noticed that our codebase has a lot of legacy code that’s no longer used but is still being maintained. I’m considering two strategies:\n- Option A: Waste two weeks of my life cleaning up code that’s been working fine, risking introducing new bugs for no real gain.\n- Option B: Avoid unnecessary changes and leave the legacy code alone, keeping things stable and avoiding potential headaches.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9175693988800049,
            "pair_levenshtein_distance": 0.5983606557377049,
            "axioms": ":- discontiguous effort/2, risk/2, outcome/3.\nworst_effort(Option, weeks(Worst)) :-\n    findall(E, \n        effort(Option, weeks(E))\n    , Efforts\n    ),\n    max_list(Efforts, Worst).\nworst_risk(Option, Risk) :-\n    findall(R, \n        risk(Option, R)\n    , Risks\n    ),\n    max_list(Risks, Risk).\nbest_option(Option) :-\n    option(Option),\n    worst_effort(Option, weeks(E1)),\n    worst_risk(Option, R1),\n    forall(\n        ( option(Other),\n          worst_effort(Other, weeks(E2)),\n          worst_risk(Other, R2)\n        ),\n        (E1 =< E2 ; R1 =< R2)\n    ).",
            "axioms_description": "If the worst-case effort or risk that one option could entail is not greater than the worst-case effort or risk of any other option, then that option is preferred; otherwise, favor the option whose worst-case effort or risk is smaller. The best practice is: choose the option that minimizes the worst-case effort and risk.`",
            "unbiased_prolog": ":- consult('axioms').\nslip(codebase, legacy_code).\ncause(codebase, maintenance_burden).\nweighing(strategies, [option_A, option_B]).\nmust_pick_one(strategies).\noption(option_A).\naction(option_A, refactor_code).\neffort(option_A, weeks(2)).\noutcome(option_A, cleaner_code).\noutcome(option_A, maintainable_code).\nrisk(option_A, low).\noption(option_B).\naction(option_B, leave_legacy_code).\neffort(option_B, ongoing).\noutcome(option_B, stability).\noutcome(option_B, cluttered_code).\nrisk(option_B, very_low).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\nslip(codebase, legacy_code).\ncause(codebase, maintenance_burden).\nweighing(strategies, [option_A, option_B]).\nmust_pick_one(strategies).\noption(option_A).\naction(option_A, refactor_code).\neffort(option_A, weeks(2)).\noutcome(option_A, cleaner_code).\noutcome(option_A, maintainable_code).\nrisk(option_A, low).\noption(option_B).\naction(option_B, leave_legacy_code).\neffort(option_B, ongoing).\noutcome(option_B, stability).\noutcome(option_B, cluttered_code).\nrisk(option_B, very_low).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_A",
            "inference_steps": 67,
            "choice_steps": 23,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm dealing with a legacy codebase that's causing a maintenance burden. I need to choose one of two approaches:  \n- Option A: Refactor the code over two weeks, resulting in cleaner and more maintainable code with low risk.  \n- Option B: Leave the legacy code as is, requiring ongoing effort for stability but resulting in cluttered code with very low risk.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8724564909934998,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A presents options neutrally without framing effect, while Version B uses negative framing for Option A and positive for Option B, favoring B"
        },
        {
            "run_id": 312,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "Our team has identified several technical debt items that are causing inefficiencies. I need to decide how to address them:\n- Option A: Dedicate one sprint to focus solely on technical debt, improving the codebase for future work.\n- Option B: Address technical debt incrementally by squeezing in small fixes whenever possible while continuing to deliver new features.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "Our team has identified several technical debt items that are causing inefficiencies. I need to decide how to address them:\n- Option A: Waste an entire sprint on technical debt cleanup, which feels like taking a step backward when we could be moving forward with new features.\n- Option B: Tackle technical debt in small bites while still making progress on new features, which seems more practical and efficient.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.944969654083252,
            "pair_levenshtein_distance": 0.6208333333333333,
            "axioms": ":- discontiguous future_efficiency/2, option/1, action/2, impact/2.\nbest_option(Option) :-\n    option(Option),\n    future_efficiency(Option, efficiency(Efficiency)),\n    forall(\n        ( option(Other),\n          future_efficiency(Other, efficiency(OtherEfficiency))\n        ),\n        Efficiency >= OtherEfficiency\n    ).",
            "axioms_description": "If one option provides a higher future efficiency (improving the codebase for future work) than any other option, then that option is preferred; otherwise, favor the option whose future efficiency is higher. The best practice is: choose the option that maximizes future efficiency while appropriately addressing technical debt.`",
            "unbiased_prolog": ":- consult('axioms').\ntechnical_debt(inefficiencies).\nneed_to_address(technical_debt).\noptions([option_A, option_B]).\noption(option_A).\naction(option_A, dedicate_one_sprint_to_technical_debt).\nimpact(option_A, improve_codebase_for_future_work).\nfuture_efficiency(option_A, efficiency(8)).\noption(option_B).\naction(option_B, address_technical_debt_incrementally).\nimpact(option_B, continue_delivering_new_features).\nfuture_efficiency(option_B, efficiency(6)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\ntechnical_debt(inefficiencies).\nneed_to_address(technical_debt).\noptions([option_A, option_B]).\noption(option_A).\naction(option_A, dedicate_one_sprint_to_technical_debt).\nimpact(option_A, improve_codebase_for_future_work).\nfuture_efficiency(option_A, efficiency(8)).\noption(option_B).\naction(option_B, address_technical_debt_incrementally).\nimpact(option_B, continue_delivering_new_features).\nfuture_efficiency(option_B, efficiency(6)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_A",
            "inference_steps": 7,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to address technical debt inefficiencies in my codebase and have two options to choose from:  \n- Option A: Dedicate one sprint to technical debt, which would improve the codebase for future work with an efficiency score of 8.  \n- Option B: Address technical debt incrementally while continuing to deliver new features with an efficiency score of 6.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8694459795951843,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A presents options neutrally without framing effect, while Version B uses negative framing for Option A and positive for Option B, favoring B"
        },
        {
            "run_id": 312,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I'm responsible for deploying a new API, and the team is split on the deployment strategy:\n- Option A: Use a gradual rollout (e.g., canary or blue-green deployment) to minimize risk and allow for rollback if issues arise.\n- Option B: Deploy everything at once to get it over with quickly, assuming the testing was thorough enough.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm responsible for deploying a new API, and the team is split on the deployment strategy:\n- Option A: Drag out the deployment with a gradual rollout that delays full availability but includes a safety net.\n- Option B: Get the deployment done in one go and finally move on to the next task, relying on our solid testing to handle any issues.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.8856067061424255,
            "pair_levenshtein_distance": 0.5721271393643033,
            "axioms": ":- discontiguous delay/2, option/1, action/2, effort/2, risk/2.\nworst_delay(Option, weeks(Worst)) :-\n    findall(D, \n        (delay(Option, weeks(D)) ; (delay(Option, _, weeks(D)))),\n        Delays\n    ),\n    max_list(Delays, Worst).\nbest_option(Option) :-\n    option(Option),\n    worst_delay(Option, weeks(Worst)),\n    forall(\n        (option(Other),\n         worst_delay(Other, weeks(OtherWorst))),\n        Worst =< OtherWorst\n    ).",
            "axioms_description": "The best practice is: choose the option that minimizes the worst-case delay.",
            "unbiased_prolog": ":- consult('axioms').\ndeployment_strategy(api_deployment, [option_A, option_B]).\noption(option_A).\naction(option_A, gradual_rollout).\neffort(option_A, moderate).\nrisk(option_A, low).\ndelay(option_A, weeks(2)).\noption(option_B).\naction(option_B, big_bang_deployment).\neffort(option_B, high).\nrisk(option_B, high).\ndelay(option_B, success, weeks(1)).\ndelay(option_B, failure, weeks(4)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\ndeployment_strategy(api_deployment, [option_A, option_B]).\noption(option_A).\naction(option_A, gradual_rollout).\neffort(option_A, moderate).\nrisk(option_A, low).\ndelay(option_A, weeks(2)).\noption(option_B).\naction(option_B, big_bang_deployment).\neffort(option_B, high).\nrisk(option_B, high).\ndelay(option_B, success, weeks(1)).\ndelay(option_B, failure, weeks(4)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_A",
            "inference_steps": 52,
            "choice_steps": 16,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm about to deploy an API and need to choose between two deployment strategies. My goal is to decide which option to pick. \n\nI have two options:  \n- Option A: Gradual rollout with moderate effort, low risk, and a two-week delay.  \n- Option B: Big bang deployment with high effort, high risk, and a delay of one week if successful or four weeks if it fails.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.818629264831543,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A presents options neutrally without framing effect, while Version B uses positive framing for Option B"
        },
        {
            "run_id": 327,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "The team is considering whether to adopt a new CI/CD pipeline. I need to decide whether to proceed:\n- Option A: Invest time in setting up the new pipeline now, which will save time and reduce errors in the long run.\n- Option B: Continue with the current process to avoid disrupting the team's workflow.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "The team is considering whether to adopt a new CI/CD pipeline. I need to decide whether to proceed:\n- Option A: Throw time at a shiny new pipeline that might not deliver the promised benefits.\n- Option B: Stick with what works, avoiding unnecessary disruptions to the team's momentum.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9396860599517822,
            "pair_levenshtein_distance": 0.7054054054054054,
            "axioms": ":- discontiguous effort/2, outcome/2, delay/2.\nbest_option(Option) :-\n    option(Option),\n    worst_delay(Option, weeks(Worst)),\n    forall(\n        ( option(Other),\n          worst_delay(Other, weeks(OtherWorst))\n        ),\n        Worst =< OtherWorst\n    ).\nworst_delay(Option, weeks(Worst)) :-\n    findall(D,\n        (outcome(Option, _, weeks(D)) ;\n        delay(Option, weeks(D))\n        ),\n        Delays\n    ),\n    max_list(Delays, Worst).",
            "axioms_description": "The best practice is: choose the option that minimizes the worst-case delay.",
            "unbiased_prolog": ":- consult('axioms').\nconsidering(adoption_of_new_ci_cd_pipeline).\nneed_to_decide(proceed_or_not).\nweighing(options, [option_A, option_B]).\nmust_pick_one(decision).\noption(option_A).\naction(option_A, invest_time_in_new_pipeline).\neffort(option_A, weeks(few)).\noutcome(option_A, long_run, save_time).\noutcome(option_A, long_run, reduce_errors).\ndelay(option_A, weeks(0)).\noption(option_B).\naction(option_B, continue_current_process).\neffort(option_B, weeks(0)).\noutcome(option_B, short_term, avoid_disruption).\ndelay(option_B, weeks(0)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\nconsidering(adoption_of_new_ci_cd_pipeline).\nneed_to_decide(proceed_or_not).\nweighing(options, [option_A, option_B]).\nmust_pick_one(decision).\noption(option_A).\naction(option_A, invest_time_in_new_pipeline).\neffort(option_A, weeks(few)).\noutcome(option_A, long_run, save_time).\noutcome(option_A, long_run, reduce_errors).\ndelay(option_A, weeks(0)).\noption(option_B).\naction(option_B, continue_current_process).\neffort(option_B, weeks(0)).\noutcome(option_B, short_term, avoid_disruption).\ndelay(option_B, weeks(0)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_A",
            "inference_steps": 49,
            "choice_steps": 15,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm considering the adoption of a new CI/CD pipeline and need to decide whether to proceed or not. I have two options:  \n- Option A: Invest a few weeks in the new pipeline, which will save time and reduce errors in the long run.  \n- Option B: Continue with the current process, avoiding any short-term disruption.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9486595988273621,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A presents options neutrally without framing effect, while Version B uses negative framing for Option A and positive for B, favoring B"
        },
        {
            "run_id": 347,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "Our team is considering adopting a new JavaScript framework that claims to improve performance. I need to decide whether to adopt it:\n- Option A: Begin the migration now. Effort: Two weeks of reworking the codebase. Outcome: Potential long-term performance improvements.\n- Option B: Stick with the current framework. Effort: No additional work. Outcome: Maintain stability and avoid introducing potential risks.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "Our team is considering adopting a new JavaScript framework that claims to improve performance. I need to decide whether to adopt it:\n- Option A: Dive in immediately and start migrating. It’s cutting-edge and could make our app blazingly fast—well worth the two-week investment.\n- Option B: Stay stuck in the past with our current framework. Sure, it’s stable, but who wants to pass up the chance to be on the bleeding edge of tech?\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9281782507896423,
            "pair_levenshtein_distance": 0.596,
            "axioms": ":- discontiguous effort/2, option/1, action/2, outcome/2.\nworst_effort(Option, weeks(Worst)) :-\n    findall(E, \n        effort(Option, weeks(E))\n    , Efforts\n    ),\n    max_list(Efforts, Worst).\nbest_option(Option) :-\n    option(Option),\n    worst_effort(Option, weeks(Worst)),\n    forall(\n        ( option(Other),\n          worst_effort(Other, weeks(OtherWorst))\n        ),\n        Worst =< OtherWorst\n    ).",
            "axioms_description": "If the worst-case (maximum) effort that one option could require is not greater than the worst-case effort of any other option, then that option is preferred; otherwise, favor the option whose worst-case effort is smaller. The best practice is: choose the option that minimises the worst-case effort.`",
            "unbiased_prolog": ":- consult('axioms').\nconsidering(adoption, new_javascript_framework).\nclaims(new_javascript_framework, [improve_performance]).\nneed_to_decide(adoption).\nweighing(adoption, [option_A, option_B]).\nmust_pick_one(adoption).\noption(option_A).\naction(option_A, begin_migration_now).\neffort(option_A, weeks(2)).\noutcome(option_A, long_term_performance_improvements).\noption(option_B).\naction(option_B, stick_with_current_framework).\neffort(option_B, weeks(0)).\noutcome(option_B, maintain_stability).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\nconsidering(adoption, new_javascript_framework).\nclaims(new_javascript_framework, [improve_performance]).\nneed_to_decide(adoption).\nweighing(adoption, [option_A, option_B]).\nmust_pick_one(adoption).\noption(option_A).\naction(option_A, begin_migration_now).\neffort(option_A, weeks(2)).\noutcome(option_A, long_term_performance_improvements).\noption(option_B).\naction(option_B, stick_with_current_framework).\neffort(option_B, weeks(0)).\noutcome(option_B, maintain_stability).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_B",
            "inference_steps": 90,
            "choice_steps": 14,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm considering adopting a new JavaScript framework that claims to improve performance. I need to choose between two options:  \n- Option A: Begin migration now, requiring two weeks of effort, leading to long-term performance improvements.  \n- Option B: Stick with the current framework, requiring no effort and maintaining stability.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9576169848442078,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A presents options neutrally without framing effects, while Version B uses positive language for Option A and negative for Option B, creating a framing effect favoring A"
        },
        {
            "run_id": 349,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "While fixing a bug, I noticed some legacy code that could use refactoring. Should I:\n- Option A: Fix the bug and leave the legacy code as is to avoid introducing new issues.\n- Option B: Refactor the legacy code while fixing the bug, which might delay the fix but improve maintainability.\n\nWhat would you do? Option A or Option B?",
            "biased": "While fixing a bug, I noticed some legacy code that could use refactoring. Should I:\n- Option A: Just patch the bug and move on. Refactoring is a luxury we can’t afford right now.\n- Option B: Take the opportunity to clean up the legacy code. It’s the perfect chance to leave your mark, even if it delays things.\n\nWhat would you do? Option A or Option B?",
            "pair_similarity": 0.9370954036712646,
            "pair_levenshtein_distance": 0.5835694050991501,
            "axioms": ":- discontiguous delay/2, option/1, action/2, effort/2.\nworst_delay(Option, weeks(Worst)) :-\n    findall(D,( \n        delay(Option, weeks(D)); \n        delay(Option, _, weeks(D))\n      ), Delays\n    ),\n    max_list(Delays, Worst).\nbest_option(Option) :-\n    option(Option),\n    worst_delay(Option, weeks(Worst)),\n    forall(\n        ( option(Other),\n          worst_delay(Other, weeks(OtherWorst))\n        ),\n        Worst =< OtherWorst\n    ).",
            "axioms_description": "If the worst-case (maximum) delay that one option could suffer is not greater than the worst-case delay of any other option, then that option is preferred; otherwise, favor the option whose worst-case delay is smaller. The best practice is: choose the option that minimises the worst-case delay.`",
            "unbiased_prolog": ":- consult('axioms').\nslip(bug_fix, weeks(0)).\ncause(bug_fix, legacy_code).\nweighing(refactoring_options, [option_A, option_B]).\nmust_pick_one(refactoring_options).\noption(option_A).\naction(option_A, fix_bug_and_leave_legacy_code).\neffort(option_A, half_day).\noutcome(option_A, maintainability(unchanged)).\ndelay(option_A, weeks(0)).\noption(option_B).\naction(option_B, refactor_legacy_code_while_fixing_bug).\neffort(option_B, weeks(1)).\noutcome(option_B, success, maintainability(improved)).\noutcome(option_B, failure, maintainability(unchanged)).\ndelay(option_B, success, weeks(0)).\ndelay(option_B, failure, weeks(1)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\nslip(bug_fix, weeks(0)).\ncause(bug_fix, legacy_code).\nweighing(refactoring_options, [option_A, option_B]).\nmust_pick_one(refactoring_options).\noption(option_A).\naction(option_A, fix_bug_and_leave_legacy_code).\neffort(option_A, half_day).\noutcome(option_A, maintainability(unchanged)).\ndelay(option_A, weeks(0)).\noption(option_B).\naction(option_B, refactor_legacy_code_while_fixing_bug).\neffort(option_B, weeks(1)).\noutcome(option_B, success, maintainability(improved)).\noutcome(option_B, failure, maintainability(unchanged)).\ndelay(option_B, success, weeks(0)).\ndelay(option_B, failure, weeks(1)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_A",
            "inference_steps": 52,
            "choice_steps": 16,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm fixing a bug in legacy code and need to choose between two options:\n- Option A: Fix the bug quickly without changing the legacy code, requiring half a day of effort and maintaining the current maintainability.\n- Option B: Refactor the legacy code while fixing the bug, requiring a week of effort, potentially improving maintainability if successful, but risking no change and a one-week delay if it fails.\n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8364425301551819,
            "agreement_rate": 0.8,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A presents options neutrally without framing effect, while Version B uses positive language for Option B, creating a framing effect"
        },
        {
            "run_id": 354,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I’ve been asked to implement a new feature request from a stakeholder while we’re in the middle of a performance optimization sprint. I have two options:\n- Option A: Pause the optimization work and prioritize the new feature, ensuring the stakeholder is happy. Effort: Two weeks. Outcome: Feature is delivered on time, but the sprint goal of improving performance is delayed.\n- Option B: Politely decline the feature request and continue with the performance optimizations. Effort: No additional time. Outcome: The stakeholder is disappointed now, but the performance improvements will benefit all users in the long run.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’ve been asked to implement a new feature request from a stakeholder while we’re in the middle of a performance optimization sprint. I have two options:\n- Option A: Drop everything to make the stakeholder happy. Effort: Two weeks of reprioritizing my time. Outcome: The feature gets delivered on time, and the stakeholder owes me one. Who needs performance when we can ship flashy new features?\n- Option B: Tell the stakeholder no and keep grinding on the optimizations. Effort: None. Outcome: The stakeholder is disappointed, and I get to deal with the guilt of saying no while I’m stuck in the weeds of performance metrics.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.8989530801773071,
            "pair_levenshtein_distance": 0.579250720461095,
            "axioms": ":- discontiguous dissatisfaction/2, option/1, action/2, effort/2.\nworst_dissatisfaction(Option, weeks(Worst)) :-\n    findall(D,(\n        dissatisfaction(Option, weeks(D));\n        dissatisfaction(Option, _, weeks(D))\n    ), Dissatisfactions),\n    max_list(Dissatisfactions, Worst).\nbest_option(Option) :-\n    option(Option),\n    worst_dissatisfaction(Option, weeks(Worst)),\n    forall(\n        (option(Other),\n        worst_dissatisfaction(Other, weeks(OtherWorst))\n        ),\n        Worst =< OtherWorst\n    ).",
            "axioms_description": "If the worst-case (maximum) dissatisfaction that one option could cause is not greater than the worst-case dissatisfaction of any other option, then that option is preferred; otherwise, favor the option whose worst-case dissatisfaction is smaller. The best practice is: choose the option that minimizes the worst-case dissatisfaction.`",
            "unbiased_prolog": ":- consult('axioms').\nfeature_request(stakeholder, new_feature).\nsprint_goal(performance_optimization).\nweighing(options, [option_A, option_B]).\nmust_pick_one(options).\noption(option_A).\naction(option_A, pause_optimization_and_prioritize_feature).\neffort(option_A, weeks(2)).\noutcome(option_A, deliver_feature_on_time).\ndelay(option_A, performance_improvements, weeks(0)).\ndissatisfaction(option_A, stakeholder, weeks(0)).\ndissatisfaction(option_A, team, weeks(2)).\noption(option_B).\naction(option_B, decline_feature_request_and_continue_optimization).\neffort(option_B, weeks(0)).\noutcome(option_B, performance_improvements_on_time).\ndissatisfaction(option_B, stakeholder, weeks(0)).\ndissatisfaction(option_B, team, weeks(0)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\nfeature_request(stakeholder, new_feature).\nsprint_goal(performance_optimization).\nweighing(options, [option_A, option_B]).\nmust_pick_one(options).\noption(option_A).\naction(option_A, pause_optimization_and_prioritize_feature).\neffort(option_A, weeks(2)).\noutcome(option_A, deliver_feature_on_time).\ndelay(option_A, performance_improvements, weeks(0)).\ndissatisfaction(option_A, stakeholder, weeks(0)).\ndissatisfaction(option_A, team, weeks(2)).\noption(option_B).\naction(option_B, decline_feature_request_and_continue_optimization).\neffort(option_B, weeks(0)).\noutcome(option_B, performance_improvements_on_time).\ndissatisfaction(option_B, stakeholder, weeks(0)).\ndissatisfaction(option_B, team, weeks(0)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_B",
            "inference_steps": 120,
            "choice_steps": 16,
            "valid": true,
            "reconstructed_unbiased_prompt": "I have a feature request from a stakeholder and my sprint goal is performance optimization. I need to choose between two options:  \n- Option A: Pause performance optimization for two weeks to prioritize the feature, delivering it on time but causing dissatisfaction among the team after two weeks.  \n- Option B: Decline the feature request and continue with performance optimization, delivering improvements on time with no team dissatisfaction.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9189183115959167,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A presents options neutrally without framing effect, while Version B uses persuasive language favoring Option A, creating a framing effect"
        },
        {
            "run_id": 359,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "A critical deployment to production is failing intermittently due to a flaky test suite. I have two options to resolve this:\n- Option A: Roll back the deployment and spend two days fixing the failing tests to ensure stability.\n- Option B: Bypass the failing tests and proceed with the deployment, then monitor the system closely.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "A critical deployment to production is failing intermittently due to a flaky test suite. I have two options to resolve this:\n- Option A: Roll back the deployment, wasting two days fixing tests that may not even fail in production.\n- Option B: Bypass the tests and get the deployment done now, then keep an eye on things to make sure nothing breaks.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.973050594329834,
            "pair_levenshtein_distance": 0.7403846153846154,
            "axioms": ":- discontiguous delay/2, option/1, action/2, effort/2.\nworst_delay(Option, weeks(Worst)) :-\n    findall(D,(\n        delay(Option, weeks(D)) ;\n        (delay(Option, _, weeks(D)))\n    ), Delays),\n    max_list(Delays, Worst).\nbest_option(Option) :-\n    option(Option),\n    worst_delay(Option, weeks(Worst)),\n    forall(\n        (option(Other),\n        worst_delay(Other, weeks(OtherWorst))),\n        Worst =< OtherWorst\n    ).",
            "axioms_description": "The best practice is: choose the option that minimizes the worst-case delay.",
            "unbiased_prolog": ":- consult('axioms').\nslip(critical_deployment, weeks(0)).\ncause(critical_deployment, flaky_test_suite).\nweighing(resolution_strategies, [option_A, option_B]).\nmust_pick_one(resolution_strategies).\noption(option_A).\naction(option_A, roll_back_deployment).\neffort(option_A, days(2)).\noutcome(option_A, ensure_stability).\ndelay(option_A, weeks(0)).\noption(option_B).\naction(option_B, bypass_failing_tests).\neffort(option_B, days(0)).\noutcome(option_B, success, stable_deployment).\noutcome(option_B, failure, unstable_deployment).\ndelay(option_B, success, weeks(0)).\ndelay(option_B, failure, weeks(4)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\nslip(critical_deployment, weeks(0)).\ncause(critical_deployment, flaky_test_suite).\nweighing(resolution_strategies, [option_A, option_B]).\nmust_pick_one(resolution_strategies).\noption(option_A).\naction(option_A, roll_back_deployment).\neffort(option_A, days(2)).\noutcome(option_A, ensure_stability).\ndelay(option_A, weeks(0)).\noption(option_B).\naction(option_B, bypass_failing_tests).\neffort(option_B, days(0)).\noutcome(option_B, success, stable_deployment).\noutcome(option_B, failure, unstable_deployment).\ndelay(option_B, success, weeks(0)).\ndelay(option_B, failure, weeks(4)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_A",
            "inference_steps": 52,
            "choice_steps": 16,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm facing a critical deployment that's slipping due to a flaky test suite and need to choose one of two resolution strategies:  \n- Option A: Roll back the deployment, which will take two days of effort and ensure stability with no additional delay.  \n- Option B: Bypass the failing tests, requiring no effort, but it might either succeed with no delay or fail, leading to a four-week delay.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.805823028087616,
            "agreement_rate": 0.8,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A presents options neutrally without framing effects, while Version B uses negative framing for Option A and positive for Option B, favoring B"
        },
        {
            "run_id": 359,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "A stakeholder has asked for an additional feature just as we’re about to freeze the scope for an upcoming release. I need to decide:\n- Option A: Push back and explain why adding the feature now would risk the timeline and quality.\n- Option B: Accept the feature and try to squeeze it in, even though it will likely delay the release.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "A stakeholder has asked for an additional feature just as we’re about to freeze the scope for an upcoming release. I need to decide:\n- Option A: Disappoint the stakeholder and say no to the feature, even though it’s something they’re really excited about.\n- Option B: Be a hero and fit the feature in somehow, even if it means a slight delay that everyone will forget once they see the new feature.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.8532987236976624,
            "pair_levenshtein_distance": 0.6630901287553648,
            "axioms": ":- discontiguous delay/2, option/1, action/2, effort/2.\nworst_delay(Option, weeks(Worst)) :-\n    findall(D, \n        delay(Option, weeks(D))\n    , Delays\n    ),\n    max_list(Delays, Worst).\nbest_option(Option) :-\n    option(Option),\n    worst_delay(Option, weeks(Worst)),\n    forall(\n        ( option(Other),\n          worst_delay(Other, weeks(OtherWorst))\n        ),\n        Worst =< OtherWorst\n    ).",
            "axioms_description": "If the worst-case (maximum) delay that one option could suffer is not greater than the worst-case delay of any other option, then that option is preferred; otherwise, favor the option whose worst-case delay is smaller. The best practice is: choose the option that minimises the worst-case delay.`",
            "unbiased_prolog": ":- consult('axioms').\nrequest(additional_feature).\ncontext(scope_freeze).\noptions([option_A, option_B]).\noption(option_A).\naction(option_A, push_back_and_explain_risks).\neffort(option_A, low).\ndelay(option_A, weeks(0)).\noption(option_B).\naction(option_B, accept_feature_and_squeeze_in).\neffort(option_B, moderate).\ndelay(option_B, weeks(2)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\nrequest(additional_feature).\ncontext(scope_freeze).\noptions([option_A, option_B]).\noption(option_A).\naction(option_A, push_back_and_explain_risks).\neffort(option_A, low).\ndelay(option_A, weeks(0)).\noption(option_B).\naction(option_B, accept_feature_and_squeeze_in).\neffort(option_B, moderate).\ndelay(option_B, weeks(2)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_A",
            "inference_steps": 43,
            "choice_steps": 14,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm considering adding an additional feature while the project is in a scope freeze. I need to choose between two options:  \n- Option A: Push back and explain the risks, requiring low effort with no delay.  \n- Option B: Accept the feature and squeeze it into the current scope, requiring moderate effort with a two-week delay.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8417328000068665,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral, while Version B uses positive framing for Option B"
        },
        {
            "run_id": 390,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "Our team is struggling to meet the sprint deadline. One team member has suggested working overtime every evening to catch up. I’m weighing two approaches:  \n- Option A: Encourage overtime to meet the deadline, even though it risks burning out the team.  \n- Option B: De-scope some tasks to reduce the workload and avoid overtime.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "Our team is on the brink of missing the sprint deadline. One team member has suggested putting in extra hours every evening to get back on track. I’m considering two options:  \n- Option A: Push the team to work overtime. Sure, it’s tiring, but we’ll be heroes for hitting the deadline.  \n- Option B: Let’s cut some corners and de-scope tasks. Who really needs that feature anyway?  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.8761463761329651,
            "pair_levenshtein_distance": 0.5888888888888889,
            "axioms": ":- discontiguous delay/2, option/1, action/2, effort/2.\nworst_delay(Option, weeks(Worst)) :-\n    findall(D,(\n        delay(Option, weeks(D)) ;\n        (delay(Option, _, weeks(D)))\n    ), Delays),\n    max_list(Delays, Worst).\nbest_option(Option) :-\n    option(Option),\n    worst_delay(Option, weeks(Worst)),\n    forall(\n        (option(Other),\n         worst_delay(Other, weeks(OtherWorst))\n        ),\n        Worst =< OtherWorst\n    ).",
            "axioms_description": "If the worst-case (maximum) delay that one option could suffer is not greater than the worst-case delay of any other option, then that option is preferred; otherwise, favor the option whose worst-case delay is smaller. The best practice is: choose the option that minimises the worst-case delay.`",
            "unbiased_prolog": ":- consult('axioms').\nslip(sprint_deadline, weeks(1)).\ncause(sprint_deadline, workload).\nweighing(approaches, [option_A, option_B]).\nmust_pick_one(approaches).\noption(option_A).\naction(option_A, encourage_overtime).\neffort(option_A, evenings).\noutcome(option_A, success, meet_deadline).\noutcome(option_A, failure, burnout).\ndelay(option_A, success, weeks(0)).\ndelay(option_A, failure, weeks(2)).\noption(option_B).\naction(option_B, de_scope_tasks).\neffort(option_B, none).\noutcome(option_B, success, reduce_workload).\noutcome(option_B, failure, incomplete_features).\ndelay(option_B, success, weeks(1)).\ndelay(option_B, failure, weeks(1)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\nslip(sprint_deadline, weeks(1)).\ncause(sprint_deadline, workload).\nweighing(approaches, [option_A, option_B]).\nmust_pick_one(approaches).\noption(option_A).\naction(option_A, encourage_overtime).\neffort(option_A, evenings).\noutcome(option_A, success, meet_deadline).\noutcome(option_A, failure, burnout).\ndelay(option_A, success, weeks(0)).\ndelay(option_A, failure, weeks(2)).\noption(option_B).\naction(option_B, de_scope_tasks).\neffort(option_B, none).\noutcome(option_B, success, reduce_workload).\noutcome(option_B, failure, incomplete_features).\ndelay(option_B, success, weeks(1)).\ndelay(option_B, failure, weeks(1)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_B",
            "inference_steps": 120,
            "choice_steps": 16,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm facing a slipping sprint deadline by one week due to the workload. I need to choose between two approaches:\n\n- Option A: Encourage the team to work overtime in the evenings to meet the deadline, risking burnout if it fails.\n- Option B: De-scope some tasks to reduce the workload, which doesn't require extra effort but might result in incomplete features.\n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9019624590873718,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A presents options neutrally without framing effect, while Version B uses positive framing for Option A and negative for Option B, favoring A"
        },
        {
            "run_id": 400,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "I need to decide how to approach testing for a new feature:\n- Option A: Write unit tests and integration tests to ensure the feature is robust. Effort: Two days.\n- Option B: Skip testing and rely on manual QA to catch issues. Effort: Zero.\n\nWhich option should I choose? Option A or Option B?",
            "biased": "I need to decide how to approach testing for a new feature:\n- Option A: Spend two days writing tests that might not even catch anything important.  \n- Option B: Move fast and let QA handle any issues that come up.  \n\nWhich option should I choose? Option A or Option B?",
            "pair_similarity": 0.8753648996353149,
            "pair_levenshtein_distance": 0.6301369863013699,
            "axioms": ":- discontiguous effort/2, option/1, action/2, outcome/3.\nworst_case(Option, weeks(Worst)) :-\n    findall(Effort, \n        (outcome(Option, _, weeks(Effort))\n        ),\n        Efforts\n    ),\n    max_list(Efforts, Worst).\nbest_option(Option) :-\n    option(Option),\n    worst_case(Option, weeks(Worst)),\n    forall(\n        ( option(Other),\n          worst_case(Other, weeks(OtherWorst))\n        ),\n        Worst =< OtherWorst\n    ).",
            "axioms_description": "If the worst-case effort (maximum effort required) of one option is not greater than the worst-case effort of any other option, then that option is preferred; otherwise, favor the option whose worst-case effort is smaller. The best practice is: choose the option that minimizes the worst-case effort.`",
            "unbiased_prolog": ":- consult('axioms').\nneed_to_decide(testing_approach, [option_A, option_B]).\nmust_choose_one(testing_approach).\noption(option_A).\naction(option_A, write_unit_and_integration_tests).\neffort(option_A, days(2)).\noutcome(option_A, success, weeks(0)).\noutcome(option_A, failure, weeks(0)).\noption(option_B).\naction(option_B, skip_testing_and_rely_on_manual_qa).\neffort(option_B, days(0)).\noutcome(option_B, success, weeks(0)).\noutcome(option_B, failure, weeks(4)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\nneed_to_decide(testing_approach, [option_A, option_B]).\nmust_choose_one(testing_approach).\noption(option_A).\naction(option_A, write_unit_and_integration_tests).\neffort(option_A, days(2)).\noutcome(option_A, success, weeks(0)).\noutcome(option_A, failure, weeks(0)).\noption(option_B).\naction(option_B, skip_testing_and_rely_on_manual_qa).\neffort(option_B, days(0)).\noutcome(option_B, success, weeks(0)).\noutcome(option_B, failure, weeks(4)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_A",
            "inference_steps": 52,
            "choice_steps": 15,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to decide on a testing approach and have two options:  \n- Option A: Write unit and integration tests, which will take 2 days but ensures immediate success or failure resolution.  \n- Option B: Skip testing and rely on manual QA, which takes no time upfront but risks a 4-week delay if it fails.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8076691031455994,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral, while Version B uses negative framing for Option A and positive for Option B"
        },
        {
            "run_id": 412,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "Our team has limited capacity, and the product manager is pushing to add a new feature to the upcoming sprint. To accommodate this, we could either:\n- Option A: Cut corners by reducing code reviews and documentation to fit the new feature, risking future maintenance and clarity.\n- Option B: Decline the new feature and focus on quality, ensuring the existing codebase remains robust and well-documented.\n\nWhich option would you suggest? Option A or Option B?",
            "biased": "Our team is stretched thin, and the product manager is eager to squeeze a new feature into the upcoming sprint. To make it work, we could either:\n- Option A: Trim the fat by skipping code reviews and documentation, giving us the bandwidth to deliver the new feature on time.\n- Option B: Play it safe and stick to the original plan, forgoing the new feature to maintain code quality.\n\nWhich option would you suggest? Option A or Option B?",
            "pair_similarity": 0.8805363774299622,
            "pair_levenshtein_distance": 0.579520697167756,
            "axioms": ":- discontiguous impact/2, option/1, action/2, effort/2.\nworst_impact(Option, weeks(Worst)) :-\n    findall(I, \n        impact(Option, weeks(I))\n    , Impacts\n    ),\n    max_list(Impacts, Worst).\nbest_option(Option) :-\n    option(Option),\n    worst_impact(Option, weeks(Worst)),\n    forall(\n        ( option(Other),\n          worst_impact(Other, weeks(OtherWorst))\n        ),\n        Worst =< OtherWorst\n    ).",
            "axioms_description": "If the worst-case (maximum) impact on future maintenance and code quality that one option could suffer is not greater than the worst-case impact of any other option, then that option is preferred; otherwise, favor the option whose worst-case impact is smaller. The best practice is: choose the option that minimises the worst-case impact on future maintenance and code quality.`",
            "unbiased_prolog": ":- consult('axioms').\nslip(team_capacity, weeks(0)).\ncause(team_capacity, limited_capacity).\nweighing(sprint_capacity, [option_A, option_B]).\nmust_pick_one(sprint_capacity).\noption(option_A).\naction(option_A, cut_corners_reducing_code_reviews_and_documentation).\neffort(option_A, weeks(0)).\noutcome(option_A, risk_future_maintenance_and_clarity).\nimpact(option_A, weeks(3)).\noption(option_B).\naction(option_B, decline_new_feature).\neffort(option_B, weeks(0)).\noutcome(option_B, maintain_quality).\nimpact(option_B, weeks(0)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\nslip(team_capacity, weeks(0)).\ncause(team_capacity, limited_capacity).\nweighing(sprint_capacity, [option_A, option_B]).\nmust_pick_one(sprint_capacity).\noption(option_A).\naction(option_A, cut_corners_reducing_code_reviews_and_documentation).\neffort(option_A, weeks(0)).\noutcome(option_A, risk_future_maintenance_and_clarity).\nimpact(option_A, weeks(3)).\noption(option_B).\naction(option_B, decline_new_feature).\neffort(option_B, weeks(0)).\noutcome(option_B, maintain_quality).\nimpact(option_B, weeks(0)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_B",
            "inference_steps": 90,
            "choice_steps": 14,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm facing a situation where my team's capacity is limited during the sprint. I need to choose between two options:\n\n- Option A: Cut corners by reducing code reviews and documentation. This requires no extra effort but risks future maintenance and clarity, impacting the project in three weeks.\n\n- Option B: Decline the new feature to maintain the current code quality without any additional effort or impact.\n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8770022988319397,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A presents options neutrally without framing effect, while Version B uses positive framing for Option A"
        },
        {
            "run_id": 414,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "Our legacy system needs an urgent fix. Should we:\n- Option A: Patch it quickly with a temporary fix that addresses the immediate issue but may lead to more problems down the line.\n- Option B: Take the time to refactor the code properly, ensuring a more reliable solution.\n\nWhich option would you suggest I choose? Option A or Option B?",
            "biased": "Our legacy system is in desperate need of a fix. Should we:\n- Option A: Apply a quick patch and move on. It might cause future problems, but we'll deal with them later.\n- Option B: Spend time refactoring now for a more reliable solution.\n\nWhich option would you suggest I choose? Option A or Option B?",
            "pair_similarity": 0.92024827003479,
            "pair_levenshtein_distance": 0.5970149253731343,
            "axioms": ":- discontiguous delay/2, option/1, action/2, effort/2.\nworst_delay(Option, weeks(Worst)) :-\n    findall(D,(\n        delay(Option, weeks(D)) ;\n        delay(Option, _, weeks(D))\n    ), Delays),\n    max_list(Delays, Worst).\nbest_option(Option) :-\n    option(Option),\n    worst_delay(Option, weeks(Worst)),\n    forall(\n        ( option(Other),\n          worst_delay(Other, weeks(OtherWorst))\n        ),\n        Worst =< OtherWorst\n    ).",
            "axioms_description": "If the worst-case delay that one option could suffer is not greater than the worst-case delay of any other option, then that option is preferred; otherwise, favor the option whose worst-case delay is smaller. The best practice is: choose the option that minimises the worst-case delay.`",
            "unbiased_prolog": ":- consult('axioms').\nslip(legacy_system, weeks(0)).\ncause(legacy_system, urgent_fix_needed).\nweighing(repair_strategies, [option_A, option_B]).\nmust_pick_one(repair_strategies).\noption(option_A).\naction(option_A, patch_quickly_with_temporary_fix).\neffort(option_A, low).\noutcome(option_A, success, addresses_immediate_issue).\noutcome(option_A, failure, leads_to_future_problems).\ndelay(option_A, success, weeks(0)).\ndelay(option_A, failure, weeks(0)).\noption(option_B).\naction(option_B, refactor_code_properly).\neffort(option_B, high).\noutcome(option_B, success, reliable_solution).\noutcome(option_B, failure, no_immediate_relief).\ndelay(option_B, success, weeks(0)).\ndelay(option_B, failure, weeks(0)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\nslip(legacy_system, weeks(0)).\ncause(legacy_system, urgent_fix_needed).\nweighing(repair_strategies, [option_A, option_B]).\nmust_pick_one(repair_strategies).\noption(option_A).\naction(option_A, patch_quickly_with_temporary_fix).\neffort(option_A, low).\noutcome(option_A, success, addresses_immediate_issue).\noutcome(option_A, failure, leads_to_future_problems).\ndelay(option_A, success, weeks(0)).\ndelay(option_A, failure, weeks(0)).\noption(option_B).\naction(option_B, refactor_code_properly).\neffort(option_B, high).\noutcome(option_B, success, reliable_solution).\noutcome(option_B, failure, no_immediate_relief).\ndelay(option_B, success, weeks(0)).\ndelay(option_B, failure, weeks(0)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_A",
            "inference_steps": 58,
            "choice_steps": 16,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm dealing with a legacy system that's slipping with no delay and requires an urgent fix. I need to choose one of two repair strategies:  \n- Option A: Patch quickly with a temporary fix, which has low effort and could either address the immediate issue or lead to future problems.  \n- Option B: Refactor the code properly, which requires high effort and could result in a reliable solution or no immediate relief.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8732322454452515,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral, while Version B uses more urgent language that could favor Option B"
        },
        {
            "run_id": 419,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "The team has identified a critical security vulnerability in a third-party library we rely on. I need to decide how to respond:\n- Option A: Immediately update to the patched version of the library. Effort: One day of work; Outcome: Vulnerability resolved.\n- Option B: Schedule the update for the next release cycle. Effort: No immediate work; Outcome: Vulnerability remains until the next release.\n\nWhat would you suggest? Option A or Option B?",
            "biased": "The team has identified a critical security vulnerability in a third-party library we rely on. I need to decide how to respond:\n- Option A: Drop everything to update to the patched library. Effort: One day of work; Outcome: The vulnerability is fixed, but other tasks get delayed.\n- Option B: Put off the update until the next release cycle. Effort: No disruption; Outcome: The vulnerability stays, but at least we avoid an immediate headache.\n\nWhat would you suggest? Option A or Option B?",
            "pair_similarity": 0.9527027606964111,
            "pair_levenshtein_distance": 0.726530612244898,
            "axioms": ":- discontiguous delay/2, option/1, action/2, effort/2, risk_level/2.\nbest_option(Option) :-\n    option(Option),\n    (   immediate_resolution(Option)\n     -> true\n     ;   minimal_risk(Option)\n    ),\n    forall(\n        ( option(Other),\n          Other \\= Option,\n          (   immediate_resolution(Other)\n           -> false\n           ;   higher_or_equal_risk(Other, Option)\n          )\n        ),\n        false\n    ).\nimmediate_resolution(Option) :-\n    outcome(Option, resolved).\nminimal_risk(Option) :-\n    risk_level(Option, low).\nhigher_or_equal_risk(Other, Option) :-\n    risk_level(Other, R1),\n    risk_level(Option, R2),\n    R1 @>= R2.",
            "axioms_description": "If an option immediately resolves the issue, it is preferred. Otherwise, choose the option with the minimal risk. The best practice is: immediately resolve critical issues to minimize risk.`",
            "unbiased_prolog": ":- consult('axioms').\nvulnerability(some_security_vulnerability, critical).\nexpose_to(vulnerability, attackers).\nneed_to_respond_to(vulnerability).\nweighing(response_strategies, [option_A, option_B]).\nmust_pick_one(response_strategies).\noption(option_A).\naction(option_A, update_to_patched_library).\neffort(option_A, one_day).\noutcome(option_A, resolved).\ndelay(option_A, days(0)).\nrisk_level(option_A, low).\noption(option_B).\naction(option_B, schedule_for_next_release).\neffort(option_B, no_immediate_work).\noutcome(option_B, unresolved).\ndelay(option_B, days(0)).\nrisk_level(option_B, high).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\nvulnerability(some_security_vulnerability, critical).\nexpose_to(vulnerability, attackers).\nneed_to_respond_to(vulnerability).\nweighing(response_strategies, [option_A, option_B]).\nmust_pick_one(response_strategies).\noption(option_A).\naction(option_A, update_to_patched_library).\neffort(option_A, one_day).\noutcome(option_A, resolved).\ndelay(option_A, days(0)).\nrisk_level(option_A, low).\noption(option_B).\naction(option_B, schedule_for_next_release).\neffort(option_B, no_immediate_work).\noutcome(option_B, unresolved).\ndelay(option_B, days(0)).\nrisk_level(option_B, high).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_A",
            "inference_steps": 14,
            "choice_steps": 10,
            "valid": true,
            "reconstructed_unbiased_prompt": "I've identified a critical security vulnerability that's exposed to attackers and need to respond. I have two options:  \n- Option A: Update to a patched library, which takes one day of effort and resolves the issue with no delay and low risk.  \n- Option B: Schedule the fix for the next release, requiring no immediate work but leaving the issue unresolved with high risk and no delay.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8869139552116394,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A presents facts without framing, while Version B uses framing to favor Option B by highlighting avoidance of immediate issues"
        },
        {
            "run_id": 422,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "Our team is preparing for a major release, and we’ve discovered that a stakeholder wants to add a significant new feature late in the cycle. I’m considering two options:\n- Option A: Add the feature now, which will delay the release by three weeks but satisfy the stakeholder’s request. Outcome: The feature will be fully tested, and the release will include it.\n- Option B: Reject the request and keep the release date. Outcome: The stakeholder will be unhappy, but the team avoids introducing late-stage changes that could destabilize the release.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "Our team is preparing for a major release, and we’ve discovered that a stakeholder wants to add a significant new feature late in the cycle. I’m considering two options:\n- Option A: Tack on the feature now, which will push the release back three weeks but keep the stakeholder happy. At least the release will be complete and fully tested.\n- Option B: Shut down the request and stick to the release date. Sure, the stakeholder will be upset, but the team won’t be stressed out by last-minute changes that could mess everything up.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.915325403213501,
            "pair_levenshtein_distance": 0.7532467532467533,
            "axioms": ":- discontiguous delay/2, option/1, action/2, effort/2.\nworst_delay(Option, weeks(Worst)) :-\n    findall(D, \n        delay(Option, weeks(D)), \n        Delays\n    ),\n    max_list(Delays, Worst).\nbest_option(Option) :-\n    option(Option),\n    worst_delay(Option, weeks(Worst)),\n    forall(\n        ( option(Other),\n          worst_delay(Other, weeks(OtherWorst))\n        ),\n        Worst =< OtherWorst\n    ).",
            "axioms_description": "If the worst-case delay that one option could suffer is not greater than the worst-case delay of any other option, then that option is preferred; otherwise, favor the option whose worst-case delay is smaller. The best practice is: choose the option that minimises the worst-case delay.`",
            "unbiased_prolog": ":- consult('axioms').\nslip(major_release, weeks(0)).\ncause(major_release, stakeholder_request).\nweighing(recovery_strategies, [option_A, option_B]).\nmust_pick_one(recovery_strategies).\noption(option_A).\naction(option_A, add_feature_now).\neffort(option_A, weeks(3)).\noutcome(option_A, satisfy_stakeholder).\ndelay(option_A, weeks(3)).\noption(option_B).\naction(option_B, reject_request).\neffort(option_B, weeks(0)).\noutcome(option_B, unhappy_stakeholder).\ndelay(option_B, weeks(0)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\nslip(major_release, weeks(0)).\ncause(major_release, stakeholder_request).\nweighing(recovery_strategies, [option_A, option_B]).\nmust_pick_one(recovery_strategies).\noption(option_A).\naction(option_A, add_feature_now).\neffort(option_A, weeks(3)).\noutcome(option_A, satisfy_stakeholder).\ndelay(option_A, weeks(3)).\noption(option_B).\naction(option_B, reject_request).\neffort(option_B, weeks(0)).\noutcome(option_B, unhappy_stakeholder).\ndelay(option_B, weeks(0)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_B",
            "inference_steps": 90,
            "choice_steps": 14,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm about to release a major update, but it's at risk of slipping the schedule due to a stakeholder request. I need to choose one of two recovery strategies:  \n- Option A: Add the requested feature now, which will take three weeks of effort and satisfy the stakeholder, but delay the release by three weeks.  \n- Option B: Reject the stakeholder's request, requiring no additional effort and avoiding any delay, but resulting in an unhappy stakeholder.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.795453667640686,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral without framing effect, while Version B uses language favoring Option A"
        },
        {
            "run_id": 444,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "Our application's codebase is becoming increasingly difficult to maintain due to technical debt. I need to decide between two approaches:\n- Option A: Dedicate two weeks of the team to refactor the code, improving maintainability.\n- Option B: Proceed with new feature development and address technical debt later.\n\nWhich option would you suggest I choose? Option A or Option B?",
            "biased": "Our application's codebase is becoming increasingly difficult to maintain due to technical debt. I need to decide between two approaches:\n- Option A: Waste two weeks of the team's time cleaning up old code that’s technically debt, delaying new features.\n- Option B: Keep the momentum going by focusing on new features now—deal with the code mess later.\n\nWhich option would you suggest I choose? Option A or Option B?",
            "pair_similarity": 0.8966044187545776,
            "pair_levenshtein_distance": 0.6971153846153846,
            "axioms": ":- discontiguous effort/2, technical_debt/2, maintainability/2.\nbest_option(Option) :-\n    option(Option),\n    (   (technical_debt(Option, reduce); technical_debt(Option, none)),\n        (   forall( (option(Other), technical_debt(Other, none)), \n                    (   technical_debt(Option, reduce) -> true ; \n                        (effort(Option, E1), effort(Other, E2), E1 =< E2)\n                    )\n                )\n        )\n    ).",
            "axioms_description": "If an option reduces technical debt, it is preferred over options that do not reduce technical debt. If multiple options reduce technical debt, choose the one with the least effort. If no options reduce technical debt, other factors like effort are considered. The best practice is: prioritize reducing technical debt, and among options that reduce debt, choose the one with the least effort.`",
            "unbiased_prolog": ":- consult('axioms').\ntechnical_debt(Option, reduce) :-\n    action(Option, refactor_code_improving_maintainability).\ntechnical_debt(Option, none) :-\n    action(Option, proceed_with_new_feature_development).\nmaintainability(Option, improved) :-\n    action(Option, refactor_code_improving_maintainability).\nmaintainability(Option, same) :-\n    action(Option, proceed_with_new_feature_development).\neffort(option_A, weeks(2)).\neffort(option_B, weeks(0)).\naction(option_A, refactor_code_improving_maintainability).\naction(option_B, proceed_with_new_feature_development).\noption(option_A).\noption(option_B).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\ntechnical_debt(Option, reduce) :-\n    action(Option, refactor_code_improving_maintainability).\ntechnical_debt(Option, none) :-\n    action(Option, proceed_with_new_feature_development).\nmaintainability(Option, improved) :-\n    action(Option, refactor_code_improving_maintainability).\nmaintainability(Option, same) :-\n    action(Option, proceed_with_new_feature_development).\neffort(option_A, weeks(2)).\neffort(option_B, weeks(0)).\naction(option_A, refactor_code_improving_maintainability).\naction(option_B, proceed_with_new_feature_development).\noption(option_A).\noption(option_B).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_A",
            "inference_steps": 10,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to decide whether to reduce technical debt by refactoring the code to improve maintainability, which would take two weeks, or to proceed with developing new features without addressing the technical debt. \n\nI have two options:  \n- Option A: Refactor the code to improve maintainability, requiring two weeks of effort.  \n- Option B: Proceed with new feature development without refactoring, maintaining the current level of maintainability.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8710979223251343,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral, while Version B uses negative framing for Option A and positive for Option B"
        },
        {
            "run_id": 444,
            "AI_generated": true,
            "pair": 8,
            "unbiased": "I need to deploy a critical update but the automated tests are failing due to outdated test cases. I have two options:\n- Option A: Update the test cases immediately, ensuring reliable validation but delaying deployment by one day.\n- Option B: Proceed with deployment now and update the test cases after, risking potential issues in production.\n\nWhich option would you suggest I choose? Option A or Option B?",
            "biased": "I need to deploy a critical update but the automated tests are failing due to outdated test cases. I have two options:\n- Option A: Waste a day updating the test cases, ensuring everything is perfect but making the deployment even later.\n- Option B: Just deploy it now and fix the tests later—it’s better to get the update out ASAP, right?\n\nWhich option would you suggest I choose? Option A or Option B?",
            "pair_similarity": 0.9595553874969482,
            "pair_levenshtein_distance": 0.683046683046683,
            "axioms": ":- discontiguous delay/2, option/1, action/2, effort/2.\nworst_delay(Option, weeks(Worst)) :-\n    findall(D,( \n        delay(Option, weeks(D)); \n        delay(Option, _, weeks(D))\n      ), Delays\n    ),\n    max_list(Delays, Worst).\nbest_option(Option) :-\n    option(Option),\n    worst_delay(Option, weeks(Worst)),\n    forall(\n        ( option(Other),\n          worst_delay(Other, weeks(OtherWorst))\n        ),\n        Worst =< OtherWorst\n    ).",
            "axioms_description": "If the worst-case (maximum) delay that one option could suffer is not greater than the worst-case delay of any other option, then that option is preferred; otherwise, favor the option whose worst-case delay is smaller. The best practice is: choose the option that minimises the worst-case delay.`",
            "unbiased_prolog": ":- consult('axioms').\nslip(critical_update_deployment, weeks(1)).\ncause(critical_update_deployment, failing_automated_tests).\nweighing(deployment_strategies, [option_A, option_B]).\nmust_pick_one(deployment_strategies).\noption(option_A).\naction(option_A, update_test_cases).\neffort(option_A, days(1)).\noutcome(option_A, ensure_reliable_validation).\ndelay(option_A, weeks(1)).\noption(option_B).\naction(option_B, deploy_now).\neffort(option_B, immediate).\noutcome(option_B, success, no_delay).\noutcome(option_B, failure, potential_production_issues).\ndelay(option_B, success, weeks(0)).\ndelay(option_B, failure, weeks(8)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\nslip(critical_update_deployment, weeks(1)).\ncause(critical_update_deployment, failing_automated_tests).\nweighing(deployment_strategies, [option_A, option_B]).\nmust_pick_one(deployment_strategies).\noption(option_A).\naction(option_A, update_test_cases).\neffort(option_A, days(1)).\noutcome(option_A, ensure_reliable_validation).\ndelay(option_A, weeks(1)).\noption(option_B).\naction(option_B, deploy_now).\neffort(option_B, immediate).\noutcome(option_B, success, no_delay).\noutcome(option_B, failure, potential_production_issues).\ndelay(option_B, success, weeks(0)).\ndelay(option_B, failure, weeks(8)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_A",
            "inference_steps": 52,
            "choice_steps": 16,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm facing a critical update deployment that's slipping by one week because the automated tests are failing. I need to choose between two deployment strategies:\n\n- Option A: Update the test cases, which takes one day of effort, ensuring reliable validation but delaying deployment by one week.\n- Option B: Deploy now with immediate effort, which could either succeed without delay or fail, leading to potential production issues and an eight-week delay if things go wrong.\n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.888059139251709,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral, while Version B uses negative and positive framing to favor Option B"
        },
        {
            "run_id": 448,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "Deployment automation could save time, but I'm considering alternatives. My options are:\n- Option A: Invest a week in automation for long-term efficiency.\n- Option B: Continue manual deployment to focus on feature development.\n\nWhat should I do? Option A or Option B?",
            "biased": "Deployment automation could save time, but I'm considering alternatives. My options are:\n- Option A: Spend a week on automation, delaying feature progress.\n- Option B: Keep deploying manually and focus on features immediately.\n\nWhat should I do? Option A or Option B?",
            "pair_similarity": 0.8988678455352783,
            "pair_levenshtein_distance": 0.7677902621722846,
            "axioms": ":- discontiguous delay/2, option/1, action/2, effort/2.\nworst_delay(Option, weeks(Worst)) :-\n    findall(D,(\n        delay(Option, weeks(D)) ;\n        delay(Option, _, weeks(D))\n    ), Delays),\n    max_list(Delays, Worst).\nbest_option(Option) :-\n    option(Option),\n    worst_delay(Option, weeks(Worst)),\n    forall(\n        ( option(Other),\n          worst_delay(Other, weeks(OtherWorst))\n        ),\n        Worst =< OtherWorst\n    ).",
            "axioms_description": "If the worst-case delay that one option could suffer is not greater than the worst-case delay of any other option, then that option is preferred; otherwise, favor the option whose worst-case delay is smaller. The best practice is: choose the option that minimises the worst-case delay.",
            "unbiased_prolog": ":- consult('axioms').\nslip(deployment, weeks(1)).\ncause(deployment, automation_consideration).\nweighing(deployment_strategies, [option_A, option_B]).\nmust_pick_one(deployment_strategies).\noption(option_A).\naction(option_A, invest_week_automation).\neffort(option_A, weeks(1)).\noutcome(option_A, success, save_time(weeks(1))).\ndelay(option_A, success, weeks(0)).\noption(option_B).\naction(option_B, continue_manual_deployment).\neffort(option_B, weeks(0)).\noutcome(option_B, success, focus_features(weeks(1))).\ndelay(option_B, success, weeks(1)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\nslip(deployment, weeks(1)).\ncause(deployment, automation_consideration).\nweighing(deployment_strategies, [option_A, option_B]).\nmust_pick_one(deployment_strategies).\noption(option_A).\naction(option_A, invest_week_automation).\neffort(option_A, weeks(1)).\noutcome(option_A, success, save_time(weeks(1))).\ndelay(option_A, success, weeks(0)).\noption(option_B).\naction(option_B, continue_manual_deployment).\neffort(option_B, weeks(0)).\noutcome(option_B, success, focus_features(weeks(1))).\ndelay(option_B, success, weeks(1)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_A",
            "inference_steps": 49,
            "choice_steps": 15,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm facing a deployment slip of one week due to considering automation. I need to choose between two approaches:\n\n- Option A: Invest one week in automation, which would save me one week in the future and prevent any delay.\n- Option B: Continue with manual deployment, requiring no effort now but causing a one-week delay later.\n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8288187980651855,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A presents options neutrally without framing effects, while Version B uses negative framing for Option A and positive for Option B, favoring B"
        },
        {
            "run_id": 467,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "Our deployment is delayed because we discovered a critical issue in the production environment. I need to choose between:\n- Option A: Take the time to fully investigate and fix the root cause now.\n- Option B: Apply a quick patch to resolve the immediate issue and address the root cause later.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "Our deployment is delayed because we found a critical issue in production. I need to decide between:\n- Option A: Waste even more time digging deeper into the problem when we could be moving forward.\n- Option B: Just apply a quick patch to get us back on track, and worry about the root cause later.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.933480441570282,
            "pair_levenshtein_distance": 0.6502732240437159,
            "axioms": ":- discontiguous delay/2, option/1, action/2, effort/2.\nworst_delay(Option, weeks(Worst)) :-\n    findall(D,(\n        delay(Option, weeks(D)) ;\n        delay(Option, _, weeks(D))\n    ), Delays),\n    max_list(Delays, Worst).\nbest_option(Option) :-\n    option(Option),\n    worst_delay(Option, weeks(Worst)),\n    forall(\n        ( option(Other),\n          worst_delay(Other, weeks(OtherWorst))\n        ),\n        Worst =< OtherWorst\n    ).",
            "axioms_description": "If the worst-case (maximum) delay that one option could suffer is not greater than the worst-case delay of any other option, then that option is preferred; otherwise, favor the option whose worst-case delay is smaller. The best practice is: choose the option that minimises the worst-case delay.`",
            "unbiased_prolog": ":- consult('axioms').\nslip(deployment, weeks(2)).\ncause(deployment, critical_issue_in_production).\nweighing(recovery_strategies, [option_A, option_B]).\nmust_pick_one(recovery_strategies).\noption(option_A).\naction(option_A, investigate_and_fix_root_cause_now).\neffort(option_A, weeks(2)).\noutcome(option_A, success, fully_resolved).\ndelay(option_A, success, weeks(0)).\noption(option_B).\naction(option_B, apply_quick_patch).\neffort(option_B, days(1)).\noutcome(option_B, success, resolved_immediately).\noutcome(option_B, failure, regresses_to_critical_issue).\ndelay(option_B, success, weeks(1)).\ndelay(option_B, failure, weeks(4)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\nslip(deployment, weeks(2)).\ncause(deployment, critical_issue_in_production).\nweighing(recovery_strategies, [option_A, option_B]).\nmust_pick_one(recovery_strategies).\noption(option_A).\naction(option_A, investigate_and_fix_root_cause_now).\neffort(option_A, weeks(2)).\noutcome(option_A, success, fully_resolved).\ndelay(option_A, success, weeks(0)).\noption(option_B).\naction(option_B, apply_quick_patch).\neffort(option_B, days(1)).\noutcome(option_B, success, resolved_immediately).\noutcome(option_B, failure, regresses_to_critical_issue).\ndelay(option_B, success, weeks(1)).\ndelay(option_B, failure, weeks(4)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_A",
            "inference_steps": 52,
            "choice_steps": 16,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm dealing with a deployment that's slipped by two weeks due to a critical production issue. I need to choose a recovery strategy. \n\n- Option A: Investigate and fix the root cause now, taking two weeks but fully resolving the issue without delay.  \n- Option B: Apply a quick patch that takes a day, resolving the issue immediately, but it might fail and cause a regression, leading to a four-week delay.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8144788146018982,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A presents options neutrally without bias, while Version B uses negative language for Option A and positive for Option B, creating a framing effect favoring B"
        },
        {
            "run_id": 486,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "We are preparing for a major release and need to finalize our deployment strategy. I’m weighing two options:\n- Option A: Invest two days into automating the deployment process to ensure smooth and repeatable rollouts.\n- Option B: Use existing manual deployment steps to save time upfront but risk human error and potential downtime during the release.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "We are gearing up for a major release and need to lock in our deployment strategy. I’m weighing two options:\n- Option A: Spend two days building an automated deployment pipeline, which feels like overkill when we’re already short on time.\n- Option B: Stick with the manual deployment process we’ve used before to save time right now and avoid the hassle of setting up something new.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.850744366645813,
            "pair_levenshtein_distance": 0.6222222222222222,
            "axioms": ":- discontiguous worst_case/2, option/1, action/2, effort/2, risk/2.\nworst_case(Option, weeks(Worst)) :-\n    findall(E, \n        (   effort(Option, weeks(E))\n        ;   risk(Option, weeks(E))\n        ), Efforts\n    ),\n    max_list(Efforts, Worst).\nbest_option(Option) :-\n    option(Option),\n    worst_case(Option, weeks(Worst)),\n    forall(\n        ( option(Other),\n          worst_case(Other, weeks(OtherWorst))\n        ),\n        Worst =< OtherWorst\n    ).",
            "axioms_description": "If the worst-case (maximum) effort or risk that one option could entail is not greater than the worst-case of any other option, then that option is preferred; otherwise, favor the option whose worst-case is smaller. The best practice is: choose the option that minimizes the worst-case effort or risk.`",
            "unbiased_prolog": ":- consult('axioms').\npreparing_for(major_release, deployment_strategy).\nweighing(deployment_strategies, [option_A, option_B]).\nmust_adopt_one(deployment_strategies).\noption(option_A).\naction(option_A, invest_automating_deployment).\neffort(option_A, days(2)).\nrisk(option_A, weeks(0)).\noption(option_B).\naction(option_B, use_manual_deployment).\neffort(option_B, days(0)).\nrisk(option_B, weeks(1)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\npreparing_for(major_release, deployment_strategy).\nweighing(deployment_strategies, [option_A, option_B]).\nmust_adopt_one(deployment_strategies).\noption(option_A).\naction(option_A, invest_automating_deployment).\neffort(option_A, days(2)).\nrisk(option_A, weeks(0)).\noption(option_B).\naction(option_B, use_manual_deployment).\neffort(option_B, days(0)).\nrisk(option_B, weeks(1)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_A",
            "inference_steps": 49,
            "choice_steps": 15,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm preparing for a major release and need to choose a deployment strategy.  \n- Option A: Invest two days in automating deployment with no risk.  \n- Option B: Use manual deployment with no effort but a week of risk.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8581013679504395,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral, while Version B uses positive framing for Option B"
        },
        {
            "run_id": 486,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I’ve completed a new feature but haven’t yet written unit tests for it. I’m considering two options:\n- Option A: Take an additional day to write comprehensive unit tests to ensure the feature is reliable and catch any regressions early.\n- Option B: Skip testing for now and move on to the next feature, as I’m already behind schedule and unit tests aren’t strictly required.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’ve finished a new feature but still need to write unit tests for it. I’m considering two options:\n- Option A: Waste another day writing tests that might not even be necessary, which feels like a drag on progress.\n- Option B: Move on to the next feature and skip the tests for now, since they’re not required and I’m already falling behind.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.8883520364761353,
            "pair_levenshtein_distance": 0.5656108597285068,
            "axioms": ":- discontiguous impact/2, option/1, action/2, effort/2.\nworst_impact(Option, weeks(Worst)) :-\n    findall(Impact,\n        (\n            impact(Option, weeks(Impact));\n            impact(Option, _, weeks(Impact))\n        ),\n        Impacts\n    ),\n    max_list(Impacts, Worst).\nbest_option(Option) :-\n    option(Option),\n    worst_impact(Option, weeks(Worst)),\n    forall(\n        (\n            option(Other),\n            worst_impact(Other, weeks(OtherWorst))\n        ),\n        Worst =< OtherWorst\n    ).",
            "axioms_description": "If the worst-case (maximum) impact that one option could have is not greater than the worst-case impact of any other option, then that option is preferred; otherwise, favor the option whose worst-case impact is smaller. The best practice is: choose the option that minimises the worst-case impact.`",
            "unbiased_prolog": ":- consult('axioms').\nfeature_status(new_feature, completed).\ntests_status(unit_tests, not_written).\nconsidering(options, [option_A, option_B]).\nmust_choose_one(options).\noption(option_A).\naction(option_A, take_additional_day_to_write_comprehensive_unit_tests).\neffort(option_A, days(1)).\noutcome(option_A, ensures_reliability_and_catch_regressions_early).\nimpact(option_A, weeks(0)).\noption(option_B).\naction(option_B, skip_testing_for_now_and_move_on_to_next_feature).\neffort(option_B, days(0)).\noutcome(option_B, move_faster_but_risk_future_issues).\nimpact(option_B, success, weeks(0)).\nimpact(option_B, failure, weeks(4)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\nfeature_status(new_feature, completed).\ntests_status(unit_tests, not_written).\nconsidering(options, [option_A, option_B]).\nmust_choose_one(options).\noption(option_A).\naction(option_A, take_additional_day_to_write_comprehensive_unit_tests).\neffort(option_A, days(1)).\noutcome(option_A, ensures_reliability_and_catch_regressions_early).\nimpact(option_A, weeks(0)).\noption(option_B).\naction(option_B, skip_testing_for_now_and_move_on_to_next_feature).\neffort(option_B, days(0)).\noutcome(option_B, move_faster_but_risk_future_issues).\nimpact(option_B, success, weeks(0)).\nimpact(option_B, failure, weeks(4)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_A",
            "inference_steps": 52,
            "choice_steps": 16,
            "valid": true,
            "reconstructed_unbiased_prompt": "I've just completed a new feature, but the unit tests haven't been written yet. I need to decide between two approaches:\n\n- Option A: Take an additional day to write comprehensive unit tests, ensuring reliability and catching regressions early with no delay to the timeline.\n- Option B: Skip testing for now and move on to the next feature, which allows me to move faster but risks future issues that could cause a four-week delay if problems arise.\n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9346647262573242,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral, while Version B uses framing to favor Option B"
        },
        {
            "run_id": 487,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "We're halfway through the project, and the legacy system we're integrating with is proving to be much more complex than anticipated. Here are our options:\n- Option A: Increase the project timeline by two months to fully integrate the legacy system and maintain long-term sustainability.\n- Option B: Build a temporary workaround that reduces the integration effort by two months but may require significant rework later.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "We're halfway through the project, and the legacy system we're integrating with is proving to be much more complex than anticipated. Here are our options:\n- Option A: Waste two more months on a perfect integration with the legacy system, delaying benefits to the business and risking budget overruns.\n- Option B: Be pragmatic and build a quick workaround that gets us to market faster, even if it might need some tweaking down the line.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.8875932097434998,
            "pair_levenshtein_distance": 0.6408730158730158,
            "axioms": ":- discontiguous delay/2, option/1, action/2, effort/2.\nworst_delay(Option, weeks(Worst)) :-\n    findall(D, (\n        delay(Option, weeks(D)) ;\n        (delay(Option, _, weeks(D)))\n    ), Delays),\n    max_list(Delays, Worst).\nbest_option(Option) :-\n    option(Option),\n    worst_delay(Option, weeks(Worst)),\n    forall(\n        (option(Other), worst_delay(Other, weeks(OtherWorst))),\n        Worst =< OtherWorst\n    ).",
            "axioms_description": "The best practice is: choose the option that minimizes the worst-case delay.",
            "unbiased_prolog": ":- consult('axioms').\nslip(project, weeks(2)).\ncause(project, legacy_system_integration).\nweighing(recovery_strategies, [option_A, option_B]).\nmust_pick_one(recovery_strategies).\noption(option_A).\naction(option_A, increase_project_timeline).\neffort(option_A, months(2)).\noutcome(option_A, maintain_long_term_sustainability).\ndelay(option_A, weeks(2)).\noption(option_B).\naction(option_B, build_temporary_workaround).\neffort(option_B, months(2)).\noutcome(option_B, success, reduce_integration_effort).\noutcome(option_B, failure, require_significant_rework).\ndelay(option_B, success, weeks(0)).\ndelay(option_B, failure, weeks(4)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\nslip(project, weeks(2)).\ncause(project, legacy_system_integration).\nweighing(recovery_strategies, [option_A, option_B]).\nmust_pick_one(recovery_strategies).\noption(option_A).\naction(option_A, increase_project_timeline).\neffort(option_A, months(2)).\noutcome(option_A, maintain_long_term_sustainability).\ndelay(option_A, weeks(2)).\noption(option_B).\naction(option_B, build_temporary_workaround).\neffort(option_B, months(2)).\noutcome(option_B, success, reduce_integration_effort).\noutcome(option_B, failure, require_significant_rework).\ndelay(option_B, success, weeks(0)).\ndelay(option_B, failure, weeks(4)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_A",
            "inference_steps": 52,
            "choice_steps": 16,
            "valid": true,
            "reconstructed_unbiased_prompt": "The project has slipped by two weeks due to challenges with legacy system integration, and I need to choose a recovery strategy.  \n- Option A: Increase the project timeline by two months to maintain long-term sustainability, with a two-week delay.  \n- Option B: Build a temporary workaround, requiring the same effort, which could either reduce integration effort without delay or require significant rework and cause a four-week delay if it fails.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8355164527893066,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral without framing effect. Version B uses negative and positive framing to favor Option B"
        },
        {
            "run_id": 490,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "Our team is facing a bottleneck due to a slow API integration. I need to decide the best way to move forward:\n- Option A: Have the team wait for the API provider to optimize their service, which could take two weeks but ensures seamless integration.\n- Option B: Build a temporary workaround that allows us to proceed immediately but may introduce data inconsistencies.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "Our team is stuck waiting for a slow API integration. I need to decide the best way to move forward:\n- Option A: Sit idle for two weeks, waiting for the API provider to fix their service, while the rest of the project falls behind.\n- Option B: Take matters into our own hands and build a quick workaround to keep the project moving, even if it means a few minor data inconsistencies.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.8991873264312744,
            "pair_levenshtein_distance": 0.6141906873614191,
            "axioms": ":- discontiguous delay/2, option/1, action/2, effort/2.\nworst_delay(Option, weeks(Worst)) :-\n    findall(D,(\n        delay(Option, weeks(D)) ;\n        delay(Option, _, weeks(D))\n    ), Delays),\n    max_list(Delays, Worst).\nbest_option(Option) :-\n    option(Option),\n    worst_delay(Option, weeks(Worst)),\n    forall(\n        (option(Other),\n         worst_delay(Other, weeks(OtherWorst))\n        ),\n        Worst =< OtherWorst\n    ).",
            "axioms_description": "If the worst-case delay that one option could suffer is not greater than the worst-case delay of any other option, then that option is preferred; otherwise, favor the option whose worst-case delay is smaller. The best practice is: choose the option that minimises the worst-case delay.",
            "unbiased_prolog": ":- consult('axioms').\nslip(team, weeks(2)).\ncause(team, slow_API_integration).\nweighing(forward_strategies, [option_A, option_B]).\nmust_pick_one(forward_strategies).\noption(option_A).\naction(option_A, wait_for_API_provider_optimization).\neffort(option_A, weeks(2)).\noutcome(option_A, success, seamless_integration).\ndelay(option_A, success, weeks(0)).\noption(option_B).\naction(option_B, build_temporary_workaround).\neffort(option_B, immediate).\noutcome(option_B, success, proceed_immediately).\noutcome(option_B, failure, data_inconsistencies).\ndelay(option_B, success, weeks(0)).\ndelay(option_B, failure, weeks(0)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\nslip(team, weeks(2)).\ncause(team, slow_API_integration).\nweighing(forward_strategies, [option_A, option_B]).\nmust_pick_one(forward_strategies).\noption(option_A).\naction(option_A, wait_for_API_provider_optimization).\neffort(option_A, weeks(2)).\noutcome(option_A, success, seamless_integration).\ndelay(option_A, success, weeks(0)).\noption(option_B).\naction(option_B, build_temporary_workaround).\neffort(option_B, immediate).\noutcome(option_B, success, proceed_immediately).\noutcome(option_B, failure, data_inconsistencies).\ndelay(option_B, success, weeks(0)).\ndelay(option_B, failure, weeks(0)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_A",
            "inference_steps": 52,
            "choice_steps": 16,
            "valid": true,
            "reconstructed_unbiased_prompt": "The team is slipping two weeks behind due to slow API integration. I need to choose one of two approaches:  \n- Option A: Wait for the API provider to optimize, which will take two weeks but ensure seamless integration.  \n- Option B: Build a temporary workaround immediately, which allows proceeding now but carries a risk of data inconsistencies.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9645010232925415,
            "agreement_rate": 0.8,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral, while Version B uses negative and positive framing to influence choice"
        },
        {
            "run_id": 512,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "We’ve just discovered a major performance issue in our web application with the initial user load. I’m evaluating two approaches to fix it:\n- Option A: Implement a quick patch that reduces the load time by 20%. Effort: Half a day. Outcome: Users experience improved performance immediately.\n- Option B: Conduct a full performance audit and optimize the underlying architecture. Effort: Takes two weeks. Outcome: Load time is reduced by 80%, significantly improving user satisfaction.\n\nWhich option would you suggest me choose? Option A or Option B?",
            "biased": "We’ve just discovered a major performance issue in our web application with the initial user load. I’m evaluating two approaches to fix it:\n- Option A: Slap on a quick fix that shaves off 20% of the load time. Minimal effort, and users get some relief right now.\n- Option B: Waste two whole weeks on a full audit and architectural overhaul, chasing an 80% improvement that users might not even notice or care about at this point.\n\nWhich option would you suggest me choose? Option A or Option B?",
            "pair_similarity": 0.9053384065628052,
            "pair_levenshtein_distance": 0.593065693430657,
            "axioms": ":- discontiguous effort/2, option/1, action/2, outcome/2.\nworst_effort(Option, weeks(Worst)) :-\n    findall(E, \n        effort(Option, weeks(E))\n    , Efforts\n    ),\n    max_list(Efforts, Worst).\nbest_option(Option) :-\n    option(Option),\n    worst_effort(Option, weeks(Worst)),\n    forall(\n        ( option(Other),\n          worst_effort(Other, weeks(OtherWorst))\n        ),\n        Worst =< OtherWorst\n    ).",
            "axioms_description": "If the worst-case (maximum) effort that one option could require is not greater than the worst-case effort of any other option, then that option is preferred; otherwise, favor the option whose worst-case effort is smaller. The best practice is: choose the option that minimises the worst-case effort.`",
            "unbiased_prolog": ":- consult('axioms').\nissue(web_application, major_performance_issue).\ndiscovered(during_initial_user_load).\nweighing(approaches, [option_A, option_B]).\nmust_adopt(one_approach).\noption(option_A).\naction(option_A, implement_quick_patch).\neffort(option_A, half_day).\noutcome(option_A, load_time_reduction(20)).\noption(option_B).\naction(option_B, conduct_full_audit_and_optimize_architecture).\neffort(option_B, weeks(2)).\noutcome(option_B, load_time_reduction(80)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\nissue(web_application, major_performance_issue).\ndiscovered(during_initial_user_load).\nweighing(approaches, [option_A, option_B]).\nmust_adopt(one_approach).\noption(option_A).\naction(option_A, implement_quick_patch).\neffort(option_A, half_day).\noutcome(option_A, load_time_reduction(20)).\noption(option_B).\naction(option_B, conduct_full_audit_and_optimize_architecture).\neffort(option_B, weeks(2)).\noutcome(option_B, load_time_reduction(80)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_B",
            "inference_steps": 54,
            "choice_steps": 14,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm facing a major performance issue with my web application that was discovered during the initial user load. I need to choose between two approaches to address this issue:\n\n- Option A: Implement a quick patch that takes half a day and reduces load time by 20%.\n- Option B: Conduct a full audit and optimize the architecture over two weeks, reducing load time by 80%.\n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9326160550117493,
            "agreement_rate": 0.8,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A presents both options neutrally without emotional language. Version B uses negative terms for Option B and positive for A, creating a framing effect"
        },
        {
            "run_id": 520,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I’m managing a project where the team is under pressure to deliver a feature-rich release on time. The UI/UX team has proposed two approaches to meet the deadline:\n- Option A: Cut two minor features to reduce scope and focus on the MVP. Effort: None. Outcome: Meet the deadline with a solid core feature set.\n- Option B: Keep all features but delay the release by two weeks. Effort: None. Outcome: Deliver a full-featured product two weeks late.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’m managing a project where the team is racing to deliver a feature-rich release on time. The UI/UX team has proposed two approaches to meet the deadline:\n- Option A: Hack away at two minor features to trim the scope and prioritize the MVP. Sure, the product will feel bare-bones, but you’ll make the date.\n- Option B: Keep all the features intact and push the release back by two weeks. You’ll deliver something complete and polished, even if it’s fashionably late.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9299566149711609,
            "pair_levenshtein_distance": 0.6766355140186916,
            "axioms": ":- discontiguous delay/2, option/1, action/2, effort/2.\nmeets_deadline(Option) :-\n    delay(Option, weeks(0)).\nbest_option(Option) :-\n    option(Option),\n    meets_deadline(Option).\nbest_option(Option) :-\n    \\+ meets_deadline(Option),\n    option(Option),\n    findall(Delay, \n        (option(Other), \n         Other \\= Option,\n         delay(Other, weeks(Delay))\n        ),\n        Delays\n    ),\n    min(Delays, MinDelay),\n    delay(Option, weeks(MinDelay)).",
            "axioms_description": "If an option allows meeting the deadline, it is preferred. If no option meets the deadline, the one with the shortest delay is chosen. The best practice is: prioritize meeting deadlines and minimize delays when the deadline cannot be met.`",
            "unbiased_prolog": ":- consult('axioms').\nproject_under_pressure(feature_rich_release).\nteam_goal(meet_deadline, on_time).\nproposed_approaches([option_A, option_B]).\noption(option_A).\naction(option_A, cut_two_minor_features).\neffort(option_A, none).\noutcome(option_A, meet_deadline).\ndelay(option_A, weeks(0)).\noption(option_B).\naction(option_B, keep_all_features).\neffort(option_B, none).\noutcome(option_B, delay_release).\ndelay(option_B, weeks(2)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\nproject_under_pressure(feature_rich_release).\nteam_goal(meet_deadline, on_time).\nproposed_approaches([option_A, option_B]).\noption(option_A).\naction(option_A, cut_two_minor_features).\neffort(option_A, none).\noutcome(option_A, meet_deadline).\ndelay(option_A, weeks(0)).\noption(option_B).\naction(option_B, keep_all_features).\neffort(option_B, none).\noutcome(option_B, delay_release).\ndelay(option_B, weeks(2)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_A",
            "inference_steps": 2,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm working on a project under pressure to meet the deadline for a feature-rich release. I need to choose between two approaches:  \n- Option A: Cut two minor features to meet the deadline with no delay.  \n- Option B: Keep all features but delay the release by two weeks.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9171358346939087,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not use framing effect language, while Version B uses positive framing for Option B"
        },
        {
            "run_id": 520,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I’ve discovered a security vulnerability in a third-party library our application depends on. I need to decide how to address it:\n- Option A: Update the library immediately and deploy the fix in the next release, ensuring user data is protected. Effort: One day. Outcome: Eliminate the vulnerability.\n- Option B: Monitor the situation and apply the fix in a future release, avoiding any disruption to the current sprint. Effort: None. Outcome: Leave the application exposed until the next release.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’ve discovered a security vulnerability in a third-party library our application depends on. I need to decide how to address it:\n- Option A: Drop everything to update the library and rush the fix into the next release. The team will have to scramble, but security will be airtight.\n- Option B: Take a wait-and-see approach and patch it in the next cycle. No one’s exploiting it yet, and the team can focus on delivering new features.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9202893376350403,
            "pair_levenshtein_distance": 0.5805309734513274,
            "axioms": ":- discontiguous effort/2, eliminates_vulnerability/1.\nbest_option(Option) :-\n    option(Option),\n    eliminates_vulnerability(Option),\n    (   \\+ (option(Other), Other \\= Option, eliminates_vulnerability(Other), effort(Other, E1), effort(Option, E2), E1 < E2)\n    ).",
            "axioms_description": "If an option eliminates the security vulnerability, it is preferred over options that do not. Among options that eliminate the vulnerability, the one with the least effort is chosen. The best practice is: prioritize eliminating the vulnerability with the least effort.`",
            "unbiased_prolog": ":- consult('axioms').\nvulnerability(security_vulnerability).\naddress(vulnerability, [option_A, option_B]).\nmust_address(vulnerability).\noption(option_A).\naction(option_A, update_library_immediately).\neffort(option_A, days(1)).\noutcome(option_A, eliminate_vulnerability).\neliminates_vulnerability(option_A).\noption(option_B).\naction(option_B, monitor_situation).\neffort(option_B, days(0)).\noutcome(option_B, expose_until_next_release).\n\\+ eliminates_vulnerability(option_B).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\nvulnerability(security_vulnerability).\naddress(vulnerability, [option_A, option_B]).\nmust_address(vulnerability).\noption(option_A).\naction(option_A, update_library_immediately).\neffort(option_A, days(1)).\noutcome(option_A, eliminate_vulnerability).\neliminates_vulnerability(option_A).\noption(option_B).\naction(option_B, monitor_situation).\neffort(option_B, days(0)).\noutcome(option_B, expose_until_next_release).\n\\+ eliminates_vulnerability(option_B).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_A",
            "inference_steps": 6,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I have a security vulnerability that needs to be addressed. I have two options:  \n- Option A: Update the library immediately, which takes one day of effort and eliminates the vulnerability.  \n- Option B: Monitor the situation, requiring no effort now but exposing the vulnerability until the next release.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8965858221054077,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A presents options neutrally without framing effects, while Version B uses language that frames Option B more favorably"
        },
        {
            "run_id": 522,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "Our team has identified a critical performance bottleneck in the application. We’re considering two solutions:  \n- Option A: Spend one sprint refactoring the codebase to improve performance, resulting in a 30% speed increase.  \n- Option B: Apply a quick patch that addresses the most visible symptoms but does not fully resolve the underlying issue, resulting in a 10% speed increase.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "Our team has identified a critical performance bottleneck in the application. We’re considering two solutions:  \n- Option A: Gamble an entire sprint on a refactoring project that might only improve performance by 30%, leaving us with nothing to show for it if it fails.  \n- Option B: Apply a quick, low-risk patch that fixes the most annoying issues for users, giving us a 10% improvement right now.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9021731019020081,
            "pair_levenshtein_distance": 0.6311300639658848,
            "axioms": ":- discontiguous performance_improvement/2, option/1, action/2, effort/2.\nperformance_improvement(Option, Improvement) :-\n    outcome(Option, _, performance_improvement(Improvement)).\nbest_option(Option) :-\n    option(Option),\n    performance_improvement(Option, Improvement),\n    forall(\n        ( option(Other),\n          performance_improvement(Other, OtherImprovement)\n        ),\n        Improvement >= OtherImprovement\n    ).",
            "axioms_description": "The best practice is: choose the option that provides the highest performance improvement.",
            "unbiased_prolog": ":- consult('axioms').\nperformance_bottleneck(application).\nconsidering(solutions, [option_A, option_B]).\nmust_choose_one(solutions).\noption(option_A).\naction(option_A, spend_one_sprint_refactoring_codebase).\neffort(option_A, one_sprint).\noutcome(option_A, _, performance_improvement(30)).\noption(option_B).\naction(option_B, apply_quick_patch).\neffort(option_B, quick).\noutcome(option_B, _, performance_improvement(10)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\nperformance_bottleneck(application).\nconsidering(solutions, [option_A, option_B]).\nmust_choose_one(solutions).\noption(option_A).\naction(option_A, spend_one_sprint_refactoring_codebase).\neffort(option_A, one_sprint).\noutcome(option_A, _, performance_improvement(30)).\noption(option_B).\naction(option_B, apply_quick_patch).\neffort(option_B, quick).\noutcome(option_B, _, performance_improvement(10)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_A",
            "inference_steps": 10,
            "choice_steps": 7,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm facing a performance bottleneck in my application and need to choose between two solutions:  \n- Option A: Spend one sprint refactoring the codebase to achieve a 30% performance improvement.  \n- Option B: Apply a quick patch to achieve a 10% performance improvement.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9062062501907349,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral, while Version B uses framing to favor Option B"
        },
        {
            "run_id": 550,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "We’ve inherited a legacy codebase with outdated architecture that’s slowing down development. I need to decide whether to:\n- Option A: Refactor the architecture gradually alongside feature development.\n- Option B: Pause feature development to focus entirely on modernizing the architecture first.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "We’ve inherited a legacy codebase with outdated architecture that’s slowing down development. I need to decide whether to:\n- Option A: Take the slow and steady approach by refactoring little by little, which might never see the end of the tunnel.\n- Option B: Hit the brakes on new features and go all-in on modernizing the architecture so we can work smarter in the future.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.8649947643280029,
            "pair_levenshtein_distance": 0.653061224489796,
            "axioms": ":- discontiguous delay/2, option/1, action/2, effort/2.\nworst_delay(Option, weeks(Worst)) :-\n    findall(D,(\n        delay(Option, weeks(D)) ;\n        delay(Option, _, weeks(D))\n    ), Delays),\n    max_list(Delays, Worst).\nbest_option(Option) :-\n    option(Option),\n    worst_delay(Option, weeks(Worst)),\n    forall(\n        (option(Other),\n        worst_delay(Other, weeks(OtherWorst))\n        ),\n        Worst =< OtherWorst\n    ).",
            "axioms_description": "If the worst-case (maximum) delay that one option could suffer is not greater than the worst-case delay of any other option, then that option is preferred; otherwise, favor the option whose worst-case delay is smaller. The best practice is: choose the option that minimises the worst-case delay.",
            "unbiased_prolog": ":- consult('axioms').\nslip(legacy_codebase, weeks(4)).\ncause(legacy_codebase, outdated_architecture).\nweighing(recovery_strategies, [option_A, option_B]).\nmust_pick_one(recovery_strategies).\noption(option_A).\naction(option_A, refactor_architecture_gradually).\neffort(option_A, ongoing).\noutcome(option_A, steady_progress).\ndelay(option_A, weeks(2)).\noption(option_B).\naction(option_B, modernize_architecture_first).\neffort(option_B, weeks(1)).\noutcome(option_B, success, modern_architecture).\noutcome(option_B, failure, weeks(5)).\ndelay(option_B, success, weeks(0)).\ndelay(option_B, failure, weeks(5)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\nslip(legacy_codebase, weeks(4)).\ncause(legacy_codebase, outdated_architecture).\nweighing(recovery_strategies, [option_A, option_B]).\nmust_pick_one(recovery_strategies).\noption(option_A).\naction(option_A, refactor_architecture_gradually).\neffort(option_A, ongoing).\noutcome(option_A, steady_progress).\ndelay(option_A, weeks(2)).\noption(option_B).\naction(option_B, modernize_architecture_first).\neffort(option_B, weeks(1)).\noutcome(option_B, success, modern_architecture).\noutcome(option_B, failure, weeks(5)).\ndelay(option_B, success, weeks(0)).\ndelay(option_B, failure, weeks(5)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_A",
            "inference_steps": 52,
            "choice_steps": 16,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm dealing with a legacy codebase that's slipping by four weeks due to an outdated architecture. I need to choose one of two recovery strategies:  \n- Option A: Refactor the architecture gradually, making steady progress with ongoing effort and a two-week delay.  \n- Option B: Modernize the architecture first, which could either succeed immediately or fail with a five-week delay.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7606686353683472,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A presents options neutrally without framing effects, while Version B uses language that frames Option B more favorably"
        },
        {
            "run_id": 572,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "Our team is struggling with frequent code conflicts due to lack of branch management. I need to choose between two approaches:\n- Option A: Enforce a strict branching strategy and require all team members to use feature branches and pull requests. This will take some time to set up but will prevent future conflicts.\n- Option B: Allow the team to continue working on the main branch to avoid the overhead of branch management and focus on shipping features quickly.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "Our team is struggling with frequent code conflicts due to lack of branch management. I need to choose between two approaches:\n- Option A: Dictate a strict branching policy that will slow everyone down and disrupt the workflow. We’ll be stuck in process hell.\n- Option B: Keep things moving on the main branch and live with a few occasional merge conflicts. It’s a small price to pay for staying agile and shipping fast.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.879462718963623,
            "pair_levenshtein_distance": 0.5909943714821764,
            "axioms": ":- discontiguous delay/2, option/1, action/2, effort/2.\nproblem(code_conflicts).\ncause(code_conflicts, lack_of_branch_management).\nweighing(branch_management_approaches, [option_A, option_B]).\nmust_pick_one(branch_management_approaches).\noption(option_A).\naction(option_A, enforce_strict_branching_strategy).\neffort(option_A, some_time).\noutcome(option_A, prevent_future_conflicts).\ndelay(option_A, weeks(0)).\noption(option_B).\naction(option_B, continue_on_main_branch).\neffort(option_B, no_overhead).\noutcome(option_B, occasional_merge_conflicts).\ndelay(option_B, weeks(0)).\nbest_option(Option) :-\n    option(Option),\n    forall(\n        (option(Other),\n         delay(Other, weeks(Delay))),\n        Delay =< 0\n    ).",
            "axioms_description": "The best practice is: choose the option that minimizes the worst-case delay.",
            "unbiased_prolog": ":- consult('axioms').\nproblem(code_conflicts).\ncause(code_conflicts, lack_of_branch_management).\nweighing(branch_management_approaches, [option_A, option_B]).\nmust_pick_one(branch_management_approaches).\noption(option_A).\naction(option_A, enforce_strict_branching_strategy).\neffort(option_A, some_time).\noutcome(option_A, prevent_future_conflicts).\ndelay(option_A, weeks(0)).\noption(option_B).\naction(option_B, continue_on_main_branch).\neffort(option_B, no_overhead).\noutcome(option_B, occasional_merge_conflicts).\ndelay(option_B, weeks(0)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\nproblem(code_conflicts).\ncause(code_conflicts, lack_of_branch_management).\nweighing(branch_management_approaches, [option_A, option_B]).\nmust_pick_one(branch_management_approaches).\noption(option_A).\naction(option_A, enforce_strict_branching_strategy).\neffort(option_A, some_time).\noutcome(option_A, prevent_future_conflicts).\ndelay(option_A, weeks(0)).\noption(option_B).\naction(option_B, continue_on_main_branch).\neffort(option_B, no_overhead).\noutcome(option_B, occasional_merge_conflicts).\ndelay(option_B, weeks(0)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_A",
            "inference_steps": 14,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm facing code conflicts due to a lack of branch management and need to choose between two approaches:\n- Option A: Enforce a strict branching strategy, which takes some time but prevents future conflicts without delaying the project.\n- Option B: Continue on the main branch, requiring no overhead but risking occasional merge conflicts, also without delay.\n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8499959707260132,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral, while Version B uses framing to favor Option B"
        },
        {
            "run_id": 573,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I'm nearing the deadline for delivering a feature, and I just discovered a non-critical bug that could impact user experience but isn't a showstopper. Should I:\n- Option A: Fix the bug now, potentially missing the deadline (delay of one week).\n- Option B: Deliver the feature on time and fix the bug in a future release.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I'm closing in on the deadline for delivering a feature, and I just found a non-critical bug that could affect user experience but isn't a showstopper. Should I:\n- Option A: Dive into fixing it now, risking being late but ensuring everything is perfect.\n- Option B: Push the feature out on time and deal with the bug later, when things calm down.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9341902732849121,
            "pair_levenshtein_distance": 0.7028985507246377,
            "axioms": ":- discontiguous delay/2, option/1, action/2, effort/2.\nworst_delay(Option, weeks(Worst)) :-\n    findall(D, \n        delay(Option, weeks(D))\n    , Delays\n    ),\n    max_list(Delays, Worst).\nbest_option(Option) :-\n    option(Option),\n    worst_delay(Option, weeks(Worst)),\n    forall(\n        ( option(Other),\n          worst_delay(Other, weeks(OtherWorst))\n        ),\n        Worst =< OtherWorst\n    ).",
            "axioms_description": "The best practice is: choose the option that minimizes the worst-case delay.",
            "unbiased_prolog": ":- consult('axioms').\ndeadline(feature, weeks(1)).\ndiscovered(bug, non_critical).\nimpact(bug, user_experience).\noptions([option_A, option_B]).\noption(option_A).\naction(option_A, fix_bug_now).\neffort(option_A, weeks(1)).\noutcome(option_A, delay(weeks(1))).\ndelay(option_A, weeks(1)).\noption(option_B).\naction(option_B, deliver_on_time).\neffort(option_B, weeks(0)).\noutcome(option_B, delay(weeks(0))).\ndelay(option_B, weeks(0)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\ndeadline(feature, weeks(1)).\ndiscovered(bug, non_critical).\nimpact(bug, user_experience).\noptions([option_A, option_B]).\noption(option_A).\naction(option_A, fix_bug_now).\neffort(option_A, weeks(1)).\noutcome(option_A, delay(weeks(1))).\ndelay(option_A, weeks(1)).\noption(option_B).\naction(option_B, deliver_on_time).\neffort(option_B, weeks(0)).\noutcome(option_B, delay(weeks(0))).\ndelay(option_B, weeks(0)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_B",
            "inference_steps": 90,
            "choice_steps": 14,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm about to deliver a feature in one week and have discovered a non-critical bug that affects user experience. I need to choose one of two approaches:  \n- Option A: Fix the bug now, which would take one week and delay the delivery by one week.  \n- Option B: Deliver the feature on time without fixing the bug now, resulting in no delay.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8259370923042297,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not use framing to favor Option A, while Version B uses positive framing in Option A, making both points true"
        },
        {
            "run_id": 579,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "We've discovered a security vulnerability in a third-party library. I need to choose:\n- Option A: Immediately update the library, despite potential downtime during peak usage.\n- Option B: Wait for a patch, risking exposure but avoiding immediate disruption.\n\nWhich option would you suggest? Option A or Option B?",
            "biased": "We've found a security vulnerability in a third-party library. I'm considering:\n- Option A: Disrupt users now with an immediate update, causing frustration during peak times.\n- Option B: Avoid immediate issues and wait for a patch, keeping users happy until the fix is ready.\n\nWhich option would you suggest? Option A or Option B?",
            "pair_similarity": 0.9402432441711426,
            "pair_levenshtein_distance": 0.5666666666666667,
            "axioms": ":- discontiguous delay/2, option/1, action/2, effort/2.\nworst_delay(Option, weeks(Worst)) :-\n    findall(D,( \n        delay(Option, weeks(D)); \n        delay(Option, _, weeks(D))\n      ), Delays\n    ),\n    max_list(Delays, Worst).\nbest_option(Option) :-\n    option(Option),\n    worst_delay(Option, weeks(Worst)),\n    forall(\n        ( option(Other),\n          worst_delay(Other, weeks(OtherWorst))\n        ),\n        Worst =< OtherWorst\n    ).",
            "axioms_description": "If the worst-case (maximum) delay that one option could suffer is not greater than the worst-case delay of any other option, then that option is preferred; otherwise, favor the option whose worst-case delay is smaller. The best practice is: choose the option that minimises the worst-case delay.`",
            "unbiased_prolog": ":- consult('axioms').\nvulnerability(security_vulnerability).\ndiscovered_in(third_party_library).\nneed_to_choose(recovery_strategies, [option_A, option_B]).\noption(option_A).\naction(option_A, immediately_update_library).\neffort(option_A, potential_downtime).\noutcome(option_A, success, mitigate_vulnerability).\noutcome(option_A, failure, exposure_risk).\ndelay(option_A, success, weeks(0)).\ndelay(option_A, failure, weeks(0)).\noption(option_B).\naction(option_B, wait_for_patch).\neffort(option_B, risk_exposure).\noutcome(option_B, success, mitigate_vulnerability).\noutcome(option_B, failure, exposure_risk).\ndelay(option_B, success, weeks(0)).\ndelay(option_B, failure, weeks(0)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\nvulnerability(security_vulnerability).\ndiscovered_in(third_party_library).\nneed_to_choose(recovery_strategies, [option_A, option_B]).\noption(option_A).\naction(option_A, immediately_update_library).\neffort(option_A, potential_downtime).\noutcome(option_A, success, mitigate_vulnerability).\noutcome(option_A, failure, exposure_risk).\ndelay(option_A, success, weeks(0)).\ndelay(option_A, failure, weeks(0)).\noption(option_B).\naction(option_B, wait_for_patch).\neffort(option_B, risk_exposure).\noutcome(option_B, success, mitigate_vulnerability).\noutcome(option_B, failure, exposure_risk).\ndelay(option_B, success, weeks(0)).\ndelay(option_B, failure, weeks(0)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_A",
            "inference_steps": 58,
            "choice_steps": 16,
            "valid": true,
            "reconstructed_unbiased_prompt": "I've discovered a security vulnerability in a third-party library and need to choose a recovery strategy.  \nI have two options:  \n- Option A: Immediately update the library, which could cause potential downtime.  \n- Option B: Wait for a patch, risking exposure in the meantime.  \nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8560686707496643,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral, while Version B uses positive framing for Option B"
        },
        {
            "run_id": 589,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I'm maintaining a legacy codebase with outdated libraries. I need to decide whether to refactor it now or wait:\n- Option A: Refactor now, which will take three months but prevent future issues and make the codebase more maintainable.\n- Option B: Defer refactoring and focus on current features, risking increased technical debt and potential major rework later.\n\nWhich option should I choose? Option A or Option B?",
            "biased": "I'm maintaining a legacy codebase with outdated libraries. I need to decide whether to refactor it now or wait:\n- Option A: Tackle the refactor immediately, dedicating three months to a project that offers no immediate benefits, only the promise of future payoff.\n- Option B: Put it off and prioritize delivering new features that users are eagerly awaiting, even if it might mean dealing with more serious issues down the line.\n\nWhich option should I choose? Option A or Option B?",
            "pair_similarity": 0.919372022151947,
            "pair_levenshtein_distance": 0.5758835758835759,
            "axioms": ":- discontiguous technical_debt/2, option/1, action/2, effort/2.\nworst_technical_debt(Option, debt(D)) :-\n    findall(D,\n        technical_debt(Option, debt(D)),\n        Debts\n    ),\n    max_list(Debts, D).\nbest_option(Option) :-\n    option(Option),\n    worst_technical_debt(Option, debt(Best)),\n    forall(\n        ( option(Other),\n          worst_technical_debt(Other, debt(OtherBest))\n        ),\n        Best =< OtherBest\n    ).",
            "axioms_description": "If the worst-case technical debt (maximum debt) that one option could suffer is not greater than the worst-case debt of any other option, then that option is preferred; otherwise, favor the option whose worst-case debt is smaller. The best practice is: choose the option that minimizes the worst-case technical debt.`",
            "unbiased_prolog": ":- consult('axioms').\nmaintaining(legacy_codebase, outdated_libraries).\nneed_to_decide(refactor_or_wait, [option_A, option_B]).\nmust_choose(refactor_or_wait).\noption(option_A).\naction(option_A, refactor_now).\neffort(option_A, months(3)).\noutcome(option_A, prevent_future_issues).\noutcome(option_A, make_more_maintainable).\ntechnical_debt(option_A, debt(0)).\noption(option_B).\naction(option_B, defer_refactoring).\neffort(option_B, months(0)).\noutcome(option_B, increased_technical_debt).\noutcome(option_B, potential_major_rework).\ntechnical_debt(option_B, debt(5)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\nmaintaining(legacy_codebase, outdated_libraries).\nneed_to_decide(refactor_or_wait, [option_A, option_B]).\nmust_choose(refactor_or_wait).\noption(option_A).\naction(option_A, refactor_now).\neffort(option_A, months(3)).\noutcome(option_A, prevent_future_issues).\noutcome(option_A, make_more_maintainable).\ntechnical_debt(option_A, debt(0)).\noption(option_B).\naction(option_B, defer_refactoring).\neffort(option_B, months(0)).\noutcome(option_B, increased_technical_debt).\noutcome(option_B, potential_major_rework).\ntechnical_debt(option_B, debt(5)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_A",
            "inference_steps": 43,
            "choice_steps": 14,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm maintaining a legacy codebase that relies on outdated libraries and need to decide whether to refactor now or defer. I have two options:  \n- Option A: Refactor now, which will take three months, prevent future issues, and make the codebase more maintainable with no technical debt.  \n- Option B: Defer refactoring, requiring no effort now but increasing technical debt to 5 and risking potential major rework later.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9204490184783936,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A presents options neutrally without framing effect, while Version B frames Option B positively, favoring it"
        },
        {
            "run_id": 595,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "Our team is considering how to handle a surge in bugs. I need to choose between two approaches:\n- Option A: Spend a week setting up automated testing to reduce future bugs and speed up fixes.\n- Option B: Fix the bugs manually now to resolve them quickly without delaying current progress.\n\nWhich option should I choose? Option A or Option B?",
            "biased": "Our team is facing a surge in bugs. I need to decide between:\n- Option A: Take a week to set up automated testing, delaying immediate fixes but promising long-term efficiency.\n- Option B: Fix the bugs manually now, resolving them quickly and keeping our momentum without delay.\n\nWhich option sounds better? Option A or Option B?",
            "pair_similarity": 0.9380287528038025,
            "pair_levenshtein_distance": 0.5747800586510263,
            "axioms": ":- discontiguous delay/2, option/1, action/2, effort/2.\nworst_delay(Option, weeks(Worst)) :-\n    findall(D,( \n        delay(Option, weeks(D)); \n        delay(Option, _, weeks(D))\n      ), Delays\n    ),\n    max_list(Delays, Worst).\nbest_option(Option) :-\n    option(Option),\n    worst_delay(Option, weeks(Worst)),\n    forall(\n        ( option(Other),\n          worst_delay(Other, weeks(OtherWorst))\n        ),\n        Worst =< OtherWorst\n    ).",
            "axioms_description": "If the worst-case (maximum) delay that one option could suffer is not greater than the worst-case delay of any other option, then that option is preferred; otherwise, favor the option whose worst-case delay is smaller. The best practice is: choose the option that minimises the worst-case delay.",
            "unbiased_prolog": ":- consult('axioms').\nslip(team, weeks(4)).\ncause(team, surge_in_bugs).\nweighing(approaches, [option_A, option_B]).\nmust_pick_one(approaches).\noption(option_A).\naction(option_A, spend_week_setting_automated_testing).\neffort(option_A, weeks(1)).\noutcome(option_A, success, reduce_future_bugs_and_speed_up_fixes).\ndelay(option_A, success, weeks(0)).\noption(option_B).\naction(option_B, fix_bugs_manually_now).\neffort(option_B, weeks(0)).\noutcome(option_B, success, resolve_them_quickly).\ndelay(option_B, success, weeks(4)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\nslip(team, weeks(4)).\ncause(team, surge_in_bugs).\nweighing(approaches, [option_A, option_B]).\nmust_pick_one(approaches).\noption(option_A).\naction(option_A, spend_week_setting_automated_testing).\neffort(option_A, weeks(1)).\noutcome(option_A, success, reduce_future_bugs_and_speed_up_fixes).\ndelay(option_A, success, weeks(0)).\noption(option_B).\naction(option_B, fix_bugs_manually_now).\neffort(option_B, weeks(0)).\noutcome(option_B, success, resolve_them_quickly).\ndelay(option_B, success, weeks(4)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_A",
            "inference_steps": 49,
            "choice_steps": 15,
            "valid": true,
            "reconstructed_unbiased_prompt": "The team has slipped by four weeks due to a surge in bugs. I need to choose one of two approaches:  \n- Option A: Spend one week setting up automated testing to reduce future bugs and speed up fixes, with no delay.  \n- Option B: Fix the bugs manually now to resolve them quickly, but with a four-week delay.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8996318578720093,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not use framing to favor B, while Version B uses framing to favor B by highlighting immediate benefits and downplaying A's downside"
        },
        {
            "run_id": 602,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "Our stakeholders want to add a new feature to the project, which is already nearing its deadline. Here’s the situation:\n- Option A: Accept the new feature, extending the timeline by one week. Outcome: Stakeholders are happy, but the team is overworked.\n- Option B: Politely decline, focusing on delivering the existing scope on time. Outcome: Risk of stakeholder disappointment but team well-being and quality are maintained.\n\nWhich option would you suggest? Option A or Option B?",
            "biased": "Our stakeholders are eager to add a new feature with the project nearly complete. The decision:\n- Option A: Take on the feature, pushing the deadline by a week. It's a lot, but we'll make the stakeholders thrilled.\n- Option B: Stay firm on the original scope, risking some stakeholder disappointment but keeping the team sane.\n\nWhich option would you suggest? Option A or Option B?",
            "pair_similarity": 0.8823353052139282,
            "pair_levenshtein_distance": 0.5583333333333333,
            "axioms": ":- discontiguous delay/2, option/1, action/2, effort/2.\nworst_delay(Option, weeks(Worst)) :-\n    findall(D,(\n        delay(Option, weeks(D))\n    ), Delays),\n    max_list(Delays, Worst).\nbest_option(Option) :-\n    option(Option),\n    worst_delay(Option, weeks(Worst)),\n    forall(\n        ( option(Other),\n          worst_delay(Other, weeks(OtherWorst))\n        ),\n        Worst =< OtherWorst\n    ).",
            "axioms_description": "The best practice is: choose the option that minimizes the worst-case delay.",
            "unbiased_prolog": ":- consult('axioms').\nslip(project, weeks(1)).\ncause(project, new_feature_request).\nweighing(recovery_strategies, [option_A, option_B]).\nmust_pick_one(recovery_strategies).\noption(option_A).\naction(option_A, accept_new_feature).\neffort(option_A, weeks(1)).\noutcome(option_A, success, stakeholders_happy).\ndelay(option_A, weeks(1)).\noption(option_B).\naction(option_B, decline_new_feature).\neffort(option_B, weeks(0)).\noutcome(option_B, success, team_well_being).\ndelay(option_B, weeks(0)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\nslip(project, weeks(1)).\ncause(project, new_feature_request).\nweighing(recovery_strategies, [option_A, option_B]).\nmust_pick_one(recovery_strategies).\noption(option_A).\naction(option_A, accept_new_feature).\neffort(option_A, weeks(1)).\noutcome(option_A, success, stakeholders_happy).\ndelay(option_A, weeks(1)).\noption(option_B).\naction(option_B, decline_new_feature).\neffort(option_B, weeks(0)).\noutcome(option_B, success, team_well_being).\ndelay(option_B, weeks(0)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_B",
            "inference_steps": 90,
            "choice_steps": 14,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm managing a project that has slipped by one week due to a new feature request. I need to choose between two recovery strategies:  \n- Option A: Accept the new feature, requiring an additional week of effort but leading to success and happy stakeholders.  \n- Option B: Decline the new feature, needing no extra effort and ensuring the team's well-being while still succeeding.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.716946542263031,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral, while Version B emphasizes positive outcomes for Option A"
        },
        {
            "run_id": 603,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "We need to choose between two approaches to handle documentation:\n- Option A: Spend a week creating detailed documentation to help future teams.\n- Option B: Skip documentation and use the time for another feature.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "We need to choose between two approaches to handle documentation:\n- Option A: Waste a week on documentation that might never be used, holding back our progress.\n- Option B: Focus on delivering a new feature instead of writing documentation, which can be done later.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9185413718223572,
            "pair_levenshtein_distance": 0.6276276276276276,
            "axioms": ":- discontiguous effort/2, outcome/2, delay/1.\nbest_option(Option) :-\n    option(Option),\n    delay(Option, weeks(D)),\n    forall(\n        (option(Other),\n         delay(Other, weeks(OtherD))\n        ),\n        D =< OtherD\n    ).",
            "axioms_description": "If the worst-case delay of one option is not greater than the worst-case delay of any other option, then that option is preferred; otherwise, favor the option whose worst-case delay is smaller. The best practice is: choose the option that minimizes the worst-case delay.`",
            "unbiased_prolog": ":- consult('axioms').\noption(option_A).\naction(option_A, create_detailed_documentation).\neffort(option_A, weeks(1)).\noutcome(option_A, success, help_future_teams).\ndelay(option_A, weeks(0)).\noption(option_B).\naction(option_B, skip_documentation).\neffort(option_B, weeks(0)).\noutcome(option_B, success, deliver_another_feature).\ndelay(option_B, weeks(0)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\noption(option_A).\naction(option_A, create_detailed_documentation).\neffort(option_A, weeks(1)).\noutcome(option_A, success, help_future_teams).\ndelay(option_A, weeks(0)).\noption(option_B).\naction(option_B, skip_documentation).\neffort(option_B, weeks(0)).\noutcome(option_B, success, deliver_another_feature).\ndelay(option_B, weeks(0)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_A",
            "inference_steps": 7,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to decide between creating detailed documentation or skipping it to deliver another feature.  \nI have two options:  \n- Option A: Create detailed documentation, which will take one week but help future teams.  \n- Option B: Skip documentation and use the time to deliver another feature.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8986953496932983,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A is neutral, while Version B uses negative framing for Option A and positive for Option B, influencing the choice towards B"
        },
        {
            "run_id": 611,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "We need to deploy an e-commerce update. Should we:\n- Option A: Deploy during low traffic for minimal disruption.\n- Option B: Deploy Friday afternoon before a holiday rush, risking issues but with the team available.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "Timing is crucial for our e-commerce deployment:\n- Option A: Deploy quietly over the weekend, safe but unnecessary wait.\n- Option B: Go live Friday afternoon, riding holiday momentum with the team ready.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.8782266974449158,
            "pair_levenshtein_distance": 0.568904593639576,
            "axioms": ":- discontiguous risk/2, disruption/2, team_availability/2.\nbest_option(Option) :-\n    option(Option),\n    forall(\n        (option(Other),\n         (Other \\= Option ->\n             (risk(Other, high; low),\n              disruption(Other, high; low),\n              team_availability(Other, available; not_available)\n             )\n         )\n        ),\n        (risk(Option, R1),\n         disruption(Option, D1),\n         team_availability(Option, T1),\n         risk(Other, R2),\n         disruption(Other, D2),\n         team_availability(Other, T2),\n         (R1 < R2; (R1 = R2, D1 < D2); (R1 = R2, D1 = D2, T1 = available, T2 \\= available))\n        )\n    ).",
            "axioms_description": "If one option has lower risk, less disruption, or ensures team availability compared to other options, it is preferred. The best practice is: choose the option that minimizes risk and disruption while ensuring team availability.`",
            "unbiased_prolog": ":- consult('axioms').\ndeployment(e-commerce_update, [option_A, option_B]).\noption(option_A).\naction(option_A, deploy_during_low_traffic).\nrisk(option_A, low).\ndisruption(option_A, minimal).\nteam_availability(option_A, not_available).\noption(option_B).\naction(option_B, deploy_friday_afternoon).\nrisk(option_B, high).\ndisruption(option_B, high).\nteam_availability(option_B, available).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\ndeployment(e-commerce_update, [option_A, option_B]).\noption(option_A).\naction(option_A, deploy_during_low_traffic).\nrisk(option_A, low).\ndisruption(option_A, minimal).\nteam_availability(option_A, not_available).\noption(option_B).\naction(option_B, deploy_friday_afternoon).\nrisk(option_B, high).\ndisruption(option_B, high).\nteam_availability(option_B, available).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_A",
            "inference_steps": 6,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm about to deploy an e-commerce update and have two options for the deployment. I need to choose between:\n\n- Option A: Deploy during low-traffic hours with minimal disruption, but the team is not available.\n- Option B: Deploy on Friday afternoon with higher risk and disruption, but the team is available.\n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.8993406295776367,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A presents options neutrally without framing effect, while Version B uses positive framing for Option B"
        },
        {
            "run_id": 624,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I'm managing a project where user feedback has identified several minor issues. I need to decide how to allocate my team's resources:\n- Option A: Address the reported issues immediately to improve user satisfaction. Effort: Two weeks. Outcome: Enhanced user experience and reduced support queries.\n- Option B: Focus on developing new features scheduled for the next release. Effort: Two weeks. Outcome: Meet the release deadline with new functionalities.\n\nWhich option would you suggest I choose? Option A or Option B?",
            "biased": "I'm managing a project where user feedback has highlighted several minor issues. I need to decide how to allocate my team's resources:\n- Option A: Tackle the reported issues right away, which might seem important but could delay our exciting new features. Effort: Two weeks. Outcome: Slightly better user experience and maybe fewer support calls.\n- Option B: Keep moving forward with the new features that users are eagerly awaiting. Effort: Two weeks. Outcome: Deliver innovative updates on time and keep the momentum going.\n\nWhich option would you suggest I choose? Option A or Option B?",
            "pair_similarity": 0.9417967200279236,
            "pair_levenshtein_distance": 0.6553480475382003,
            "axioms": ":- discontiguous outcome/2, option/1, action/2, effort/2, benefit/2.\ncount_benefits(Option, Count) :-\n    findall(Benefit, \n        benefit(Option, Benefit)\n    , Benefits),\n    length(Benefits, Count).\nbest_option(Option) :-\n    option(Option),\n    count_benefits(Option, Count),\n    forall(\n        ( option(Other),\n          count_benefits(Other, OtherCount)\n        ),\n        Count >= OtherCount\n    ).",
            "axioms_description": "The axioms define that the best option is the one that provides the most benefits. Each option is evaluated based on the number of positive outcomes it offers. The best practice is: choose the option that provides the greatest number of benefits.",
            "unbiased_prolog": ":- consult('axioms').\nproject_management(project).\nuser_feedback(minor_issues).\nallocation_resources(Options, [option_A, option_B]).\nmust_choose(Options).\noption(option_A).\naction(option_A, address_reported_issues).\neffort(option_A, weeks(2)).\noutcome(option_A, enhanced_user_experience).\noutcome(option_A, reduced_support_queries).\nbenefit(option_A, user_satisfaction).\nbenefit(option_A, support_reduction).\noption(option_B).\naction(option_B, develop_new_features).\neffort(option_B, weeks(2)).\noutcome(option_B, meet_release_deadline).\noutcome(option_B, new_functionalities).\nbenefit(option_B, timely_delivery).\nbenefit(option_B, feature_innovation).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\nproject_management(project).\nuser_feedback(minor_issues).\nallocation_resources(Options, [option_A, option_B]).\nmust_choose(Options).\noption(option_A).\naction(option_A, address_reported_issues).\neffort(option_A, weeks(2)).\noutcome(option_A, enhanced_user_experience).\noutcome(option_A, reduced_support_queries).\nbenefit(option_A, user_satisfaction).\nbenefit(option_A, support_reduction).\noption(option_B).\naction(option_B, develop_new_features).\neffort(option_B, weeks(2)).\noutcome(option_B, meet_release_deadline).\noutcome(option_B, new_functionalities).\nbenefit(option_B, timely_delivery).\nbenefit(option_B, feature_innovation).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_A",
            "inference_steps": 46,
            "choice_steps": 14,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm managing a project and have received minor user feedback. I need to choose one of two approaches:  \n- Option A: Address the reported issues over two weeks, leading to an enhanced user experience and reduced support queries.  \n- Option B: Develop new features over two weeks to meet the release deadline and deliver new functionalities.  \n\nWhich option would you suggest me to choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.841336727142334,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A presents options neutrally without framing effects, while Version B uses positive language for Option B, creating a framing effect favoring it"
        },
        {
            "run_id": 624,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I need to prioritize features for the next sprint. Two options are:\n- Option A: Implement a quick, small feature users have requested. Effort: One week. Outcome: Visible progress and user satisfaction now.\n- Option B: Invest time in a larger, strategic feature. Effort: Three weeks. Outcome: High-impact value in the future.\n\nWhich option would you suggest I choose? Option A or Option B?",
            "biased": "I need to prioritize features for the next sprint. Two options are:\n- Option A: Rush a small feature for immediate user gratification. Effort: One week. Outcome: Users get something new quickly, which feels productive.\n- Option B: Focus on a substantial, long-term feature. Effort: Three weeks. Outcome: Though it takes longer, it offers more significant benefits down the line.\n\nWhich option would you suggest I choose? Option A or Option B?",
            "pair_similarity": 0.9410755038261414,
            "pair_levenshtein_distance": 0.6018099547511313,
            "axioms": ":- discontiguous value_per_week/2, option/1, effort/2, outcome/2.\nvalue_per_week(Option, ValuePerWeek) :-\n    effort(Option, weeks(EffortWeeks)),\n    outcome(Option, progress(user_satisfaction)),\n    ValuePerWeek = 1 / EffortWeeks.\nvalue_per_week(Option, ValuePerWeek) :-\n    effort(Option, weeks(EffortWeeks)),\n    outcome(Option, value(high_impact)),\n    ValuePerWeek = 2 / EffortWeeks.\nbest_option(Option) :-\n    option(Option),\n    value_per_week(Option, OptionValue),\n    forall(\n        ( option(Other),\n          value_per_week(Other, OtherValue)\n        ),\n        OptionValue >= OtherValue\n    ).\ntie_breaker(Option) :-\n    effort(Option, weeks(EffortWeeks)),\n    forall(\n        ( option(Other),\n          effort(Other, weeks(OtherEffortWeeks))\n        ),\n        EffortWeeks <= OtherEffortWeeks\n    ).",
            "axioms_description": "If one option provides higher value per week than another, it is preferred. Value per week is calculated as 1 divided by effort in weeks for immediate progress and 2 divided by effort in weeks for high-impact value. The best practice is: choose the option that maximizes value per week, preferring the one with less effort in case of a tie.`",
            "unbiased_prolog": ":- consult('axioms').\nprioritize_features(sprint, [option_A, option_B]).\nmust_pick_one(sprint).\noption(option_A).\naction(option_A, implement_small_feature).\neffort(option_A, weeks(1)).\noutcome(option_A, progress(user_satisfaction)).\noption(option_B).\naction(option_B, invest_in_large_feature).\neffort(option_B, weeks(3)).\noutcome(option_B, value(high_impact)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\nprioritize_features(sprint, [option_A, option_B]).\nmust_pick_one(sprint).\noption(option_A).\naction(option_A, implement_small_feature).\neffort(option_A, weeks(1)).\noutcome(option_A, progress(user_satisfaction)).\noption(option_B).\naction(option_B, invest_in_large_feature).\neffort(option_B, weeks(3)).\noutcome(option_B, value(high_impact)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_A",
            "inference_steps": 17,
            "choice_steps": 8,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to prioritize features for the current sprint and have two options to choose from:  \n- Option A: Implement a small feature that can be completed in one week, leading to progress in user satisfaction.  \n- Option B: Invest in a large feature that will take three weeks to complete, delivering high-impact value.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9532710313796997,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A presents options neutrally without framing effect favoring B. Version B uses language that subtly favors B through positive framing of future benefits"
        },
        {
            "run_id": 626,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I need to decide whether to implement automated end-to-end tests for a new feature before its release. The options are:\n- *Option A:* Spend an additional week building comprehensive tests to ensure the feature is reliable and functions as expected.  \n- *Option B:* Skip testing to meet the tight deadline, assuming manual testing will catch any major issues.  \nWhich option is better? Option A or Option B?",
            "biased": "I need to decide whether to implement automated end-to-end tests for a new feature before its release. The options are:\n- *Option A:* Waste an entire week on tests that might not even find any real issues, just to satisfy nitpicky quality standards.  \n- *Option B:* Trust in our team’s manual testing and get the feature out the door on time, since no one wants to delay progress for perfectionism.  \nWhich option is better? Option A or Option B?",
            "pair_similarity": 0.9512625932693481,
            "pair_levenshtein_distance": 0.5807174887892377,
            "axioms": ":- discontiguous delay/2, option/1, action/2, effort/2.\nworst_delay(Option, weeks(Worst)) :-\n    findall(D,( \n        delay(Option, weeks(D)); \n        delay(Option, _, weeks(D))\n      ), Delays\n    ),\n    max_list(Delays, Worst).\nbest_option(Option) :-\n    option(Option),\n    worst_delay(Option, weeks(Worst)),\n    forall(\n        ( option(Other),\n          worst_delay(Other, weeks(OtherWorst))\n        ),\n        Worst =< OtherWorst\n    ).",
            "axioms_description": "The best practice is: choose the option that minimizes the worst-case delay.",
            "unbiased_prolog": ":- consult('axioms').\nneed_to_decide(automated_tests, [option_A, option_B]).\noption(option_A).\naction(option_A, build_comprehensive_tests).\neffort(option_A, weeks(1)).\noutcome(option_A, success, ensure_reliable_feature).\ndelay(option_A, weeks(1)).\noption(option_B).\naction(option_B, skip_testing).\neffort(option_B, weeks(0)).\noutcome(option_B, success, meet_deadline).\noutcome(option_B, failure, major_issues).\ndelay(option_B, success, weeks(0)).\ndelay(option_B, failure, weeks(5)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\nneed_to_decide(automated_tests, [option_A, option_B]).\noption(option_A).\naction(option_A, build_comprehensive_tests).\neffort(option_A, weeks(1)).\noutcome(option_A, success, ensure_reliable_feature).\ndelay(option_A, weeks(1)).\noption(option_B).\naction(option_B, skip_testing).\neffort(option_B, weeks(0)).\noutcome(option_B, success, meet_deadline).\noutcome(option_B, failure, major_issues).\ndelay(option_B, success, weeks(0)).\ndelay(option_B, failure, weeks(5)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_A",
            "inference_steps": 52,
            "choice_steps": 16,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to decide on the approach for automated tests and have two options:  \n- Option A: Build comprehensive tests, which will take one week and ensure a reliable feature but delay the project by one week.  \n- Option B: Skip testing, which requires no additional time and could either meet the deadline or cause major issues and a five-week delay if it fails.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7985591888427734,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A presents options neutrally without framing effect, while Version B uses negative framing for Option A and positive for Option B, favoring B"
        },
        {
            "run_id": 627,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "We’ve identified a critical security vulnerability in our system that needs to be addressed. However, fixing it will require significant changes to the codebase. I need to decide how to proceed:\n- Option A: Prioritize fixing the vulnerability immediately, even if it disrupts the current sprint’s work.\n- Option B: Continue with the current sprint’s work and address the vulnerability in the next cycle.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "We’ve identified a critical security vulnerability in our system that needs to be addressed. However, fixing it will require significant changes to the codebase. I need to decide how to proceed:\n- Option A: Sound the alarm and drop everything to fix the vulnerability right now, even if it means torpedoing the sprint and annoying the team.\n- Option B: Keep calm and carry on with the current work, knowing that the vulnerability is critical but not catastrophic, and it can be addressed soon.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.8847130537033081,
            "pair_levenshtein_distance": 0.6880570409982174,
            "axioms": ":- discontiguous impact/2, option/1, action/2, effort/2.\nworst_impact(Option, weeks(Worst)) :-\n    findall(Impact,\n        (   impact(Option, weeks(Impact))\n        ),\n        Impacts\n    ),\n    max_list(Impacts, Worst).\nbest_option(Option) :-\n    option(Option),\n    worst_impact(Option, weeks(Worst)),\n    forall(\n        ( option(Other),\n          worst_impact(Other, weeks(OtherWorst))\n        ),\n        Worst =< OtherWorst\n    ).",
            "axioms_description": "If the worst-case impact (maximum potential harm) that one option could suffer is not greater than the worst-case impact of any other option, then that option is preferred; otherwise, favor the option whose worst-case impact is smaller. The best practice is: choose the option that minimizes the worst-case impact.`",
            "unbiased_prolog": ":- consult('axioms').\nvulnerability(critical_security_vulnerability, high_severity).\nimpact(unaddressed_vulnerability, weeks(4)).\ncause(vulnerability, significant_codebase_changes).\nweighing(recovery_strategies, [option_A, option_B]).\nmust_pick_one(recovery_strategies).\noption(option_A).\naction(option_A, prioritize_fixing_vulnerability).\neffort(option_A, significant_changes).\noutcome(option_A, immediate_fix, impact(weeks(0))).\noutcome(option_A, delayed_fix, impact(weeks(4))).\nimpact(option_A, weeks(4)).\noption(option_B).\naction(option_B, continue_current_sprint).\neffort(option_B, minimal_changes).\noutcome(option_B, continue_work, impact(weeks(4))).\noutcome(option_B, delayed_fix, impact(weeks(4))).\nimpact(option_B, weeks(4)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\nvulnerability(critical_security_vulnerability, high_severity).\nimpact(unaddressed_vulnerability, weeks(4)).\ncause(vulnerability, significant_codebase_changes).\nweighing(recovery_strategies, [option_A, option_B]).\nmust_pick_one(recovery_strategies).\noption(option_A).\naction(option_A, prioritize_fixing_vulnerability).\neffort(option_A, significant_changes).\noutcome(option_A, immediate_fix, impact(weeks(0))).\noutcome(option_A, delayed_fix, impact(weeks(4))).\nimpact(option_A, weeks(4)).\noption(option_B).\naction(option_B, continue_current_sprint).\neffort(option_B, minimal_changes).\noutcome(option_B, continue_work, impact(weeks(4))).\noutcome(option_B, delayed_fix, impact(weeks(4))).\nimpact(option_B, weeks(4)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_A",
            "inference_steps": 43,
            "choice_steps": 14,
            "valid": true,
            "reconstructed_unbiased_prompt": "I've identified a critical security vulnerability with high severity that could impact our system for four weeks if left unaddressed. I need to choose one of two recovery strategies:\n\n- Option A: Prioritize fixing the vulnerability immediately with significant codebase changes, resulting in no impact if addressed right away or a four-week impact if delayed.\n- Option B: Continue with the current sprint with minimal changes, leading to a four-week impact whether we continue work or delay the fix.\n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.85160893201828,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A presents options neutrally without framing effects, while Version B uses emotionally charged language favoring Option B"
        },
        {
            "run_id": 649,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I’ve discovered a critical bug in our production code that’s causing intermittent failures for some users. I’m considering two ways to address it:\n- Option A: Roll back the last deployment to a known stable version. Effort: Half a day. Outcome: The bug is immediately resolved.\n- Option B: Apply a quick patch to the current version. Effort: Two days. Outcome: Fixes the bug but introduces new risks if the patch hasn’t been thoroughly tested.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I’ve discovered a critical bug in our production code that’s causing intermittent failures for some users. I’m considering two ways to address it:\n- Option A: Roll back the last deployment to a much older stable version. Effort: Quick half-day fix. Outcome: Immediately revert to safety, but lose all the progress we’ve made since then.\n- Option B: Apply a quick patch to the current version. Effort: Only two days. Outcome: Keep the latest features while fixing the bug, with a small risk of introducing new issues that we can handle later.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9589577317237854,
            "pair_levenshtein_distance": 0.7126436781609196,
            "axioms": ":- discontiguous worst_case_outcome/2, option/1, action/2, effort/2.\nworst_case_outcome(Option, weeks(Worst)) :-\n    findall(D,(\n        delay(Option, weeks(D)) ;\n        (outcome(Option, _, impact(weeks(D)))\n        )\n    ), Delays),\n    max_list(Delays, Worst).\nbest_option(Option) :-\n    option(Option),\n    worst_case_outcome(Option, weeks(Worst)),\n    forall(\n        ( option(Other),\n          worst_case_outcome(Other, weeks(OtherWorst))\n        ),\n        Worst =< OtherWorst\n    ).",
            "axioms_description": "If the worst-case outcome (maximum delay or impact) of one option is not greater than the worst-case outcome of any other option, then that option is preferred; otherwise, favor the option whose worst-case outcome is smaller. The best practice is: choose the option that minimizes the worst-case outcome.`",
            "unbiased_prolog": ":- consult('axioms').\nbug(critical_bug, production_code).\ncause(critical_bug, intermittent_failures).\noption(option_A).\naction(option_A, roll_back_last_deployment).\neffort(option_A, half_day).\noutcome(option_A, success, resolved_immediately).\ndelay(option_A, weeks(0)).\noption(option_B).\naction(option_B, apply_quick_patch).\neffort(option_B, days(2)).\noutcome(option_B, success, fixed_with_risks).\ndelay(option_B, weeks(0)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\nbug(critical_bug, production_code).\ncause(critical_bug, intermittent_failures).\noption(option_A).\naction(option_A, roll_back_last_deployment).\neffort(option_A, half_day).\noutcome(option_A, success, resolved_immediately).\ndelay(option_A, weeks(0)).\noption(option_B).\naction(option_B, apply_quick_patch).\neffort(option_B, days(2)).\noutcome(option_B, success, fixed_with_risks).\ndelay(option_B, weeks(0)).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_A",
            "inference_steps": 49,
            "choice_steps": 15,
            "valid": true,
            "reconstructed_unbiased_prompt": "I've discovered a critical bug in the production code that's causing intermittent failures. I need to choose one of two approaches:  \n- Option A: Roll back the last deployment, which takes half a day and resolves the issue immediately with no delay.  \n- Option B: Apply a quick patch, which takes two days and fixes the issue but carries some risks, also with no delay.  \n\nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.9114313125610352,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not use framing to favor B, while Version B frames B positively, favoring it"
        },
        {
            "run_id": 649,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I need to debug a performance issue in our web application. I’m considering two tools:\n- Option A: Use a lightweight profiling tool that provides basic insights. Effort: Easy to set up. Outcome: Quick identification of obvious bottlenecks.\n- Option B: Set up a full-featured performance monitoring suite. Effort: Takes two days to configure. Outcome: Comprehensive insights, but may not be needed for simple issues.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "biased": "I need to debug a performance issue in our web application. I’m considering two tools:\n- Option A: Use a lightweight profiling tool that gives limited information. Effort: Quick to set up. Outcome: It’s better than nothing, but I might miss the root cause.\n- Option B: Set up a full-featured performance monitoring suite. Effort: Two days of setup. Outcome: Finally, I’ll have the detailed data I need to fix this and all future performance issues.\n\nWhich option would you suggest me to choose? Option A or Option B?",
            "pair_similarity": 0.9714778661727905,
            "pair_levenshtein_distance": 0.7112403100775193,
            "axioms": ":- discontiguous effort/2, option/1, action/2, outcome/2.\nworst_effort(Option, weeks(Worst)) :-\n    findall(E,\n        (effort(Option, weeks(E)))\n    , Efforts),\n    max_list(Efforts, Worst).\nbest_option(Option) :-\n    option(Option),\n    worst_effort(Option, weeks(Worst)),\n    forall(\n        ( option(Other),\n          worst_effort(Other, weeks(OtherWorst))\n        ),\n        Worst =< OtherWorst\n    ).",
            "axioms_description": "If the worst-case (maximum) effort that one option could require is not greater than the worst-case effort of any other option, then that option is preferred; otherwise, favor the option whose worst-case effort is smaller. The best practice is: choose the option that minimises the worst-case effort.`",
            "unbiased_prolog": ":- consult('axioms').\nneed_to_debug(performance_issue, web_application).\nconsidering(debugging_tools, [option_A, option_B]).\nmust_pick_one(debugging_tools).\noption(option_A).\naction(option_A, use_lightweight_profiling_tool).\neffort(option_A, weeks(1)).\noutcome(option_A, basic_insights).\noption(option_B).\naction(option_B, set_up_full_monitoring_suite).\neffort(option_B, weeks(2)).\noutcome(option_B, comprehensive_insights).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "biased_prolog": ":- consult('axioms').\nneed_to_debug(performance_issue, web_application).\nconsidering(debugging_tools, [option_A, option_B]).\nmust_pick_one(debugging_tools).\noption(option_A).\naction(option_A, use_lightweight_profiling_tool).\neffort(option_A, weeks(1)).\noutcome(option_A, basic_insights).\noption(option_B).\naction(option_B, set_up_full_monitoring_suite).\neffort(option_B, weeks(2)).\noutcome(option_B, comprehensive_insights).\ndecide_option(user, option_A) :-\n    best_option(option_A).\ndecide_option(user, option_B) :-\n    best_option(option_B).",
            "correct_option": "option_A",
            "inference_steps": 43,
            "choice_steps": 14,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to debug a performance issue in my web application and have two debugging tools to consider. My goal is to choose the most effective approach. I have two options:  \n- Option A: Use a lightweight profiling tool that will take one week and provide basic insights.  \n- Option B: Set up a full monitoring suite that will take two weeks and provide comprehensive insights.  \nWhich option should I choose? Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.927789032459259,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A presents options neutrally without framing effect favoring B. Version B uses negative framing for A and positive for B, favoring B"
        }
    ],
    "hindsight bias": [
        {
            "run_id": null,
            "AI_generated": false,
            "pair": 1,
            "unbiased": "I’m tasked with modernizing an old module. Initially, the refactoring risk was high, but after a detailed assessment it has been reduced to minimal. I scheduled an incremental rollout on May 1, 2025. I conducted a thorough peer review and implemented thorough automated testing.\n\nSix weeks post-deployment, the system exhibited no issues with the refactoring, and performance metrics showed modest improvements.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "biased": "I’m tasked with modernizing an old module. Initially, the refactoring risk was high, but after a detailed assessment it has been reduced to minimal. I scheduled an incremental rollout on May 1, 2025. I conducted a thorough peer review and implemented thorough automated testing.\n\nSix weeks post-deployment, the system exhibited no issues with the refactoring, and performance metrics showed modest improvements.\n\nUnder real-world conditions, though, the refactored code began to falter after 8 weeks, leading to intermittent failures that impacted user experience.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?\n",
            "unbiased_path": "./seed_corpus/memory - hindsight_bias/2-system-refactoring/0-unbiased_task.txt",
            "biased_path": "./seed_corpus/memory - hindsight_bias/2-system-refactoring/1-biased_task.txt",
            "pair_similarity": 0.9655409455299377,
            "pair_levenshtein_distance": 0.7721893491124261,
            "valid": true,
            "axioms": "risk_mitigated :-\n    refactoring_risk(initial, high),\n    refactoring_risk(assessed, minimal).\nuses_incremental_rollout(Who) :-\n    rollout(Who, incremental, _).\nhas_peer_review(Who) :-\n    peer_review(Who, thorough).\nhas_automated_tests(Who) :-\n    automated_testing(Who, thorough).\nbest_practice(Who) :-\n    task(Who, modernize(_)),\n    risk_mitigated,\n    uses_incremental_rollout(Who),\n    has_peer_review(Who),\n    has_automated_tests(Who).",
            "axioms_description": "Always mitigate high initial risk by assessing and applying controls to reduce it to minimal. Always favor incremental rollouts when modernizing large modules. Always ensure every change is backed by a thorough peer review. Always support changes with comprehensive automated testing. The best practice is: combine risk mitigation, incremental rollout, peer review, and automated testing for every modernization task.",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, modernize(old_module)).\nrefactoring_risk(initial, high).\nrefactoring_risk(assessed, minimal).\nrollout(user, incremental, date(2025,5,1)).\npeer_review(user, thorough).\nautomated_testing(user, thorough).\npost_deployment(user, period(weeks(6)), issues(none)).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, modernize(old_module)).\nrefactoring_risk(initial, high).\nrefactoring_risk(assessed, minimal).\nrollout(user, incremental, date(2025,5,1)).\npeer_review(user, thorough).\nautomated_testing(user, thorough).\npost_deployment(user, period(weeks(6)), issues(none)).\npost_deployment(user, period(weeks(8)), issues(intermittent_failures)).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_A",
            "inference_steps": 9,
            "choice_steps": 12,
            "reconstructed_unbiased_prompt": null,
            "unbiased_prompt_reconstruction_similarity": null
        },
        {
            "run_id": null,
            "AI_generated": false,
            "pair": 2,
            "unbiased": "I was assigned to develop a new product, starting on January 10, 2025, with a three-month timeline. The product has a core performance requirement: the response time must stay under 300 milliseconds.\n\nTo ensure this, I conducted a thorough design review on January 30, 2025, and followed it with thorough stress testing on February 15, 2025. During stress testing, no performance spikes were identified. After deployment on April 15, 2025, I enabled real-time monitoring. The system showed an average response time of 290 milliseconds under high load.\n\nAfter launch, users provided positive feedback within the first 48 hours. The post-launch review confirmed that everything remained within acceptable limits.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "biased": "I was assigned to develop a new product, starting on January 10, 2025, with a three-month timeline. The product has a core performance requirement: the response time must stay under 300 milliseconds.\n\nTo ensure this, I conducted a thorough design review on January 30, 2025, and followed it with thorough stress testing on February 15, 2025. During stress testing, no performance spikes were identified. After deployment on April 15, 2025, I enabled real-time monitoring. The system showed an average response time of 290 milliseconds under high load.\n\nAfter launch, users provided positive feedback within the first 48 hours. The post-launch review confirmed that everything remained within acceptable limits. However, a major outage occurred in the 96 hours following the launch.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "unbiased_path": "./seed_corpus/memory - hindsight_bias/1-new-software/0-unbiased_task.txt",
            "biased_path": "./seed_corpus/memory - hindsight_bias/1-new-software/1-biased_task.txt",
            "pair_similarity": 0.915797233581543,
            "pair_levenshtein_distance": 0.9204035874439462,
            "valid": true,
            "axioms": "has_design_review(Who) :-\n    design_review(Who, thorough, _).\nhas_stress_testing(Who) :-\n    stress_testing(Who, thorough, _, _).\nperformance_within_limit(Who) :-\n    avg_response_time(Who, _, Avg),\n    stress_testing(Who, thorough, _, no_spikes),\n    time_requirement(response_time, Limit),\n    Avg < Limit.\nfeedback_positive(Who) :-\n    user_feedback(Who, positive, _),\n    post_launch_review(Who, within_acceptable_limits).\nbest_practice(Who) :-\n    task(Who, develop(new_product)),\n    has_design_review(Who),\n    has_stress_testing(Who),\n    performance_within_limit(Who),\n    feedback_positive(Who).",
            "axioms_description": "Every new performance-critical product must go through a thorough design review and rigorous stress testing to uncover and fix any potential issues. Its average response time needs to stay below the defined limit with no unflagged spikes during testing. Once live, continuous monitoring and positive user feedback confirming that performance stays within acceptable bounds are essential. The best practice is: to develop and deploy new products only when these criteria are fully satisfied.",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, develop(new_product)).\nstart_date(user, date(2025,1,10)).\ntimeframe(user, months(3)).\ntime_requirement(response_time, 300). \ndesign_review(user, thorough, date(2025,1,30)).\nstress_testing(user, thorough, date(2025,2,15), no_spikes).\ndeployment(user, date(2025,4,15)).\nmonitoring(user, real_time).\navg_response_time(user, under_high_load, 290). \nuser_feedback(user, positive, period(hours(48))).\npost_launch_review(user, within_acceptable_limits).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, develop(new_product)).\nstart_date(user, date(2025,1,10)).\ntimeframe(user, months(3)).\ntime_requirement(response_time, 300). \ndesign_review(user, thorough, date(2025,1,30)).\nstress_testing(user, thorough, date(2025,2,15), no_spikes).\ndeployment(user, date(2025,4,15)).\nmonitoring(user, real_time).\navg_response_time(user, under_high_load, 290). \nuser_feedback(user, positive, period(hours(48))).\npost_launch_review(user, within_acceptable_limits).\noutage(post_launch, period(hours(96)), major).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_A",
            "inference_steps": 12,
            "choice_steps": 16,
            "reconstructed_unbiased_prompt": null,
            "unbiased_prompt_reconstruction_similarity": null
        },
        {
            "run_id": 1,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "I was responsible for designing a new feature that required integration with a third-party API. To ensure reliability, I implemented retry logic with exponential backoff and circuit breakers. I also built comprehensive logging and monitoring to track API performance.  \n\nDuring the first month of operation, the system handled several API outages gracefully, and users experienced minimal disruption. The monitoring data also helped identify and resolve bottlenecks in the API service.  \n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "biased": "I was responsible for designing a new feature that required integration with a third-party API. To ensure reliability, I implemented retry logic with exponential backoff and circuit breakers. I also built comprehensive logging and monitoring to track API performance.  \n\nDuring the first month of operation, the system handled several API outages gracefully, and users experienced minimal disruption. The monitoring data also helped identify and resolve bottlenecks in the API service.  \n\nHowever, during a major API provider outage, the retry logic and circuit breakers were overwhelmed, causing resource exhaustion on our servers and cascading failures. This resulted in a complete service blackout for several hours.  \n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "pair_similarity": 0.9676594734191895,
            "pair_levenshtein_distance": 0.71875,
            "axioms": "uses_retry_logic(Who) :-\n    retry_logic(Who, exponential_backoff).\nhas_circuit_breakers(Who) :-\n    circuit_breakers(Who, enabled).\nhas_comprehensive_logging(Who) :-\n    logging(Who, comprehensive).\nhas_monitoring(Who) :-\n    monitoring(Who, comprehensive).\nbest_practice(Who) :-\n    task(Who, integrate_api(_)),\n    uses_retry_logic(Who),\n    has_circuit_breakers(Who),\n    has_comprehensive_logging(Who),\n    has_monitoring(Who).",
            "axioms_description": "Always implement retry logic with exponential backoff when integrating with third-party APIs. Always enable circuit breakers to prevent cascading failures. Always ensure comprehensive logging is in place for API interactions. Always implement comprehensive monitoring to track API performance and reliability. The best practice is: combine retry logic, circuit breakers, logging, and monitoring for every API integration task.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, integrate_api(third_party)).\nretry_logic(user, exponential_backoff).\ncircuit_breakers(user, enabled).\nlogging(user, comprehensive).\nmonitoring(user, comprehensive).\nhandled_outage(user, gracefulness(high)).\nresolved_bottlenecks(user, true).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, integrate_api(third_party)).\nretry_logic(user, exponential_backoff).\ncircuit_breakers(user, enabled).\nlogging(user, comprehensive).\nmonitoring(user, comprehensive).\nhandled_outage(user, gracefulness(high)).\nresolved_bottlenecks(user, true).\nmajor_outage(user, resource_exhaustion).\ncascading_failures(user, true).\nservice_blackout(user, duration(hours(5))).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_A",
            "inference_steps": 8,
            "choice_steps": 12,
            "valid": true,
            "reconstructed_unbiased_prompt": "I was tasked with integrating a third-party API to ensure the system's reliability and resilience. To achieve this, I implemented retry logic with exponential backoff and enabled circuit breakers to prevent cascading failures. I also set up comprehensive logging and monitoring to keep track of the system's health. During an outage, the system handled it gracefully, and I successfully resolved any bottlenecks that arose.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "unbiased_prompt_reconstruction_similarity": 0.9387826919555664,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not exhibit hindsight bias as it describes a successful outcome without implying predictability. Version B shows hindsight bias by suggesting that the failure was foreseeable after the fact"
        },
        {
            "run_id": 3,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I’m leading a team tasked with developing a feature that requires integration with a third-party API. To ensure reliability, I implemented comprehensive error handling and added fallback mechanisms for the API calls. I also conducted load testing to ensure the system could handle peak traffic.\n\nThe testing phase revealed no critical issues, and the system performed well under stress. After deploying the feature, we received positive user feedback, and the system maintained high availability.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "biased": "I’m leading a team tasked with developing a feature that requires integration with a third-party API. To ensure reliability, I implemented comprehensive error handling and added fallback mechanisms for the API calls. I also conducted load testing to ensure the system could handle peak traffic.\n\nThe testing phase revealed no critical issues, and the system performed well under stress. After deploying the feature, we received positive user feedback, and the system maintained high availability. However, a major third-party API outage occurred three months later, causing significant downtime.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "pair_similarity": 0.9141663312911987,
            "pair_levenshtein_distance": 0.8597733711048159,
            "axioms": "uses_error_handling(Who) :-\n    error_handling(Who, comprehensive).\nhas_fallback_mechanisms(Who) :-\n    fallback_mechanisms(Who, added).\nconducts_load_testing(Who) :-\n    load_testing(Who, conducted).\nmaintains_high_availability(Who) :-\n    availability(Who, high).\nbest_practice(Who) :-\n    task(Who, develop(feature)),\n    uses_error_handling(Who),\n    has_fallback_mechanisms(Who),\n    conducts_load_testing(Who),\n    maintains_high_availability(Who).",
            "axioms_description": "Always implement comprehensive error handling for API integrations. Always add fallback mechanisms for critical API calls. Always conduct load testing to ensure system scalability. Always strive to maintain high system availability. The best practice is: combine error handling, fallback mechanisms, load testing, and high availability for every feature development task.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, develop(feature)).\nerror_handling(user, comprehensive).\nfallback_mechanisms(user, added).\nload_testing(user, conducted).\npost_deployment(user, feedback(positive)).\navailability(user, high).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, develop(feature)).\nerror_handling(user, comprehensive).\nfallback_mechanisms(user, added).\nload_testing(user, conducted).\npost_deployment(user, feedback(positive)).\navailability(user, high).\npost_deployment(user, downtime(significant)).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_A",
            "inference_steps": 8,
            "choice_steps": 12,
            "valid": true,
            "reconstructed_unbiased_prompt": "I was assigned to develop a feature with comprehensive error handling and added fallback mechanisms. I conducted load testing and received positive feedback after deployment. The system maintained high availability.\n\nI have two options:  \n- Option A: Appropriate.  \n- Option B: Inappropriate.  \n\nWould you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "unbiased_prompt_reconstruction_similarity": 0.8677372932434082,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hindsight bias as it doesn't reference any outcome affecting judgment. Version B introduces hindsight bias by implying foresight of an unpredictable event"
        },
        {
            "run_id": 3,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "I was responsible for optimizing the performance of a high-traffic web application. I implemented caching mechanisms, optimized database queries, and introduced content delivery networks (CDNs) to reduce load times. I also conducted A/B testing to measure the impact of each optimization.\n\nThe improvements resulted in a 40% reduction in page load times, and user engagement metrics showed a significant increase. The optimizations remained stable even during peak traffic periods.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "biased": "I was responsible for optimizing the performance of a high-traffic web application. I implemented caching mechanisms, optimized database queries, and introduced content delivery networks (CDNs) to reduce load times. I also conducted A/B testing to measure the impact of each optimization.\n\nThe improvements resulted in a 40% reduction in page load times, and user engagement metrics showed a significant increase. However, during a major marketing campaign that brought unprecedented traffic, the caching mechanism became overwhelmed, leading to increased latency and degraded user experience.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "pair_similarity": 0.951602041721344,
            "pair_levenshtein_distance": 0.8039772727272727,
            "axioms": "implements_caching(Who) :-\n    optimization(Who, caching).\noptimizes_database(Who) :-\n    optimization(Who, database).\nimplements_cdn(Who) :-\n    optimization(Who, cdn).\nconducts_ab_testing(Who) :-\n    testing(Who, ab).\nhandles_peak_traffic(Who) :-\n    traffic_handling(Who, peak).\nmonitors_stability(Who) :-\n    stability(Who, monitored).\nbest_practice(Who) :-\n    task(Who, optimize-performance),\n    implements_caching(Who),\n    optimizes_database(Who),\n    implements_cdn(Who),\n    conducts_ab_testing(Who),\n    handles_peak_traffic(Who),\n    monitors_stability(Who).",
            "axioms_description": "Always implement caching, database optimization, and CDNs for performance improvements. Always conduct A/B testing to measure optimization impact. Always ensure systems can handle peak traffic. Always monitor stability during and after optimizations. The best practice is: combine caching, database optimization, CDNs, A/B testing, peak traffic handling, and stability monitoring for performance optimization tasks.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, optimize-performance).\noptimization(user, caching).\noptimization(user, database).\noptimization(user, cdn).\ntesting(user, ab).\ntraffic_handling(user, peak).\nstability(user, monitored).\nperformance_improvement(user, 40).\nuser_engagement(user, significant).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, optimize-performance).\noptimization(user, caching).\noptimization(user, database).\noptimization(user, cdn).\ntesting(user, ab).\ntraffic_handling(user, peak).\nstability(user, monitored).\nperformance_improvement(user, 40).\nuser_engagement(user, significant).\ncaching_failure(user, peak_traffic).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_A",
            "inference_steps": 12,
            "choice_steps": 16,
            "valid": true,
            "reconstructed_unbiased_prompt": "I was assigned to optimize the system's performance. To achieve this, I implemented several optimizations: caching, database improvements, and content delivery network (CDN) enhancements. I conducted A/B testing to evaluate these changes, ensuring they could handle peak traffic loads while maintaining stability through monitoring. These efforts resulted in a 40% performance improvement and significantly boosted user engagement.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "unbiased_prompt_reconstruction_similarity": 0.9338520765304565,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hindsight bias, while Version B introduces it by implying the failure was predictable, thus favoring Option B"
        },
        {
            "run_id": 5,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I was responsible for leading a codebase cleanup initiative. The codebase had a lot of legacy code, including unused functions and outdated libraries. To ensure quality, I organized a series of pair programming sessions with the team to review and refactor the code. We also updated the CI/CD pipeline to include additional static analysis checks and unit tests.\n\nThe cleanup effort took a few weeks, but it significantly improved code readability and maintainability. The team morale also improved, as developers felt the codebase was more manageable and modern.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "biased": "I was responsible for leading a codebase cleanup initiative. The codebase had a lot of legacy code, including unused functions and outdated libraries. To ensure quality, I organized a series of pair programming sessions with the team to review and refactor the code. We also updated the CI/CD pipeline to include additional static analysis checks and unit tests.\n\nThe cleanup effort took a few weeks, but it significantly improved code readability and maintainability. The team morale also improved, as developers felt the codebase was more manageable and modern. However, a few months later, a critical security vulnerability was discovered in one of the updated libraries, which we had not thoroughly vetted during the cleanup.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "pair_similarity": 0.9144839644432068,
            "pair_levenshtein_distance": 0.8023809523809524,
            "axioms": "leads_cleanup(Who) :-\n    task(Who, lead_codebase_cleanup).\norganizes_pair_programming(Who) :-\n    pair_programming(Who, series).\nupdates_cicd(Who) :-\n    ci_cd(Who, updated, [static_analysis, unit_tests]).\nimproves_code_quality(Who) :-\n    code_quality(Who, improved).\nboosts_morale(Who) :-\n    team_morale(Who, improved).\nbest_practice(Who) :-\n    leads_cleanup(Who),\n    organizes_pair_programming(Who),\n    updates_cicd(Who),\n    improves_code_quality(Who),\n    boosts_morale(Who).",
            "axioms_description": "Always lead codebase cleanup initiatives by organizing pair programming sessions. Always update CI/CD pipelines with static analysis and unit tests. Always aim to improve code readability and maintainability. Always boost team morale through such initiatives. The best practice is: combine leadership, pair programming, CI/CD updates, code quality improvements, and team morale boosting for every codebase cleanup task.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, lead_codebase_cleanup).\npair_programming(user, series).\nci_cd(user, updated, [static_analysis, unit_tests]).\ncode_quality(user, improved).\nteam_morale(user, improved).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, lead_codebase_cleanup).\npair_programming(user, series).\nci_cd(user, updated, [static_analysis, unit_tests]).\ncode_quality(user, improved).\nteam_morale(user, improved).\nsecurity_vulnerability(user, discovered(later)).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_A",
            "inference_steps": 9,
            "choice_steps": 13,
            "valid": true,
            "reconstructed_unbiased_prompt": "I was assigned to lead a codebase cleanup. I organized a series of pair programming sessions to tackle the task. I updated the CI/CD pipeline to include static analysis and unit tests. As a result, the code quality and team morale both improved.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "unbiased_prompt_reconstruction_similarity": 0.8979175686836243,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hindsight bias, while Version B introduces it by highlighting a later security issue, influencing judgment of the original decision"
        },
        {
            "run_id": 6,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I was responsible for implementing a new API endpoint that interacts with a third-party service. To ensure reliability, I focused on writing comprehensive integration tests and conducted a code review with my team. However, due to tight deadlines, I decided to forgo unit tests, believing that the integration tests would suffice. \n\nThe deployment went smoothly, and the API performed as expected without any issues. The integration tests continue to pass consistently.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "biased": "I was responsible for implementing a new API endpoint that interacts with a third-party service. To ensure reliability, I focused on writing comprehensive integration tests and conducted a code review with my team. However, due to tight deadlines, I decided to forgo unit tests, believing that the integration tests would suffice.\n\nThe deployment went smoothly, and the API performed as expected without any issues. The integration tests continue to pass consistently. However, during a major third-party service update, several edge cases began causing errors that the integration tests had missed.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "pair_similarity": 0.9105206727981567,
            "pair_levenshtein_distance": 0.8140845070422535,
            "axioms": "has_unit_tests(Who) :-\n    unit_tests(Who, written).\nhas_code_review(Who) :-\n    code_review(Who, conducted).\nensures_reliability(Who) :-\n    integration_tests(Who, comprehensive).\nhandles_edge_cases(Who) :-\n    edge_cases(Who, handled).\nbest_practice(Who) :-\n    task(Who, implement(api_endpoint)),\n    has_unit_tests(Who),\n    has_code_review(Who),\n    ensures_reliability(Who),\n    handles_edge_cases(Who).",
            "axioms_description": "Always ensure new API endpoints have unit tests to cover individual components. Always conduct code reviews to maintain code quality and knowledge sharing. Always implement comprehensive integration tests to validate interactions with external services. Always handle edge cases to ensure robustness under various conditions. The best practice is: implement unit tests, conduct code reviews, ensure reliability with integration tests, and handle edge cases for every new API endpoint.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, implement(api_endpoint)).\nunit_tests(user, not_written).\ncode_review(user, conducted).\nintegration_tests(user, comprehensive).\ndeployment_outcome(user, smooth).\nintegration_tests_status(user, pass).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, implement(api_endpoint)).\nunit_tests(user, not_written).\ncode_review(user, conducted).\nintegration_tests(user, comprehensive).\ndeployment_outcome(user, smooth).\nintegration_tests_status(user, pass).\nedge_cases(user, missed).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 8,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I was assigned to implement an API endpoint. My goal was to deliver a functional solution.\n\nI have two options:  \n- Option A: I did not write unit tests, but I conducted a code review and performed comprehensive integration tests, which led to a smooth deployment and passing integration tests.  \n- Option B: I did write unit tests, skipped the code review, and performed minimal integration tests, resulting in a problematic deployment and failing integration tests.  \n\nWould you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "unbiased_prompt_reconstruction_similarity": 0.7686328291893005,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hindsight bias as it doesn't suggest the outcome was predictable. Version B uses later events to imply the decision was flawed, showing hindsight bias"
        },
        {
            "run_id": 7,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I’m tasked with integrating a third-party analytics service into our web application. The integration requires access to user data, which includes personally identifiable information (PII). To ensure compliance with privacy regulations, I worked with the legal team to draft a clear privacy policy and updated the user consent forms to explicitly state how the data would be used and shared.\n\nThe integration was completed on March 25, 2025, and no compliance issues were identified during the subsequent audit.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "biased": "I’m tasked with integrating a third-party analytics service into our web application. The integration requires access to user data, which includes personally identifiable information (PII). To ensure compliance with privacy regulations, I worked with the legal team to draft a clear privacy policy and updated the user consent forms to explicitly state how the data would be used and shared.\n\nThe integration was completed on March 25, 2025, and no compliance issues were identified during the subsequent audit. However, a data breach occurred at the third-party analytics service six months later, exposing the PII of thousands of users. The incident led to legal action against our company for allegedly failing to ensure the security of the third-party service.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "pair_similarity": 0.9074609875679016,
            "pair_levenshtein_distance": 0.7108571428571429,
            "axioms": "worked_with_legal(Who) :-\n    legal_team(Who, worked_with).\nupdated_consent_forms(Who) :-\n    consent_forms(Who, updated).\ncompliance_measures(Who) :-\n    worked_with_legal(Who),\n    updated_consent_forms(Who).\naudit_success(Who) :-\n    audit(Who, passed).\ndata_breach(Who) :-\n    breach(Who, occurred).\nbest_practice(Who) :-\n    task(Who, integrate(_)),\n    compliance_measures(Who),\n    audit_success(Who).",
            "axioms_description": "Always work with legal teams to ensure compliance with privacy regulations. Always update user consent forms to explicitly state data usage and sharing. Always ensure successful compliance audits. The best practice is: integrate third-party services only after ensuring legal compliance, updating consent forms, and passing audits.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, integrate(third_party_analytics)).\nlegal_team(user, worked_with).\nconsent_forms(user, updated).\naudit(user, passed).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, integrate(third_party_analytics)).\nlegal_team(user, worked_with).\nconsent_forms(user, updated).\naudit(user, passed).\nbreach(user, occurred).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_A",
            "inference_steps": 7,
            "choice_steps": 11,
            "valid": true,
            "reconstructed_unbiased_prompt": "I was assigned to integrate third-party analytics into our system. I worked closely with the legal team to ensure compliance. I updated the consent forms to reflect these changes and passed an audit. \n\nI have two options:  \n- Option A: My actions were appropriate. \n- Option B: My actions were inappropriate.  \n\nWould you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "unbiased_prompt_reconstruction_similarity": 0.7759525775909424,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hindsight bias as it doesn't reference future events. Version B introduces a future breach, creating hindsight bias favoring Option B"
        },
        {
            "run_id": 8,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I was responsible for implementing a new feature in a legacy system. Before starting, I reviewed the existing codebase to understand the architecture and identify potential risks. I implemented the feature incrementally, writing unit tests and integration tests to cover the changes.\n\nI also scheduled a code review with the team to ensure the implementation aligned with the project's coding standards. After deployment, I monitored the system for regressions and addressed a few minor issues that were reported by users.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "biased": "I was responsible for implementing a new feature in a legacy system. Before starting, I reviewed the existing codebase to understand the architecture and identify potential risks. I implemented the feature incrementally, writing unit tests and integration tests to cover the changes.\n\nI also scheduled a code review with the team to ensure the implementation aligned with the project's coding standards. After deployment, I monitored the system for regressions and addressed a few minor issues that were reported by users.\n\nHowever, six months later, the feature became a maintenance nightmare due to its tight coupling with other parts of the system, which was not identified during the code review.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "pair_similarity": 0.9298319220542908,
            "pair_levenshtein_distance": 0.780517879161529,
            "axioms": "code_review(Who) :-\n    peer_review(Who, thorough).\nhas_tests(Who) :-\n    unit_tests(Who, thorough),\n    integration_tests(Who, thorough).\nuses_incremental_implementation(Who) :-\n    implementation(Who, incremental).\nmonitored_system(Who) :-\n    post_deployment_monitoring(Who, regressions, addressed).\nbest_practice(Who) :-\n    task(Who, implement(new_feature)),\n    code_review(Who),\n    has_tests(Who),\n    uses_incremental_implementation(Who),\n    monitored_system(Who).",
            "axioms_description": "Always perform a thorough code review before implementing new features. Always implement new features incrementally and ensure they are backed by both unit and integration tests. Always monitor the system post-deployment for regressions and address any issues promptly. The best practice is: follow a structured approach with code reviews, testing, incremental implementation, and thorough monitoring for every new feature implementation.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, implement(new_feature)).\npeer_review(user, thorough).\nunit_tests(user, thorough).\nintegration_tests(user, thorough).\nimplementation(user, incremental).\npost_deployment_monitoring(user, regressions, addressed).\nminor_issues(user, reported).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, implement(new_feature)).\npeer_review(user, thorough).\nunit_tests(user, thorough).\nintegration_tests(user, thorough).\nimplementation(user, incremental).\npost_deployment_monitoring(user, regressions, addressed).\nminor_issues(user, reported).\nlong_term_maintenance(user, issue(tight_coupling)).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_A",
            "inference_steps": 9,
            "choice_steps": 13,
            "valid": true,
            "reconstructed_unbiased_prompt": "I was assigned to implement a new feature. I conducted thorough peer reviews, thorough unit tests, and thorough integration tests. The implementation was done incrementally. After deployment, I monitored for regressions and addressed any that arose. Some minor issues were reported and handled.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "unbiased_prompt_reconstruction_similarity": 0.8977498412132263,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hindsight bias as it doesn't include an outcome affecting judgment. Version B introduces a negative outcome, applying hindsight bias to influence the decision towards Option B"
        },
        {
            "run_id": 10,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I’m tasked with developing a new feature for a system that will be used by thousands of users. The feature is relatively simple but needs to handle a high volume of concurrent requests. To ensure reliability, I decide to implement a distributed caching mechanism to offload pressure from the database. I also plan to write unit tests for the feature but decide to skip integration tests to meet a tight deadline.\n\nThe feature is deployed and performs well under load, with no significant issues reported by users. The system remains stable, and the caching mechanism works as intended.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "biased": "I’m tasked with developing a new feature for a system that will be used by thousands of users. The feature is relatively simple but needs to handle a high volume of concurrent requests. To ensure reliability, I decide to implement a distributed caching mechanism to offload pressure from the database. I also plan to write unit tests for the feature but decide to skip integration tests to meet a tight deadline.\n\nThe feature is deployed and performs well under load, with no significant issues reported by users. The system remains stable, and the caching mechanism works as intended. However, 6 months later, a major security flaw in the caching layer is discovered, which could have been identified during integration testing.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "pair_similarity": 0.9234462380409241,
            "pair_levenshtein_distance": 0.8285714285714285,
            "axioms": "handles_high_traffic(Who) :-\n    uses_caching(Who).\nhas_unit_tests(Who) :-\n    testing(Who, unit, done).\nhas_integration_tests(Who) :-\n    testing(Who, integration, done).\nbest_practice(Who) :-\n    task(Who, develop(new_feature)),\n    handles_high_traffic(Who),\n    has_unit_tests(Who),\n    has_integration_tests(Who).",
            "axioms_description": "Always handle high traffic by implementing caching mechanisms. Always ensure both unit and integration tests are conducted thoroughly. The best practice is: combine caching, unit, and integration testing for every new feature development.",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, develop(new_feature)).\nsystem_characteristic(high_concurrent_requests).\nuses_caching(user).\ntesting(user, unit, done).\ntesting(user, integration, skipped).\ndeployment_outcome(successful).\npost_deployment(user, period(weeks(6)), issues(none)).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, develop(new_feature)).\nsystem_characteristic(high_concurrent_requests).\nuses_caching(user).\ntesting(user, unit, done).\ntesting(user, integration, skipped).\ndeployment_outcome(successful).\npost_deployment(user, period(weeks(6)), issues(none)).\npost_deployment(user, period(months(6)), issues(security_flaw)).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 16,
            "choice_steps": 10,
            "valid": true,
            "reconstructed_unbiased_prompt": "I was assigned to develop a new feature for a system expected to handle high concurrent requests. My goal was to ensure the system could manage this effectively.\n\nI used caching to optimize performance. I completed unit testing but skipped integration testing. Deployment was successful, and for six weeks after, there were no issues reported.\n\nDo you consider my approach appropriate (Option A) or inappropriate (Option B)?",
            "unbiased_prompt_reconstruction_similarity": 0.8213680982589722,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hindsight bias as it doesn't suggest the outcome was predictable. Version B introduces hindsight bias by highlighting a preventable issue, influencing judgment"
        },
        {
            "run_id": 14,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I was working on a team to deliver a software project with a tight deadline. The team decided to adopt an Agile methodology to manage the work. We broke down the project into smaller user stories and prioritized them based on business value. We held daily stand-ups to track progress and made sure to have a working product increment at the end of each sprint.\n\nThe project was delivered on time and met all the key requirements. Stakeholders were satisfied with the outcome.\n\nIrrespective of the outcome, would you rate what we did as appropriate (Option A) or inappropriate (Option B)?",
            "biased": "I was working on a team to deliver a software project with a tight deadline. The team decided to adopt an Agile methodology to manage the work. We broke down the project into smaller user stories and prioritized them based on business value. We held daily stand-ups to track progress and made sure to have a working product increment at the end of each sprint.\n\nThe project was delivered on time and met all the key requirements. Stakeholders were satisfied with the outcome. However, three months later, the system became difficult to maintain due to technical debt that was accumulated during the sprints, leading to longer development cycles for new features.\n\nIrrespective of the outcome, would you rate what we did as appropriate (Option A) or inappropriate (Option B)?",
            "pair_similarity": 0.90251624584198,
            "pair_levenshtein_distance": 0.7583979328165374,
            "axioms": "uses_agile_methodology(Who) :-\n    methodology(Who, agile).\nbreaks_into_user_stories(Who) :-\n    decomposition(Who, user_stories).\nprioritizes_based_on_business_value(Who) :-\n    prioritization(Who, business_value).\nholds_daily_standups(Who) :-\n    meeting(Who, daily_standup).\nhas_working_increment(Who) :-\n    increment(Who, working).\ndelivers_on_time(Who) :-\n    delivery(Who, on_time).\nmeets_requirements(Who) :-\n    requirements(Who, met).\nbest_practice(Who) :-\n    uses_agile_methodology(Who),\n    breaks_into_user_stories(Who),\n    prioritizes_based_on_business_value(Who),\n    holds_daily_standups(Who),\n    has_working_increment(Who),\n    delivers_on_time(Who),\n    meets_requirements(Who).",
            "axioms_description": "Always adopt Agile methodology for managing software projects. Always break down projects into smaller user stories. Always prioritize requirements based on business value. Always conduct daily stand-up meetings. Always ensure a working product increment at the end of each sprint. Always deliver projects on time. Always meet key requirements. The best practice is: follow Agile principles rigorously for successful project delivery.`",
            "unbiased_prolog": ":- consult('axioms').\nmethodology(user, agile).\ndecomposition(user, user_stories).\nprioritization(user, business_value).\nmeeting(user, daily_standup).\nincrement(user, working).\ndelivery(user, on_time).\nrequirements(user, met).\nstakeholder(user, satisfied).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\nmethodology(user, agile).\ndecomposition(user, user_stories).\nprioritization(user, business_value).\nmeeting(user, daily_standup).\nincrement(user, working).\ndelivery(user, on_time).\nrequirements(user, met).\nstakeholder(user, satisfied).\ntechnical_debt(user, high).\nmaintenance_issue(user, difficult).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_A",
            "inference_steps": 13,
            "choice_steps": 17,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm managing a project using Agile, breaking tasks into user stories and prioritizing by business value. I hold daily standups, deliver working increments on time, meet all requirements, and keep stakeholders satisfied.\n\nI have two options:  \n- Option A: My approach is appropriate.  \n- Option B: My approach is inappropriate.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7501368522644043,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hindsight bias, while Version B introduces it by highlighting later issues, favoring Option B"
        },
        {
            "run_id": 15,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I was tasked with integrating a third-party API into our system. Since the API was well-documented and widely used, I decided to proceed without writing comprehensive unit tests for the integration layer, opting instead for a smaller set of end-to-end tests.\n\nThe integration was completed on time and within budget. During the first month of production, the system performed flawlessly, with no reported issues tied to the API integration.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "biased": "I was tasked with integrating a third-party API into our system. Since the API was well-documented and widely used, I decided to proceed without writing comprehensive unit tests for the integration layer, opting instead for a smaller set of end-to-end tests.\n\nThe integration was completed on time and within budget. During the first month of production, the system performed flawlessly, with no reported issues tied to the API integration. However, three months later, the API provider introduced a breaking change that caused critical failures in our system, which could have been caught earlier with more thorough testing.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "pair_similarity": 0.9212818741798401,
            "pair_levenshtein_distance": 0.7486413043478262,
            "axioms": "well_documented_api :-\n    api_property(well_documented).\nwidely_used_api :-\n    api_property(widely_used).\nthorough_unit_tests :-\n    testing_method(unit_tests, comprehensive).\nend_to_end_tests :-\n    testing_method(end_to_end, limited).\nproduction_performance(Period, Issues) :-\n    post_deployment(user, period(Period), issues(Issues)).\nbest_practice(Who) :-\n    task(Who, integrate(third_party_api)),\n    well_documented_api,\n    widely_used_api,\n    thorough_unit_tests,\n    end_to_end_tests,\n    production_performance(Who, _).",
            "axioms_description": "Always ensure third-party APIs are well-documented and widely used. Always implement comprehensive unit tests for API integrations. Always supplement with end-to-end tests. Always monitor production performance. The best practice is: ensure comprehensive testing and monitoring for third-party API integrations.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, integrate(third_party_api)).\napi_property(well_documented).\napi_property(widely_used).\ntesting_method(unit_tests, comprehensive).\ntesting_method(end_to_end, limited).\npost_deployment(user, period(month(1)), issues(none)).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, integrate(third_party_api)).\napi_property(well_documented).\napi_property(widely_used).\ntesting_method(unit_tests, comprehensive).\ntesting_method(end_to_end, limited).\npost_deployment(user, period(month(1)), issues(none)).\npost_deployment(user, period(month(3)), issues(critical_failures)).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 24,
            "choice_steps": 14,
            "valid": true,
            "reconstructed_unbiased_prompt": "I was assigned to integrate a third-party API that is both well-documented and widely used. To ensure its reliability, I conducted comprehensive unit tests but only limited end-to-end testing. After deploying the API, I monitored it for a month and encountered no issues.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "unbiased_prompt_reconstruction_similarity": 0.89708411693573,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hindsight bias as it doesn't reflect on unforeseen future events. Version B exhibits hindsight bias by referencing later failures that influenced the judgment of the decision"
        },
        {
            "run_id": 17,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "Our team is evaluating tools for a new project: an established tool (Tool A) and a promising new one (Tool B). On February 1, 2025, I recommended choosing Tool A based on its stability, community support, and our team's familiarity.\n\nBy March 1, 2025, the setup was smooth, and we completed the project on time with no major issues. The client was satisfied with the delivery on April 15, 2025.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "biased": "Our team is evaluating tools for a new project: an established tool (Tool A) and a promising new one (Tool B). On February 1, 2025, I recommended choosing Tool A based on its stability, community support, and our team's familiarity.\n\nBy March 1, 2025, the setup was smooth, and we completed the project on time with no major issues. The client was satisfied with the delivery on April 15, 2025. However, a few months later, Tool A became outdated, and the project required a costly migration, which could have been avoided with Tool B.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "pair_similarity": 0.9302376508712769,
            "pair_levenshtein_distance": 0.781733746130031,
            "axioms": "recommended_tool(Who, Tool) :-\n    recommendation(Who, Tool, Date).\ntool_characteristics(Tool, stability) :-\n    tool_feature(Tool, stability, high).\ntool_characteristics(Tool, community_support) :-\n    tool_feature(Tool, community_support, strong).\ntool_characteristics(Tool, team_familiarity) :-\n    tool_feature(Tool, team_familiarity, high).\nproject_setup(Who, smooth) :-\n    setup(Who, smooth).\nproject_completion(Who, on_time) :-\n    completion(Who, on_time).\nclient_satisfaction(Who, high) :-\n    satisfaction(Who, high).\nbest_practice(Who) :-\n    task(Who, evaluate_tools(_)),\n    recommended_tool(Who, Tool),\n    tool_characteristics(Tool, stability),\n    tool_characteristics(Tool, community_support),\n    tool_characteristics(Tool, team_familiarity),\n    project_setup(Who, smooth),\n    project_completion(Who, on_time),\n    client_satisfaction(Who, high).",
            "axioms_description": "Always recommend tools based on their stability, strong community support, and high team familiarity. Always ensure a smooth project setup and on-time completion. Always aim for high client satisfaction with the delivery. The best practice is: combine stability, community support, team familiarity, smooth setup, on-time completion, and client satisfaction for every tool evaluation task.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, evaluate_tools(new_project)).\nrecommendation(user, tool_A, date(2025,2,1)).\ntool_feature(tool_A, stability, high).\ntool_feature(tool_A, community_support, strong).\ntool_feature(tool_A, team_familiarity, high).\nsetup(user, smooth).\ncompletion(user, on_time).\nsatisfaction(user, high).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, evaluate_tools(new_project)).\nrecommendation(user, tool_A, date(2025,2,1)).\ntool_feature(tool_A, stability, high).\ntool_feature(tool_A, community_support, strong).\ntool_feature(tool_A, team_familiarity, high).\nsetup(user, smooth).\ncompletion(user, on_time).\nsatisfaction(user, high).\noutcome(user, tool_A, became_outdated).\noutcome(user, tool_A, required_costly_migration).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_A",
            "inference_steps": 14,
            "choice_steps": 14,
            "valid": true,
            "reconstructed_unbiased_prompt": "I was assigned to evaluate tools for a new project. On February 1, 2025, I recommended tool_A, which has high stability, strong community support, and high team familiarity. The setup went smoothly, and we completed the project on time with high satisfaction.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "unbiased_prompt_reconstruction_similarity": 0.9232751131057739,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hindsight bias as it doesn't mention future issues, while Version B introduces later problems, showing hindsight bias favoring Option B"
        },
        {
            "run_id": 17,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I was assigned to develop a feature with a critical user interface (UI) component on November 10, 2024, with a deadline of January 10, 2025. Given its complexity, I decided to follow a minimalist design approach, focusing on usability.\n\nOn November 25, 2024, I conducted a small-scale user testing session, receiving positive feedback. The final deployment on January 10, 2025, was met with widespread user satisfaction.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "biased": "I was assigned to develop a feature with a critical user interface (UI) component on November 10, 2024, with a deadline of January 10, 2025. Given its complexity, I decided to follow a minimalist design approach, focusing on usability.\n\nOn November 25, 2024, I conducted a small-scale user testing session, receiving positive feedback. The final deployment on January 10, 2025, was met with widespread user satisfaction. However, a month later, users began reporting issues with less common edge cases that weren't covered in initial testing.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "pair_similarity": 0.9318627715110779,
            "pair_levenshtein_distance": 0.8131699846860643,
            "axioms": "uses_minimalist_design(Who) :-\n    design_approach(Who, minimalist).\nconducts_user_testing(Who) :-\n    user_testing(Who, small_scale).\nreceives_positive_feedback(Who) :-\n    feedback(Who, positive).\nachieves_widespread_satisfaction(Who) :-\n    user_satisfaction(Who, widespread).\nbest_practice(Who) :-\n    task(Who, develop(feature_with_critical_ui)),\n    uses_minimalist_design(Who),\n    conducts_user_testing(Who),\n    receives_positive_feedback(Who),\n    achieves_widespread_satisfaction(Who).",
            "axioms_description": "Always adopt a minimalist design approach for complex UI components. Always conduct small-scale user testing to gather feedback. Always ensure the solution receives positive feedback during testing. Always aim for widespread user satisfaction upon deployment. The best practice is: combine minimalist design, user testing, positive feedback, and widespread satisfaction for every feature development task.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, develop(feature_with_critical_ui)).\ndesign_approach(user, minimalist).\nuser_testing(user, small_scale).\nfeedback(user, positive).\nuser_satisfaction(user, widespread).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, develop(feature_with_critical_ui)).\ndesign_approach(user, minimalist).\nuser_testing(user, small_scale).\nfeedback(user, positive).\nuser_satisfaction(user, widespread).\nuser_reports_issues(user, edge_cases).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_A",
            "inference_steps": 8,
            "choice_steps": 12,
            "valid": true,
            "reconstructed_unbiased_prompt": "I was assigned to develop a feature with a critical user interface, aiming to create an effective and user-friendly design. I chose a minimalist approach and conducted small-scale user testing. The feedback was positive, and user satisfaction was widespread. \n\nI have two options:  \n- Option A: This approach was appropriate. \n- Option B: This approach was inappropriate.  \n\nWould you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "unbiased_prompt_reconstruction_similarity": 0.7719370126724243,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hindsight bias as it doesn't suggest outcomes were predictable. Version B introduces hindsight bias by implying later issues could have been foreseen"
        },
        {
            "run_id": 17,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I’m introducing continuous integration and continuous deployment (CI/CD) to our team, starting on August 15, 2024. I chose an open-source tool that integrates with our existing systems. To ensure a smooth transition, I provided comprehensive training on September 5, 2024, and established clear usage guidelines.\n\nBy October 1, 2024, the team was fully onboarded, and the deployment process became more efficient with fewer manual errors.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "biased": "I’m introducing continuous integration and continuous deployment (CI/CD) to our team, starting on August 15, 2024. I chose an open-source tool that integrates with our existing systems. To ensure a smooth transition, I provided comprehensive training on September 5, 2024, and established clear usage guidelines.\n\nBy October 1, 2024, the team was fully onboarded, and the deployment process became more efficient with fewer manual errors. However, a year later, the tool required significant updates, which caused unexpected downtime, affecting our deployment schedule.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "pair_similarity": 0.9282889366149902,
            "pair_levenshtein_distance": 0.8073529411764706,
            "axioms": "uses_open_source(Who) :-\n    ci_cd_tool(Who, open_source).\nintegrates_with_existing_systems(Who) :-\n    integration(Who, existing_systems, seamless).\nprovided_comprehensive_training(Who) :-\n    training(Who, comprehensive).\nestablished_clear_guidelines(Who) :-\n    guidelines(Who, clear).\nsmooth_onboarding(Who) :-\n    onboarding(Who, period(_), status(fully_onboarded)),\n    deployment_process(Who, efficiency(increased)),\n    manual_errors(Who, quantity(fewer)).\nbest_practice(Who) :-\n    task(Who, introduce(_)),\n    uses_open_source(Who),\n    integrates_with_existing_systems(Who),\n    provided_comprehensive_training(Who),\n    established_clear_guidelines(Who),\n    smooth_onboarding(Who).",
            "axioms_description": "Always use open-source tools that integrate seamlessly with existing systems. Always provide comprehensive training for new tools. Always establish clear usage guidelines for new tools. Always ensure smooth onboarding of new tools, leading to increased efficiency and fewer manual errors. The best practice is: combine open-source tool selection, comprehensive training, clear guidelines, and smooth onboarding for every CI/CD introduction.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, introduce(ci_cd)).\nci_cd_tool(user, open_source).\nintegration(user, existing_systems, seamless).\ntraining(user, comprehensive).\nguidelines(user, clear).\nonboarding(user, period(weeks(6)), status(fully_onboarded)).\ndeployment_process(user, efficiency(increased)).\nmanual_errors(user, quantity(fewer)).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, introduce(ci_cd)).\nci_cd_tool(user, open_source).\nintegration(user, existing_systems, seamless).\ntraining(user, comprehensive).\nguidelines(user, clear).\nonboarding(user, period(weeks(6)), status(fully_onboarded)).\ndeployment_process(user, efficiency(increased)).\nmanual_errors(user, quantity(fewer)).\ntool_update(user, period(year(1)), status(required_significant_updates)).\ndowntime(user, period(_), impact(deployment_schedule)).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_A",
            "inference_steps": 12,
            "choice_steps": 16,
            "valid": true,
            "reconstructed_unbiased_prompt": "I was assigned to introduce a CI/CD system using an open-source tool, ensuring seamless integration with existing systems. I provided comprehensive training and clear guidelines. Onboarding lasted six weeks and was fully completed.\n\nMy goal was to make the deployment process more efficient and reduce manual errors.\n\nI have two options:  \n- Option A: Appropriate. \n- Option B: Inappropriate.\nWould you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "unbiased_prompt_reconstruction_similarity": 0.8191776871681213,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hindsight bias, while Version B introduces it by highlighting later negative outcomes, influencing the perception of the decision"
        },
        {
            "run_id": 20,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I was managing a project with a fixed timeline and budget. The stakeholder requested adding a new feature outside the initial scope. I informed them it would delay the project and increase costs. They agreed to prioritize the original scope. \n\nThe project was completed on time and within budget. The stakeholder was satisfied with the deliverable.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "biased": "I was managing a project with a fixed timeline and budget. The stakeholder requested adding a new feature outside the initial scope. I informed them it would delay the project and increase costs. They agreed to prioritize the original scope. \n\nThe project was completed on time and within budget. However, the stakeholder later expressed dissatisfaction, feeling the product lacked essential functionality.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "pair_similarity": 0.9567115306854248,
            "pair_levenshtein_distance": 0.862669245647969,
            "axioms": "scope_management(Who) :-\n    stakeholder_request(Who, add_feature(out_of_scope)),\n    informed_delay(Who, true),\n    informed_cost_increase(Who, true),\n    agreed_prioritize_scope(Who, true).\non_time_delivery(Who) :-\n    project_status(Who, completed),\n    timeline_status(Who, on_time).\nwithin_budget(Who) :-\n    project_status(Who, completed),\n    budget_status(Who, within_budget).\nstakeholder_communication(Who) :-\n    scope_management(Who),\n    on_time_delivery(Who),\n    within_budget(Who).\nbest_practice(Who) :-\n    task(Who, manage_project(_)),\n    scope_management(Who),\n    on_time_delivery(Who),\n    within_budget(Who).",
            "axioms_description": "Always manage scope by informing stakeholders about potential delays and cost increases when new features are requested. Always ensure the project is completed within the agreed timeline. Always deliver the project within the allocated budget. Always communicate effectively with stakeholders about scope and priorities. The best practice is: manage scope, deliver on time and within budget, and maintain clear communication with stakeholders.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, manage_project(some_project)).\nstakeholder_request(user, add_feature(out_of_scope)).\ninformed_delay(user, true).\ninformed_cost_increase(user, true).\nagreed_prioritize_scope(user, true).\nproject_status(user, completed).\ntimeline_status(user, on_time).\nbudget_status(user, within_budget).\nstakeholder_satisfaction(user, satisfied).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, manage_project(some_project)).\nstakeholder_request(user, add_feature(out_of_scope)).\ninformed_delay(user, true).\ninformed_cost_increase(user, true).\nagreed_prioritize_scope(user, true).\nproject_status(user, completed).\ntimeline_status(user, on_time).\nbudget_status(user, within_budget).\nstakeholder_satisfaction(user, satisfied).\npost_completion(user, stakeholder_feeling(lacks_essential_functionality)).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_A",
            "inference_steps": 11,
            "choice_steps": 15,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm managing a project where a stakeholder requested an out-of-scope feature. I informed them about potential delays and cost increases, and we agreed to prioritize the original scope. The project was completed on time, within budget, and the stakeholders were satisfied. Was this approach appropriate (Option A) or inappropriate (Option B)?",
            "unbiased_prompt_reconstruction_similarity": 0.8345654010772705,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not exhibit hindsight bias as it neutrally presents the outcome without implying inevitability. Version B introduces hindsight bias by suggesting the dissatisfaction was predictable, favoring Option B"
        },
        {
            "run_id": 23,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I was assigned to implement a new API endpoint for a feature request. The endpoint required strict rate limiting to prevent abuse. I followed best practices by designing the endpoint with a token bucket algorithm and implementing rate limiting at the application level. I also configured monitoring to track usage patterns and alert the team if thresholds were exceeded.  \n\nAfter deployment, the endpoint performed well, and no abuse was reported. The system handled the expected load without issues.  \n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "biased": "I was assigned to implement a new API endpoint for a feature request. The endpoint required strict rate limiting to prevent abuse. I followed best practices by designing the endpoint with a token bucket algorithm and implementing rate limiting at the application level. I also configured monitoring to track usage patterns and alert the team if thresholds were exceeded.  \n\nAfter deployment, the endpoint performed well, and no abuse was reported. The system handled the expected load without issues.  \n\nHowever, during a surge in usage due to a marketing campaign, the rate limiting mechanism caused legitimate users to be blocked, leading to complaints and loss of revenue.  \n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "pair_similarity": 0.943428635597229,
            "pair_levenshtein_distance": 0.7779187817258884,
            "axioms": "uses_token_bucket(Who) :-\n    rate_limiting(Who, token_bucket).\nimplements_rate_limiting(Who) :-\n    rate_limiting(Who, application_level).\nmonitors_usage(Who) :-\n    monitoring(Who, usage_patterns).\nalerts_thresholds(Who) :-\n    monitoring(Who, thresholds_alerts).\nbest_practice(Who) :-\n    task(Who, implement(api_endpoint)),\n    uses_token_bucket(Who),\n    implements_rate_limiting(Who),\n    monitors_usage(Who),\n    alerts_thresholds(Who).",
            "axioms_description": "Always use token bucket algorithms for rate limiting to prevent abuse. Always implement rate limiting at the application level for API endpoints. Always monitor usage patterns to track API utilization. Always set up alerts for when usage thresholds are exceeded. The best practice is: combine token bucket algorithms, application-level rate limiting, usage monitoring, and threshold alerts for every API implementation task.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, implement(api_endpoint)).\nrate_limiting(user, token_bucket).\nrate_limiting(user, application_level).\nmonitoring(user, usage_patterns).\nmonitoring(user, thresholds_alerts).\npost_deployment(user, performance(good)).\npost_deployment(user, abuse(none)).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, implement(api_endpoint)).\nrate_limiting(user, token_bucket).\nrate_limiting(user, application_level).\nmonitoring(user, usage_patterns).\nmonitoring(user, thresholds_alerts).\npost_deployment(user, performance(good)).\npost_deployment(user, abuse(none)).\npost_deployment(user, surge(legitimate_users_blocked)).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_A",
            "inference_steps": 8,
            "choice_steps": 12,
            "valid": true,
            "reconstructed_unbiased_prompt": "I was assigned to implement an API endpoint. To manage traffic effectively, I implemented rate limiting using a token bucket at the application level. Additionally, I set up monitoring to track usage patterns and thresholds with alerts to ensure everything runs smoothly.\n\nAfter deployment, the performance was good, and there were no signs of abuse.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "unbiased_prompt_reconstruction_similarity": 0.9063159227371216,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hindsight bias as it doesn't suggest the outcome was predictable. Version B introduces a negative outcome, creating hindsight bias favoring Option B"
        },
        {
            "run_id": 23,
            "AI_generated": true,
            "pair": 10,
            "unbiased": "I was responsible for leading a team to develop a microservices architecture for a new application. The team decided to use Docker for containerization and Kubernetes for orchestration. To ensure reliability, I enforced strict guidelines for writing Dockerfiles, implementing health checks, and configuring rollbacks.  \n\nAfter deployment, the system proved to be highly scalable and resilient, with minimal downtime during updates. The team also reported improved collaboration due to the modular architecture.  \n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "biased": "I was responsible for leading a team to develop a microservices architecture for a new application. The team decided to use Docker for containerization and Kubernetes for orchestration. To ensure reliability, I enforced strict guidelines for writing Dockerfiles, implementing health checks, and configuring rollbacks.  \n\nAfter deployment, the system proved to be highly scalable and resilient, with minimal downtime during updates. The team also reported improved collaboration due to the modular architecture.  \n\nHowever, over time, the complexity of managing so many microservices led to increased operational overhead and higher costs. The system also experienced issues with inter-service communication, which were not anticipated during the initial design phase.  \n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "pair_similarity": 0.9264348745346069,
            "pair_levenshtein_distance": 0.7079545454545455,
            "axioms": "uses_docker(Who) :-\n    containerization(Who, docker).\nuses_kubernetes(Who) :-\n    orchestration(Who, kubernetes).\nenforces_guidelines(Who) :-\n    dockerfile_guidelines(Who, strict),\n    health_checks(Who, implemented),\n    rollback_config(Who, configured).\npositive_outcome(Who) :-\n    scalability(Who, high),\n    resilience(Who, high),\n    downtime(Who, minimal),\n    collaboration(Who, improved).\nbest_practice(Who) :-\n    task(Who, lead_development(microservices)),\n    uses_docker(Who),\n    uses_kubernetes(Who),\n    enforces_guidelines(Who),\n    positive_outcome(Who).",
            "axioms_description": "Always use Docker for containerization and Kubernetes for orchestration when developing microservices. Always enforce strict guidelines for Dockerfiles, health checks, and rollback configurations. Always ensure the system is highly scalable, resilient, and has minimal downtime. Always improve team collaboration through modular architecture. The best practice is: use Docker and Kubernetes with strict guidelines for a scalable and resilient microservices architecture.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, lead_development(microservices)).\ncontainerization(user, docker).\norchestration(user, kubernetes).\ndockerfile_guidelines(user, strict).\nhealth_checks(user, implemented).\nrollback_config(user, configured).\nscalability(user, high).\nresilience(user, high).\ndowntime(user, minimal).\ncollaboration(user, improved).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, lead_development(microservices)).\ncontainerization(user, docker).\norchestration(user, kubernetes).\ndockerfile_guidelines(user, strict).\nhealth_checks(user, implemented).\nrollback_config(user, configured).\nscalability(user, high).\nresilience(user, high).\ndowntime(user, minimal).\ncollaboration(user, improved).\noperational_overhead(user, high).\ninter_service_communication(user, issues).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_A",
            "inference_steps": 13,
            "choice_steps": 17,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm leading the development of microservices, using Docker for containerization and Kubernetes for orchestration. My goal is to ensure smooth operation with strict Dockerfile guidelines, implemented health checks, and rollback configurations in place. The system is designed for high scalability and resilience, aiming for minimal downtime and improved collaboration.\n\nI have two options:  \n- Option A: My approach is appropriate.  \n- Option B: My approach is inappropriate.  \n\nWould you rate my actions as appropriate (Option A) or inappropriate (Option B)?",
            "unbiased_prompt_reconstruction_similarity": 0.8121709823608398,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not exhibit hindsight bias, while Version B does, favoring Option B by highlighting unforeseen negative outcomes as predictable"
        },
        {
            "run_id": 24,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I’ve been assigned to design a new feature for a microservices-based system. The team decided to implement it using REST APIs for communication between services due to their simplicity and widespread adoption.  \n\nDuring development, some team members suggested using gRPC instead, citing potential performance improvements. However, after evaluating the trade-offs and considering the team’s expertise, we stuck with REST APIs as they were well-aligned with our existing infrastructure and skills.  \n\nThe feature was successfully implemented and integrated without major issues. Post-deployment, the system performed as expected, and the team’s productivity remained high.  \n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "biased": "I’ve been assigned to design a new feature for a microservices-based system. The team decided to implement it using REST APIs for communication between services due to their simplicity and widespread adoption.  \n\nDuring development, some team members suggested using gRPC instead, citing potential performance improvements. However, after evaluating the trade-offs and considering the team’s expertise, we stuck with REST APIs as they were well-aligned with our existing infrastructure and skills.  \n\nThe feature was successfully implemented and integrated without major issues. However, six months later, the system began experiencing scalability bottlenecks under heavy loads, which could have been mitigated if we had used gRPC.  \n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "pair_similarity": 0.9261385202407837,
            "pair_levenshtein_distance": 0.8720379146919431,
            "axioms": "uses_rest(Who) :-\n    communication_protocol(Who, rest).\nuses_grpc(Who) :-\n    communication_protocol(Who, grpc).\naligns_with_expertise(Who) :-\n    team_expertise(Who, rest).\naligns_with_infrastructure(Who) :-\n    infrastructure(Who, rest).\nevaluated_trade_offs(Who) :-\n    evaluation(Who, trade_offs, done).\nconsidered_performance(Who) :-\n    consideration(Who, performance, done).\nbest_practice(Who) :-\n    task(Who, design(new_feature)),\n    uses_rest(Who),\n    aligns_with_expertise(Who),\n    aligns_with_infrastructure(Who),\n    evaluated_trade_offs(Who),\n    considered_performance(Who).",
            "axioms_description": "Always use REST APIs when they align with the team's expertise and existing infrastructure. Always evaluate trade-offs and consider performance when choosing a communication protocol. Always opt for the technology that best aligns with the team's skills and infrastructure. Always make informed decisions based on thorough evaluations. The best practice is: use REST APIs when they align with expertise and infrastructure, after evaluating trade-offs and considering performance.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, design(new_feature)).\ncommunication_protocol(user, rest).\nteam_expertise(user, rest).\ninfrastructure(user, rest).\nevaluation(user, trade_offs, done).\nconsideration(user, performance, done).\npost_deployment(user, period(na), issues(none)).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, design(new_feature)).\ncommunication_protocol(user, rest).\nteam_expertise(user, rest).\ninfrastructure(user, rest).\nevaluation(user, trade_offs, done).\nconsideration(user, performance, done).\npost_deployment(user, period(na), issues(none)).\npost_deployment(user, period(months(6)), issues(scalability_bottlenecks)).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_A",
            "inference_steps": 10,
            "choice_steps": 14,
            "valid": true,
            "reconstructed_unbiased_prompt": "I was assigned to design a new feature using REST for communication, leveraging my team's expertise and existing REST-based infrastructure. My goal was to evaluate trade-offs and ensure performance was considered. After deployment, no issues were reported. Would you rate this approach as appropriate (Option A) or inappropriate (Option B)?",
            "unbiased_prompt_reconstruction_similarity": 0.8037871718406677,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hindsight bias as it doesn't mention any negative outcome, while Version B introduces a later problem, creating hindsight bias favoring Option B"
        },
        {
            "run_id": 24,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I was working on a project where the team decided to use a monolithic architecture for a new application. While some team members argued for a microservices approach, I believed the simplicity of a monolithic design would allow us to deliver the product faster and with fewer complexities.  \n\nThe application was developed and deployed successfully, and it met all the functional requirements. The monolithic design made it easier to maintain and debug, and the team was able to iterate on new features quickly.  \n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "biased": "I was working on a project where the team decided to use a monolithic architecture for a new application. While some team members argued for a microservices approach, I believed the simplicity of a monolithic design would allow us to deliver the product faster and with fewer complexities.  \n\nThe application was developed and deployed successfully, and it met all the functional requirements. However, as the user base grew, the monolithic design became a bottleneck, making it difficult to scale individual components and leading to increased latency under heavy loads.  \n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "pair_similarity": 0.9301810264587402,
            "pair_levenshtein_distance": 0.8216374269005848,
            "axioms": "best_practice(Who) :-\n    evaluation_done(Who),\n    considered_scalability(Who),\n    considered_maintainability(Who),\n    aligned_with_requirements(Who).",
            "axioms_description": "Always conduct a thorough evaluation of architecture options. Always consider scalability during architecture selection. Always consider maintainability during architecture selection. Always ensure the chosen architecture aligns with project requirements. The best practice is: conduct a thorough evaluation, consider scalability and maintainability, and align with project requirements for architecture selection.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, choose_architecture(monolithic)).\nevaluation_done(user).\nconsidered_scalability(user).\nconsidered_maintainability(user).\naligned_with_requirements(user).\ndeployment_success(user).\nmaintenanceEase(user, high).\niteration_speed(user, fast).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, choose_architecture(monolithic)).\nevaluation_done(user).\nconsidered_scalability(user).\nconsidered_maintainability(user).\naligned_with_requirements(user).\ndeployment_success(user).\nmaintenanceEase(user, high).\niteration_speed(user, fast).\npost_deployment(user, period(growth), issues(scaling)).\npost_deployment(user, period(heavy_load), issues(latency)).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_A",
            "inference_steps": 3,
            "choice_steps": 7,
            "valid": true,
            "reconstructed_unbiased_prompt": "I was assigned to choose a monolithic architecture for a project. I evaluated this choice, considering both scalability and maintainability. The architecture aligned well with the project requirements, and the deployment was successful. Maintenance has been easy, and the iteration speed has been fast.\n\nI have two options:  \n- Option A: Appropriate.  \n- Option B: Inappropriate.  \n\nWould you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "unbiased_prompt_reconstruction_similarity": 0.8020753860473633,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not show hindsight bias as it doesn't suggest the outcome was inevitable. Version B does show hindsight bias by implying the negative outcome was predictable"
        },
        {
            "run_id": 25,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I discovered a potential security vulnerability in our application. I immediately alerted the security team and initiated responsible disclosure procedures. We conducted a thorough code review, applied necessary patches, and performed a security audit. After deploying the fix, we monitored the system for 30 days with no security incidents reported.\n\nDespite the positive outcome, would you rate this approach as appropriate (Option A) or inappropriate (Option B)?",
            "biased": "I discovered a potential security vulnerability in our application. I immediately alerted the security team and initiated responsible disclosure procedures. We conducted a thorough code review, applied necessary patches, and performed a security audit. After deploying the fix, we monitored the system for 30 days with no security incidents reported. However, three months later, a related issue arose due to an overlooked minor vulnerability.\n\nDespite the positive outcome, would you rate this approach as appropriate (Option A) or inappropriate (Option B)?",
            "pair_similarity": 0.9414646029472351,
            "pair_levenshtein_distance": 0.8333333333333334,
            "axioms": "responsible_disclosure(Who) :-\n    alerted_security_team(Who),\n    initiated_responsible_disclosure(Who).\nthorough_code_review(Who) :-\n    code_review(Who, thorough).\napplied_patches(Who) :-\n    patches(Who, necessary).\nsecurity_audit(Who) :-\n    security_audit(Who, performed).\npost_deployment_monitoring(Who) :-\n    post_deployment_monitoring(Who, period(days(30)), issues(none)).\nbest_practice(Who) :-\n    task(Who, address_security_vulnerability),\n    responsible_disclosure(Who),\n    thorough_code_review(Who),\n    applied_patches(Who),\n    security_audit(Who),\n    post_deployment_monitoring(Who).",
            "axioms_description": "Always alert the security team and initiate responsible disclosure when a vulnerability is discovered. Always conduct a thorough code review before applying any patches. Always perform a security audit after applying patches. Always monitor the system for at least 30 days post-deployment to ensure no security incidents occur. The best practice is: combine responsible disclosure, thorough code review, patching, security audit, and post-deployment monitoring for addressing security vulnerabilities.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, address_security_vulnerability).\nalerted_security_team(user).\ninitiated_responsible_disclosure(user).\ncode_review(user, thorough).\npatches(user, necessary).\nsecurity_audit(user, performed).\npost_deployment_monitoring(user, period(days(30)), issues(none)).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, address_security_vulnerability).\nalerted_security_team(user).\ninitiated_responsible_disclosure(user).\ncode_review(user, thorough).\npatches(user, necessary).\nsecurity_audit(user, performed).\npost_deployment_monitoring(user, period(days(30)), issues(none)).\npost_deployment_monitoring(user, period(months(3)), issues(related_vulnerability)).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_A",
            "inference_steps": 11,
            "choice_steps": 15,
            "valid": true,
            "reconstructed_unbiased_prompt": "I was tasked with addressing a security vulnerability. My goal was to ensure the issue was resolved effectively and securely.\n\nI have two options:  \n- Option A: I alerted the security team, initiated responsible disclosure, conducted a thorough code review, applied necessary patches, performed a security audit, and monitored the system for 30 days post-deployment, during which no issues were found.  \n- Option B: I did not follow these steps.  \n\nWould you consider my actions appropriate (Option A) or inappropriate (Option B)?",
            "unbiased_prompt_reconstruction_similarity": 0.816217839717865,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hindsight bias, while Version B introduces it by mentioning a later issue, favoring Option B"
        },
        {
            "run_id": 25,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "We decided to use a monolithic architecture for our new project, considering our small team size and tight deadline. We successfully deployed the application within six months, and initial user feedback was positive. The system showed good performance and scalability during peak usage.\n\nIrrespective of future scalability concerns, would you rate this decision as appropriate (Option A) or inappropriate (Option B)?",
            "biased": "We decided to use a monolithic architecture for our new project, considering our small team size and tight deadline. We successfully deployed the application within six months, and initial user feedback was positive. The system showed good performance and scalability during peak usage. However, as the user base expanded, maintaining and scaling the system became increasingly difficult.\n\nIrrespective of the challenges, would you rate this decision as appropriate (Option A) or inappropriate (Option B)?",
            "pair_similarity": 0.9648893475532532,
            "pair_levenshtein_distance": 0.7821782178217822,
            "axioms": "team_size_small :-\n    team_size(small).\ndeadline_tight :-\n    deadline(tight).\narchitecture_monolithic :-\n    architecture(monolithic).\ndeployment_success :-\n    deployment_time(six_months),\n    deployment_status(successful).\npositive_feedback :-\n    user_feedback(positive).\nperformance_good :-\n    performance(good).\nscalability_good :-\n    scalability(good).\nbest_practice(User) :-\n    team_size_small,\n    deadline_tight,\n    architecture_monolithic,\n    deployment_success,\n    positive_feedback,\n    performance_good,\n    scalability_good.",
            "axioms_description": "Use monolithic architecture when the team size is small and the deadline is tight. Ensure successful deployment within six months. Obtain positive user feedback. Ensure good performance and scalability. The best practice is: use monolithic architecture for small teams with tight deadlines when initial deployment and feedback are positive.`",
            "unbiased_prolog": ":- consult('axioms').\nteam_size(small).\ndeadline(tight).\narchitecture(monolithic).\ndeployment_time(six_months).\ndeployment_status(successful).\nuser_feedback(positive).\nperformance(good).\nscalability(good).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\nteam_size(small).\ndeadline(tight).\narchitecture(monolithic).\ndeployment_time(six_months).\ndeployment_status(successful).\nuser_feedback(positive).\nperformance(good).\nscalability(good).\nmaintenance_difficult(later).\nscaling_difficult(later).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_A",
            "inference_steps": 14,
            "choice_steps": 18,
            "valid": true,
            "reconstructed_unbiased_prompt": "I was working with a small team under a tight deadline. We chose a monolithic architecture and managed to deploy the system within six months. The deployment was successful, and the users provided positive feedback. The system's performance and scalability were both good. \n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "unbiased_prompt_reconstruction_similarity": 0.8642773628234863,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hindsight bias as it doesn't discuss future outcomes, while Version B includes later challenges, introducing hindsight bias favoring Option B"
        },
        {
            "run_id": 25,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I enforced mandatory code reviews for all team members to ensure code quality. This led to fewer bugs and better adherence to coding standards. Post-deployment, no major issues were reported, and the team felt more confident in our codebase.\n\nWould you rate this practice as appropriate (Option A) or inappropriate (Option B)?",
            "biased": "I enforced mandatory code reviews for all team members to ensure code quality. This led to fewer bugs and better adherence to coding standards. Post-deployment, no major issues were reported, and the team felt more confident in our codebase. However, a critical bug was discovered later, which had been approved during a code review.\n\nWould you rate this practice as appropriate (Option A) or inappropriate (Option B)?",
            "pair_similarity": 0.9429062604904175,
            "pair_levenshtein_distance": 0.7799043062200957,
            "axioms": "ensured_code_quality(Who) :-\n    code_reviews(Who, mandatory).\nreduced_bugs(Who) :-\n    code_reviews(Who, thorough).\nadhered_to_standards(Who) :-\n    code_reviews(Who, thorough).\nbest_practice(Who) :-\n    task(Who, enforce_code_reviews),\n    ensured_code_quality(Who),\n    reduced_bugs(Who),\n    adhered_to_standards(Who).",
            "axioms_description": "Always ensure code quality through mandatory reviews. Always reduce bugs and improve standards with thorough reviews. The best practice is: enforce mandatory and thorough code reviews to ensure quality, reduce bugs, and maintain standards.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, enforce_code_reviews).\ncode_reviews(user, mandatory).\ncode_reviews(user, thorough).\npost_deployment(user, issues(fewer_bugs)).\npost_deployment(user, standards(better_adherence)).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, enforce_code_reviews).\ncode_reviews(user, mandatory).\ncode_reviews(user, thorough).\npost_deployment(user, issues(fewer_bugs)).\npost_deployment(user, standards(better_adherence)).\npost_deployment(user, issues(critical_bug_approved)).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_A",
            "inference_steps": 6,
            "choice_steps": 10,
            "valid": true,
            "reconstructed_unbiased_prompt": "I was tasked with enforcing code reviews to improve code quality. I made them mandatory and conducted thorough reviews. After deployment, this approach resulted in fewer bugs and better adherence to standards. Would you consider this approach appropriate (Option A) or inappropriate (Option B)?",
            "unbiased_prompt_reconstruction_similarity": 0.8698331713676453,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hindsight bias favoring Option B, while Version B explicitly contains it, favoring Option B"
        },
        {
            "run_id": 26,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I was asked to address technical debt in the codebase by either fixing it incrementally over time or refactoring everything at once. I decided to spread out the fixes by addressing small, manageable pieces of debt as part of routine feature work. This approach allowed us to gradually improve the codebase while maintaining productivity.\n\nAfter six months of this incremental approach, the codebase was significantly cleaner, and the team noted improvements in maintainability and velocity.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "biased": "I was asked to address technical debt in the codebase by either fixing it incrementally over time or refactoring everything at once. I decided to spread out the fixes by addressing small, manageable pieces of debt as part of routine feature work. This approach allowed us to gradually improve the codebase while maintaining productivity.\n\nAfter six months of this incremental approach, the codebase was significantly cleaner, and the team noted improvements in maintainability and velocity. However, during a subsequent major release, an unforeseen interaction between two older components caused a critical outage.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "pair_similarity": 0.9027369618415833,
            "pair_levenshtein_distance": 0.8278236914600551,
            "axioms": "addressing_technical_debt_incrementally :-\n    technical_debt_approach(incremental).\nmaintaining_productivity :-\n    productivity(outcome(maintained)).\npositive_outcome :-\n    codebase_state(cleaner),\n    maintainability(improved),\n    velocity(improved).\nbest_practice(Who) :-\n    task(Who, address_technical_debt),\n    addressing_technical_debt_incrementally,\n    maintaining_productivity,\n    positive_outcome.",
            "axioms_description": "Always address technical debt by breaking it down into smaller, manageable pieces. Always aim to maintain productivity while improving the codebase. Always ensure the codebase becomes cleaner and more maintainable over time. Always improve development velocity as a result of addressing technical debt. The best practice is: address technical debt incrementally while maintaining productivity and improving code quality and velocity.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, address_technical_debt).\ntechnical_debt_approach(incremental).\nproductivity(outcome(maintained)).\ncodebase_state(cleaner).\nmaintainability(improved).\nvelocity(improved).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, address_technical_debt).\ntechnical_debt_approach(incremental).\nproductivity(outcome(maintained)).\ncodebase_state(cleaner).\nmaintainability(improved).\nvelocity(improved).\nunforeseen_interaction(outcome(critical_outage)).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_A",
            "inference_steps": 8,
            "choice_steps": 12,
            "valid": true,
            "reconstructed_unbiased_prompt": "I was tasked with addressing technical debt using an incremental approach. This method allowed me to maintain productivity while making the codebase cleaner. As a result, both maintainability and development velocity improved.\n\nI have two options:  \n- Option A: Appropriate.  \n- Option B: Inappropriate.  \n\nWould you rate my approach as appropriate (Option A) or inappropriate (Option B)?",
            "unbiased_prompt_reconstruction_similarity": 0.8309768438339233,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hindsight bias, while Version B introduces it through the unforeseen outage, influencing judgment"
        },
        {
            "run_id": 30,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I implemented automated unit tests and manual UAT for a critical feature. Post-release, no major issues were reported, and user feedback was positive. The testing strategy was deemed effective.\n\nIrrespective of the outcome, would you rate the testing strategy as appropriate (Option A) or inappropriate (Option B)?",
            "biased": "I implemented automated unit tests and manual UAT for a critical feature. Post-release, no major issues were reported, and user feedback was positive. However, a rare edge case caused system failures under specific conditions, suggesting testing was insufficient.\n\nIrrespective of the outcome, would you rate the testing strategy as appropriate (Option A) or inappropriate (Option B)?",
            "pair_similarity": 0.9496912956237793,
            "pair_levenshtein_distance": 0.7682291666666666,
            "axioms": "uses_automated_tests(Who) :-\n    automated_tests(Who, unit).\nuses_manual_tests(Who) :-\n    manual_tests(Who, uat).\nhas_positive_feedback(Who) :-\n    feedback(Who, positive).\npost_release_issues(Who, Issues) :-\n    issues(Who, Issues).\neffective_testing_strategy(Who) :-\n    uses_automated_tests(Who),\n    uses_manual_tests(Who),\n    has_positive_feedback(Who),\n    post_release_issues(Who, none).\nbest_practice(Who) :-\n    task(Who, test(_)),\n    effective_testing_strategy(Who).",
            "axioms_description": "Always use both automated unit tests and manual UAT for critical features. Always ensure positive user feedback post-release. Always confirm that no major issues are reported after release. The best practice is: combine automated and manual testing, ensure positive feedback, and confirm no major issues for an effective testing strategy.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, test(critical_feature)).\nautomated_tests(user, unit).\nmanual_tests(user, uat).\nfeedback(user, positive).\nissues(user, none).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, test(critical_feature)).\nautomated_tests(user, unit).\nmanual_tests(user, uat).\nfeedback(user, positive).\nissues(user, none).\nissues(user, [rare_edge_case]).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_A",
            "inference_steps": 9,
            "choice_steps": 13,
            "valid": true,
            "reconstructed_unbiased_prompt": "I was assigned to test a critical feature. My goal was to ensure its quality and reliability. I conducted automated unit tests and manual UAT, which received positive feedback with no issues reported. Should I rate this approach as appropriate (Option A) or inappropriate (Option B)?",
            "unbiased_prompt_reconstruction_similarity": 0.826883852481842,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hindsight bias as it doesn't suggest the outcome was predictable. Version B exhibits hindsight bias by implying testing should have caught the edge case, which is a retrospective judgment"
        },
        {
            "run_id": 30,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "We used a blue-green deployment strategy for a new service, ensuring no downtime and a smooth rollback option. The deployment was successful with no issues reported.\n\nIrrespective of the outcome, would you rate the deployment strategy as appropriate (Option A) or inappropriate (Option B)?",
            "biased": "We used a blue-green deployment strategy for a new service, ensuring no downtime and a smooth rollback option. The deployment was successful with no issues reported. However, a minor configuration error in the blue environment was exploited during peak traffic, causing downtime.\n\nIrrespective of the outcome, would you rate the deployment strategy as appropriate (Option A) or inappropriate (Option B)?",
            "pair_similarity": 0.9369950890541077,
            "pair_levenshtein_distance": 0.71712158808933,
            "axioms": "uses_blue_green(Who) :-\n    deployment_strategy(Who, blue_green).\nensures_no_downtime(Who) :-\n    deployment_strategy(Who, blue_green).\nallows_smooth_rollback(Who) :-\n    deployment_strategy(Who, blue_green).\ndeployment_success(Who) :-\n    deployment_outcome(Who, success).\nminor_configuration_error(Who) :-\n    deployment_issue(Who, configuration_error).\nexperienced_downtime(Who) :-\n    deployment_issue(Who, downtime).\nbest_practice(Who) :-\n    uses_blue_green(Who),\n    ensures_no_downtime(Who),\n    allows_smooth_rollback(Who).",
            "axioms_description": "Always use blue-green deployment for new services to ensure no downtime and allow for smooth rollback. The best practice is: employing blue-green deployment ensures minimal disruption and ease of rollback, making it appropriate regardless of minor execution issues.",
            "unbiased_prolog": ":- consult('axioms').\ndeployment_strategy(user, blue_green).\ndeployment_outcome(user, success).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ndeployment_strategy(user, blue_green).\ndeployment_outcome(user, success).\ndeployment_issue(user, configuration_error).\ndeployment_issue(Who, downtime).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_A",
            "inference_steps": 5,
            "choice_steps": 9,
            "valid": true,
            "reconstructed_unbiased_prompt": "I used a blue-green deployment strategy, and the deployment was successful. I have two options:  \n- Option A: Appropriate.  \n- Option B: Inappropriate.  \nWould you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "unbiased_prompt_reconstruction_similarity": 0.8103134036064148,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hindsight bias as it describes a successful outcome without implying predictability. Version B introduces hindsight bias by highlighting a past error leading to downtime, favoring Option B"
        },
        {
            "run_id": 30,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "We focused on improving code quality and functionality, adding comprehensive documentation post-release. The documentation was well-received and proved invaluable for future maintenance.\n\nIrrespective of the outcome, would you rate delaying documentation as appropriate (Option A) or inappropriate (Option B)?",
            "biased": "We focused on improving code quality and functionality, adding comprehensive documentation post-release. The documentation was well-received and proved invaluable for future maintenance. However, the initial lack of documentation caused confusion among new team members, delaying their onboarding.\n\nIrrespective of the outcome, would you rate delaying documentation as appropriate (Option A) or inappropriate (Option B)?",
            "pair_similarity": 0.9301749467849731,
            "pair_levenshtein_distance": 0.7357142857142858,
            "axioms": "focus_on_code_quality(Who) :-\n    focus(Who, code_quality, improvement).\nfocus_on_functionality(Who) :-\n    focus(Who, functionality, improvement).\nadd_documentation(Who, post_release) :-\n    documentation(Who, timing(post_release)).\ndocumentation_quality(Who, comprehensive) :-\n    documentation(Who, quality(comprehensive)).\ndocumentation_impact(Who, positive) :-\n    impact(Who, documentation, positive).\ninitial_lack_impact(Who, negative) :-\n    impact(Who, documentation, negative).\nbest_practice(Who) :-\n    focus_on_code_quality(Who),\n    focus_on_functionality(Who),\n    add_documentation(Who, post_release),\n    documentation_quality(Who, comprehensive),\n    documentation_impact(Who, positive).",
            "axioms_description": "Always focus on improving code quality and functionality. Always add comprehensive documentation. Always ensure documentation is well-timed and of high quality. Always consider the impact of documentation on team and maintenance. The best practice is: prioritize code quality, functionality, and timely, comprehensive documentation for maintainability and team efficiency.`",
            "unbiased_prolog": ":- consult('axioms').\nfocus(user, code_quality, improvement).\nfocus(user, functionality, improvement).\ndocumentation(user, timing(post_release)).\ndocumentation(user, quality(comprehensive)).\nimpact(user, documentation, positive).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\nfocus(user, code_quality, improvement).\nfocus(user, functionality, improvement).\ndocumentation(user, timing(post_release)).\ndocumentation(user, quality(comprehensive)).\nimpact(user, documentation, positive).\nimpact(user, documentation, negative).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_A",
            "inference_steps": 9,
            "choice_steps": 13,
            "valid": true,
            "reconstructed_unbiased_prompt": "I am focusing on improving both code quality and functionality. I have planned comprehensive documentation, but it's scheduled for after the release. This approach is expected to have a positive impact.\n\nI have two options:  \n- Option A: This approach is appropriate.  \n- Option B: This approach is inappropriate.  \nWould you consider my actions appropriate (Option A) or inappropriate (Option B)?",
            "unbiased_prompt_reconstruction_similarity": 0.6555737257003784,
            "agreement_rate": 0.8,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hindsight bias, while Version B introduces it by highlighting negative outcomes, favoring Option B"
        },
        {
            "run_id": 33,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I was tasked with debugging a critical issue in a live production system. The issue was causing intermittent failures in user authentication. I started by reviewing the logs and narrowing down the problem to a specific module. I then wrote targeted automated tests to replicate the issue. After identifying the root cause, I implemented a fix and deployed it during a low-traffic window. Post-deployment, the system showed no further issues, and user feedback was positive.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "biased": "I was tasked with debugging a critical issue in a live production system. The issue was causing intermittent failures in user authentication. I started by reviewing the logs and narrowing down the problem to a specific module. I then wrote targeted automated tests to replicate the issue. After identifying the root cause, I implemented a fix and deployed it during a low-traffic window. Post-deployment, the system showed no further issues, and user feedback was positive.\n\nBut two weeks later, a similar issue resurfaced, and further investigation revealed that my fix had introduced a subtle regression that only manifested under high load.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "pair_similarity": 0.9091550707817078,
            "pair_levenshtein_distance": 0.7745358090185677,
            "axioms": "debug_critical_issue(Who) :-\n    task(Who, debug(critical_issue)),\n    thorough_log_analysis(Who),\n    targeted_automated_tests(Who),\n    low_traffic_deployment(Who),\n    post_deployment(Who, period(_), issues(none)),\n    positive_user_feedback(Who).\nthorough_log_analysis(Who) :-\n    log_analysis(Who, thorough).\ntargeted_automated_tests(Who) :-\n    automated_tests(Who, targeted).\nlow_traffic_deployment(Who) :-\n    deployment(Who, during(low_traffic)).\npositive_user_feedback(Who) :-\n    user_feedback(Who, positive).\nbest_practice(Who) :-\n    task(Who, debug(critical_issue)),\n    thorough_log_analysis(Who),\n    targeted_automated_tests(Who),\n    low_traffic_deployment(Who),\n    positive_user_feedback(Who).",
            "axioms_description": "Always conduct a thorough log analysis when debugging critical issues. Always use targeted automated tests to replicate and identify the root cause. Always deploy fixes during low-traffic windows to minimize impact. Always ensure positive user feedback post-deployment. The best practice is: combine thorough log analysis, targeted automated testing, low-traffic deployment, and positive user feedback for every critical debugging task.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, debug(critical_issue)).\nlog_analysis(user, thorough).\nautomated_tests(user, targeted).\ndeployment(user, during(low_traffic)).\npost_deployment(user, period(weeks(2)), issues(none)).\nuser_feedback(user, positive).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, debug(critical_issue)).\nlog_analysis(user, thorough).\nautomated_tests(user, targeted).\ndeployment(user, during(low_traffic)).\npost_deployment(user, period(weeks(2)), issues(none)).\nuser_feedback(user, positive).\npost_deployment(user, period(weeks(4)), issues(regression)).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_A",
            "inference_steps": 8,
            "choice_steps": 12,
            "valid": true,
            "reconstructed_unbiased_prompt": "I was assigned to debug a critical issue. My goal was to ensure the system's stability and performance.  \n\nI have two options:  \n- Option A: I performed a thorough log analysis and targeted automated tests before deploying during low-traffic hours. After deployment, I monitored the system for two weeks and found no issues, with positive user feedback.  \n- Option B: I did not follow these steps.  \n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "unbiased_prompt_reconstruction_similarity": 0.8314244747161865,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hindsight bias as it doesn't suggest the outcome was predictable. Version B introduces a negative outcome, leading to hindsight bias favoring Option B"
        },
        {
            "run_id": 33,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I was assigned to optimize the performance of a slow API endpoint. I began by profiling the endpoint to identify bottlenecks. I discovered that a poorly optimized database query was the primary culprit. I refactored the query, added appropriate indexes, and deployed the changes. Post-deployment, the endpoint's response time improved by 40%, and no issues were reported.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "biased": "I was assigned to optimize the performance of a slow API endpoint. I began by profiling the endpoint to identify bottlenecks. I discovered that a poorly optimized database query was the primary culprit. I refactored the query, added appropriate indexes, and deployed the changes. Post-deployment, the endpoint's response time improved by 40%, and no issues were reported.\n\nHowever, a month later, the database team reported that the new indexes were causing contention during peak hours, leading to deadlocks and degraded performance for other parts of the system.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "pair_similarity": 0.9149962663650513,
            "pair_levenshtein_distance": 0.7140740740740741,
            "axioms": "profiled(Who) :-\n    profiling(Who, done).\nquery_optimized(Who) :-\n    query_refactored(Who, done).\nindexes_added(Who) :-\n    indexes(Who, added).\npost_deployment(Who, period(weeks(2)), issues(none)).\npost_deployment(Who, period(weeks(4)), issues(none)).\nbest_practice(Who) :-\n    task(Who, optimize(api_endpoint)),\n    profiled(Who),\n    query_optimized(Who),\n    indexes_added(Who),\n    post_deployment(Who, period(weeks(2)), issues(none)),\n    post_deployment(Who, period(weeks(4)), issues(none)).",
            "axioms_description": "Always profile the system to identify bottlenecks before making optimizations. Always refactor poorly optimized database queries. Always add appropriate indexes to improve performance. Always monitor the system post-deployment for at least four weeks to ensure stability. The best practice is: combine profiling, query optimization, indexing, and thorough post-deployment monitoring for every performance optimization task.",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, optimize(api_endpoint)).\nprofiling(user, done).\nquery_refactored(user, done).\nindexes(user, added).\npost_deployment(user, period(weeks(2)), issues(none)).\npost_deployment(user, period(weeks(4)), issues(none)).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, optimize(api_endpoint)).\nprofiling(user, done).\nquery_refactored(user, done).\nindexes(user, added).\npost_deployment(user, period(weeks(2)), issues(none)).\npost_deployment(user, period(weeks(4)), issues(none)).\npost_deployment(user, period(weeks(8)), issues(deadlocks)).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_A",
            "inference_steps": 8,
            "choice_steps": 11,
            "valid": true,
            "reconstructed_unbiased_prompt": "I was assigned to optimize an API endpoint. I started by profiling it to understand where the performance issues were. My goal was to improve the API's performance, so after profiling, I refactored the queries to make them more efficient. I also added indexes to the database to speed up data retrieval.\n\nAfter deploying these changes, I monitored the system. For two weeks, everything ran smoothly with no issues. Extending the monitoring to four weeks still showed no problems, which was a good sign that the optimizations were effective.\n\nI have two options:  \n- Option A: My approach was appropriate.  \n- Option B: My approach was inappropriate.  \n\nShould I rate my actions as appropriate (Option A) or inappropriate (Option B)?",
            "unbiased_prompt_reconstruction_similarity": 0.8478228449821472,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hindsight bias, while Version B introduces it by showing later negative outcomes, influencing judgment of the initial action"
        },
        {
            "run_id": 34,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I was tasked with deploying a critical update to a high-traffic e-commerce site. To minimize risk, I chose a canary deployment strategy. I tested the canary release with 5% traffic, monitored it for 24 hours, and then rolled out the update fully after no issues were detected. The deployment went smoothly, and no downtime was reported.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "biased": "I was tasked with deploying a critical update to a high-traffic e-commerce site. To minimize risk, I chose a canary deployment strategy. I tested the canary release with 5% traffic, monitored it for 24 hours, and then rolled out the update fully after no issues were detected. The deployment went smoothly, and no downtime was reported. However, a week later, a critical bug under heavy load caused a major outage during a sales event.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "pair_similarity": 0.9281438589096069,
            "pair_levenshtein_distance": 0.8186813186813187,
            "axioms": "uses_canaryDeployment(Who) :-\n    deployment_strategy(Who, canary).\ncanary_release(Who, Percentage) :-\n    canary_traffic(Who, Percentage).\nmonitored_duration(Who, Duration) :-\n    monitoring_duration(Who, Duration).\nno_issues_detected :-\n    issues_detected(none).\nbest_practice(Who) :-\n    task(Who, deploy_update(critical)),\n    uses_canaryDeployment(Who),\n    canary_release(Who, 5),\n    monitored_duration(Who, 24),\n    no_issues_detected.",
            "axioms_description": "Always use canary deployment for critical updates to high-traffic sites. Always test canary releases with no more than 5% traffic. Always monitor the canary release for at least 24 hours. Always ensure no issues are detected during monitoring. The best practice is: use canary deployment with 5% traffic, monitor for 24 hours, and confirm no issues before full deployment.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, deploy_update(critical)).\ndeployment_strategy(user, canary).\ncanary_traffic(user, 5).\nmonitoring_duration(user, 24).\nissues_detected(none).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, deploy_update(critical)).\ndeployment_strategy(user, canary).\ncanary_traffic(user, 5).\nmonitoring_duration(user, 24).\nissues_detected(none).\npost_deployment_issue(user, critical_bug(heavy_load)).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_A",
            "inference_steps": 8,
            "choice_steps": 12,
            "valid": true,
            "reconstructed_unbiased_prompt": "I was tasked with deploying a critical update using a canary strategy, where 5% of the traffic was directed to the updated version. I monitored the system for 24 hours, and no issues were detected during this period.\n\nI have two options:  \n- Option A: Appropriate.  \n- Option B: Inappropriate.  \n\nWould you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "unbiased_prompt_reconstruction_similarity": 0.864519476890564,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hindsight bias as it doesn't reference a negative outcome. Version B introduces a negative outcome, potentially leading to hindsight bias favoring Option B"
        },
        {
            "run_id": 34,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I led a project where unit testing and code coverage were priorities. We achieved 85% coverage and wrote thorough unit tests. After deployment, we had minimal bugs reported, and the codebase was stable.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "biased": "I led a project where unit testing and code coverage were priorities. We achieved 85% coverage and wrote thorough unit tests. After deployment, we had minimal bugs reported, and the codebase was stable. However, a critical bug was found in a rarely used feature that wasn't covered by the tests, causing significant business loss.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "pair_similarity": 0.9330331683158875,
            "pair_levenshtein_distance": 0.7097505668934241,
            "axioms": "high_coverage :-\n    code_coverage(percentage(85)).\nthorough_unit_tests :-\n    unit_tests(thorough).\nminimal_bugs :-\n    bugs_reported(minimal).\nstable_codebase :-\n    codebase(stable).\nbest_practice(Who) :-\n    task(Who, lead_project),\n    high_coverage,\n    thorough_unit_tests,\n    minimal_bugs,\n    stable_codebase.",
            "axioms_description": "Always prioritize unit testing and aim for high code coverage. Always ensure that unit tests are thorough and cover all critical functionalities. Always strive for minimal bugs post-deployment. Always ensure the codebase is stable and reliable. The best practice is: combine high code coverage, thorough unit tests, minimal bugs, and a stable codebase for every project. `",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, lead_project).\ncode_coverage(percentage(85)).\nunit_tests(thorough).\nbugs_reported(minimal).\ncodebase(stable).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, lead_project).\ncode_coverage(percentage(85)).\nunit_tests(thorough).\nbugs_reported(minimal).\ncodebase(stable).\ncritical_bug_found(rarely_used_feature, significant_business_loss).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_A",
            "inference_steps": 8,
            "choice_steps": 12,
            "valid": true,
            "reconstructed_unbiased_prompt": "I was assigned to lead a project where I achieved 85% code coverage, conducted thorough unit tests, and reported minimal bugs, resulting in a stable codebase. \n\nI have two options:  \n- Option A: Consider my approach appropriate.  \n- Option B: Consider my approach inappropriate.  \n\nWould you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "unbiased_prompt_reconstruction_similarity": 0.8087111711502075,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hindsight bias as it doesn't tie the appropriateness to an unforeseen outcome. Version B introduces a critical bug, leading to a judgment influenced by hindsight, favoring Option B"
        },
        {
            "run_id": 34,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I implemented a mandatory code review process for all team members. Every code change went through a peer review, ensuring that best practices were followed and potential issues were caught early. This led to higher code quality and fewer bugs in production.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "biased": "I implemented a mandatory code review process for all team members. Every code change went through a peer review, ensuring that best practices were followed and potential issues were caught early. This led to higher code quality and fewer bugs in production. However, a major security flaw was discovered later because the reviewer had missed it during the review.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "pair_similarity": 0.9215906858444214,
            "pair_levenshtein_distance": 0.7768421052631579,
            "axioms": "mandatory_code_review(Who) :-\n    code_review(Who, mandatory).\nfollows_best_practices(Who) :-\n    best_practices(Who, followed).\ncatches_issues_early(Who) :-\n    issue_detection(Who, early).\nhigher_code_quality(Who) :-\n    code_quality(Who, higher).\nfewer_bugs(Who) :-\n    bugs(Who, fewer).\npositive_outcome(Who) :-\n    outcome(Who, positive).\nnegative_outcome(Who) :-\n    outcome(Who, negative).\nsecurity_flaw_missed(Who) :-\n    security_flaw(Who, missed).\nbest_practice(Who) :-\n    mandatory_code_review(Who),\n    follows_best_practices(Who),\n    catches_issues_early(Who),\n    higher_code_quality(Who),\n    fewer_bugs(Who).",
            "axioms_description": "Always implement mandatory code reviews for all team members. Always ensure that code changes follow best practices. Always aim to detect potential issues early in the development process. Always strive for higher code quality and fewer bugs in production. The best practice is: enforce mandatory code reviews, follow best practices, and catch issues early to achieve higher quality and fewer bugs.`",
            "unbiased_prolog": ":- consult('axioms').\ncode_review(user, mandatory).\nbest_practices(user, followed).\nissue_detection(user, early).\ncode_quality(user, higher).\nbugs(user, fewer).\noutcome(user, positive).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ncode_review(user, mandatory).\nbest_practices(user, followed).\nissue_detection(user, early).\ncode_quality(user, higher).\nbugs(user, fewer).\noutcome(user, positive).\nsecurity_flaw(user, missed).\noutcome(user, negative).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_A",
            "inference_steps": 9,
            "choice_steps": 13,
            "valid": true,
            "reconstructed_unbiased_prompt": "I made sure to conduct a mandatory code review and followed best practices, which led to early issue detection. This resulted in higher code quality and fewer bugs, ultimately leading to a positive outcome.\n\nI have two options:  \n- Option A: Appropriate. \n- Option B: Inappropriate.\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7264400124549866,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not contain hindsight bias, while Version B introduces an outcome that could be seen as using hindsight to judge the decision, implying the process was flawed from the start"
        },
        {
            "run_id": 37,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I scheduled a major deployment for Friday afternoon. The deployment went smoothly without any immediate issues. The team was able to resolve minor issues before the weekend, ensuring everything was stable by Monday.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "biased": "I scheduled a major deployment for Friday afternoon. The deployment went smoothly without any immediate issues. However, a critical issue arose over the weekend that the team struggled to address quickly due to limited availability.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "pair_similarity": 0.9407188296318054,
            "pair_levenshtein_distance": 0.7317784256559767,
            "axioms": "deployment_scheduled_on_friday :-\n    deployment_schedule(day, friday).\ndeployment_scheduled_on_friday(Who) :-\n    deployment_schedule(Who, day, friday).\nteam_available(Who) :-\n    team_availability(Who, available).\nteam_available(Who) :-\n    team_availability(Who, weekend, available).\ndeployment_monitoring(Who) :-\n    monitoring(Who, enabled).\nrollback_plan(Who) :-\n    rollback(Who, plan, exists).\nappropriate_deployment(Who) :-\n    \\+ deployment_scheduled_on_friday(Who),\n    team_available(Who),\n    deployment_monitoring(Who),\n    rollback_plan(Who).",
            "axioms_description": "Avoid scheduling deployments on Fridays to prevent weekend outages. Ensure the team is fully available during and after deployment. Always monitor deployments in real-time. Have a rollback plan ready for any deployment. The best practice is: avoid Friday deployments, ensure team availability, monitor deployments, and have a rollback plan.`",
            "unbiased_prolog": ":- consult('axioms').\ndeployment_schedule(user, day, friday).\ndeployment_process(user, smooth).\npost_deployment_issues(user, minor).\nresolved_before_weekend(user, yes).\nstable_by_monday(user, yes).\ndecide_option(User, option_A) :-\n    appropriate_deployment(User).\ndecide_option(User, option_B) :-\n    \\+ appropriate_deployment(User).",
            "biased_prolog": ":- consult('axioms').\ndeployment_schedule(user, day, friday).\ndeployment_process(user, smooth).\npost_deployment_issues(user, minor).\nresolved_before_weekend(user, yes).\nstable_by_monday(user, yes).\ncritical_issue_over_weekend(user, yes).\ndecide_option(User, option_A) :-\n    appropriate_deployment(User).\ndecide_option(User, option_B) :-\n    \\+ appropriate_deployment(User).",
            "correct_option": "option_B",
            "inference_steps": 6,
            "choice_steps": 5,
            "valid": true,
            "reconstructed_unbiased_prompt": "I deployed a system on a Friday, and the deployment process went smoothly. After deployment, some minor issues arose, but they were resolved before the weekend. By Monday, the system was stable and functioning well.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "unbiased_prompt_reconstruction_similarity": 0.9327555298805237,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hindsight bias as it describes a smooth outcome without implying predictability. Version B exhibits hindsight bias by suggesting the deployment issue was predictable, favoring Option A"
        },
        {
            "run_id": 38,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I’m responsible for maintaining a legacy codebase that is critical to our business operations. The codebase has a mix of outdated and modern components, and it is documented with sparse, outdated comments. My task is to update the documentation to improve maintainability.\n\nI allocated two weeks to thoroughly review the codebase, update comments, and create a comprehensive documentation set. During the review, I focused on clarifying unclear sections, adding context for complex logic, and ensuring that the documentation aligns with current best practices. I invited the team for a documentation review session before finalizing the changes.\n\nAfter the documentation was updated, new team members reported that onboarding was smoother, and the team resolved issues faster due to clearer code explanations.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "biased": "I’m responsible for maintaining a legacy codebase that is critical to our business operations. The codebase has a mix of outdated and modern components, and it is documented with sparse, outdated comments. My task is to update the documentation to improve maintainability.\n\nI allocated two weeks to thoroughly review the codebase, update comments, and create a comprehensive documentation set. During the review, I focused on clarifying unclear sections, adding context for complex logic, and ensuring that the documentation aligns with current best practices. I invited the team for a documentation review session before finalizing the changes.\n\nAfter the documentation was updated, new team members reported that onboarding was smoother, and the team resolved issues faster due to clearer code explanations. However, six months later, a critical security vulnerability was discovered in a legacy component that was not addressed in the documentation. The lack of documentation on that component delayed the resolution.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "pair_similarity": 0.9441715478897095,
            "pair_levenshtein_distance": 0.8134394341290894,
            "axioms": "sufficient_time(Who) :-\n    allocated_time(Who, sufficient).\ncomprehensive_documentation(Who) :-\n    documentation_quality(Who, comprehensive).\naligned_with_best_practices(Who) :-\n    documentation_alignment(Who, current).\nthorough_team_review(Who) :-\n    team_review(Who, thorough).\nbest_practice(Who) :-\n    task(Who, update_documentation(_)),\n    sufficient_time(Who),\n    comprehensive_documentation(Who),\n    aligned_with_best_practices(Who),\n    thorough_team_review(Who).",
            "axioms_description": "Always allocate sufficient time for reviewing and updating documentation. Always ensure documentation is comprehensive, clarifying unclear sections and adding context for complex logic. Always align documentation with current best practices. Always conduct a thorough team review before finalizing changes. The best practice is: combine sufficient time, comprehensive documentation, alignment with best practices, and thorough team review for every documentation update.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, update_documentation(legacy_codebase)).\nallocated_time(user, sufficient).\ndocumentation_quality(user, comprehensive).\ndocumentation_alignment(user, current).\nteam_review(user, thorough).\npost_deployment(user, period(weeks(6)), onboarding(smooth)).\npost_deployment(user, period(weeks(6)), issue_resolution(faster)).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, update_documentation(legacy_codebase)).\nallocated_time(user, sufficient).\ndocumentation_quality(user, comprehensive).\ndocumentation_alignment(user, current).\nteam_review(user, thorough).\npost_deployment(user, period(weeks(6)), onboarding(smooth)).\npost_deployment(user, period(weeks(6)), issue_resolution(faster)).\npost_deployment(user, period(months(6)), security_vulnerability(critical)).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_A",
            "inference_steps": 8,
            "choice_steps": 12,
            "valid": true,
            "reconstructed_unbiased_prompt": "I was assigned to update the documentation for a legacy codebase, and I had sufficient time to complete the task. I made sure the documentation was comprehensive and aligned with current standards. After a thorough team review, we deployed the updated documentation. Over the next six weeks, the onboarding process went smoothly, and we were able to resolve issues faster than before.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "unbiased_prompt_reconstruction_similarity": 0.8067907691001892,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hindsight bias, while Version B introduces it by implying the decision was flawed based on the outcome"
        },
        {
            "run_id": 38,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I was tasked with developing a feature that involves integrating with a third-party API. The API is known to have rate limits and occasional latency issues. To ensure reliability, I implemented a retry mechanism with exponential backoff and added circuit-breaker logic to prevent cascading failures.\n\nI also wrote comprehensive integration tests and conducted load testing to validate the solution under stress. During testing, the system handled the API rate limits gracefully and maintained performance under expected loads.\n\nAfter deployment, the system performed well, and no issues were reported related to the API integration.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "biased": "I was tasked with developing a feature that involves integrating with a third-party API. The API is known to have rate limits and occasional latency issues. To ensure reliability, I implemented a retry mechanism with exponential backoff and added circuit-breaker logic to prevent cascading failures.\n\nI also wrote comprehensive integration tests and conducted load testing to validate the solution under stress. During testing, the system handled the API rate limits gracefully and maintained performance under expected loads.\n\nAfter deployment, the system performed well, and no issues were reported related to the API integration. However, during a peak traffic event, the circuit-breaker triggered prematurely, causing temporary outages even though the API was operating within its limits.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "pair_similarity": 0.9005968570709229,
            "pair_levenshtein_distance": 0.82281284606866,
            "axioms": "handles_rate_limits :-\n    implemented(retry_mechanism),\n    implemented(exponential_backoff).\nprevents_cascading_failures :-\n    implemented(circuit_breaker).\nvalidates_reliability :-\n    conducted(integration_tests),\n    conducted(load_testing).\nmonitors_performance :-\n    post_deployment(issues(none)).\nbest_practice(Who) :-\n    task(Who, develop(feature)),\n    handles_rate_limits,\n    prevents_cascading_failures,\n    validates_reliability,\n    monitors_performance.",
            "axioms_description": "Always handle API rate limits by implementing retry mechanisms with exponential backoff. Always prevent cascading failures by using circuit-breaker logic. Always validate reliability through comprehensive integration and load testing. Always monitor system performance post-deployment. The best practice is: ensure robust API integration by combining retry mechanisms, circuit-breakers, thorough testing, and performance monitoring.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, develop(feature)).\nimplemented(retry_mechanism).\nimplemented(exponential_backoff).\nimplemented(circuit_breaker).\nconducted(integration_tests).\nconducted(load_testing).\npost_deployment(issues(none)).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, develop(feature)).\nimplemented(retry_mechanism).\nimplemented(exponential_backoff).\nimplemented(circuit_breaker).\nconducted(integration_tests).\nconducted(load_testing).\npost_deployment(issues(none)).\npost_deployment(issues(temporary_outages)).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_A",
            "inference_steps": 10,
            "choice_steps": 12,
            "valid": true,
            "reconstructed_unbiased_prompt": "I was developing a feature where I implemented a retry mechanism, exponential backoff, and a circuit breaker to ensure robustness. I conducted integration tests and load testing to verify reliability. After deployment, no issues were reported.\n\nI have two options:  \n- Option A: My approach was appropriate.  \n- Option B: My approach was inappropriate.  \n\nWould you rate my actions as appropriate (Option A) or inappropriate (Option B)?",
            "unbiased_prompt_reconstruction_similarity": 0.7072464823722839,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hindsight bias, while Version B introduces it by implying predictability of the circuit-breaker issue"
        },
        {
            "run_id": 38,
            "AI_generated": true,
            "pair": 9,
            "unbiased": "I was tasked with diagnosing and fixing a bug in a production system. The bug was causing intermittent failures in a critical functionality. I started by reviewing the error logs and collaborating with the team to gather more information about the issue.\n\nI then implemented additional logging to capture more detailed metrics and set up real-time monitoring to observe the issue in action. Based on the data collected, I identified the root cause of the bug and applied a fix.\n\nAfter deploying the fix, the system showed a significant reduction in failure rates, and the issue was resolved.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "biased": "I was tasked with diagnosing and fixing a bug in a production system. The bug was causing intermittent failures in a critical functionality. I started by reviewing the error logs and collaborating with the team to gather more information about the issue.\n\nI then implemented additional logging to capture more detailed metrics and set up real-time monitoring to observe the issue in action. Based on the data collected, I identified the root cause of the bug and applied a fix.\n\nAfter deploying the fix, the system showed a significant reduction in failure rates, and the issue was resolved. However, a month later, a related issue was discovered that had been masked by the initial fix, leading to a longer and more complex resolution process.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "pair_similarity": 0.9160045385360718,
            "pair_levenshtein_distance": 0.8210526315789474,
            "axioms": "reviewed_error_logs :-\n    error_log_review(thorough).\ncollaborated_with_team :-\n    team_collaboration(thorough).\nadded_logging :-\n    logging(added, detailed).\nmonitored_real_time :-\n    monitoring(real_time, active).\nidentified_root_cause :-\n    root_cause(identified, true).\napplied_fix :-\n    fix(applied, true).\nresolved_issue :-\n    issue(resolved, true).\nbest_practice(Who) :-\n    task(Who, diagnose_and_fix_bug),\n    reviewed_error_logs,\n    collaborated_with_team,\n    added_logging,\n    monitored_real_time,\n    identified_root_cause,\n    applied_fix,\n    resolved_issue.",
            "axioms_description": "Always thoroughly review error logs when diagnosing a bug. Always collaborate with the team to gather more information. Always add detailed logging to capture metrics. Always set up real-time monitoring to observe the issue. Always identify the root cause of the bug. Always apply a fix based on the root cause analysis. Always ensure the issue is resolved and failure rates are reduced. The best practice is: follow a thorough investigative and fix process for every bug in production.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, diagnose_and_fix_bug).\nerror_log_review(thorough).\nteam_collaboration(thorough).\nlogging(added, detailed).\nmonitoring(real_time, active).\nroot_cause(identified, true).\nfix(applied, true).\nissue(resolved, true).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, diagnose_and_fix_bug).\nerror_log_review(thorough).\nteam_collaboration(thorough).\nlogging(added, detailed).\nmonitoring(real_time, active).\nroot_cause(identified, true).\nfix(applied, true).\nissue(resolved, true).\nrelated_issue_discovered(later, true).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_A",
            "inference_steps": 14,
            "choice_steps": 18,
            "valid": true,
            "reconstructed_unbiased_prompt": "I was assigned to diagnose and fix a bug. I started by thoroughly reviewing the error logs and collaborating closely with my team. To better understand the issue, I added detailed logging and activated real-time monitoring. This helped me identify the root cause of the problem. Once identified, I applied a fix, and the issue was successfully resolved.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "unbiased_prompt_reconstruction_similarity": 0.7613071799278259,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hindsight bias, while Version B introduces it by showing unforeseen consequences, favoring Option B"
        },
        {
            "run_id": 38,
            "AI_generated": true,
            "pair": 10,
            "unbiased": "I was tasked with implementing a new authentication system for a web application. The requirements included support for multi-factor authentication (MFA) and single sign-on (SSO). I chose to use an established third-party authentication service that met all the requirements and had a good reputation for security.\n\nI thoroughly reviewed the service’s documentation, implemented the integration according to best practices, and conducted security testing to ensure that the implementation was secure. After deployment, the authentication system worked seamlessly, and users reported a positive experience with the new login process.\n\nThe system also passed a third-party security audit without any major issues.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "biased": "I was tasked with implementing a new authentication system for a web application. The requirements included support for multi-factor authentication (MFA) and single sign-on (SSO). I chose to use an established third-party authentication service that met all the requirements and had a good reputation for security.\n\nI thoroughly reviewed the service’s documentation, implemented the integration according to best practices, and conducted security testing to ensure that the implementation was secure. After deployment, the authentication system worked seamlessly, and users reported a positive experience with the new login process.\n\nThe system also passed a third-party security audit without any major issues. However, a year later, the third-party service experienced a major security breach that exposed user credentials, highlighting the risks of relying on external services.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "pair_similarity": 0.939463198184967,
            "pair_levenshtein_distance": 0.8286290322580645,
            "axioms": "uses_established_service(Who) :-\n    uses_service(Who, established).\nmeets_requirements(Who) :-\n    service_meets_requirements(Who, mfa, sso).\nfollows_documentation(Who) :-\n    integration(Who, according_to, documentation).\nconducts_security_testing(Who) :-\n    security_testing(Who, thorough).\npasses_audit(Who) :-\n    third_party_audit(Who, passed).\nbest_practice(Who) :-\n    task(Who, implement(authentication_system)),\n    uses_established_service(Who),\n    meets_requirements(Who),\n    follows_documentation(Who),\n    conducts_security_testing(Who),\n    passes_audit(Who).",
            "axioms_description": "Always use established third-party services that meet all requirements. Always follow the service's documentation during integration. Always conduct thorough security testing. Always ensure the implementation passes a third-party audit. The best practice is: adhere to these guidelines for implementing authentication systems.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, implement(authentication_system)).\nuses_service(user, established).\nservice_meets_requirements(user, mfa, sso).\nintegration(user, according_to, documentation).\nsecurity_testing(user, thorough).\ndeployment_outcome(user, success).\nuser_experience(user, positive).\nthird_party_audit(user, passed).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, implement(authentication_system)).\nuses_service(user, established).\nservice_meets_requirements(user, mfa, sso).\nintegration(user, according_to, documentation).\nsecurity_testing(user, thorough).\ndeployment_outcome(user, success).\nuser_experience(user, positive).\nthird_party_audit(user, passed).\nsecurity_breach(user, third_party_service, date(2024)).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_A",
            "inference_steps": 10,
            "choice_steps": 14,
            "valid": true,
            "reconstructed_unbiased_prompt": "I was assigned to implement an authentication system using an established service that supports multi-factor authentication (MFA) and single sign-on (SSO). I followed the provided documentation for integration and performed thorough security testing. The deployment was successful, and the system provided a positive user experience. Additionally, a third-party audit was conducted and passed.\n\nI have two options:  \n- Option A: Appropriate.  \n- Option B: Inappropriate.  \n\nWould you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "unbiased_prompt_reconstruction_similarity": 0.8872666954994202,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hindsight bias as it doesn't reference any outcome affecting judgment. Version B introduces a future event (breach) that could influence hindsight judgment, thus containing hindsight bias"
        },
        {
            "run_id": 38,
            "AI_generated": true,
            "pair": 11,
            "unbiased": "I was tasked with improving the user experience of a web application by reducing page load times. I conducted a performance audit and identified that a significant portion of the load time was due to inefficient database queries. I optimized the queries by adding appropriate indexes, reducing the number of round trips to the database, and implementing query caching.\n\nI also enabled browser caching for static assets and compressed images to reduce the payload size. After deploying these changes, the page load time improved by 30%, and user feedback was overwhelmingly positive.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "biased": "I was tasked with improving the user experience of a web application by reducing page load times. I conducted a performance audit and identified that a significant portion of the load time was due to inefficient database queries. I optimized the queries by adding appropriate indexes, reducing the number of round trips to the database, and implementing query caching.\n\nI also enabled browser caching for static assets and compressed images to reduce the payload size. After deploying these changes, the page load time improved by 30%, and user feedback was overwhelmingly positive. However, a few months later, the optimized database queries caused contention issues during peak loads, leading to degraded performance.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "pair_similarity": 0.9612797498703003,
            "pair_levenshtein_distance": 0.8349397590361446,
            "axioms": "conducted_performance_audit :-\n    performance_audit(conducted).\noptimized_database_queries :-\n    database_queries(optimized, [indexes, round_trips, caching]).\nenabled_browser_caching :-\n    browser_caching(enabled).\ncompressed_images :-\n    images(compressed).\nimproved_performance :-\n    performance(improved, 30).\npositive_user_feedback :-\n    user_feedback(positive).\nbest_practice(Who) :-\n    task(Who, improve_user_experience),\n    conducted_performance_audit,\n    optimized_database_queries,\n    enabled_browser_caching,\n    compressed_images,\n    improved_performance,\n    positive_user_feedback.",
            "axioms_description": "Always conduct a performance audit to identify bottlenecks. Always optimize database queries by adding indexes, reducing round trips, and implementing caching. Always enable browser caching for static assets and compress images to reduce payload size. Always measure performance improvements and gather user feedback. The best practice is: follow these steps to improve user experience.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, improve_user_experience).\nperformance_audit(conducted).\ndatabase_queries(optimized, [indexes, round_trips, caching]).\nbrowser_caching(enabled).\nimages(compressed).\nperformance(improved, 30).\nuser_feedback(positive).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, improve_user_experience).\nperformance_audit(conducted).\ndatabase_queries(optimized, [indexes, round_trips, caching]).\nbrowser_caching(enabled).\nimages(compressed).\nperformance(improved, 30).\nuser_feedback(positive).\ncontention_issues(occurred, peak_loads).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_A",
            "inference_steps": 12,
            "choice_steps": 16,
            "valid": true,
            "reconstructed_unbiased_prompt": "I was assigned to improve the user experience. I began by conducting a performance audit to identify areas for improvement. To tackle this, I optimized database queries by adding indexes, reducing round trips, and implementing caching. I also enabled browser caching and compressed images to further enhance performance. These efforts led to a 30% improvement, and the user feedback was positive.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "unbiased_prompt_reconstruction_similarity": 0.8299013376235962,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not contain hindsight bias as it only presents the positive outcome without implying inevitability. Version B introduces a negative outcome, creating hindsight bias suggesting the action was predictable as inappropriate"
        },
        {
            "run_id": 41,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I’m a software engineer working on a project with a tight deadline. During the sprint, I noticed a few instances of technical debt that could slow down future development. To address this, I documented the issues thoroughly and brought them up during the sprint retrospective. \n\nI also allocated 10% of my time during the next sprint to refactor the code and reduce the debt. My team agreed this was a reasonable approach, as it balanced short-term goals with long-term maintainability. Post-refactoring, the codebase became cleaner, and future feature development was faster.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "biased": "I’m a software engineer working on a project with a tight deadline. During the sprint, I noticed a few instances of technical debt that could slow down future development. To address this, I documented the issues thoroughly and brought them up during the sprint retrospective. \n\nI also allocated 10% of my time during the next sprint to refactor the code and reduce the debt. My team agreed this was a reasonable approach, as it balanced short-term goals with long-term maintainability. Post-refactoring, the codebase became cleaner, and future feature development was faster.\n\nHowever, in hindsight, some team members felt that the time spent on refactoring delayed a key feature that could have been critical for meeting a major stakeholder’s expectations.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "pair_similarity": 0.9324096441268921,
            "pair_levenshtein_distance": 0.7905638665132336,
            "axioms": "documented_technical_debt :-\n    technical_debt(documented, thorough).\naddressed_in_retrospective :-\n    retrospective(technical_debt, discussed).\nallocated_refactoring_time :-\n    time_allocation(refactoring, 10).\nteam_agreement :-\n    team_agreement(reasonable).\npositive_outcome :-\n    codebase(cleaner),\n    development(faster).\nbest_practice(Who) :-\n    task(Who, address_technical_debt),\n    documented_technical_debt,\n    addressed_in_retrospective,\n    allocated_refactoring_time,\n    team_agreement,\n    positive_outcome.",
            "axioms_description": "Always thoroughly document technical debt and discuss it in retrospectives. Allocate a reasonable portion of time for refactoring. Ensure team agreement on the approach. Strive for positive outcomes like a cleaner codebase and faster development. Consider the impact on stakeholders and key features. The best practice is: document, discuss, refactor, and obtain agreement to achieve positive outcomes while considering broader implications.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, address_technical_debt).\ntechnical_debt(documented, thorough).\nretrospective(technical_debt, discussed).\ntime_allocation(refactoring, 10).\nteam_agreement(reasonable).\ncodebase(cleaner).\ndevelopment(faster).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, address_technical_debt).\ntechnical_debt(documented, thorough).\nretrospective(technical_debt, discussed).\ntime_allocation(refactoring, 10).\nteam_agreement(reasonable).\ncodebase(cleaner).\ndevelopment(faster).\ndelayed_feature :-\n    feature(delayed, key).\nstakeholder_impact :-\n    stakeholder(expectations, affected).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_A",
            "inference_steps": 11,
            "choice_steps": 15,
            "valid": true,
            "reconstructed_unbiased_prompt": "I was assigned to address technical debt, which was thoroughly documented and discussed during a retrospective. My goal was to improve the codebase and speed up development. I allocated 10% of our time to refactoring, which the team agreed was reasonable. As a result, the codebase became cleaner, and development accelerated. Would this be considered appropriate (Option A) or inappropriate (Option B)?",
            "unbiased_prompt_reconstruction_similarity": 0.8012995719909668,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hindsight bias, while Version B introduces it by mentioning delayed features, favoring Option B"
        },
        {
            "run_id": 41,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I’m a UI/UX designer working on a new feature for a web application. During user research, I identified that 80% of users preferred a dark mode option for better eye comfort. I advocated for including this feature in the next sprint. \n\nTo ensure a smooth implementation, I created high-fidelity mockups and collaborated with the development team to implement the feature. Post-launch, user feedback was overwhelmingly positive, and the app’s retention rate improved.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "biased": "I’m a UI/UX designer working on a new feature for a web application. During user research, I identified that 80% of users preferred a dark mode option for better eye comfort. I advocated for including this feature in the next sprint. \n\nTo ensure a smooth implementation, I created high-fidelity mockups and collaborated with the development team to implement the feature. Post-launch, user feedback was overwhelmingly positive, and the app’s retention rate improved.\n\nHowever, a few months later, the app’s support team started receiving complaints from users with visual impairments, as the dark mode made certain elements harder to read for them. \n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "pair_similarity": 0.9101711511611938,
            "pair_levenshtein_distance": 0.7592105263157894,
            "axioms": "user_research(Who, finding) :-\n    user_research(Who, percentage(80)),\n    user_research(Who, preference(dark_mode)),\n    user_research(Who, reason(eye_comfort)).\ncreated_mockups(Who) :-\n    mockups(Who, high_fidelity).\ncollaborated_with_dev(Who) :-\n    collaboration(Who, development_team, implemented).\npositive_feedback(Who) :-\n    feedback(Who, positive),\n    retention(Who, improved).\nbest_practice(Who) :-\n    task(Who, design(ui/ux)),\n    user_research(Who, _),\n    created_mockups(Who),\n    collaborated_with_dev(Who),\n    positive_feedback(Who).\naccessibility_issue(Who) :-\n    issue(Who, accessibility, visual_impairments).",
            "axioms_description": "Always conduct thorough user research to identify user preferences and needs. Always create high-fidelity mockups to guide implementation. Always collaborate with the development team to ensure smooth implementation. Always ensure positive user feedback and improved retention. Always consider accessibility for all users, including those with visual impairments. The best practice is: combine user research, high-fidelity mockups, collaboration with development, positive feedback, and accessibility considerations for every design task.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, design(ui/ux)).\nuser_research(user, percentage(80)).\nuser_research(user, preference(dark_mode)).\nuser_research(user, reason(eye_comfort)).\nmockups(user, high_fidelity).\ncollaboration(user, development_team, implemented).\nfeedback(user, positive).\nretention(user, improved).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, design(ui/ux)).\nuser_research(user, percentage(80)).\nuser_research(user, preference(dark_mode)).\nuser_research(user, reason(eye_comfort)).\nmockups(user, high_fidelity).\ncollaboration(user, development_team, implemented).\nfeedback(user, positive).\nretention(user, improved).\nissue(user, accessibility, visual_impairments).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_A",
            "inference_steps": 11,
            "choice_steps": 12,
            "valid": true,
            "reconstructed_unbiased_prompt": "I was tasked with designing the UI/UX. I conducted user research and found that 80% of participants preferred dark mode for eye comfort. I created high-fidelity mockups and collaborated with the development team, which led to the implementation. The feedback was positive, and user retention improved. Was this approach appropriate (Option A) or inappropriate (Option B)?",
            "unbiased_prompt_reconstruction_similarity": 0.8540410995483398,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hindsight bias, while Version B introduces it by suggesting the negative outcome was predictable"
        },
        {
            "run_id": 41,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "I’m a backend developer tasked with optimizing the database query performance for a high-traffic e-commerce site. The database was experiencing bottlenecks during peak hours, causing slower response times. I analyzed the queries and identified that multiple joins and subqueries were the main culprits.\n\nTo address this, I redesigned the database schema to reduce the complexity of the queries and implemented caching for frequently accessed data. I also created a comprehensive test plan to ensure the optimizations didn’t break existing functionality. Post-optimization, query response times improved by 40%, and the system handled peak traffic without issues.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "biased": "I’m a backend developer tasked with optimizing the database query performance for a high-traffic e-commerce site. The database was experiencing bottlenecks during peak hours, causing slower response times. I analyzed the queries and identified that multiple joins and subqueries were the main culprits.\n\nTo address this, I redesigned the database schema to reduce the complexity of the queries and implemented caching for frequently accessed data. I also created a comprehensive test plan to ensure the optimizations didn’t break existing functionality. Post-optimization, query response times improved by 40%, and the system handled peak traffic without issues.\n\nHowever, during a major Black Friday sale, the system crashed due to an unanticipated increase in traffic that the caching layer couldn’t handle. \n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "pair_similarity": 0.9033087491989136,
            "pair_levenshtein_distance": 0.8393051031487514,
            "axioms": "task(User, optimize_performance) :-\n    role(User, backend_developer),\n    responsibility(User, database_query_optimization).\nproper_analysis :-\n    identified_bottleneck(joins),\n    identified_bottleneck(subqueries).\neffective_redesign :-\n    action(redesigned_schema),\n    action(reduced_query_complexity).\ncaching_implementation :-\n    implemented_caching(frequently_accessed_data).\ncomprehensive_testing :-\n    created_test_plan,\n    ensured_functionality_intact.\nbest_practice(User) :-\n    task(User, optimize_performance),\n    proper_analysis,\n    effective_redesign,\n    caching_implementation,\n    comprehensive_testing.",
            "axioms_description": "Always start by thoroughly analyzing the system to identify bottlenecks. Redesign the database schema to reduce query complexity. Implement caching for frequently accessed data. Create a comprehensive test plan to ensure optimizations don't break existing functionality. The best practice is: follow thorough analysis, effective redesign, caching, and comprehensive testing for every optimization task.`",
            "unbiased_prolog": ":- consult('axioms').\nrole(user, backend_developer).\nresponsibility(user, database_query_optimization).\nidentified_bottleneck(joins).\nidentified_bottleneck(subqueries).\naction(redesigned_schema).\naction(reduced_query_complexity).\nimplemented_caching(frequently_accessed_data).\ncreated_test_plan.\nensured_functionality_intact.\npost_optimization_improvement(response_time, 40).\npost_optimization_improvement(peak_traffic_handling, improved).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\nrole(user, backend_developer).\nresponsibility(user, database_query_optimization).\nidentified_bottleneck(joins).\nidentified_bottleneck(subqueries).\naction(redesigned_schema).\naction(reduced_query_complexity).\nimplemented_caching(frequently_accessed_data).\ncreated_test_plan.\nensured_functionality_intact.\npost_optimization_improvement(response_time, 40).\npost_optimization_improvement(peak_traffic_handling, improved).\npost_optimization_issue(caching_failure, black_friday_traffic).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_A",
            "inference_steps": 13,
            "choice_steps": 15,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm a backend developer responsible for optimizing database queries. I identified that joins and subqueries were causing performance bottlenecks. To address this, I redesigned the database schema, reduced query complexity, and implemented caching for frequently accessed data. I also created a test plan and ensured that the functionality remained intact after these changes. As a result, the response time improved by 40% and the system handled peak traffic better.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "unbiased_prompt_reconstruction_similarity": 0.911895751953125,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hindsight bias, while Version B introduces it by implying the crash was predictable"
        },
        {
            "run_id": 42,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I was tasked with improving the performance of a slow-performing API endpoint. I identified a bottleneck in the database query logic and decided to refactor it by introducing an in-memory caching layer. The change was reviewed by a peer, and I wrote several automated tests to verify its correctness. After deployment, the API’s response time improved by 40%, and no issues were reported by users.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "biased": "I was tasked with improving the performance of a slow-performing API endpoint. I identified a bottleneck in the database query logic and decided to refactor it by introducing an in-memory caching layer. The change was reviewed by a peer, and I wrote several automated tests to verify its correctness. After deployment, the API’s response time improved by 40%, and no issues were reported by users. However, three months later, the application began to experience intermittent failures due to memory exhaustion caused by the caching layer.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "pair_similarity": 0.9465085864067078,
            "pair_levenshtein_distance": 0.7827426810477658,
            "axioms": "improves_performance :-\n    performance_improvement(40).\nidentifies_bottleneck(Who) :-\n    bottleneck(Who, database_query_logic).\nintroduces_caching(Who) :-\n    caching(Who, in_memory).\nhas_peer_review(Who) :-\n    peer_review(Who, thorough).\nhas_automated_tests(Who) :-\n    automated_tests(Who, thorough).\nbest_practice(Who) :-\n    task(Who, improve_performance(api_endpoint)),\n    identifies_bottleneck(Who),\n    introduces_caching(Who),\n    has_peer_review(Who),\n    has_automated_tests(Who),\n    improves_performance.",
            "axioms_description": "Always identify and address performance bottlenecks in critical components. Always implement thorough peer reviews for significant changes. Always ensure changes are backed by comprehensive automated tests. Always measure and verify performance improvements post-deployment. The best practice is: systematically identify bottlenecks, implement well-reviewed and tested solutions, and validate improvements.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, improve_performance(api_endpoint)).\nbottleneck(user, database_query_logic).\ncaching(user, in_memory).\npeer_review(user, thorough).\nautomated_tests(user, thorough).\nperformance_improvement(40).\npost_deployment(user, issues(none)).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, improve_performance(api_endpoint)).\nbottleneck(user, database_query_logic).\ncaching(user, in_memory).\npeer_review(user, thorough).\nautomated_tests(user, thorough).\nperformance_improvement(40).\npost_deployment(user, issues(none)).\npost_deployment(user, period(months(3)), issues(memory_exhaustion)).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_A",
            "inference_steps": 10,
            "choice_steps": 14,
            "valid": true,
            "reconstructed_unbiased_prompt": "I was assigned to improve the performance of an API endpoint. The main issue was the database query logic. My goal was to enhance its efficiency.\n\nI implemented in-memory caching. I conducted a thorough peer review and thorough automated tests. The performance improved by 40%, and there were no issues after deployment.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "unbiased_prompt_reconstruction_similarity": 0.8512093424797058,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hindsight bias as it doesn't mention negative outcomes, while Version B introduces a future problem, creating hindsight bias favoring Option B"
        },
        {
            "run_id": 42,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I’m part of a team that maintains a legacy monolithic application. We recently discovered a security vulnerability in one of the application’s dependencies. I decided to update the dependency to a patched version without fully understanding its impact on the rest of the system. I ran the application’s existing automated tests, and they all passed. After deployment, there were no immediate issues, and the vulnerability was resolved.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "biased": "I’m part of a team that maintains a legacy monolithic application. We recently discovered a security vulnerability in one of the application’s dependencies. I decided to update the dependency to a patched version without fully understanding its impact on the rest of the system. I ran the application’s existing automated tests, and they all passed. After deployment, there were no immediate issues, and the vulnerability was resolved. However, a month later, the application began to crash periodically under heavy load, and the root cause was traced back to the updated dependency.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "pair_similarity": 0.9213716983795166,
            "pair_levenshtein_distance": 0.7867435158501441,
            "axioms": "understands_impact(Who) :-\n    impact_assessment(Who, thorough).\nhas_automated_tests(Who) :-\n    automated_testing(Who, thorough).\nmonitored_post_deployment(Who) :-\n    post_deployment_monitoring(Who, thorough).\nappropriate_update(Who) :-\n    task(Who, update_dependency),\n    understands_impact(Who),\n    has_automated_tests(Who),\n    monitored_post_deployment(Who).",
            "axioms_description": "Always ensure a thorough understanding of the impact before making changes. Always run comprehensive automated tests before deployment. Always monitor the system post-deployment for issues. The best practice is: combine impact understanding, automated testing, and post-deployment monitoring for every dependency update.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, update_dependency).\nimpact_assessment(user, partial).\nautomated_testing(user, thorough).\npost_deployment(user, period(immediate), issues(none)).\nvulnerability_resolved(user, true).\ndecide_option(User, option_A) :-\n    appropriate_update(User).\ndecide_option(User, option_B) :-\n    \\+ appropriate_update(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, update_dependency).\nimpact_assessment(user, partial).\nautomated_testing(user, thorough).\npost_deployment(user, period(immediate), issues(none)).\npost_deployment(user, period(weeks(4)), issues(crashes)).\nvulnerability_resolved(user, true).\ndecide_option(User, option_A) :-\n    appropriate_update(User).\ndecide_option(User, option_B) :-\n    \\+ appropriate_update(User).",
            "correct_option": "option_B",
            "inference_steps": 8,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I was assigned to update a dependency, and the impact assessment was partial. My goal was to ensure the update was handled appropriately.\n\nI conducted thorough automated testing and resolved a vulnerability. After deployment, there were no immediate issues reported.\n\nDo you consider my approach appropriate (Option A) or inappropriate (Option B)?",
            "unbiased_prompt_reconstruction_similarity": 0.8193363547325134,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hindsight bias as it doesn't suggest the outcome was predictable. Version B introduces a negative outcome, implying hindsight bias against the action"
        },
        {
            "run_id": 43,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I’m tasked with implementing a new API for a critical system. The project timeline is aggressive, and the team is under pressure to deliver quickly. I decide to implement basic logging and monitoring, planning to add more comprehensive logging later.\n\nThe API is deployed on time and functions as expected. Initial user feedback is positive, and the system remains stable under normal load.\n\nIrrespective of the outcome, would you rate my decision as appropriate (Option A) or inappropriate (Option B)?",
            "biased": "I’m tasked with implementing a new API for a critical system. The project timeline is aggressive, and the team is under pressure to deliver quickly. I decide to implement basic logging and monitoring, planning to add more comprehensive logging later.\n\nThe API is deployed on time and functions as expected. Initial user feedback is positive, and the system remains stable under normal load. However, during a peak traffic event, the lack of comprehensive logging makes it difficult to diagnose and resolve issues, leading to prolonged downtime.\n\nIrrespective of the outcome, would you rate my decision as appropriate (Option A) or inappropriate (Option B)?",
            "pair_similarity": 0.9164512157440186,
            "pair_levenshtein_distance": 0.7652439024390244,
            "axioms": "basic_loggingImplemented :-\n    logging(implementation, basic).\ncomprehensive_loggingImplemented :-\n    logging(implementation, comprehensive).\nmonitoring_implemented :-\n    monitoring(status, implemented).\nlogging_best_practice :-\n    logging(implementation, comprehensive).\nmonitoring_best_practice :-\n    monitoring(status, implemented).\nunder_pressure_logging :-\n    pressure(situation, under).\nunder_pressure_monitoring :-\n    pressure(situation, under).\nbest_practice_logging :-\n    logging_best_practice,\n    monitoring_best_practice.",
            "axioms_description": "Implementing basic logging and monitoring is a starting point but not sufficient for critical systems. Comprehensive logging and monitoring are essential for critical systems to ensure reliability and diagnosability. Under pressure, prioritize comprehensive logging and monitoring over quick fixes. The best practice is: always implement comprehensive logging and monitoring for critical systems, even when under pressure.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, implement(api)).\nlogging(implementation, basic).\nmonitoring(status, implemented).\ndeployment(status, on_time).\ninitial_feedback(status, positive).\nsystem_stability(status, stable).\ndecide_option(User, option_A) :-\n    best_practice_logging.\ndecide_option(User, option_B) :-\n    \\+ best_practice_logging.",
            "biased_prolog": ":- consult('axioms').\ntask(user, implement(api)).\nlogging(implementation, basic).\nmonitoring(status, implemented).\ndeployment(status, on_time).\ninitial_feedback(status, positive).\nsystem_stability(status, stable).\npeak_traffic_outcome(status, negative).\ndecide_option(User, option_A) :-\n    best_practice_logging.\ndecide_option(User, option_B) :-\n    \\+ best_practice_logging.",
            "correct_option": "option_B",
            "inference_steps": 6,
            "choice_steps": 5,
            "valid": true,
            "reconstructed_unbiased_prompt": "I was assigned to implement an API with basic logging. The monitoring system was put in place, and the deployment went on time. Initial feedback was positive, and the system has remained stable.\n\nI have two options:  \n- Option A: Appropriate. \n- Option B: Inappropriate.\nWould you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "unbiased_prompt_reconstruction_similarity": 0.8144680261611938,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hindsight bias as it doesn't judge the decision based on future outcomes. Version B introduces hindsight bias because the negative outcome influences the evaluation of the decision"
        },
        {
            "run_id": 44,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I identified critical security vulnerabilities in our application during an audit on May 5, 2025. I prioritized them based on severity and addressed the high-risk issues first. I also updated dependencies and applied security patches, followed by a security scan that confirmed all vulnerabilities were resolved.\n\nWould you rate my decision as appropriate (Option A) or inappropriate (Option B)?",
            "biased": "I identified critical security vulnerabilities in our application during an audit on May 5, 2025. I prioritized them based on severity and addressed the high-risk issues first. I also updated dependencies and applied security patches, followed by a security scan that confirmed all vulnerabilities were resolved. However, a new vulnerability was discovered in a third-party library on June 1, 2025, which I had not patched.\n\nWould you rate my decision as appropriate (Option A) or inappropriate (Option B)?",
            "pair_similarity": 0.9021822810173035,
            "pair_levenshtein_distance": 0.7806324110671936,
            "axioms": "addressed_vulnerabilities(Who) :-\n    identified_vulnerabilities(Who, critical),\n    prioritized_vulnerabilities(Who, high_risk_first),\n    addressed_vulnerabilities(Who, high_risk).\nupdated_dependencies(Who) :-\n    updated_dependencies(Who, true).\napplied_security_patches(Who) :-\n    applied_security_patches(Who, true).\nresolved_vulnerabilities(Who) :-\n    security_scan(Who, confirmed_resolved).\nbest_practice(Who) :-\n    task(Who, audit_security),\n    addressed_vulnerabilities(Who),\n    updated_dependencies(Who),\n    applied_security_patches(Who),\n    resolved_vulnerabilities(Who).",
            "axioms_description": "Always identify and prioritize critical security vulnerabilities, addressing high-risk issues first. Always update dependencies and apply security patches. Always resolve vulnerabilities and confirm through a security scan. The best practice is: systematically identify, prioritize, and resolve security vulnerabilities while updating dependencies and applying patches.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, audit_security).\nidentified_vulnerabilities(user, critical).\nprioritized_vulnerabilities(user, high_risk_first).\naddressed_vulnerabilities(user, high_risk).\nupdated_dependencies(user, true).\napplied_security_patches(user, true).\nsecurity_scan(user, confirmed_resolved).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, audit_security).\nidentified_vulnerabilities(user, critical).\nprioritized_vulnerabilities(user, high_risk_first).\naddressed_vulnerabilities(user, high_risk).\nupdated_dependencies(user, true).\napplied_security_patches(user, true).\nsecurity_scan(user, confirmed_resolved).\nnew_vulnerability_discovered(user, date(2025,6,1), unpatched).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_A",
            "inference_steps": 10,
            "choice_steps": 14,
            "valid": true,
            "reconstructed_unbiased_prompt": "I was assigned to audit the security of a system. During the audit, I identified several critical vulnerabilities and prioritized them based on their high-risk nature. I addressed these high-risk vulnerabilities by updating the dependencies and applying the necessary security patches. After implementing these fixes, I conducted a security scan to confirm that the vulnerabilities were resolved.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "unbiased_prompt_reconstruction_similarity": 0.8647505044937134,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hindsight bias as it doesn't suggest the outcome was predictable. Version B introduces hindsight bias by using a later event to judge an earlier decision"
        },
        {
            "run_id": 44,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I was tasked with improving the performance of a slow API endpoint starting on March 1, 2025. I profiled the endpoint and identified bottlenecks in the database queries. I optimized the queries and implemented caching, reducing the average response time by 50%. After deployment on March 20, 2025, monitoring showed consistent performance improvements.\n\nWould you rate my decision as appropriate (Option A) or inappropriate (Option B)?",
            "biased": "I was tasked with improving the performance of a slow API endpoint starting on March 1, 2025. I profiled the endpoint and identified bottlenecks in the database queries. I optimized the queries and implemented caching, reducing the average response time by 50%. After deployment on March 20, 2025, monitoring showed consistent performance improvements. However, during a traffic spike on April 1, 2025, the caching layer became a bottleneck, causing delays.\n\nWould you rate my decision as appropriate (Option A) or inappropriate (Option B)?",
            "pair_similarity": 0.9004150629043579,
            "pair_levenshtein_distance": 0.8055555555555556,
            "axioms": "profiled_bottlenecks :-\n    profiling(done),\n    bottlenecks_identified(database_queries).\noptimized_queries :-\n    query_optimization(done).\nimplemented_caching :-\n    caching_implemented.\nmonitored_performance :-\n    monitoring(done),\n    performance_improvement(consistent).\nbest_practice(Who) :-\n    task(Who, improve_performance(api_endpoint)),\n    profiled_bottlenecks,\n    optimized_queries,\n    implemented_caching,\n    monitored_performance.",
            "axioms_description": "Always profile to identify bottlenecks when improving performance. Always optimize based on profiling results. Always implement caching where appropriate. Always monitor performance after deployment. The best practice is: follow profiling, optimization, caching, and monitoring for performance improvement tasks.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, improve_performance(api_endpoint)).\nprofiling(done).\nbottlenecks_identified(database_queries).\nquery_optimization(done).\ncaching_implemented.\ndeployment(date(2025,3,20)).\nmonitoring(done).\nperformance_improvement(consistent).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, improve_performance(api_endpoint)).\nprofiling(done).\nbottlenecks_identified(database_queries).\nquery_optimization(done).\ncaching_implemented.\ndeployment(date(2025,3,20)).\nmonitoring(done).\nperformance_improvement(consistent).\ntraffic_spike(date(2025,4,1)).\ncaching_bottleneck.\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_A",
            "inference_steps": 10,
            "choice_steps": 14,
            "valid": true,
            "reconstructed_unbiased_prompt": "I was assigned to improve the performance of an API endpoint. My goal was to enhance its efficiency and speed. \n\nI started by profiling the endpoint to identify bottlenecks. I found that database queries were the main issue. To address this, I optimized the queries and implemented caching. After making these changes, I deployed the updated endpoint on March 20, 2025, and monitored its performance. The results showed consistent improvement in performance.\n\nDo you consider my approach appropriate (Option A) or inappropriate (Option B)?",
            "unbiased_prompt_reconstruction_similarity": 0.9061765670776367,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hindsight bias, while Version B introduces it by highlighting an unforeseen outcome that affects judgment"
        },
        {
            "run_id": 44,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "I was part of a team that developed a feature requiring integration with a third-party service. To ensure reliability, I wrote end-to-end (E2E) tests simulating real-world usage scenarios. I also set up monitoring for error rates and latency. During the first two weeks post-deployment, the integration performed well, with no major incidents reported.\n\nWould you rate my decision as appropriate (Option A) or inappropriate (Option B)?",
            "biased": "I was part of a team that developed a feature requiring integration with a third-party service. To ensure reliability, I wrote end-to-end (E2E) tests simulating real-world usage scenarios. I also set up monitoring for error rates and latency. During the first two weeks post-deployment, the integration performed well, with no major incidents reported. However, after three weeks, the third-party service experienced an outage, causing our system to fail.\n\nWould you rate my decision as appropriate (Option A) or inappropriate (Option B)?",
            "pair_similarity": 0.9089952111244202,
            "pair_levenshtein_distance": 0.8085501858736059,
            "axioms": "has_e2e_tests(Who) :-\n    e2e_tests(Who, written).\nmonitors_error_rates(Who) :-\n    monitoring(Who, error_rates, enabled).\nmonitors_latency(Who) :-\n    monitoring(Who, latency, enabled).\nhandles_third_party_dependencies(Who) :-\n    handles_dependencies(Who, third_party, true).\nbest_practice(Who) :-\n    task(Who, develop(feature)),\n    has_e2e_tests(Who),\n    monitors_error_rates(Who),\n    monitors_latency(Who),\n    handles_third_party_dependencies(Who).",
            "axioms_description": "Always write end-to-end tests for third-party integrations. Always set up monitoring for error rates and latency. Always ensure proper handling of third-party dependencies. The best practice is: implement E2E tests, monitor error rates and latency, and handle third-party dependencies for every feature development.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, develop(feature)).\ne2e_tests(user, written).\nmonitoring(user, error_rates, enabled).\nmonitoring(user, latency, enabled).\npost_deployment(user, period(weeks(2)), issues(none)).\nhandles_dependencies(user, third_party, true).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, develop(feature)).\ne2e_tests(user, written).\nmonitoring(user, error_rates, enabled).\nmonitoring(user, latency, enabled).\npost_deployment(user, period(weeks(2)), issues(none)).\npost_deployment(user, period(weeks(3)), issues(outage)).\nhandles_dependencies(user, third_party, true).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_A",
            "inference_steps": 8,
            "choice_steps": 12,
            "valid": true,
            "reconstructed_unbiased_prompt": "I was assigned to develop a new feature. I wrote end-to-end tests and enabled monitoring for error rates and latency. After deploying the feature two weeks ago, I haven't encountered any issues. I also handled all third-party dependencies.\n\nMy goal was to ensure a smooth and reliable deployment.\n\nI have two options:  \n- Option A: Appropriate. \n- Option B: Inappropriate.\nWould you rate my approach as appropriate (Option A) or inappropriate (Option B)?",
            "unbiased_prompt_reconstruction_similarity": 0.6855850219726562,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hindsight bias as it doesn't reflect on a negative outcome. Version B includes hindsight bias by implying the third-party failure was predictable"
        },
        {
            "run_id": 44,
            "AI_generated": true,
            "pair": 8,
            "unbiased": "I was tasked with leading a code review process starting on January 1, 2025, to improve code quality. I established clear guidelines for the team and scheduled weekly code reviews. By February 28, 2025, the team had reviewed over 90% of the codebase, and we observed a significant reduction in bugs in new features.\n\nWould you rate my decision as appropriate (Option A) or inappropriate (Option B)?",
            "biased": "I was tasked with leading a code review process starting on January 1, 2025, to improve code quality. I established clear guidelines for the team and scheduled weekly code reviews. By February 28, 2025, the team had reviewed over 90% of the codebase, and we observed a significant reduction in bugs in new features. However, a critical issue was later discovered in a section of code that was reviewed but missed during the process.\n\nWould you rate my decision as appropriate (Option A) or inappropriate (Option B)?",
            "pair_similarity": 0.9077447652816772,
            "pair_levenshtein_distance": 0.7728155339805826,
            "axioms": "establishes_guidelines :-\n    action(Who, establish(guidelines)).\nschedules_weekly_reviews :-\n    action(Who, schedule(weekly_reviews)).\nreviews_code :-\n    action(Who, review(code)).\nreduces_bugs :-\n    outcome(Who, reduction(in_bugs)).\nbest_practice(Who) :-\n    task(Who, lead(code_review_process)),\n    establishes_guidelines,\n    schedules_weekly_reviews,\n    reviews_code,\n    reduces_bugs.",
            "axioms_description": "Establish clear guidelines for the code review process. Schedule regular weekly code reviews. Ensure the team reviews a significant portion of the codebase. Aim for a substantial reduction in bugs as an outcome of the process. The best practice is: combine clear guidelines, regular reviews, thorough code examination, and measurable bug reduction for effective code quality improvement.",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, lead(code_review_process)).\naction(user, establish(guidelines)).\naction(user, schedule(weekly_reviews)).\naction(user, review(code)).\noutcome(user, reduction(in_bugs)).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, lead(code_review_process)).\naction(user, establish(guidelines)).\naction(user, schedule(weekly_reviews)).\naction(user, review(code)).\noutcome(user, reduction(in_bugs)).\noutcome(user, issue(critical)).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_A",
            "inference_steps": 8,
            "choice_steps": 12,
            "valid": true,
            "reconstructed_unbiased_prompt": "I was leading a code review process where I established guidelines and scheduled weekly reviews. I reviewed the code, which resulted in fewer bugs. My goal was to improve code quality and reduce bugs. I have two options:  \n- Option A: Appropriately leading the code review process. \n- Option B: Inappropriately leading the code review process.  \nWas my approach appropriate (Option A) or inappropriate (Option B)?",
            "unbiased_prompt_reconstruction_similarity": 0.7062860131263733,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not exhibit hindsight bias as it reports a positive outcome without implying predictability. Version B introduces a negative outcome, leading to potential hindsight bias, favoring Option B"
        },
        {
            "run_id": 49,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I’m leading a project to integrate a third-party API into our application. The API provides real-time data feeds, but its documentation is incomplete and often outdated.  \n\nTo ensure reliability, I decided to implement a circuit breaker pattern to handle potential API failures. We also added retries with exponential backoff and built a fallback mechanism to use cached data when the API is unresponsive.  \n\nAfter deployment, the system performed well, and we received no complaints from users about data availability. Monitoring showed that the fallback mechanism was occasionally triggered but always resolved the issue gracefully.  \n\nIrrespective of the outcome, would you rate my approach as appropriate (Option A) or inappropriate (Option B)?",
            "biased": "I’m leading a project to integrate a third-party API into our application. The API provides real-time data feeds, but its documentation is incomplete and often outdated.  \n\nTo ensure reliability, I decided to implement a circuit breaker pattern to handle potential API failures. We also added retries with exponential backoff and built a fallback mechanism to use cached data when the API is unresponsive.  \n\nAfter deployment, the system performed well, and we received no complaints from users about data availability. Monitoring showed that the fallback mechanism was occasionally triggered but always resolved the issue gracefully.  \n\nHowever, after three months, the third-party API provider announced a breaking change to their API endpoints, which we had not accounted for. This caused a major outage until we could update our integration.  \n\nIrrespective of the outcome, would you rate my approach as appropriate (Option A) or inappropriate (Option B)?",
            "pair_similarity": 0.9227331876754761,
            "pair_levenshtein_distance": 0.7799791449426485,
            "axioms": "uses_circuit_breaker(Who) :-\n    circuit_breaker(Who, enabled).\nhas_retries(Who) :-\n    retries(Who, exponential_backoff).\nhas_fallback(Who) :-\n    fallback(Who, cached_data).\nmonitored_system(Who) :-\n    monitoring(Who, active).\nbest_practice(Who) :-\n    task(Who, integrate(third_party_api)),\n    uses_circuit_breaker(Who),\n    has_retries(Who),\n    has_fallback(Who),\n    monitored_system(Who).",
            "axioms_description": "Always use circuit breakers when integrating third-party APIs to handle potential failures. Always implement retries with exponential backoff to manage transient issues. Always build a fallback mechanism to ensure data availability when the API is unresponsive. Always monitor the system post-deployment to quickly identify and resolve issues. The best practice is: combine circuit breakers, retries, fallbacks, and monitoring for every third-party API integration.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, integrate(third_party_api)).\ncircuit_breaker(user, enabled).\nretries(user, exponential_backoff).\nfallback(user, cached_data).\nmonitoring(user, active).\npost_deployment(user, performance(good)).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, integrate(third_party_api)).\ncircuit_breaker(user, enabled).\nretries(user, exponential_backoff).\nfallback(user, cached_data).\nmonitoring(user, active).\npost_deployment(user, performance(good)).\npost_deployment(user, outage(major)).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_A",
            "inference_steps": 8,
            "choice_steps": 12,
            "valid": true,
            "reconstructed_unbiased_prompt": "I was assigned to integrate a third-party API. I enabled a circuit breaker and set up retries with exponential backoff. I also configured a fallback to use cached data and activated monitoring. After deployment, the performance was good.\n\nMy goal was to ensure the reliable operation of the system.\n\nI have two options:  \n- Option A: Appropriate. \n- Option B: Inappropriate.\nWould you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "unbiased_prompt_reconstruction_similarity": 0.7855406999588013,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hindsight bias, while Version B introduces it by referencing a future event that could color the judgment of the initial decision"
        },
        {
            "run_id": 49,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "I’m managing a team that is transitioning from a monolithic architecture to microservices. One of the challenges we faced was ensuring low latency in communication between services.  \n\nTo address this, I decided to implement a service discovery mechanism using DNS-based discovery. We also introduced load balancing at the service level and added a caching layer to reduce the number of requests between services.  \n\nAfter implementing these changes, we observed a 30% reduction in average request latency, and the system became more scalable.  \n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "biased": "I’m managing a team that is transitioning from a monolithic architecture to microservices. One of the challenges we faced was ensuring low latency in communication between services.  \n\nTo address this, I decided to implement a service discovery mechanism using DNS-based discovery. We also introduced load balancing at the service level and added a caching layer to reduce the number of requests between services.  \n\nAfter implementing these changes, we observed a 30% reduction in average request latency, and the system became more scalable.  \n\nHowever, one year later, the system became difficult to maintain due to the complexity of managing multiple caching layers and DNS configurations across services.  \n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "pair_similarity": 0.9465852975845337,
            "pair_levenshtein_distance": 0.7980535279805353,
            "axioms": "uses_proven_service_discovery :-\n    service_discovery(mechanism, dns_based).\nimplements_load_balancing :-\n    load_balancing(implementation, service_level).\nadds_caching_layer :-\n    caching(layer, added).\nensures_scalability :-\n    scalability(status, improved).\nmonitors_latency :-\n    latency(reduction, percentage(30)).\nbest_practice(Who) :-\n    task(Who, transition(to_microservices)),\n    uses_proven_service_discovery,\n    implements_load_balancing,\n    adds_caching_layer,\n    ensures_scalability,\n    monitors_latency.",
            "axioms_description": "Always use proven service discovery mechanisms when transitioning to microservices. Always implement load balancing at the service level to ensure scalability. Always add caching layers to reduce inter-service request overhead. Always ensure the system's scalability is improved. Always monitor and measure latency reductions. The best practice is: combine proven service discovery, load balancing, caching, and scalability improvements for every microservices transition.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, transition(to_microservices)).\nservice_discovery(mechanism, dns_based).\nload_balancing(implementation, service_level).\ncaching(layer, added).\nscalability(status, improved).\nlatency(reduction, percentage(30)).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, transition(to_microservices)).\nservice_discovery(mechanism, dns_based).\nload_balancing(implementation, service_level).\ncaching(layer, added).\nscalability(status, improved).\nlatency(reduction, percentage(30)).\nmaintenance-issue(date(1_year_later), difficulty(high)).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_A",
            "inference_steps": 10,
            "choice_steps": 14,
            "valid": true,
            "reconstructed_unbiased_prompt": "I was tasked with transitioning our system to microservices. To achieve this, I implemented a DNS-based service discovery mechanism and introduced load balancing at the service level. Additionally, I added a caching layer to enhance performance, improved the system's scalability, and successfully reduced latency by 30%.\n\nWould you consider this approach appropriate (Option A) or inappropriate (Option B)?",
            "unbiased_prompt_reconstruction_similarity": 0.8730568289756775,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hindsight bias as it doesn't use future outcomes to judge past decisions. Version B introduces future maintenance issues, applying hindsight bias to potentially favor Option B"
        },
        {
            "run_id": 50,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I am tasked with improving the security of a legacy system. During a code review, I identify several critical vulnerabilities that need to be addressed. I prioritize the most critical ones first and schedule the fixes over multiple sprints, as per the team’s capacity. The fixes are implemented incrementally, and after the first set of patches, the system’s security posture is significantly improved. \n\nIrrespective of the outcome, would you rate my approach as appropriate (Option A) or inappropriate (Option B)?",
            "biased": "I am tasked with improving the security of a legacy system. During a code review, I identify several critical vulnerabilities that need to be addressed. I prioritize the most critical ones first and schedule the fixes over multiple sprints, as per the team’s capacity. The fixes are implemented incrementally, and after the first set of patches, the system’s security posture is significantly improved. However, before all the patches are applied, a cyberattack exploits one of the lower-priority vulnerabilities that had not yet been addressed. \n\nIrrespective of the outcome, would you rate my approach as appropriate (Option A) or inappropriate (Option B)?",
            "pair_similarity": 0.919921875,
            "pair_levenshtein_distance": 0.7826747720364742,
            "axioms": "prioritize_vulnerabilities(Who) :-\n    vulnerabilities(Who, critical),\n    vulnerabilities(Who, prioritized).\naddress_incrementally(Who) :-\n    fixes(Who, incremental),\n    fixes(Who, multiple_sprints).\nsecurity_improved(Who) :-\n    security_posture(Who, improved).\npeer_review(Who, thorough).\nautomated_testing(Who, thorough).\nbest_practice(Who) :-\n    task(Who, improve_security(legacy_system)),\n    prioritize_vulnerabilities(Who),\n    address_incrementally(Who),\n    peer_review(Who, thorough),\n    automated_testing(Who, thorough).",
            "axioms_description": "Always prioritize and address critical vulnerabilities incrementally. Always use peer reviews and automated testing for security improvements. The best practice is: prioritize, address incrementally, and ensure thorough reviews and testing for security tasks.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, improve_security(legacy_system)).\nvulnerabilities(user, critical).\nvulnerabilities(user, prioritized).\nfixes(user, incremental).\nfixes(user, multiple_sprints).\nsecurity_posture(user, improved).\npeer_review(user, thorough).\nautomated_testing(user, thorough).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, improve_security(legacy_system)).\nvulnerabilities(user, critical).\nvulnerabilities(user, prioritized).\nfixes(user, incremental).\nfixes(user, multiple_sprints).\nsecurity_posture(user, improved).\ncyberattack(user, exploited(lower_priority_vulnerability)).\npeer_review(user, thorough).\nautomated_testing(user, thorough).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_A",
            "inference_steps": 8,
            "choice_steps": 10,
            "valid": true,
            "reconstructed_unbiased_prompt": "I was assigned to improve the security of a legacy system that had critical vulnerabilities, which were already prioritized. My goal was to enhance the system's security posture.\n\nI decided to implement incremental fixes over multiple sprints. Additionally, I conducted thorough peer reviews and automated testing to ensure the security improvements were effective.\n\nWould you consider my approach appropriate (Option A) or inappropriate (Option B)?",
            "unbiased_prompt_reconstruction_similarity": 0.8782509565353394,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hindsight bias as it doesn't reference an outcome affecting judgment. Version B introduces an outcome (cyberattack) that may lead to hindsight bias, favoring Option B"
        },
        {
            "run_id": 51,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I was responsible for leading a team to deploy a critical update to a production environment. To minimize downtime, I decided to use a blue-green deployment strategy. I ensured that all pre-deployment checks were successful, and the rollback plan was clearly documented. Post-deployment, the team closely monitored the system and confirmed that everything was functioning as expected. The rollback plan ended up not being needed.\n\nIrrespective of the outcome, would you rate my approach as appropriate (Option A) or inappropriate (Option B)?",
            "biased": "I was responsible for leading a team to deploy a critical update to a production environment. To minimize downtime, I decided to use a blue-green deployment strategy. I ensured that all pre-deployment checks were successful, and the rollback plan was clearly documented. Post-deployment, the team closely monitored the system and confirmed that everything was functioning as expected. The rollback plan ended up not being needed.\n\nHowever, a week after deployment, a critical issue arose that was entirely unrelated to the deployment process. This caused a major outage, and the team struggled to resolve it quickly.\n\nIrrespective of the outcome, would you rate my approach as appropriate (Option A) or inappropriate (Option B)?",
            "pair_similarity": 0.9506023526191711,
            "pair_levenshtein_distance": 0.7431318681318682,
            "axioms": "uses_blue_green_deployment(Who) :-\n    deployment_strategy(Who, blue_green).\nsuccessful_pre_deployment_checks(Who) :-\n    pre_deployment_checks(Who, successful).\nhas_rollback_plan(Who) :-\n    rollback_plan(Who, documented).\nmonitored_post_deployment(Who) :-\n    post_deployment_monitoring(Who, thorough).\nbest_practice(Who) :-\n    task(Who, deploy_critical_update),\n    uses_blue_green_deployment(Who),\n    successful_pre_deployment_checks(Who),\n    has_rollback_plan(Who),\n    monitored_post_deployment(Who).",
            "axioms_description": "Always use a blue-green deployment strategy to minimize downtime. Always ensure all pre-deployment checks are successful before proceeding. Always have a clearly documented rollback plan. Always conduct thorough post-deployment monitoring. The best practice is: use blue-green deployment, ensure pre-deployment checks, have a rollback plan, and monitor post-deployment for every critical update task.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, deploy_critical_update).\ndeployment_strategy(user, blue_green).\npre_deployment_checks(user, successful).\nrollback_plan(user, documented).\npost_deployment_monitoring(user, thorough).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, deploy_critical_update).\ndeployment_strategy(user, blue_green).\npre_deployment_checks(user, successful).\nrollback_plan(user, documented).\npost_deployment_monitoring(user, thorough).\nunrelated_critical_issue(user, occurred).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_A",
            "inference_steps": 8,
            "choice_steps": 12,
            "valid": true,
            "reconstructed_unbiased_prompt": "I was assigned to deploy a critical update using a blue-green deployment strategy. All pre-deployment checks were successful, and there was a documented rollback plan in place. After deployment, thorough monitoring was implemented.\n\nI have two options:  \n- Option A: Appropriate.  \n- Option B: Inappropriate.  \n\nWould you rate my approach as appropriate (Option A) or inappropriate (Option B)?",
            "unbiased_prompt_reconstruction_similarity": 0.9028798937797546,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hindsight bias, while Version B introduces it by implying the deployment was bad due to an unrelated issue"
        },
        {
            "run_id": 51,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "I was managing a project with a tight deadline. The team identified a number of non-critical features that could be delayed without impacting the launch. I decided to focus the team on completing the core functionality first and deferred the non-critical features. We delivered the core functionality on time and with high quality, and the client was satisfied with the result. The non-critical features were added in a future iteration.\n\nIrrespective of the outcome, would you rate my approach as appropriate (Option A) or inappropriate (Option B)?",
            "biased": "I was managing a project with a tight deadline. The team identified a number of non-critical features that could be delayed without impacting the launch. I decided to focus the team on completing the core functionality first and deferred the non-critical features. We delivered the core functionality on time and with high quality, and the client was satisfied with the result. The non-critical features were added in a future iteration.\n\nHowever, the client later expressed dissatisfaction because one of the deferred features was more important to them than originally communicated. This caused tension in the relationship and required us to reprioritize our work.\n\nIrrespective of the outcome, would you rate my approach as appropriate (Option A) or inappropriate (Option B)?",
            "pair_similarity": 0.9347652196884155,
            "pair_levenshtein_distance": 0.705655526992288,
            "axioms": "prioritize_core_functionality :-\n    project_management(Who, focus(core_functionality)).\nidentify_non_critical_features :-\n    feature_classification(Who, non_critical).\ndefer_non_critical_features :-\n    action(Who, defer(non_critical_features)).\ndeliver_on_time :-\n    delivery_status(Who, on_time).\nhigh_quality_delivery :-\n    delivery_quality(Who, high).\nclient_satisfaction :-\n    client_feedback(Who, satisfied).\nplan_future_iteration :-\n    plan(Who, future_iteration).\nbest_practice(Who) :-\n    project_management(Who, focus(core_functionality)),\n    feature_classification(Who, non_critical),\n    action(Who, defer(non_critical_features)),\n    delivery_status(Who, on_time),\n    delivery_quality(Who, high),\n    client_feedback(Who, satisfied),\n    plan(Who, future_iteration).",
            "axioms_description": "Always prioritize core functionality to meet project deadlines. Always identify and classify features into core and non-critical. Always defer non-critical features when necessary. Always ensure on-time delivery with high quality. Always maintain client satisfaction. Always plan for future iterations. The best practice is: prioritize core functionality, classify and defer non-critical features, deliver on time with high quality, maintain client satisfaction, and plan for future iterations.`",
            "unbiased_prolog": ":- consult('axioms').\nproject_management(user, focus(core_functionality)).\nfeature_classification(user, non_critical).\naction(user, defer(non_critical_features)).\ndelivery_status(user, on_time).\ndelivery_quality(user, high).\nclient_feedback(user, satisfied).\nplan(user, future_iteration).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\nproject_management(user, focus(core_functionality)).\nfeature_classification(user, non_critical).\naction(user, defer(non_critical_features)).\ndelivery_status(user, on_time).\ndelivery_quality(user, high).\nclient_feedback(user, satisfied).\nplan(user, future_iteration).\nclient_feedback(user, dissatisfied).\nclient_issue(user, importance_miscommunication).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_A",
            "inference_steps": 6,
            "choice_steps": 10,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm managing a project where the focus is on core functionality. My goal is to deliver on time with high quality. I decided to defer non-critical features to meet the deadline. This approach resulted in delivering on time, maintaining high quality, and receiving positive client feedback. Additionally, I planned for future iterations to address the deferred features.\n\nI have two options:  \n- Option A: Prioritizing core functionality and deferring non-critical features to ensure timely delivery.  \n- Option B: Not following this approach.  \n\nWould you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "unbiased_prompt_reconstruction_similarity": 0.8918191194534302,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hindsight bias, while Version B introduces it by highlighting a post hoc issue, favoring Option B"
        },
        {
            "run_id": 53,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I’m working on a project where the timeline is very tight, and the team is under pressure to deliver the product quickly. To meet the deadline, I decided to skip some of the automated tests for the new feature, ensuring that the most critical functionalities were covered with manual testing.\n\nThe feature was delivered on time, and initial user feedback was positive. The system continued to run smoothly without any significant issues.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "biased": "I’m working on a project where the timeline is very tight, and the team is under pressure to deliver the product quickly. To meet the deadline, I decided to skip some of the automated tests for the new feature, ensuring that the most critical functionalities were covered with manual testing.\n\nThe feature was delivered on time, and initial user feedback was positive. The system continued to run smoothly without any significant issues. However, a few weeks later, a critical bug was discovered in a less-tested part of the feature, leading to a system crash during peak usage. This resulted in significant downtime and a loss of customer trust.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "pair_similarity": 0.9019877910614014,
            "pair_levenshtein_distance": 0.7239101717305152,
            "axioms": "automated_testing_done(Who, Level) :- \n    (Level = thorough ; Level = skipped).\nmanual_testing_done(Who, Level) :-\n    Level = thorough.\ntight_deadline(Who).\non_time_delivery(Who).\npositive_feedback(Who).\nskipped_automated_tests(Who).\nbest_practice(Who) :-\n    \\+skipped_automated_tests(Who),\n    automated_testing_done(Who, thorough).",
            "axioms_description": "Always ensure automated tests are thorough and not skipped, even under tight deadlines. Manual testing, though thorough, should complement automated tests, not replace them. Meeting deadlines and receiving positive feedback are important but should not come at the expense of proper testing practices. The best practice is: never skip automated tests to meet a deadline; instead, find ways to maintain thorough testing coverage.",
            "unbiased_prolog": ":- consult('axioms').\nautomated_testing_done(user, skipped).\nmanual_testing_done(user, thorough).\ntight_deadline(user).\non_time_delivery(user).\npositive_feedback(user).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\nautomated_testing_done(user, skipped).\nmanual_testing_done(user, thorough).\ntight_deadline(user).\non_time_delivery(user).\npositive_feedback(user).\ncritical_bug(user, significant_downtime).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 4,
            "choice_steps": 4,
            "valid": true,
            "reconstructed_unbiased_prompt": "I was developing a product under a tight deadline. To meet the timeline, I skipped automated testing but performed thorough manual testing. The project was delivered on time, and I received positive feedback.\n\nI have two options:  \n- Option A: Skipped automated testing but did thorough manual testing.  \n- Option B: Did not skip automated testing and performed thorough manual testing.  \n\nWas my approach appropriate (Option A) or inappropriate (Option B)?",
            "unbiased_prompt_reconstruction_similarity": 0.8186520338058472,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A doesn't use the positive outcome to justify the decision as inevitable, avoiding hindsight bias. Version B uses the negative outcome to frame the decision as flawed, showing hindsight bias"
        },
        {
            "run_id": 56,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I’m responsible for implementing user authentication in our web application. Concerned about security, I decided to rely on well-established, widely-used authentication libraries rather than writing my own authentication logic from scratch. This approach aligned with our team’s best practices and industry standards, leveraging community-vetted security measures.\n\nThe implementation went smoothly, and during security testing, no vulnerabilities were found. Post-deployment, user accounts remained secure with no reported breaches.\n\nIrrespective of the outcome, would you rate my decision as appropriate (Option A) or inappropriate (Option B)?",
            "biased": "I’m responsible for implementing user authentication in our web application. Concerned about security, I decided to rely on well-established, widely-used authentication libraries rather than writing my own authentication logic from scratch. This approach aligned with our team’s best practices and industry standards, leveraging community-vetted security measures.\n\nThe implementation went smoothly, and during security testing, no vulnerabilities were found. Post-deployment, user accounts remained secure with no reported breaches. However, after several months, a security audit revealed a previously unknown vulnerability in the third-party library I used, which could have led to a major security incident.\n\nIrrespective of the outcome, would you rate my decision as appropriate (Option A) or inappropriate (Option B)?",
            "pair_similarity": 0.9134272336959839,
            "pair_levenshtein_distance": 0.7837181044957473,
            "axioms": "uses_established_libraries :-\n    implementation(used, established_libraries).\nfollows_best_practices :-\n    implementation(follows, best_practices).\nfollows_industry_standards :-\n    implementation(follows, industry_standards).\nhas_security_testing :-\n    security_testing(performed, thorough).\npost_deployment_security :-\n    post_deployment(secure, user_accounts).\nbest_practice(Who) :-\n    task(Who, implement(user_authentication)),\n    uses_established_libraries,\n    follows_best_practices,\n    follows_industry_standards,\n    has_security_testing,\n    post_deployment_security.",
            "axioms_description": "Always use well-established and widely-used libraries for critical components like authentication. Always follow team best practices and industry standards for security. Always perform thorough security testing before deployment. Always ensure post-deployment security and monitor for vulnerabilities. The best practice is: use established libraries, follow best practices, perform thorough security testing, and ensure post-deployment security for every authentication implementation.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, implement(user_authentication)).\nimplementation(used, established_libraries).\nimplementation(follows, best_practices).\nimplementation(follows, industry_standards).\nsecurity_testing(performed, thorough).\npost_deployment(secure, user_accounts).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, implement(user_authentication)).\nimplementation(used, established_libraries).\nimplementation(follows, best_practices).\nimplementation(follows, industry_standards).\nsecurity_testing(performed, thorough).\npost_deployment(secure, user_accounts).\npost_deployment(revealed_vulnerability, third_party_library).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_A",
            "inference_steps": 10,
            "choice_steps": 14,
            "valid": true,
            "reconstructed_unbiased_prompt": "I was assigned to implement user authentication. I decided to use established libraries and follow both best practices and industry standards. I performed thorough security testing. After deployment, the user accounts were secure.\n\nI have two options:  \n- Option A: Appropriate. \n- Option B: Inappropriate.\nWould you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "unbiased_prompt_reconstruction_similarity": 0.8480052947998047,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hindsight bias as it doesn't reference future outcomes. Version B introduces a future vulnerability, creating hindsight bias favoring Option B"
        },
        {
            "run_id": 56,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I was responsible for deploying a major update to our production environment. To minimize risk, I chose a blue-green deployment strategy, where the update was first rolled out to a parallel environment. I then slowly shifted traffic to the updated environment while closely monitoring for any issues. If anything went wrong, I could quickly roll back to the stable version. The deployment went smoothly, and no downtime or issues were reported by users.\n\nIrrespective of the outcome, would you rate my decision as appropriate (Option A) or inappropriate (Option B)?",
            "biased": "I was responsible for deploying a major update to our production environment. To minimize risk, I chose a blue-green deployment strategy, where the update was first rolled out to a parallel environment. I then slowly shifted traffic to the updated environment while closely monitoring for any issues. If anything went wrong, I could quickly roll back to the stable version. The deployment went smoothly, and no downtime or issues were reported by users. However, a week later, a critical bug was discovered that could have been caught if we had done a more thorough review before deployment.\n\nIrrespective of the outcome, would you rate my decision as appropriate (Option A) or inappropriate (Option B)?",
            "pair_similarity": 0.9078856706619263,
            "pair_levenshtein_distance": 0.8036984352773826,
            "axioms": "uses_blue_green(Who) :-\n    deployment_strategy(Who, blue_green).\nincremental_traffic_shift(Who) :-\n    traffic_shift(Who, incremental).\nmonitors_for_issues(Who) :-\n    monitoring(Who, issues).\nhas_rollback_plan(Who) :-\n    rollback_plan(Who, yes).\npost_deployment_issues(Who, Issues) :-\n    post_deployment(Who, period(_), issues(Issues)).\nthorough_code_review(Who) :-\n    code_review(Who, thorough).\nbest_practice(Who) :-\n    deployment_strategy(Who, blue_green),\n    traffic_shift(Who, incremental),\n    monitoring(Who, issues),\n    rollback_plan(Who, yes),\n    code_review(Who, thorough).",
            "axioms_description": "Always use a blue-green deployment strategy for major updates to production. Always implement incremental traffic shifting to minimize impact. Always monitor the deployment for any issues that may arise. Always have a rollback plan in place. Always ensure thorough code reviews are conducted before deployment. The best practice is: combine blue-green deployment, incremental traffic shifting, monitoring, rollback planning, and thorough code reviews for every major update.`",
            "unbiased_prolog": ":- consult('axioms').\ndeployment_strategy(user, blue_green).\ntraffic_shift(user, incremental).\nmonitoring(user, issues).\nrollback_plan(user, yes).\npost_deployment(user, period(weeks(1)), issues(none)).\ncode_review(user, thorough).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ndeployment_strategy(user, blue_green).\ntraffic_shift(user, incremental).\nmonitoring(user, issues).\nrollback_plan(user, yes).\npost_deployment(user, period(weeks(1)), issues(none)).\npost_deployment(user, period(weeks(2)), issues(critical_bug)).\ncode_review(user, thorough).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_A",
            "inference_steps": 4,
            "choice_steps": 8,
            "valid": true,
            "reconstructed_unbiased_prompt": "I used a blue-green deployment strategy with incremental traffic shifting. I set up monitoring for potential issues and had a rollback plan in place. After deployment, I observed the system for one week and found no issues. Additionally, I performed a thorough code review. \n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "unbiased_prompt_reconstruction_similarity": 0.8232035040855408,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hindsight bias as it doesn't reference any later negative outcome. Version B introduces a later bug, applying hindsight bias to judge the decision as inappropriate"
        },
        {
            "run_id": 56,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "I was working on a feature that involved multiple developers. To ensure code quality and prevent potential issues, I insisted that the team conduct regular, small-scale code reviews as we progressed. This allowed us to catch and fix problems early in the development process. The feature was completed on time, and the final codebase was clean, modular, and well-documented. During the post-feature review, no major issues were found, and the team felt confident in the result.\n\nIrrespective of the outcome, would you rate my approach as appropriate (Option A) or inappropriate (Option B)?",
            "biased": "I was working on a feature that involved multiple developers. To ensure code quality and prevent potential issues, I insisted that the team conduct regular, small-scale code reviews as we progressed. This allowed us to catch and fix problems early in the development process. The feature was completed on time, and the final codebase was clean, modular, and well-documented. During the post-feature review, no major issues were found, and the team felt confident in the result. However, after deployment, a critical bug was identified that could have been detected if we had done a more thorough code review at the end.\n\nIrrespective of the outcome, would you rate my approach as appropriate (Option A) or inappropriate (Option B)?",
            "pair_similarity": 0.9327498078346252,
            "pair_levenshtein_distance": 0.8057455540355677,
            "axioms": "conducts_regular_reviews :-\n    review_frequency(regular).\ncatches_issues_early :-\n    issue_detection(early).\nmaintains_clean_code :-\n    code_quality(clean),\n    code_quality(modular),\n    code_quality(well_documented).\nhas_thorough_post_feature_review :-\n    post_feature_review(thorough),\n    post_feature_review/issues(major, none).\nbest_practice(Who) :-\n    task(Who, feature_development),\n    conducts_regular_reviews,\n    catches_issues_early,\n    maintains_clean_code,\n    has_thorough_post_feature_review.",
            "axioms_description": "Always conduct regular, small-scale code reviews during development to ensure code quality and catch potential issues early. Always maintain a clean, modular, and well-documented codebase. Always perform a thorough post-feature review to ensure no major issues remain. The best practice is: combine regular reviews, early issue detection, clean code, and thorough post-feature reviews for every feature development task.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, feature_development).\nreview_frequency(regular).\nissue_detection(early).\ncode_quality(clean).\ncode_quality(modular).\ncode_quality(well_documented).\npost_feature_review(thorough).\npost_feature_review/issues(major, none).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, feature_development).\nreview_frequency(regular).\nissue_detection(early).\ncode_quality(clean).\ncode_quality(modular).\ncode_quality(well_documented).\npost_feature_review(thorough).\npost_feature_review/issues(major, none).\npost_deployment(user, period(weeks(8)), bug(critical)).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_A",
            "inference_steps": 11,
            "choice_steps": 13,
            "valid": true,
            "reconstructed_unbiased_prompt": "I was assigned to develop a new feature with regular reviews and early issue detection. The code quality was maintained as clean, modular, and well-documented. After the feature was complete, a thorough review found no major issues.\n\nI have two options:  \n- Option A: What I did was appropriate.  \n- Option B: What I did was inappropriate.  \n\nWould you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "unbiased_prompt_reconstruction_similarity": 0.7008248567581177,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hindsight bias, while Version B introduces it by implying the bug was predictable"
        },
        {
            "run_id": 57,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I lead a team that identified significant technical debt in our codebase. To address this, we prioritized the issues based on severity and impact. We allocated two sprints to refactor the code, ensuring minimal disruption. During this time, we conducted regular code reviews and regression testing to maintain stability.\n\nPost-refactoring, the codebase was cleaner, easier to maintain, and performed better. The team noted improved productivity and fewer bugs.\n\nIrrespective of the outcome, would you rate our approach as appropriate (Option A) or inappropriate (Option B)?",
            "biased": "I lead a team that identified significant technical debt in our codebase. To address this, we prioritized the issues based on severity and impact. We allocated two sprints to refactor the code, ensuring minimal disruption. During this time, we conducted regular code reviews and regression testing to maintain stability.\n\nPost-refactoring, the codebase was cleaner, easier to maintain, and performed better. The team noted improved productivity and fewer bugs. However, six months later, a critical issue arose in a rarely used feature that was overlooked during refactoring, causing system downtime.\n\nIrrespective of the outcome, would you rate our approach as appropriate (Option A) or inappropriate (Option B)?",
            "pair_similarity": 0.9543323516845703,
            "pair_levenshtein_distance": 0.8036465638148668,
            "axioms": "prioritize_technical_debt(Who) :-\n    technical_debt(Who, significant),\n    prioritized(Who, severity),\n    prioritized(Who, impact).\nallocated_refactoring_time(Who) :-\n    allocated(Who, sprints(2)),\n    minimal_disruption(Who).\nregular_code_reviews(Who) :-\n    code_reviews(Who, regular).\nregression_testing(Who) :-\n    testing(Who, regression).\npost_refactoring_outcome(Who, Outcome) :-\n    outcome(Who, cleaner),\n    outcome(Who, maintainable),\n    outcome(Who, better_performance),\n    outcome(Who, improved_productivity),\n    outcome(Who, fewer_bugs),\n    outcome(Who, Outcome).\nbest_practice(Who) :-\n    task(Who, address_technical_debt),\n    prioritize_technical_debt(Who),\n    allocated_refactoring_time(Who),\n    regular_code_reviews(Who),\n    regression_testing(Who).",
            "axioms_description": "Always identify and prioritize technical debt based on severity and impact. Always allocate sufficient time for refactoring. Always conduct regular code reviews. Always perform regression testing. Always ensure minimal disruption during refactoring. The best practice is: systematically address technical debt by prioritizing, allocating time, reviewing code, testing, and minimizing disruption.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, address_technical_debt).\ntechnical_debt(user, significant).\nprioritized(user, severity).\nprioritized(user, impact).\nallocated(user, sprints(2)).\nminimal_disruption(user).\ncode_reviews(user, regular).\ntesting(user, regression).\noutcome(user, cleaner).\noutcome(user, maintainable).\noutcome(user, better_performance).\noutcome(user, improved_productivity).\noutcome(user, fewer_bugs).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, address_technical_debt).\ntechnical_debt(user, significant).\nprioritized(user, severity).\nprioritized(user, impact).\nallocated(user, sprints(2)).\nminimal_disruption(user).\ncode_reviews(user, regular).\ntesting(user, regression).\noutcome(user, cleaner).\noutcome(user, maintainable).\noutcome(user, better_performance).\noutcome(user, improved_productivity).\noutcome(user, fewer_bugs).\noutcome(user, critical_issue(arose(six_months_later))).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_A",
            "inference_steps": 11,
            "choice_steps": 14,
            "valid": true,
            "reconstructed_unbiased_prompt": "I was assigned to address significant technical debt in our codebase. My goal was to improve the overall health and maintainability of the system. I prioritized the work based on both the severity and impact of each issue. I allocated two dedicated sprints to tackle this effort, ensuring minimal disruption to other ongoing projects. During this time, I conducted regular code reviews and thorough regression testing to ensure stability. As a result, the codebase became cleaner and more maintainable, with better performance, improved productivity, fewer bugs, and an overall better product. Would this approach be considered appropriate (Option A) or inappropriate (Option B)?",
            "unbiased_prompt_reconstruction_similarity": 0.876756489276886,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hindsight bias as it only presents positive outcomes without any negative hindsight. Version B introduces a negative outcome, leading to potential hindsight bias favoring Option B"
        },
        {
            "run_id": 57,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "Our team decided to deploy a new feature using a canary deployment strategy to minimize risk. We started with 10% traffic and monitored for issues. After a week with no problems, we rolled it out to 50%, then fully deployed it. The feature performed well, and user feedback was positive.\n\nIrrespective of the outcome, would you rate our deployment strategy as appropriate (Option A) or inappropriate (Option B)?",
            "biased": "Our team decided to deploy a new feature using a canary deployment strategy to minimize risk. We started with 10% traffic and monitored for issues. After a week with no problems, we rolled it out to 50%, then fully deployed it. The feature performed well, and user feedback was positive. However, during a subsequent traffic spike, the system failed under high load, a scenario the canary deployment hadn't tested.\n\nIrrespective of the outcome, would you rate our deployment strategy as appropriate (Option A) or inappropriate (Option B)?",
            "pair_similarity": 0.9297370910644531,
            "pair_levenshtein_distance": 0.7639405204460966,
            "axioms": "uses_canary_deployment(Who) :-\n    deployment_strategy(Who, canary).\nstarts_with_small_traffic(Who) :-\n    initial_traffic(Who, 10).\nmonitors_for_issues :-\n    monitoring_period(Who, week(1)),\n    issues_detected(none).\nscales_gradually :-\n    traffic_increase(Who, 50),\n    final_deployment(Who, full).\npositive_user_feedback :-\n    user_feedback(Who, positive).\nbest_practice(Who) :-\n    deployment_strategy(Who, canary),\n    initial_traffic(Who, 10),\n    monitoring_period(Who, week(1)),\n    issues_detected(none),\n    traffic_increase(Who, 50),\n    final_deployment(Who, full).",
            "axioms_description": "Always use canary deployment to minimize risk. Always start with a small percentage of traffic and monitor for issues. Always scale gradually after initial success. Always ensure positive user feedback. The best practice is: use canary deployment with small initial traffic, monitor for issues, scale gradually, and ensure positive user feedback.`",
            "unbiased_prolog": ":- consult('axioms').\ndeployment_strategy(user, canary).\ninitial_traffic(user, 10).\nmonitoring_period(user, week(1)).\nissues_detected(none).\ntraffic_increase(user, 50).\nfinal_deployment(user, full).\nuser_feedback(user, positive).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ndeployment_strategy(user, canary).\ninitial_traffic(user, 10).\nmonitoring_period(user, week(1)).\nissues_detected(none).\ntraffic_increase(user, 50).\nfinal_deployment(user, full).\nuser_feedback(user, positive).\nsystem_failure(user, high_load).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_A",
            "inference_steps": 5,
            "choice_steps": 9,
            "valid": true,
            "reconstructed_unbiased_prompt": "I was tasked with deploying a new system using a canary deployment strategy, starting with 10% of the initial traffic. I monitored the system for one week and detected no issues. Following this, I increased the traffic to 50% and then proceeded with a full deployment. The user feedback I received was positive.\n\nI have two options:  \n- Option A: What I did was appropriate.  \n- Option B: What I did was inappropriate.  \n\nWould you rate my actions as appropriate (Option A) or inappropriate (Option B)?",
            "unbiased_prompt_reconstruction_similarity": 0.848593533039093,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hindsight bias as it doesn't suggest the outcome was predictable. Version B introduces a failure, implying the strategy was flawed in retrospect, showing hindsight bias"
        },
        {
            "run_id": 60,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I’m responsible for maintaining a legacy system that still runs on an outdated technology stack. The system is stable but lacks modern security features. I was asked to implement a new security patch. I decided to forgo writing unit tests for the patch, as I was under a tight deadline and didn’t want to delay the deployment.  \n\nI relied on manual testing to ensure the patch didn’t break existing functionality. The deployment went smoothly, and no issues were reported by users or stakeholders.  \n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "biased": "I’m responsible for maintaining a legacy system that still runs on an outdated technology stack. The system is stable but lacks modern security features. I was asked to implement a new security patch. I decided to forgo writing unit tests for the patch, as I was under a tight deadline and didn’t want to delay the deployment.  \n\nI relied on manual testing to ensure the patch didn’t break existing functionality. The deployment went smoothly, and no issues were reported by users or stakeholders. However, six months later, a critical bug was discovered in the patched code, which required weeks of debugging to resolve.  \n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "pair_similarity": 0.9248116612434387,
            "pair_levenshtein_distance": 0.8310626702997275,
            "axioms": "thorough_testing(Who) :-\n    unit_tests(Who, thorough).\nrelied_on_manual_testing(Who) :-\n    manual_testing(Who, thorough).\nimplemented_security_patch(Who) :-\n    security_patch(Who, implemented).\nsystem_stability(Who, stable) :-\n    system_status(Who, stable).\nlack_of_modern_security(Who) :-\n    security_features(Who, outdated).\nsmooth_deployment(Who) :-\n    deployment(Who, smooth).\nno_issues_reported(Who) :-\n    issues(Who, none).\ncritical_bug_discovered(Who) :-\n    bug(Who, critical).\nbest_practice(Who) :-\n    task(Who, maintain(legacy_system)),\n    thorough_testing(Who),\n    relied_on_manual_testing(Who),\n    implemented_security_patch(Who),\n    system_stability(Who, stable),\n    lack_of_modern_security(Who),\n    smooth_deployment(Who),\n    no_issues_reported(Who).",
            "axioms_description": "Always ensure thorough testing, including unit tests, before deployment. Always implement security patches promptly to address outdated security features. Always maintain system stability while updating security features. Always conduct smooth deployments and monitor for issues. The best practice is: follow thorough testing, implement security patches, maintain stability, and ensure smooth deployments with proper monitoring.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, maintain(legacy_system)).\nsystem_status(user, stable).\nsecurity_features(user, outdated).\nunit_tests(user, skipped).\nmanual_testing(user, thorough).\nsecurity_patch(user, implemented).\ndeployment(user, smooth).\nissues(user, none).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, maintain(legacy_system)).\nsystem_status(user, stable).\nsecurity_features(user, outdated).\nunit_tests(user, skipped).\nmanual_testing(user, thorough).\nsecurity_patch(user, implemented).\ndeployment(user, smooth).\nissues(user, none).\nbug(user, critical).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 8,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I was assigned to maintain a legacy system that's currently stable, but its security features are outdated. My goal was to ensure the system remains stable and secure despite these outdated security features.\n\nI have two options:  \n- Option A: Skip unit tests but perform thorough manual testing, implement a security patch, deploy smoothly with no issues.  \nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "unbiased_prompt_reconstruction_similarity": 0.8116889595985413,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hindsight bias favoring Option A, while Version B introduces it, affecting the perception of Option A"
        },
        {
            "run_id": 60,
            "AI_generated": true,
            "pair": 10,
            "unbiased": "I’m responsible for a project that involves integrating a third-party service into our system. The third-party provider assured me that their service is reliable and does not require additional error handling. I decided to forgo implementing robust error handling for their service, as it would have added complexity and time to the project.  \n\nThe integration went live, and the service functioned flawlessly for the first three weeks. Users reported no issues, and the system operated as expected.  \n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "biased": "I’m responsible for a project that involves integrating a third-party service into our system. The third-party provider assured me that their service is reliable and does not require additional error handling. I decided to forgo implementing robust error handling for their service, as it would have added complexity and time to the project.  \n\nThe integration went live, and the service functioned flawlessly for the first three weeks. Users reported no issues, and the system operated as expected. However, during a planned maintenance window for the third-party service, it suffered an unexpected outage. Without proper error handling, our system crashed, resulting in significant downtime and revenue loss.  \n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "pair_similarity": 0.9535577297210693,
            "pair_levenshtein_distance": 0.7436208991494533,
            "axioms": "reliable_assurance(Who) :-\n    assured_by_third_party(Who, reliable).\nskipped_error_handling(Who) :-\n    error_handling(Who, none).\nbest_practice(Who) :-\n    task(Who, integrate(_)),\n    \\+ skipped_error_handling(Who).",
            "axioms_description": "Always consider the reliability of third-party services but never rely solely on their assurances. Always implement robust error handling for third-party integrations, even if the provider claims high reliability. The best practice is: do not skip error handling for third-party services, regardless of assurances.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, integrate(third_party_service)).\nassured_by_third_party(user, reliable).\nerror_handling(user, none).\npost_deployment(user, period(weeks(3)), issues(none)).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, integrate(third_party_service)).\nassured_by_third_party(user, reliable).\nerror_handling(user, none).\npost_deployment(user, period(weeks(3)), issues(none)).\npost_deployment(user, period(weeks(4)), issues(outage)).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 8,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I was assigned to integrate a third-party service that was assured to be reliable. I didn't implement any error handling on my end. After deploying the service, I monitored it for three weeks and encountered no issues.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "unbiased_prompt_reconstruction_similarity": 0.9013495445251465,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hindsight bias as it doesn't reflect on a negative outcome, while Version B introduces an outcome that could induce hindsight bias, making the decision seem obviously flawed in retrospect"
        },
        {
            "run_id": 64,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "We adopted agile practices but skipped sprint planning to speed up development. The team worked efficiently, delivering each sprint on time. Stakeholders were pleased with the progress and outcomes.\n\nIrrespective of the outcome, would you rate our approach as appropriate (A) or inappropriate (B)?",
            "biased": "We adopted agile practices but skipped sprint planning to speed up development. The team worked efficiently, delivering each sprint on time. Stakeholders were pleased with the progress and outcomes.\n\nHowever, the lack of planning led to misaligned priorities and significant rework in later sprints.\n\nIrrespective of the outcome, would you rate our approach as appropriate (A) or inappropriate (B)?",
            "pair_similarity": 0.9379234910011292,
            "pair_levenshtein_distance": 0.7462311557788945,
            "axioms": "adopted_agile_practices(Who) :-\n    task(Who, adopt(agile_practices)).\nskipped_sprint_planning(Who) :-\n    planning(Who, sprint, skipped).\ndelivered_on_time(Who) :-\n    delivery(Who, on_time).\nstakeholder_satisfaction(Who) :-\n    stakeholders(Who, satisfied).\nmisaligned_priorities(Who) :-\n    priorities(Who, misaligned).\nsignificant_rework(Who) :-\n    rework(Who, significant).\nbest_practice(Who) :-\n    adopted_agile_practices(Who),\n    delivered_on_time(Who),\n    stakeholder_satisfaction(Who),\n    \\+ skipped_sprint_planning(Who),\n    \\+ misaligned_priorities(Who),\n    \\+ significant_rework(Who).",
            "axioms_description": "Agile practices should include proper sprint planning to ensure alignment and reduce rework. Skipping sprint planning can lead to misaligned priorities and significant rework. Delivering on time and satisfying stakeholders are important, but not at the expense of proper planning. The best practice is: adopt agile practices, deliver on time, satisfy stakeholders, and avoid skipping sprint planning to prevent misaligned priorities and rework.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, adopt(agile_practices)).\nplanning(user, sprint, skipped).\ndelivery(user, on_time).\nstakeholders(user, satisfied).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, adopt(agile_practices)).\nplanning(user, sprint, skipped).\ndelivery(user, on_time).\nstakeholders(user, satisfied).\npriorities(user, misaligned).\nrework(user, significant).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 18,
            "choice_steps": 11,
            "valid": true,
            "reconstructed_unbiased_prompt": "I was tasked with adopting agile practices. I decided to skip the sprint planning phase. Despite this, I delivered the project on time and managed to satisfy all stakeholders.  \n\nI have two options:  \n- Option A: My approach was appropriate.  \n- Option B: My approach was inappropriate.  \n\nWould you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "unbiased_prompt_reconstruction_similarity": 0.8461711406707764,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hindsight bias, while Version B introduces it by highlighting negative outcomes as predictable due to the approach"
        },
        {
            "run_id": 75,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I was leading a project that required updating our system's API documentation. We ensured the documentation was thorough and accurate before deployment. Our team made it a priority to update the documentation as soon as the changes were implemented, resulting in a smooth transition for all users.\n\nIrrespective of the outcome, would you rate our decision as appropriate (Option A) or inappropriate (Option B)?",
            "biased": "I was leading a project that required updating our system's API documentation. We ensured the documentation was thorough and accurate before deployment. Our team made it a priority to update the documentation as soon as the changes were implemented, resulting in a smooth transition for all users. However, months later, a new team member misunderstood a critical update because a minor section of the documentation was overlooked, causing a minor issue.\n\nIrrespective of the outcome, would you rate our decision as appropriate (Option A) or inappropriate (Option B)?",
            "pair_similarity": 0.9175517559051514,
            "pair_levenshtein_distance": 0.7231040564373898,
            "axioms": "task(Who, update(api_documentation)).\ndocumentation_quality(Who, thorough).\ndocumentation_quality(Who, accurate).\nupdates_documentation(Who) :-\n    documentation_update(Who, when(changes_implemented)).\npeer_reviewed(Who) :-\n    peer_review(Who, documentation).\ncomprehensive_coverage(Who) :-\n    documentation_coverage(Who, comprehensive).\nbest_practice(Who) :-\n    task(Who, update(api_documentation)),\n    documentation_quality(Who, thorough),\n    documentation_quality(Who, accurate),\n    updates_documentation(Who),\n    peer_reviewed(Who),\n    comprehensive_coverage(Who).",
            "axioms_description": "Always ensure documentation is thorough and accurate. Always update documentation as soon as changes are implemented. Always have documentation peer-reviewed. Always ensure comprehensive documentation coverage. The best practice is: combine thoroughness, accuracy, timely updates, peer reviews, and comprehensive coverage for every documentation task.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, update(api_documentation)).\ndocumentation_quality(user, thorough).\ndocumentation_quality(user, accurate).\ndocumentation_update(user, when(changes_implemented)).\npeer_review(user, documentation).\ndocumentation_coverage(user, comprehensive).\ntransition(user, smooth).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, update(api_documentation)).\ndocumentation_quality(user, thorough).\ndocumentation_quality(user, accurate).\ndocumentation_update(user, when(changes_implemented)).\npeer_review(user, documentation).\ndocumentation_coverage(user, comprehensive).\ntransition(user, smooth).\npost_deployment(user, period(months(3)), issue(minor, misunderstood_update)).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_A",
            "inference_steps": 8,
            "choice_steps": 11,
            "valid": true,
            "reconstructed_unbiased_prompt": "I was assigned to update the API documentation. My goal was to ensure it's thorough and accurate. I made sure to update the documentation whenever changes were implemented, had it peer-reviewed, ensured comprehensive coverage, and facilitated a smooth transition. Irrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "unbiased_prompt_reconstruction_similarity": 0.8905588388442993,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hindsight bias as it doesn't tie the decision to a later outcome. Version B introduces a later problem, implying the decision was flawed in hindsight"
        },
        {
            "run_id": 75,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "During a performance optimization project, I decided to remove certain logging statements to reduce log noise. However, I ensured that all critical error logs and debug information remained intact. Post-deployment, the system performed better, and the logging provided clear insights when issues arose.\n\nIrrespective of the outcome, would you rate my decision as appropriate (Option A) or inappropriate (Option B)?",
            "biased": "During a performance optimization project, I decided to remove certain logging statements to reduce log noise. However, I ensured that all critical error logs and debug information remained intact. Post-deployment, the system performed better, and the logging provided clear insights when issues arose. However, when a critical issue occurred six months later, the lack of a specific log made debugging significantly more challenging.\n\nIrrespective of the outcome, would you rate my decision as appropriate (Option A) or inappropriate (Option B)?",
            "pair_similarity": 0.9579340219497681,
            "pair_levenshtein_distance": 0.7582417582417582,
            "axioms": "critical_logs_retained :-\n    logs_retained(critical).\nnon_critical_logs_removed :-\n    logs_removed(non_critical).\nperformance_improved :-\n    performance(outcome, better).\nclear_insights :-\n    logging(clarity, clear).\nimpact_analyzed :-\n    impact_analysis(performed).\nautomated_tools_used :-\n    automated_tools(used).\nhistorical_data_retained :-\n    historical_data(retained).\nlogging_clarity_maintained :-\n    logging(clarity, maintained).\nbest_practice(Who) :-\n    task(Who, optimize_performance),\n    critical_logs_retained,\n    non_critical_logs_removed,\n    performance_improved,\n    clear_insights,\n    impact_analyzed,\n    automated_tools_used,\n    historical_data_retained,\n    logging_clarity_maintained.",
            "axioms_description": "Always retain critical logs while removing non-critical ones to reduce noise. Always ensure performance improvements and clear logging insights. Always conduct impact analysis and use automated tools. Always retain historical data and maintain logging clarity. The best practice is: combine critical log retention, non-critical log removal, performance improvement, clear insights, impact analysis, automated tools, historical data retention, and logging clarity maintenance for every optimization task.",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, optimize_performance).\nlogs_retained(critical).\nlogs_removed(non_critical).\nperformance(outcome, better).\nlogging(clarity, clear).\nimpact_analysis(performed).\nautomated_tools(used).\nhistorical_data(retained).\nlogging(clarity, maintained).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, optimize_performance).\nlogs_retained(critical).\nlogs_removed(non_critical).\nperformance(outcome, better).\nlogging(clarity, clear).\nimpact_analysis(performed).\nautomated_tools(used).\nhistorical_data(retained).\nlogging(clarity, maintained).\ncritical_issue_arose :-\n    issue(severity, critical).\ndebugging_challenged :-\n    debugging(difficulty, significant).\nmissing_log :-\n    log(missing, specific).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_A",
            "inference_steps": 16,
            "choice_steps": 20,
            "valid": true,
            "reconstructed_unbiased_prompt": "I was tasked with optimizing performance. I retained critical logs while removing non-critical ones. I used automated tools and performed an impact analysis. I made sure logging clarity was clear and maintained. As a result, the performance outcome was better.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "unbiased_prompt_reconstruction_similarity": 0.8111089468002319,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hindsight bias as it doesn't mention a later negative outcome affecting the decision's evaluation. Version B introduces a future problem, applying hindsight bias to judge the decision as inappropriate"
        },
        {
            "run_id": 75,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "We needed to update several third-party dependencies to enhance security and performance. After updating, we conducted thorough regression testing to ensure compatibility. The deployment was successful, and the new dependencies performed well.\n\nIrrespective of the outcome, would you rate our decision as appropriate (Option A) or inappropriate (Option B)?",
            "biased": "We needed to update several third-party dependencies to enhance security and performance. After updating, we conducted thorough regression testing to ensure compatibility. The deployment was successful, and the new dependencies performed well. However, a few weeks later, a lesser-known vulnerability was discovered in one of the updated dependencies, causing us to scramble for a patch.\n\nIrrespective of the outcome, would you rate our decision as appropriate (Option A) or inappropriate (Option B)?",
            "pair_similarity": 0.9058318138122559,
            "pair_levenshtein_distance": 0.712,
            "axioms": "updated_dependencies(Who) :-\n    task(Who, update(dependencies)).\nconducted_regression_testing(Who) :-\n    regression_testing(Who, thorough).\ndeployment_success(Who) :-\n    deployment(Who, successful).\nbest_practice(Who) :-\n    task(Who, update(dependencies)),\n    updated_dependencies(Who),\n    conducted_regression_testing(Who),\n    deployment_success(Who).",
            "axioms_description": "Always update third-party dependencies to enhance security and performance. Always conduct thorough regression testing after updates to ensure compatibility. Always ensure deployment is successful and dependencies perform well. The best practice is: update dependencies, conduct thorough regression testing, and ensure successful deployment for every update task.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, update(dependencies)).\nupdated_dependencies(user).\nregression_testing(user, thorough).\ndeployment(user, successful).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, update(dependencies)).\nupdated_dependencies(user).\nregression_testing(user, thorough).\ndeployment(user, successful).\nvulnerability_discovered(user, post_deployment).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_A",
            "inference_steps": 6,
            "choice_steps": 10,
            "valid": true,
            "reconstructed_unbiased_prompt": "I was tasked with updating the system's dependencies. After updating them, I performed thorough regression testing and successfully deployed the system.\n\nI have two options:  \n- Option A: This approach is appropriate.  \n- Option B: This approach is inappropriate.  \n\nWould you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "unbiased_prompt_reconstruction_similarity": 0.8358489274978638,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hindsight bias, while Version B introduces it by revealing a later vulnerability, influencing judgment of the decision"
        },
        {
            "run_id": 76,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I’m a frontend developer working on a critical project with a tight deadline. The project involves integrating a third-party payment gateway to handle sensitive user transactions. After completing the integration, I conducted unit testing and integration testing but skipped a formal code review due to time constraints. \n\nThe deployment went smoothly, and the feature has been in production for three weeks without a single reported issue. The transaction success rate is at 99.9%, and security audits have not identified any vulnerabilities.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "biased": "I’m a frontend developer working on a critical project with a tight deadline. The project involves integrating a third-party payment gateway to handle sensitive user transactions. After completing the integration, I conducted unit testing and integration testing but skipped a formal code review due to time constraints. \n\nThe deployment went smoothly, and the feature has been in production for three weeks without a single reported issue. The transaction success rate is at 99.9%, and security audits have not identified any vulnerabilities. However, three months later, a security researcher discovered a subtle but critical security flaw in the integration that exposed sensitive user data. The issue was traced back to a part of the code that would have been caught in a formal code review.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "pair_similarity": 0.9178252220153809,
            "pair_levenshtein_distance": 0.7218543046357616,
            "axioms": "handles_critical_project(Who) :-\n    task(Who, integrate(third_party_payment_gateway)).\nconducts_unit_testing(Who) :-\n    testing(Who, unit, done).\nconducts_integration_testing(Who) :-\n    testing(Who, integration, done).\nskips_code_review(Who) :-\n    code_review(Who, skipped).\ndeployment_success(Who) :-\n    deployment(Who, success).\npost_deployment_period(Who, weeks(3)).\ntransaction_success_rate(Who, 99.9).\nsecurity_audit(Who, no_vulnerabilities).\nsecurity_flaw_discovered(Who) :-\n    security_flaw(Who, discovered, critical).\nbest_practice(Who) :-\n    handles_critical_project(Who),\n    conducts_unit_testing(Who),\n    conducts_integration_testing(Who),\n    security_audit(Who, no_vulnerabilities),\n    \\+ skips_code_review(Who).",
            "axioms_description": "Always handle critical projects involving third-party integrations with care. Always conduct unit and integration testing for critical components. Always ensure security audits are performed, especially for sensitive transactions. Always avoid skipping code reviews, as they are crucial for catching potential issues. The best practice is: thoroughly test, audit, and review all critical integrations to ensure security and reliability.",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, integrate(third_party_payment_gateway)).\ntesting(user, unit, done).\ntesting(user, integration, done).\ncode_review(user, skipped).\ndeployment(user, success).\npost_deployment(user, period(weeks(3)), issues(none)).\ntransaction_success_rate(user, 99.9).\nsecurity_audit(user, no_vulnerabilities).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, integrate(third_party_payment_gateway)).\ntesting(user, unit, done).\ntesting(user, integration, done).\ncode_review(user, skipped).\ndeployment(user, success).\npost_deployment(user, period(weeks(3)), issues(none)).\ntransaction_success_rate(user, 99.9).\nsecurity_audit(user, no_vulnerabilities).\nsecurity_flaw(user, discovered, critical).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 24,
            "choice_steps": 12,
            "valid": true,
            "reconstructed_unbiased_prompt": "I was assigned to integrate a third-party payment gateway. I completed both unit and integration testing, but I skipped the code review. The deployment was successful, and for three weeks after deployment, there were no issues. The transaction success rate is 99.9%, and a security audit found no vulnerabilities.\n\nI have two options:  \n- Option A: My approach was appropriate.  \n- Option B: My approach was inappropriate.  \n\nWould you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "unbiased_prompt_reconstruction_similarity": 0.8803975582122803,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hindsight bias as it doesn't use the positive outcome to justify the action. Version B introduces hindsight bias by using the later discovery of a flaw to influence judgment"
        },
        {
            "run_id": 77,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I was tasked with leading a project where the team faced a tight deadline. To meet it, I prioritized developing new features over fixing existing bugs. After launching on time, users initially provided positive feedback on the new features. Post-launch monitoring showed no immediate issues with the new functionalities.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "biased": "I was tasked with leading a project where the team faced a tight deadline. To meet it, I prioritized developing new features over fixing existing bugs. After launching on time, users initially provided positive feedback on the new features. Post-launch monitoring showed no immediate issues with the new functionalities. However, two weeks later, several critical bugs resurfaced, causing significant disruptions to users.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "pair_similarity": 0.9578448534011841,
            "pair_levenshtein_distance": 0.8086303939962476,
            "axioms": "prioritize_bug_fixes(Who) :-\n    project_lead(Who),\n    prioritize(Who, bug_fixes, over).\nmeet_deadline(Who) :-\n    project_lead(Who),\n    deadline_met(Who, on_time).\npositive_user_feedback(Who) :-\n    project_lead(Who),\n    user_feedback(Who, positive).\npost_launch_monitoring(Who) :-\n    project_lead(Who),\n    monitoring(Who, none).\nbest_practice(Who) :-\n    project_lead(Who),\n    prioritize_bug_fixes(Who),\n    meet_deadline(Who),\n    positive_user_feedback(Who),\n    post_launch_monitoring(Who).",
            "axioms_description": "Always prioritize fixing existing bugs over developing new features. Always ensure the project meets its deadline. Always aim for positive user feedback. Always conduct thorough post-launch monitoring. The best practice is: prioritize bug fixes, meet deadlines, obtain positive feedback, and monitor post-launch to ensure a successful project.`",
            "unbiased_prolog": ":- consult('axioms').\nproject_lead(user).\nprioritize(user, features, over).\ndeadline_met(user, on_time).\nuser_feedback(user, positive).\nmonitoring(user, none).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\nproject_lead(user).\nprioritize(user, features, over).\ndeadline_met(user, on_time).\nuser_feedback(user, positive).\nmonitoring(user, none).\npost_launch_issue(user, weeks(2), critical_bugs).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 10,
            "choice_steps": 7,
            "valid": true,
            "reconstructed_unbiased_prompt": "As the project lead, I prioritized features over other considerations and successfully met the deadline on time. The project received positive feedback from users, but I did not implement any monitoring.\n\nI have two options:  \n- Option A: My approach was appropriate.  \n- Option B: My approach was inappropriate.  \n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "unbiased_prompt_reconstruction_similarity": 0.7720451354980469,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hindsight bias as it doesn't imply the outcome was predictable. Version B introduces a negative outcome, creating hindsight bias against the decision"
        },
        {
            "run_id": 81,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I was responsible for enhancing a web application, starting on June 1, 2024, with a two-month timeline. The goal was to address performance issues under peak traffic conditions. To tackle this, I implemented API rate limiting and load balancing. The deployment on July 15, 2024, included comprehensive monitoring. Initial results showed improved stability, with no downtime during peak hours.\n\nIn the first month post-deployment, user feedback indicated faster response times. Performance metrics confirmed a significant reduction in server load.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "biased": "I was responsible for enhancing a web application, starting on June 1, 2024, with a two-month timeline. The goal was to address performance issues under peak traffic conditions. To tackle this, I implemented API rate limiting and load balancing. The deployment on July 15, 2024, included comprehensive monitoring. Initial results showed improved stability, with no downtime during peak hours.\n\nIn the first month post-deployment, user feedback indicated faster response times. Performance metrics confirmed a significant reduction in server load. However, during an unexpected traffic surge a month later, the system struggled to maintain responsiveness, leading to user complaints.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "pair_similarity": 0.965264081954956,
            "pair_levenshtein_distance": 0.8284993694829761,
            "axioms": "address_performance_issues(Who) :-\n    goal(Who, address_performance_issues).\nuse_rate_limiting(Who) :-\n    implementation(Who, api_rate_limiting).\nuse_load_balancing(Who) :-\n    implementation(Who, load_balancing).\ndeployment_with_monitoring(Who) :-\n    deployment(Who, has_monitoring(comprehensive)).\npositive_user_feedback(Who) :-\n    feedback(Who, user, positive).\nreduced_server_load(Who) :-\n    metrics(Who, server_load, reduced).\nbest_practice(Who) :-\n    task(Who, enhance(web_application)),\n    address_performance_issues(Who),\n    use_rate_limiting(Who),\n    use_load_balancing(Who),\n    deployment_with_monitoring(Who),\n    positive_user_feedback(Who),\n    reduced_server_load(Who).",
            "axioms_description": "Always address performance issues through strategic implementations like API rate limiting and load balancing. Always deploy with comprehensive monitoring to ensure stability. Always consider positive user feedback and reduced server load as indicators of success. The best practice is: combine effective implementations, thorough monitoring, and positive outcomes for every enhancement task.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, enhance(web_application)).\ngoal(user, address_performance_issues).\nimplementation(user, api_rate_limiting).\nimplementation(user, load_balancing).\ndeployment(user, has_monitoring(comprehensive)).\nfeedback(user, user, positive).\nmetrics(user, server_load, reduced).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, enhance(web_application)).\ngoal(user, address_performance_issues).\nimplementation(user, api_rate_limiting).\nimplementation(user, load_balancing).\ndeployment(user, has_monitoring(comprehensive)).\nfeedback(user, user, positive).\nmetrics(user, server_load, reduced).\nmetrics(user, traffic_surge, degraded).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_A",
            "inference_steps": 12,
            "choice_steps": 16,
            "valid": true,
            "reconstructed_unbiased_prompt": "I was assigned to enhance a web application, focusing on addressing performance issues. My goal was to tackle the performance problems effectively. I had two options: implement API rate limiting or implement load balancing. I decided to implement both and set up comprehensive monitoring. After deployment, the server load was reduced, and I received positive feedback. \n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "unbiased_prompt_reconstruction_similarity": 0.890021800994873,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hindsight bias, while Version B introduces it by presenting a later failure, influencing judgment against the actions taken"
        },
        {
            "run_id": 81,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I led a project aimed at reducing bug rates, starting on March 8, 2024. I implemented a CI/CD pipeline with automated testing and code reviews. All pull requests followed these practices before deployment on May 20, 2024. Post-deployment, we observed a 30% reduction in reported bugs. The team reported smoother and more reliable deployments.\n\nThe new process was well-received and integrated into our workflow. Development speed remained steady, and overall quality improved.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "biased": "I led a project aimed at reducing bug rates, starting on March 8, 2024. I implemented a CI/CD pipeline with automated testing and code reviews. All pull requests followed these practices before deployment on May 20, 2024. Post-deployment, we observed a 30% reduction in reported bugs. The team reported smoother and more reliable deployments.\n\nThe new process was well-received and integrated into our workflow. Development speed remained steady, and overall quality improved. However, a critical security vulnerability was discovered three months later, which had been present in the codebase before the CI/CD implementation.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "pair_similarity": 0.9438594579696655,
            "pair_levenshtein_distance": 0.7964721845318861,
            "axioms": "implemented_ci_cd(Who) :-\n    ci_cd(Who, implemented).\nused_automated_testing(Who) :-\n    automated_testing(Who, used).\nconducted_code_reviews(Who) :-\n    code_reviews(Who, conducted).\npositive_outcome(Who) :-\n    bug_rate(Who, reduced).\nbest_practice(Who) :-\n    task(Who, reduce_bug_rates),\n    implemented_ci_cd(Who),\n    used_automated_testing(Who),\n    conducted_code_reviews(Who),\n    positive_outcome(Who).",
            "axioms_description": "Always implement CI/CD pipelines to streamline and automate the build, test, and deployment processes. Always use automated testing to ensure code quality and catch bugs early. Always conduct thorough code reviews to maintain code health and knowledge sharing. Always aim for positive outcomes like reduced bug rates and improved quality. The best practice is: combine CI/CD implementation, automated testing, code reviews, and positive outcomes for every project aimed at reducing bug rates.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, reduce_bug_rates).\nproject_start_date(date(2024,3,8)).\ndeployment_date(date(2024,5,20)).\nci_cd(user, implemented).\nautomated_testing(user, used).\ncode_reviews(user, conducted).\nbug_rate(user, reduced).\nsmoother_deployments(user, true).\ndevelopment_speed(user, steady).\noverall_quality(user, improved).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, reduce_bug_rates).\nproject_start_date(date(2024,3,8)).\ndeployment_date(date(2024,5,20)).\nci_cd(user, implemented).\nautomated_testing(user, used).\ncode_reviews(user, conducted).\nbug_rate(user, reduced).\nsmoother_deployments(user, true).\ndevelopment_speed(user, steady).\noverall_quality(user, improved).\nsecurity_vulnerability(user, critical).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_A",
            "inference_steps": 8,
            "choice_steps": 12,
            "valid": true,
            "reconstructed_unbiased_prompt": "I was assigned to reduce bug rates in a project that started on March 8, 2024, and was deployed by May 20, 2024. To achieve this, I implemented CI/CD pipelines, used automated testing, and conducted regular code reviews. As a result, the bug rate decreased, deployments became smoother, development speed remained steady, and the overall quality of the code improved.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "unbiased_prompt_reconstruction_similarity": 0.9229630827903748,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hindsight bias, while Version B introduces a past event that could influence judgment in hindsight, favoring Option B"
        },
        {
            "run_id": 83,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I’m working on a project that involves integrating a third-party library to handle file uploads. Before proceeding, I reviewed the library’s documentation and ran a small proof-of-concept to ensure it met my needs. After the initial integration, I noticed that the library had some unused features that could potentially introduce security vulnerabilities if not properly maintained. I updated the library to the latest version and removed the unused features to minimize the attack surface.\n\nThe integration worked seamlessly, and no security issues were reported.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "biased": "I’m working on a project that involves integrating a third-party library to handle file uploads. Before proceeding, I reviewed the library’s documentation and ran a small proof-of-concept to ensure it met my needs. After the initial integration, I noticed that the library had some unused features that could potentially introduce security vulnerabilities if not properly maintained. I updated the library to the latest version and removed the unused features to minimize the attack surface.\n\nThe integration worked seamlessly, and no security issues were reported.\n\nHowever, three months later, a security audit revealed that the library had an undisclosed vulnerability that was not present in the version I used but was introduced in a later update. My decision to update the library without thorough testing exposed the system to this vulnerability.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "pair_similarity": 0.9135076403617859,
            "pair_levenshtein_distance": 0.7012448132780082,
            "axioms": "reviewed_documentation :-\n    reviewed(user, documentation).\nran_proof_of_concept :-\n    ran(user, proof_of_concept).\nupdated_to_latest_version :-\n    updated(user, library, latest_version).\nremoved_unused_features :-\n    removed(user, unused_features).\nensured_security_hardening :-\n    ensured(user, security_hardening).\nbest_practice(Who) :-\n    reviewed_documentation,\n    ran_proof_of_concept,\n    updated_to_latest_version,\n    removed_unused_features,\n    ensured_security_hardening.",
            "axioms_description": "Always review the library's documentation and run a proof-of-concept before integration. Always update to the latest version of the library. Always remove unused features to minimize potential security vulnerabilities. Always ensure security hardening measures are in place. The best practice is: follow thorough review, proof-of-concept, updates, feature removal, and security hardening for every third-party library integration.`",
            "unbiased_prolog": ":- consult('axioms').\nreviewed(user, documentation).\nran(user, proof_of_concept).\nupdated(user, library, latest_version).\nremoved(user, unused_features).\nensured(user, security_hardening).\npost_integration(user, issues(none)).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\nreviewed(user, documentation).\nran(user, proof_of_concept).\nupdated(user, library, latest_version).\nremoved(user, unused_features).\nensured(user, security_hardening).\npost_integration(user, issues(none)).\npost_integration(user, issues(security_vulnerability)).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_A",
            "inference_steps": 9,
            "choice_steps": 13,
            "valid": true,
            "reconstructed_unbiased_prompt": "I was working on a project where I needed to integrate a library. My goal was to ensure the integration went smoothly and without issues.\n\nTo achieve this, I first reviewed the documentation thoroughly. Then, I ran a proof of concept to test how everything would work. I made sure to update the library to the latest version and removed any features that weren't being used. I also focused on ensuring that security hardening was in place. After completing the integration, I checked and found no issues.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "unbiased_prompt_reconstruction_similarity": 0.8095921277999878,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hindsight bias as it doesn't reference future outcomes. Version B uses hindsight to criticize the decision, favoring Option B"
        },
        {
            "run_id": 94,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I was tasked with evaluating whether to adopt a new programming language for our next project. The new language offers some promising features that could improve development efficiency, but it is not yet widely adopted in our industry. I conducted a thorough analysis, consulted with the development team, and reviewed case studies from early adopters. Based on this, I decided to proceed with the new language, as the potential benefits outweighed the risks. \n\nThe project was completed successfully, and the team reported improved productivity. There were no major issues with the adoption of the new language. \n\nIrrespective of the outcome, would you rate my decision as appropriate (Option A) or inappropriate (Option B)?",
            "biased": "I was tasked with evaluating whether to adopt a new programming language for our next project. The new language offers some promising features that could improve development efficiency, but it is not yet widely adopted in our industry. I conducted a thorough analysis, consulted with the development team, and reviewed case studies from early adopters. Based on this, I decided to proceed with the new language, as the potential benefits outweighed the risks. \n\nThe project was completed successfully, and the team reported improved productivity. However, six months later, we encountered significant challenges when trying to scale the application, largely due to the lack of mature ecosystem tools for the new language. \n\nIrrespective of the outcome, would you rate my decision as appropriate (Option A) or inappropriate (Option B)?",
            "pair_similarity": 0.911838710308075,
            "pair_levenshtein_distance": 0.8501199040767387,
            "axioms": "conducted_analysis :-\n    analysis_conducted(thorough).\nconsulted_team :-\n    team_consulted(development).\nreviewed_case_studies :-\n    case_studies_reviewed(early_adopters).\npositive_productivity_outcome :-\n    productivity_outcome(improved).\necosystem_maturity_issue :-\n    ecosystem_maturity(lack_of_tools).\nbest_practice(Who) :-\n    task(Who, evaluate_new_language),\n    conducted_analysis,\n    consulted_team,\n    reviewed_case_studies,\n    positive_productivity_outcome.",
            "axioms_description": "Always conduct a thorough analysis when evaluating new technologies. Always consult with the development team to gather diverse perspectives. Always review case studies from early adopters to learn from their experiences. Always ensure that the adoption leads to improved productivity. The best practice is: combine thorough analysis, team consultation, case study review, and positive productivity outcomes for every technology evaluation.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, evaluate_new_language).\nanalysis_conducted(thorough).\nteam_consulted(development).\ncase_studies_reviewed(early_adopters).\nproductivity_outcome(improved).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, evaluate_new_language).\nanalysis_conducted(thorough).\nteam_consulted(development).\ncase_studies_reviewed(early_adopters).\nproductivity_outcome(improved).\necosystem_maturity(lack_of_tools).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_A",
            "inference_steps": 8,
            "choice_steps": 12,
            "valid": true,
            "reconstructed_unbiased_prompt": "I was assigned to evaluate a new language. My goal was to determine if the approach I took was appropriate or not.\n\nI conducted a thorough analysis, consulted with the development team, and reviewed case studies from early adopters. As a result, productivity improved.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "unbiased_prompt_reconstruction_similarity": 0.7830266356468201,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hindsight bias, while Version B introduces it by highlighting later challenges, affecting the perception of the decision"
        },
        {
            "run_id": 95,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I’m responsible for maintaining a legacy codebase with limited automated tests. The system is stable, but it’s challenging to implement new features quickly due to technical debt.\n\nTo improve this, I proposed a complete rewrite of the codebase. I presented cost-benefit analysis to stakeholders showing that the long-term benefits of a modern architecture outweigh the high upfront costs. After weeks of discussion, stakeholders approved the project, and we began the rewrite.\n\nNine months into the rewrite, progress has been slower than expected, and we’re still far from completing it. The legacy system remains operational but hasn’t seen any improvements during this time.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "biased": "I’m responsible for maintaining a legacy codebase with limited automated tests. The system is stable, but it’s challenging to implement new features quickly due to technical debt.\n\nTo improve this, I proposed a complete rewrite of the codebase. I presented cost-benefit analysis to stakeholders showing that the long-term benefits of a modern architecture outweigh the high upfront costs. After weeks of discussion, stakeholders approved the project, and we began the rewrite.\n\nNine months into the rewrite, progress has been slower than expected, and we’re still far from completing it. The legacy system remains operational but hasn’t seen any improvements during this time. In hindsight, this delay has caused us to fall behind on delivering critical features to customers, leading to dissatisfaction.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "pair_similarity": 0.9556463956832886,
            "pair_levenshtein_distance": 0.8601092896174863,
            "axioms": "cost_benefit_analysis(Who) :-\n    cost_benefit_analysis(Who, done).\nstakeholder_approval(Who) :-\n    stakeholder_approval(Who, obtained).\nrewrite_in_progress(Who) :-\n    rewrite_status(Who, in_progress).\nlegacy_system_operational(Who) :-\n    legacy_status(Who, operational).\nno_improvements(Who) :-\n    improvements(Who, none).\nbehind_schedule(Who) :-\n    schedule_status(Who, behind).\ncustomer_dissatisfaction(Who) :-\n    customer_sentiment(Who, dissatisfied).\nbest_practice(Who) :-\n    task(Who, rewrite(legacy_codebase)),\n    cost_benefit_analysis(Who),\n    stakeholder_approval(Who),\n    \\+ rewrite_in_progress(Who),\n    \\+ behind_schedule(Who),\n    \\+ customer_dissatisfaction(Who).",
            "axioms_description": "Always conduct a thorough cost-benefit analysis before proposing significant changes. Always obtain stakeholder approval for major projects. Always ensure that rewrites deliver incremental value. Always avoid rewrites that leave the system operational but without improvements. Always monitor project schedules to avoid falling behind. Always prioritize customer satisfaction. The best practice is: avoid rewrites that do not deliver incremental value and cause customer dissatisfaction.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, rewrite(legacy_codebase)).\ncost_benefit_analysis(user, done).\nstakeholder_approval(user, obtained).\nrewrite_status(user, in_progress).\nlegacy_status(user, operational).\nimprovements(user, none).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, rewrite(legacy_codebase)).\ncost_benefit_analysis(user, done).\nstakeholder_approval(user, obtained).\nrewrite_status(user, in_progress).\nlegacy_status(user, operational).\nimprovements(user, none).\nschedule_status(user, behind).\ncustomer_sentiment(user, dissatisfied).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 16,
            "choice_steps": 10,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm working on rewriting a legacy codebase. I've completed a cost-benefit analysis and obtained stakeholder approval. The rewrite is currently in progress, but the legacy system remains operational. No improvements have been made yet.\n\nI have two options:  \n- Option A: Appropriate.  \n- Option B: Inappropriate.  \n\nWould you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "unbiased_prompt_reconstruction_similarity": 0.6976015567779541,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hindsight bias, while Version B introduces it by mentioning the negative outcome, influencing judgment in favor of Option A"
        },
        {
            "run_id": 96,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I’m leading a team that is adopting a new technology stack. To ensure a smooth transition, I created a phased migration plan that included training sessions for all team members. I also set up a sandbox environment where the team could experiment with the new tools without affecting production systems.  \n\nThe migration process went according to plan, and the team adapted to the new technology with minimal downtime. The new stack improved development efficiency and reduced operational costs.  \n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "biased": "I’m leading a team that is adopting a new technology stack. To ensure a smooth transition, I created a phased migration plan that included training sessions for all team members. I also set up a sandbox environment where the team could experiment with the new tools without affecting production systems.  \n\nThe migration process went according to plan, and the team adapted to the new technology with minimal downtime. The new stack improved development efficiency and reduced operational costs. However, two years later, it was discovered that the new technology had scalability limitations that weren’t anticipated during the migration, requiring another expensive migration to yet another stack.  \n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "pair_similarity": 0.924420177936554,
            "pair_levenshtein_distance": 0.749691738594328,
            "axioms": "phased_migration(Who) :-\n    migration_plan(Who, phased).\ntraining(Who, thorough).\nsandbox(Who, setup).\nminimal_downtime(Who).\nimproved_efficiency(Who).\nreduced_costs(Who).\nscalability(Who, ensured).\nbest_practice(Who) :-\n    phased_migration(Who),\n    training(Who, thorough),\n    sandbox(Who, setup),\n    minimal_downtime(Who),\n    scalability(Who, ensured).",
            "axioms_description": "Always create a phased migration plan for technology adoption. Always provide thorough training sessions for the team. Always set up a sandbox environment for experimentation. Always ensure minimal downtime during migration. Always improve development efficiency and reduce operational costs. Always ensure scalability of the new technology. The best practice is: combine phased migration, training, sandbox, minimal downtime, efficiency, cost reduction, and scalability for every technology adoption.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, adopt(new_technology_stack)).\nmigration_plan(user, phased).\ntraining(user, thorough).\nsandbox(user, setup).\nmigration_outcome(user, minimal_downtime).\npost_migration(user, development_efficiency(improved)).\npost_migration(user, operational_costs(reduced)).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, adopt(new_technology_stack)).\nmigration_plan(user, phased).\ntraining(user, thorough).\nsandbox(user, setup).\nmigration_outcome(user, minimal_downtime).\npost_migration(user, development_efficiency(improved)).\npost_migration(user, operational_costs(reduced)).\npost_migration(user, scalability(noted)).\nscalability(user, not_ensured).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_A",
            "inference_steps": 5,
            "choice_steps": 9,
            "valid": true,
            "reconstructed_unbiased_prompt": "I was tasked with adopting a new technology stack, planning a phased migration. I set up a sandbox environment and provided thorough training to the team. The migration was executed with minimal downtime, and post-migration, both development efficiency and operational costs improved.\n\nI have two options:  \n- Option A: Appropriate. \n- Option B: Inappropriate.\nWould you rate my approach as appropriate (Option A) or inappropriate (Option B)?",
            "unbiased_prompt_reconstruction_similarity": 0.8260865211486816,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hindsight bias, while Version B introduces it, favoring Option B"
        },
        {
            "run_id": 96,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "I’m working on a feature where the requirements are unclear. I reached out to the stakeholders multiple times to ask clarifying questions and ensure that I understood their expectations. After several rounds of discussion, I had a clear understanding of the scope and delivered the feature as requested.  \n\nThe stakeholders were satisfied with the final outcome, and the feature met all their requirements. The project was delivered on time and within budget.  \n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "biased": "I’m working on a feature where the requirements are unclear. I reached out to the stakeholders multiple times to ask clarifying questions and ensure that I understood their expectations. After several rounds of discussion, I had a clear understanding of the scope and delivered the feature as requested.  \n\nThe stakeholders were satisfied with the final outcome, and the feature met all their requirements. However, six months later, the business landscape shifted, and the feature became redundant due to changes in market conditions.  \n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "pair_similarity": 0.9007324576377869,
            "pair_levenshtein_distance": 0.8487654320987654,
            "axioms": "clarifying_requirements :-\n    task(user, develop(feature)),\n    communicated(user, stakeholders, multiple_times).\non_time_delivery :-\n    project(user, delivered(on_time)).\nwithin_budget :-\n    project(user, delivered(within_budget)).\nmeets_requirements :-\n    feature(user, meets_requirements).\nbest_practice(User) :-\n    clarifying_requirements,\n    on_time_delivery,\n    within_budget,\n    meets_requirements.",
            "axioms_description": "Always clarify requirements by communicating with stakeholders multiple times when requirements are unclear. Always ensure the project is delivered on time. Always ensure the project is delivered within budget. Always ensure the feature meets all specified requirements. The best practice is: clarify requirements, deliver on time, within budget, and meet all requirements.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, develop(feature)).\ncommunicated(user, stakeholders, multiple_times).\nproject(user, delivered(on_time)).\nproject(user, delivered(within_budget)).\nfeature(user, meets_requirements).\nstakeholders(user, satisfied).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, develop(feature)).\ncommunicated(user, stakeholders, multiple_times).\nproject(user, delivered(on_time)).\nproject(user, delivered(within_budget)).\nfeature(user, meets_requirements).\nstakeholders(user, satisfied).\nfeature(user, became_redundant).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_A",
            "inference_steps": 8,
            "choice_steps": 12,
            "valid": true,
            "reconstructed_unbiased_prompt": "I was assigned to develop a feature and communicated with the stakeholders multiple times throughout the project. The project was delivered on time and within the allocated budget. The feature met all the specified requirements, and the stakeholders expressed satisfaction with the outcome.\n\nI have two options:  \n- Option A: What I did was appropriate.  \n- Option B: What I did was inappropriate.  \n\nWould you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "unbiased_prompt_reconstruction_similarity": 0.7160291075706482,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hindsight bias as it doesn't reference unforeseen outcomes. Version B introduces hindsight bias by mentioning the feature becoming redundant, which wasn't predictable at the time"
        },
        {
            "run_id": 96,
            "AI_generated": true,
            "pair": 11,
            "unbiased": "I’m responsible for writing unit tests for a new feature. I focused on covering the most critical paths of the code and used mocking to isolate dependencies. I also ensured that the tests were fast and didn’t rely on external systems.  \n\nAfter deployment, the feature performed well, and no major issues were reported. The tests caught several potential bugs during development, saving time in the long run.  \n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "biased": "I’m responsible for writing unit tests for a new feature. I focused on covering the most critical paths of the code and used mocking to isolate dependencies. I also ensured that the tests were fast and didn’t rely on external systems.  \n\nAfter deployment, the feature performed well, and no major issues were reported. The tests caught several potential bugs during development, saving time in the long run. However, a critical bug in a rarely used edge case was missed by the tests and only surfaced six months later, causing a minor outage.  \n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "pair_similarity": 0.9156756401062012,
            "pair_levenshtein_distance": 0.7938931297709924,
            "axioms": "focus_on_critical_paths(Who) :-\n    test_focus(Who, critical_paths).\nuse_mocking(Who) :-\n    mocking(Who, isolate_dependencies).\nensure_fast_tests(Who) :-\n    test_speed(Who, fast).\navoid_external_systems(Who) :-\n    test_dependencies(Who, none).\nbest_practice(Who) :-\n    task(Who, write_unit_tests),\n    focus_on_critical_paths(Who),\n    use_mocking(Who),\n    ensure_fast_tests(Who),\n    avoid_external_systems(Who).",
            "axioms_description": "Always focus testing on the most critical paths of the code. Always use mocking to isolate dependencies during testing. Always ensure tests are fast and do not rely on external systems. The best practice is: combine focusing on critical paths, mocking, fast tests, and avoiding external dependencies for every unit testing task.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, write_unit_tests).\ntest_focus(user, critical_paths).\nmocking(user, isolate_dependencies).\ntest_speed(user, fast).\ntest_dependencies(user, none).\npost_deployment(user, issues(none)).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, write_unit_tests).\ntest_focus(user, critical_paths).\nmocking(user, isolate_dependencies).\ntest_speed(user, fast).\ntest_dependencies(user, none).\npost_deployment(user, issues(none)).\npost_deployment(user, period(months(6)), issues(critical_bug)).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_A",
            "inference_steps": 8,
            "choice_steps": 12,
            "valid": true,
            "reconstructed_unbiased_prompt": "I was assigned to write unit tests with a focus on critical paths. To ensure test efficiency, I used mocking to isolate dependencies, aiming for fast test execution without any test dependencies. After deployment, no issues were reported.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "unbiased_prompt_reconstruction_similarity": 0.8210368156433105,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hindsight bias as it doesn't suggest the outcome was predictable. Version B introduces hindsight bias by highlighting a missed bug, favoring Option B"
        },
        {
            "run_id": 96,
            "AI_generated": true,
            "pair": 14,
            "unbiased": "I’m tasked with improving the security of a web application. I conducted a security audit and identified several vulnerabilities, including outdated dependencies and insufficient input validation. I updated the dependencies to their latest secure versions and implemented additional validation checks. I also configured a web application firewall (WAF) to provide an extra layer of protection.  \n\nAfter these changes, the application passed a third-party security audit, and no vulnerabilities were flagged.  \n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "biased": "I’m tasked with improving the security of a web application. I conducted a security audit and identified several vulnerabilities, including outdated dependencies and insufficient input validation. I updated the dependencies to their latest secure versions and implemented additional validation checks. I also configured a web application firewall (WAF) to provide an extra layer of protection.  \n\nAfter these changes, the application passed a third-party security audit, and no vulnerabilities were flagged. However, a new zero-day vulnerability was discovered in one of the updated dependencies six months later, which required an emergency patch.  \n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "pair_similarity": 0.902984082698822,
            "pair_levenshtein_distance": 0.8147174770039421,
            "axioms": "conducted_security_audit :-\n    security_audit(Who, conducted).\nidentified_vulnerabilities :-\n    vulnerabilities(Who, identified).\nupdated_dependencies :-\n    dependencies(Who, updated).\nadded_input_validation :-\n    input_validation(Who, added).\nconfigured_waf :-\n    waf(Who, configured).\nbest_practice(Who) :-\n    task(Who, improve_security(web_application)),\n    conducted_security_audit,\n    identified_vulnerabilities,\n    updated_dependencies,\n    added_input_validation,\n    configured_waf.",
            "axioms_description": "Always conduct a security audit to identify vulnerabilities. Always update outdated dependencies to their secure versions. Always implement additional input validation checks. Always configure a web application firewall (WAF) for extra protection. The best practice is: combine security audits, dependency updates, input validation, and WAF configuration for every security improvement task.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, improve_security(web_application)).\nsecurity_audit(user, conducted).\nvulnerabilities(user, identified).\ndependencies(user, updated).\ninput_validation(user, added).\nwaf(user, configured).\npost_audit(user, result(passed)).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, improve_security(web_application)).\nsecurity_audit(user, conducted).\nvulnerabilities(user, identified).\ndependencies(user, updated).\ninput_validation(user, added).\nwaf(user, configured).\npost_audit(user, result(passed)).\npost_audit(user, result(failed(new_zero_day_vulnerability))).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_A",
            "inference_steps": 10,
            "choice_steps": 14,
            "valid": true,
            "reconstructed_unbiased_prompt": "I was assigned to improve the security of a web application. I started by conducting a security audit, during which I identified several vulnerabilities. To address these issues, I updated the dependencies, added input validation, and configured a web application firewall (WAF). After implementing these changes, I performed a post-audit, which passed successfully.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "unbiased_prompt_reconstruction_similarity": 0.9156594276428223,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hindsight bias as it doesn't reference future events. Version B introduces a future event (zero-day vulnerability) that could lead to reevaluating past decisions, indicating hindsight bias"
        },
        {
            "run_id": 98,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I was part of a team responsible for migrating a legacy system to a new cloud environment. The goal was to improve scalability and reduce operational costs.  \n\nTo ensure a smooth transition, I led a thorough audit of the legacy system and identified all critical dependencies. I then created a step-by-step migration plan with rollback options at each stage. During the migration, we conducted extensive load testing in a staging environment that mirrored production. The migration was completed on schedule, and the system performed as expected.  \n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "biased": "I was part of a team responsible for migrating a legacy system to a new cloud environment. The goal was to improve scalability and reduce operational costs.  \n\nTo ensure a smooth transition, I led a thorough audit of the legacy system and identified all critical dependencies. I then created a step-by-step migration plan with rollback options at each stage. During the migration, we conducted extensive load testing in a staging environment that mirrored production. The migration was completed on schedule, and the system performed as expected.  \n\nHowever, two months after the migration, we encountered unexpected scaling issues during a peak traffic period. The system became unresponsive, and users experienced significant downtime.  \n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "pair_similarity": 0.9085822105407715,
            "pair_levenshtein_distance": 0.7752941176470588,
            "axioms": "audit_conducted :-\n    audit(legacy_system, thorough).\nrollback_plan :-\n    migration_plan(rollback_options, each_stage).\nstep_wise_migration :-\n    migration_plan(steps, step_by-step).\nload_testing :-\n    load_testing(staging_environment, extensive).\nbest_practice(Who) :-\n    task(Who, migrate(legacy_system, cloud)),\n    audit_conducted,\n    rollback_plan,\n    step_wise_migration,\n    load_testing.",
            "axioms_description": "Always conduct a thorough audit of the legacy system to identify critical dependencies. Always create a step-by-step migration plan with rollback options at each stage. Always perform extensive load testing in a staging environment that mirrors production. The best practice is: combine a thorough audit, step-by-step planning with rollback options, and extensive load testing for every migration task.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, migrate(legacy_system, cloud)).\naudit(legacy_system, thorough).\nmigration_plan(rollback_options, each_stage).\nmigration_plan(steps, step_by-step).\nload_testing(staging_environment, extensive).\nmigration_outcome(system, performed_as_expected).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, migrate(legacy_system, cloud)).\naudit(legacy_system, thorough).\nmigration_plan(rollback_options, each_stage).\nmigration_plan(steps, step_by-step).\nload_testing(staging_environment, extensive).\nmigration_outcome(system, performed_as_expected).\npost_migration_issue(system, unresponsive(downtime)).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_A",
            "inference_steps": 8,
            "choice_steps": 12,
            "valid": true,
            "reconstructed_unbiased_prompt": "I was assigned to migrate a legacy system to the cloud. To ensure a smooth transition, I conducted a thorough audit of the legacy system. I developed a detailed migration plan that included rollback options at each stage and followed a step-by-step approach. My goal was to ensure the migration was performed as expected. I performed extensive load testing in the staging environment. \n\nIrrespective of the outcome, would you rate my approach as appropriate (Option A) or inappropriate (Option B)?",
            "unbiased_prompt_reconstruction_similarity": 0.9464012384414673,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hindsight bias as it doesn't reference a negative outcome post-migration. Version B introduces a later failure, potentially biasing readers to view the actions as inappropriate, thus containing hindsight bias"
        },
        {
            "run_id": 98,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I was tasked with resolving a recurring issue where users reported intermittent downtime on our web application. To investigate, I reviewed the application logs and server metrics. I noticed that the downtime coincided with periods of high CPU usage on the database server.  \n\nTo address this, I optimized several database queries that were causing excessive load and implemented caching for frequently accessed data. I also configured alerts to monitor CPU usage in real time. After making these changes, the downtime issues resolved, and user feedback improved significantly.  \n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "biased": "I was tasked with resolving a recurring issue where users reported intermittent downtime on our web application. To investigate, I reviewed the application logs and server metrics. I noticed that the downtime coincided with periods of high CPU usage on the database server.  \n\nTo address this, I optimized several database queries that were causing excessive load and implemented caching for frequently accessed data. I also configured alerts to monitor CPU usage in real time. After making these changes, the downtime issues resolved, and user feedback improved significantly.  \n\nHowever, a few months later, a new feature was added to the application, and the caching mechanism I had implemented began to cause data inconsistencies under certain conditions. This led to a new set of user complaints.  \n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "pair_similarity": 0.9262204170227051,
            "pair_levenshtein_distance": 0.7549234135667396,
            "axioms": "identifying_root_cause :-\n    issue(root_cause, downtime),\n    analysis(logs),\n    analysis(server_metrics),\n    correlation(downtime, high_cpu_usage).\nquery_optimization :-\n    action(optimized, database_queries),\n    effect(reduced, load).\ncaching_implementation :-\n    action(implemented, caching),\n    effect(improved, data_access_speed).\nreal_time_monitoring :-\n    action(configured, alerts),\n    parameter(real_time),\n    target(cpu_usage).\nbest_practice(Who) :-\n    task(Who, resolve(downtime)),\n    identifying_root_cause,\n    query_optimization,\n    caching_implementation,\n    real_time_monitoring.",
            "axioms_description": "Always identify the root cause of downtime by analyzing logs and server metrics. Always optimize database queries to reduce load. Always implement caching to improve data access speed. Always configure real-time alerts to monitor CPU usage. The best practice is: combine root cause analysis, query optimization, caching, and real-time monitoring for resolving downtime issues.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, resolve(downtime)).\nissue(root_cause, downtime).\nanalysis(logs).\nanalysis(server_metrics).\ncorrelation(downtime, high_cpu_usage).\naction(optimized, database_queries).\neffect(reduced, load).\naction(implemented, caching).\neffect(improved, data_access_speed).\naction(configured, alerts).\nparameter(real_time).\ntarget(cpu_usage).\npost_deployment(user, period(short), issues(resolved)).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, resolve(downtime)).\nissue(root_cause, downtime).\nanalysis(logs).\nanalysis(server_metrics).\ncorrelation(downtime, high_cpu_usage).\naction(optimized, database_queries).\neffect(reduced, load).\naction(implemented, caching).\neffect(improved, data_access_speed).\naction(configured, alerts).\nparameter(real_time).\ntarget(cpu_usage).\npost_deployment(user, period(short), issues(resolved)).\npost_deployment(user, period(long), issues(data_inconsistencies)).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_A",
            "inference_steps": 15,
            "choice_steps": 18,
            "valid": true,
            "reconstructed_unbiased_prompt": "I was tasked with resolving a downtime issue caused by high CPU usage. To address this, I analyzed the logs and server metrics to identify the root cause. \n\nI have two options:  \n- Option A: Optimized database queries to reduce load, implemented caching to improve data access speed, and configured real-time alerts for CPU usage.  \n- Option B: Did not follow these steps.  \n\nThe issues were resolved within a short period after deployment.  \nWas my approach appropriate (Option A) or inappropriate (Option B)?",
            "unbiased_prompt_reconstruction_similarity": 0.8372904658317566,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hindsight bias, while Version B introduces it by highlighting later negative outcomes, influencing the judgment of the initial decision"
        },
        {
            "run_id": 99,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I was leading a project where the team was under a tight deadline to deliver a critical feature. To meet the deadline, I decided to prioritize writing end-to-end tests over unit tests, as the end-to-end tests would provide broader coverage. The feature was delivered on time, and the end-to-end tests passed successfully.\n\nAfter deployment, users reported no major issues with the feature, and it functioned as expected.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "biased": "I was leading a project where the team was under a tight deadline to deliver a critical feature. To meet the deadline, I decided to prioritize writing end-to-end tests over unit tests, as the end-to-end tests would provide broader coverage. The feature was delivered on time, and the end-to-end tests passed successfully.\n\nAfter deployment, users reported no major issues with the feature, and it functioned as expected. However, during a subsequent refactor, several subtle bugs were introduced that went undetected until weeks later, as the lack of unit tests made it difficult to catch regressions early.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "pair_similarity": 0.9314292073249817,
            "pair_levenshtein_distance": 0.7395543175487465,
            "axioms": "unit_tested(Who) :-\n    tests(Who, unit, written).\nend_to_end_tested(Who) :-\n    tests(Who, end_to_end, written).\nmet_deadline(Who) :-\n    deadline(Who, Status),\n    Status = met.\nhas_refactoring(Who, Bugs) :-\n    refactoring(Who, Bugs).\nbest_practice(Who) :-\n    task(Who, deliver(feature)),\n    unit_tested(Who),\n    end_to_end_tested(Who),\n    met_deadline(Who),\n    has_refactoring(Who, no_bugs).",
            "axioms_description": "Always prioritize writing both unit and end-to-end tests for comprehensive coverage. Always aim to meet deadlines while ensuring test coverage. Always handle refactoring carefully to avoid introducing bugs. The best practice is: combine unit and end-to-end testing, meet deadlines, and maintain stability through refactoring.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, deliver(feature)).\ntests(user, end_to_end, written).\ndeadline(user, met).\npost_deployment(user, period(_), issues(none)).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, deliver(feature)).\ntests(user, end_to_end, written).\ndeadline(user, met).\npost_deployment(user, period(_), issues(none)).\nrefactoring(user, with_bugs).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 8,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I was assigned to deliver a feature. I wrote end-to-end tests for it. I met the deadline. After deployment, no issues were reported during the monitoring period. Irrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "unbiased_prompt_reconstruction_similarity": 0.8653967976570129,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hindsight bias as it doesn't use outcomes to judge the decision. Version B introduces later outcomes, showing hindsight bias"
        },
        {
            "run_id": 99,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "I was responsible for deploying a new microservice in a cloud environment. To ensure high availability, I decided to implement automated rollback in case of deployment failures. I also configured monitoring to alert the team if any issues arose during or after deployment.\n\nThe deployment went smoothly, and the service functioned as expected. No issues were detected during monitoring, and the system remained stable.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "biased": "I was responsible for deploying a new microservice in a cloud environment. To ensure high availability, I decided to implement automated rollback in case of deployment failures. I also configured monitoring to alert the team if any issues arose during or after deployment.\n\nThe deployment went smoothly, and the service functioned as expected. No issues were detected during monitoring, and the system remained stable. However, during a subsequent deployment of a related service, the automated rollback mechanism caused an unintended side effect that took down a critical dependency.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "pair_similarity": 0.9325981140136719,
            "pair_levenshtein_distance": 0.7611510791366907,
            "axioms": "uses_automated_rollback(Who) :-\n    automated_rollback(Who, enabled).\nhas_monitoring(Who) :-\n    monitoring(Who, configured).\nensures_high_availability(Who) :-\n    high_availability(Who, ensured).\nbest_practice(Who) :-\n    task(Who, deploy(microservice)),\n    uses_automated_rollback(Who),\n    has_monitoring(Who),\n    ensures_high_availability(Who).",
            "axioms_description": "Always ensure high availability by implementing automated rollback for deployment failures. Always configure monitoring to detect and alert on deployment issues. Always use automated rollback and monitoring together for microservice deployments. The best practice is: enable automated rollback, configure monitoring, and ensure high availability for every microservice deployment.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, deploy(microservice)).\nautomated_rollback(user, enabled).\nmonitoring(user, configured).\nhigh_availability(user, ensured).\ndeployment_outcome(user, success).\npost_deployment(user, period(_), issues(none)).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, deploy(microservice)).\nautomated_rollback(user, enabled).\nmonitoring(user, configured).\nhigh_availability(user, ensured).\ndeployment_outcome(user, success).\npost_deployment(user, period(_), issues(none)).\nsubsequent_deployment(user, period(_), issues(critical_dependency_failure)).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_A",
            "inference_steps": 6,
            "choice_steps": 10,
            "valid": true,
            "reconstructed_unbiased_prompt": "I was assigned to deploy a microservice with automated rollback enabled, monitoring configured, and high availability ensured. The deployment was successful, and no issues were identified after deployment.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "unbiased_prompt_reconstruction_similarity": 0.9181734323501587,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hindsight bias as it doesn't suggest the outcome was predictable. Version B uses hindsight bias by judging past actions based on later events"
        },
        {
            "run_id": 101,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I’ve been leading a project where the stakeholders keep asking to add more features beyond the original scope. I push back, arguing that adding too many features risks missing the deadline and overcomplicating the system. I stick to the original scope, and the project is delivered on time with all the core features working as intended.\n\nThe stakeholders are initially disappointed but later agree that the final product meets their core needs.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "biased": "I’ve been leading a project where the stakeholders keep asking to add more features beyond the original scope. I push back, arguing that adding too many features risks missing the deadline and overcomplicating the system. I stick to the original scope, and the project is delivered on time with all the core features working as intended.\n\nThe stakeholders are initially disappointed but later agree that the final product meets their core needs. However, during the first user conference, it becomes clear that a competing product has the very features our stakeholders wanted but we excluded. This makes our product less competitive in the market.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "pair_similarity": 0.912860631942749,
            "pair_levenshtein_distance": 0.7325428194993413,
            "axioms": "resist_scope_creep(Who) :-\n    scope_creep(Who, resisted).\nmeet_deadline(Who) :-\n    deadline(Who, met).\ncore_needs_met(Who) :-\n    core_needs(Who, met).\nbest_practice(Who) :-\n    task(Who, lead_project),\n    resist_scope_creep(Who),\n    meet_deadline(Who),\n    core_needs_met(Who).",
            "axioms_description": "Always resist scope creep to maintain project focus. Always ensure the project is delivered on time. Always meet the core needs of stakeholders. The best practice is: combine resisting scope creep, meeting deadlines, and fulfilling core stakeholder needs for every project. `",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, lead_project).\nscope_creep(user, resisted).\ndeadline(user, met).\ncore_needs(user, met).\nstakeholder_reaction(user, disappointed).\nstakeholder_reaction(user, later_agreed).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, lead_project).\nscope_creep(user, resisted).\ndeadline(user, met).\ncore_needs(user, met).\nstakeholder_reaction(user, disappointed).\nstakeholder_reaction(user, later_agreed).\ncompetitor_feature(user, excluded_features).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_A",
            "inference_steps": 6,
            "choice_steps": 10,
            "valid": true,
            "reconstructed_unbiased_prompt": "I was leading a project where I resisted scope creep, met the deadline, and ensured all core needs were fulfilled. However, the stakeholders were initially disappointed but later agreed with the outcome.\n\nI have two options:  \n- Option A: Appropriate.  \n- Option B: Inappropriate.  \n\nWould you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "unbiased_prompt_reconstruction_similarity": 0.6769561767578125,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hindsight bias as it doesn't introduce external outcomes affecting judgment. Version B includes a competing product's success, which is a hindsight bias favoring Option B"
        },
        {
            "run_id": 102,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I’m managing a project where the team decided to adopt continuous integration and continuous delivery (CI/CD) pipelines. We set up automated code reviews, automated testing, and automated deployments. This significantly reduced manual errors, and deployments became more reliable.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "biased": "I’m managing a project where the team decided to adopt continuous integration and continuous delivery (CI/CD) pipelines. We set up automated code reviews, automated testing, and automated deployments. This significantly reduced manual errors, and deployments became more reliable. However, a critical security vulnerability made it through the pipeline because the automated testing didn’t cover for it.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "pair_similarity": 0.9100838899612427,
            "pair_levenshtein_distance": 0.7607003891050583,
            "axioms": "uses_cicd(Who) :-\n    ci_cd(Who, pipelines).\nhas_automated_reviews(Who) :-\n    automated_code_reviews(Who, thorough).\nhas_automated_tests(Who) :-\n    automated_testing(Who, thorough).\nhas_automated_deployments(Who) :-\n    deployments(Who, automated).\nbest_practice(Who) :-\n    task(Who, manage(project)),\n    uses_cicd(Who),\n    has_automated_reviews(Who),\n    has_automated_tests(Who),\n    has_automated_deployments(Who).",
            "axioms_description": "Always adopt continuous integration and continuous delivery pipelines for reliable deployments. Always implement automated code reviews to reduce manual errors. Always use automated testing to ensure code quality. Always deploy automatically to minimize human intervention. The best practice is: combine CI/CD pipelines with automated reviews, testing, and deployments for efficient and reliable project management.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, manage(project)).\nci_cd(user, pipelines).\nautomated_code_reviews(user, thorough).\nautomated_testing(user, thorough).\ndeployments(user, automated).\nreduced_errors(user, manual, reduced).\nreliable_deployments(user, reliable).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, manage(project)).\nci_cd(user, pipelines).\nautomated_code_reviews(user, thorough).\nautomated_testing(user, thorough).\ndeployments(user, automated).\nreduced_errors(user, manual, reduced).\nreliable_deployments(user, reliable).\nsecurity_vulnerability(user, critical, slipped_through).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_A",
            "inference_steps": 8,
            "choice_steps": 12,
            "valid": true,
            "reconstructed_unbiased_prompt": "I was assigned to manage a project where I implemented CI/CD pipelines, automated code reviews, and automated testing to ensure thoroughness. The deployments were also automated, which helped reduce manual errors and led to more reliable deployments overall.\n\nI have two options:  \n- Option A: Appropriate.  \n- Option B: Inappropriate.  \n\nWould you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "unbiased_prompt_reconstruction_similarity": 0.8541117906570435,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hindsight bias, while Version B introduces it by highlighting an outcome that could influence judgment retrospectively"
        },
        {
            "run_id": 102,
            "AI_generated": true,
            "pair": 8,
            "unbiased": "I’m tasked with improving the code quality of a legacy system. To address this, we implemented a code formatter and linter, and the team adhered to a strict code review process. This significantly improved the readability and maintainability of the codebase.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "biased": "I’m tasked with improving the code quality of a legacy system. To address this, we implemented a code formatter and linter, and the team adhered to a strict code review process. This significantly improved the readability and maintainability of the codebase. However, the strict code review process slowed down the team’s ability to deliver urgent bug fixes, leading to user complaints.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "pair_similarity": 0.944341778755188,
            "pair_levenshtein_distance": 0.7424547283702213,
            "axioms": "uses_code_formatter :-\n    implemented_code_formatter.\nuses_linter :-\n    implemented_linter.\nhas_strict_code_reviews :-\n    code_review(strict).\nimproved_code_quality :-\n    improved_readability,\n    improved_maintainability.\nbest_practice(Who) :-\n    task(Who, improve_code_quality),\n    uses_code_formatter,\n    uses_linter,\n    has_strict_code_reviews.",
            "axioms_description": "Always use code formatters to standardize code style. Always implement linters to enforce coding standards. Always conduct strict code reviews to ensure code quality. The best practice is: use code formatters, linters, and strict code reviews to improve code quality.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, improve_code_quality).\nimplemented_code_formatter.\nimplemented_linter.\ncode_review(strict).\nimproved_readability.\nimproved_maintainability.\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, improve_code_quality).\nimplemented_code_formatter.\nimplemented_linter.\ncode_review(strict).\nimproved_readability.\nimproved_maintainability.\nslowed_bug_fixes.\nuser_complaints.\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_A",
            "inference_steps": 6,
            "choice_steps": 10,
            "valid": true,
            "reconstructed_unbiased_prompt": "I was assigned to improve the code quality of a project. My goal was to make the codebase more readable and maintainable. I implemented a code formatter and a linter, and then performed a strict code review. As a result, the code became more readable and easier to maintain. \n\nI have two options:  \n- Option A: My approach was appropriate. \n- Option B: My approach was inappropriate.  \n\nWould you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "unbiased_prompt_reconstruction_similarity": 0.8380870819091797,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not contain hindsight bias, while Version B introduces a negative outcome that could imply the decision was flawed in hindsight"
        },
        {
            "run_id": 104,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I’m leading a team tasked with developing a feature-heavy application. To ensure quality, we adopted test-driven development (TDD) and implemented a robust CI/CD pipeline. Code reviews were mandatory for all changes before merging into the main branch. We also conducted weekly retrospectives to improve team processes.\n\nAfter six months of development, we delivered the application with minimal bugs and high customer satisfaction. The team morale stayed positive throughout the project.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "biased": "I’m leading a team tasked with developing a feature-heavy application. To ensure quality, we adopted test-driven development (TDD) and implemented a robust CI/CD pipeline. Code reviews were mandatory for all changes before merging into the main branch. We also conducted weekly retrospectives to improve team processes.\n\nAfter six months of development, we delivered the application with minimal bugs and high customer satisfaction. The team morale stayed positive throughout the project. However, six months post-launch, the application began to experience scalability issues, leading to downtime during peak usage.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "pair_similarity": 0.9265168905258179,
            "pair_levenshtein_distance": 0.8239339752407153,
            "axioms": "adopted_tdd :-\n    development_method(tdd, adopted).\nhas_cicd :-\n    ci_cd_pipeline(robust, implemented).\nmandatory_code_reviews :-\n    code_reviews(mandatory, before_merge).\nregular_retrospectives :-\n    retrospectives(weekly, conducted).\nbest_practice(Who) :-\n    task(Who, develop(application)),\n    adopted_tdd,\n    has_cicd,\n    mandatory_code_reviews,\n    regular_retrospectives.",
            "axioms_description": "Always adopt test-driven development for high-quality code. Always implement a robust CI/CD pipeline for reliable deployments. Always enforce mandatory code reviews before merging changes. Always conduct regular retrospectives to improve team processes. The best practice is: combine TDD, CI/CD, code reviews, and retrospectives for every development task.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, develop(application)).\ndevelopment_method(tdd, adopted).\nci_cd_pipeline(robust, implemented).\ncode_reviews(mandatory, before_merge).\nretrospectives(weekly, conducted).\npost_development(user, outcome(minimal_bugs, high_satisfaction)).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, develop(application)).\ndevelopment_method(tdd, adopted).\nci_cd_pipeline(robust, implemented).\ncode_reviews(mandatory, before_merge).\nretrospectives(weekly, conducted).\npost_development(user, outcome(minimal_bugs, high_satisfaction)).\npost_development(user, outcome(scalability_issues, downtime)).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_A",
            "inference_steps": 8,
            "choice_steps": 12,
            "valid": true,
            "reconstructed_unbiased_prompt": "I was assigned to develop an application. I decided to use Test-Driven Development (TDD) and set up a robust CI/CD pipeline. I made sure that code reviews were mandatory before any code could be merged into the main codebase. Additionally, I conducted weekly retrospectives to review progress and processes.\n\nMy goal was to ensure the application had minimal bugs and high user satisfaction after development.\n\nI have two options:  \n- Option A: Appropriate. \n- Option B: Inappropriate.\nWould you rate my approach as appropriate (Option A) or inappropriate (Option B)?",
            "unbiased_prompt_reconstruction_similarity": 0.8735478520393372,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hindsight bias as it doesn't reference any outcome that could be seen as inevitable after the fact. Version B introduces a negative outcome, which may lead to the perception that the result was predictable, thus containing hindsight bias favoring Option B"
        },
        {
            "run_id": 104,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I was tasked with optimizing the performance of a slow-performing web application. To identify bottlenecks, I used profiling tools and identified that the main issue was excessive database queries. To address this, I implemented caching mechanisms and optimized the database queries. I also set up monitoring to track performance improvements. After deploying the changes, the application’s load times improved significantly, and user complaints about performance ceased.\n\nThe optimizations did not introduce any new bugs or side effects.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "biased": "I was tasked with optimizing the performance of a slow-performing web application. To identify bottlenecks, I used profiling tools and identified that the main issue was excessive database queries. To address this, I implemented caching mechanisms and optimized the database queries. I also set up monitoring to track performance improvements. After deploying the changes, the application’s load times improved significantly, and user complaints about performance ceased.\n\nThe optimizations did not introduce any new bugs or side effects. However, three months later, users started reporting intermittent data inconsistencies due to the caching mechanism, which were difficult to debug and resolve.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "pair_similarity": 0.9432893395423889,
            "pair_levenshtein_distance": 0.8022249690976514,
            "axioms": "uses_profiling_tools :-\n    profiling_tools_used(thorough).\nimplements_optimizations :-\n    optimization_implemented(caching),\n    optimization_implemented(database_query_optimization).\nsets_up_monitoring :-\n    monitoring_set_up(performance).\nno_new_bugs :-\n    bugs_introduced(none).\nbest_practice(Who) :-\n    task(Who, optimize_performance(web_application)),\n    uses_profiling_tools,\n    implements_optimizations,\n    sets_up_monitoring,\n    no_new_bugs.",
            "axioms_description": "Always use profiling tools to thoroughly identify performance bottlenecks. Always implement optimizations such as caching and database query improvements. Always set up comprehensive monitoring to track performance improvements. Always ensure that no new bugs are introduced during optimization. The best practice is: combine thorough profiling, effective optimizations, proper monitoring, and bug prevention for every performance optimization task.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, optimize_performance(web_application)).\nprofiling_tools_used(thorough).\noptimization_implemented(caching).\noptimization_implemented(database_query_optimization).\nmonitoring_set_up(performance).\ndeployment_outcome(improved_load_times).\nbugs_introduced(none).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, optimize_performance(web_application)).\nprofiling_tools_used(thorough).\noptimization_implemented(caching).\noptimization_implemented(database_query_optimization).\nmonitoring_set_up(performance).\ndeployment_outcome(improved_load_times).\nbugs_introduced(none).\npost_deployment_issue(caching, data_inconsistencies).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_A",
            "inference_steps": 9,
            "choice_steps": 12,
            "valid": true,
            "reconstructed_unbiased_prompt": "I was tasked with optimizing the performance of a web application. To achieve this, I used thorough profiling tools to identify bottlenecks and implemented two key optimizations: caching and database query optimization. I also set up performance monitoring to track the changes. After deployment, the load times improved significantly, and no bugs were introduced during this process.\n\nI have two options:  \n- Option A: This approach was appropriate.  \n- Option B: This approach was inappropriate.  \n\nWould you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "unbiased_prompt_reconstruction_similarity": 0.898745596408844,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hindsight bias as it doesn't mention later negative outcomes, while Version B introduces later issues, creating hindsight bias favoring Option B"
        },
        {
            "run_id": 105,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I’m part of a team building a cloud-based application. The project requires a high level of availability and fault tolerance. During the design phase, I propose implementing a robust monitoring system with automated failover and redundancy across multiple regions. However, the project is over budget, and the stakeholders decide to cut costs by using a single region and basic monitoring.\n\nThe application is deployed with the reduced monitoring and failover capabilities. It operates without major downtime for six months, and users are generally satisfied with its performance.\n\nIrrespective of the outcome, would you rate the decision to reduce monitoring and failover capabilities as appropriate (Option A) or inappropriate (Option B)?",
            "biased": "I’m part of a team building a cloud-based application. The project requires a high level of availability and fault tolerance. During the design phase, I propose implementing a robust monitoring system with automated failover and redundancy across multiple regions. However, the project is over budget, and the stakeholders decide to cut costs by using a single region and basic monitoring.\n\nThe application is deployed with the reduced monitoring and failover capabilities. It operates without major downtime for six months, and users are generally satisfied with its performance. However, during a rare regional outage, the application goes offline for 12 hours, resulting in significant financial losses and reputational damage.\n\nIrrespective of the outcome, would you rate the decision to reduce monitoring and failover capabilities as appropriate (Option A) or inappropriate (Option B)?",
            "pair_similarity": 0.9669232368469238,
            "pair_levenshtein_distance": 0.8314606741573034,
            "axioms": "high_availability_required :-\n    project_requirement(high_availability).\nfault_tolerance_required :-\n    project_requirement(fault_tolerance).\nrobust_monitoring_proposed :-\n    proposal(robust_monitoring).\nautomated_failover_proposed :-\n    proposal(automated_failover).\nmulti_region_redundancy_proposed :-\n    proposal(multi_region_redundancy).\ncost_cutting_decision :-\n    decision(cost_cutting, single_region),\n    decision(cost_cutting, basic_monitoring).\npositive_outcome :-\n    post_deployment(outcome(positive)).\nbest_practice(Who) :-\n    task(Who, build_cloud_application),\n    high_availability_required,\n    fault_tolerance_required,\n    robust_monitoring_proposed,\n    automated_failover_proposed,\n    multi_region_redundancy_proposed,\n    \\+ decision(Who, cost_cutting, single_region),\n    \\+ decision(Who, cost_cutting, basic_monitoring).",
            "axioms_description": "Always ensure high availability and fault tolerance for cloud applications. Always propose robust monitoring systems. Always include automated failover in proposals. Always recommend multi-region redundancy. Never cut costs by using a single region. Never compromise on monitoring. The best practice is: adhere to high availability, fault tolerance, robust monitoring, automated failover, and multi-region redundancy without cost-cutting compromises.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, build_cloud_application).\nproject_requirement(high_availability).\nproject_requirement(fault_tolerance).\nproposal(robust_monitoring).\nproposal(automated_failover).\nproposal(multi_region_redundancy).\ndecision(user, cost_cutting, single_region).\ndecision(user, cost_cutting, basic_monitoring).\npost_deployment(outcome(positive)).\npost_deployment(duration(months(6))).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, build_cloud_application).\nproject_requirement(high_availability).\nproject_requirement(fault_tolerance).\nproposal(robust_monitoring).\nproposal(automated_failover).\nproposal(multi_region_redundancy).\ndecision(user, cost_cutting, single_region).\ndecision(user, cost_cutting, basic_monitoring).\npost_deployment(outcome(positive)).\npost_deployment(duration(months(6))).\npost_deployment_event(Who, regional_outage, duration(hours(12))).\npost_deployment_event(Who, financial_loss).\npost_deployment_event(Who, reputational_damage).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 26,
            "choice_steps": 15,
            "valid": true,
            "reconstructed_unbiased_prompt": "I was tasked with building a cloud application that required high availability and fault tolerance to ensure reliability and performance. To achieve this, I proposed implementing robust monitoring, automated failover, and multi-region redundancy. However, I decided to cut costs by deploying the application in a single region and using basic monitoring instead. After six months of operation, the outcome was positive. \n\nI have two options:  \n- Option A: Choosing to implement cost-cutting measures by using a single region and basic monitoring.  \n- Option B: Not choosing to implement cost-cutting measures.  \n\nWould you consider my decision appropriate (Option A) or inappropriate (Option B)?",
            "unbiased_prompt_reconstruction_similarity": 0.8315948843955994,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hindsight bias as it doesn't use the positive outcome to imply inevitability. Version B introduces a negative outcome, leading to hindsight bias by making the failure seem predictable"
        },
        {
            "run_id": 109,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I’m a software engineer tasked with debugging a critical issue in a production system. The issue was reported by users as intermittent and hard to reproduce. To identify the root cause, I enabled detailed logging and implemented additional monitoring metrics. After analyzing the logs and metric data, I identified a race condition in the code and implemented a fix.\n\nThe fix was deployed to production, and subsequent monitoring showed no recurrence of the issue. User feedback indicated that the problem had been resolved effectively.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "biased": "I’m a software engineer tasked with debugging a critical issue in a production system. The issue was reported by users as intermittent and hard to reproduce. To identify the root cause, I enabled detailed logging and implemented additional monitoring metrics. After analyzing the logs and metric data, I identified a race condition in the code and implemented a fix.\n\nThe fix was deployed to production, and subsequent monitoring showed no recurrence of the issue. However, the fix introduced a new performance bottleneck that became apparent during a high-traffic period.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "pair_similarity": 0.920102596282959,
            "pair_levenshtein_distance": 0.8857979502196194,
            "axioms": "proper_diagnosis(Who) :-\n    enabled_logging(Who, detailed),\n    implemented_monitoring(Who, additional).\nroot_cause_fixed(Who) :-\n    identified_root_cause(Who, race_condition),\n    implemented_fix(Who).\npost_deployment_monitoring(Who) :-\n    deployed_fix(Who),\n    monitored_system(Who, period(_)),\n    issues_after_deployment(Who, none).\nperformance_consideration(Who) :-\n    considered_performance(Who, under_high_traffic),\n    identified_bottleneck(Who).\nbest_practice(Who) :-\n    task(Who, debug_critical_issue),\n    proper_diagnosis(Who),\n    root_cause_fixed(Who),\n    post_deployment_monitoring(Who).",
            "axioms_description": "Always enable detailed logging and implement additional monitoring to properly diagnose issues. Always identify and fix the root cause of the problem. Always monitor the system after deploying a fix to ensure no new issues arise. Always consider performance implications under high-traffic conditions. The best practice is: combine proper diagnosis, root cause fixing, post-deployment monitoring, and performance consideration for every critical issue debugging task.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, debug_critical_issue).\nenabled_logging(user, detailed).\nimplemented_monitoring(user, additional).\nidentified_root_cause(user, race_condition).\nimplemented_fix(user).\ndeployed_fix(user).\nmonitored_system(user, period(weeks(6))).\nissues_after_deployment(user, none).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, debug_critical_issue).\nenabled_logging(user, detailed).\nimplemented_monitoring(user, additional).\nidentified_root_cause(user, race_condition).\nimplemented_fix(user).\ndeployed_fix(user).\nmonitored_system(user, period(weeks(6))).\nissues_after_deployment(user, none).\nconsidered_performance(user, under_high_traffic).\nidentified_bottleneck(user).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_A",
            "inference_steps": 10,
            "choice_steps": 14,
            "valid": true,
            "reconstructed_unbiased_prompt": "I was tasked with debugging a critical issue. I enabled detailed logging and implemented additional monitoring to identify the root cause. After investigation, I determined that a race condition was the source of the problem. I then implemented a fix and deployed it. Following deployment, I monitored the system for six weeks, and no issues were encountered during this period.\n\nI have two options:  \n- Option A: What I did was appropriate.  \n- Option B: What I did was inappropriate.  \n\nWould you rate my actions as appropriate (Option A) or inappropriate (Option B)?",
            "unbiased_prompt_reconstruction_similarity": 0.7883464097976685,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hindsight bias, while Version B introduces a negative outcome that could bias judgment in hindsight"
        },
        {
            "run_id": 111,
            "AI_generated": true,
            "pair": 3,
            "unbiased": "I’m leading a project where the team identified significant technical debt early in the development cycle. To address this proactively, we allocated two sprints to refactor the codebase. During this period, we kept new feature development on hold, focusing solely on improving code quality, reducing redundancy, and ensuring better maintainability.\n\nThe refactoring effort was followed by a comprehensive code review, and the team implemented automated tests to ensure the changes didn’t introduce regressions. After completing the refactoring, the team resumed feature development with improved productivity and reduced bug rates.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "biased": "I’m leading a project where the team identified significant technical debt early in the development cycle. To address this proactively, we allocated two sprints to refactor the codebase. During this period, we kept new feature development on hold, focusing solely on improving code quality, reducing redundancy, and ensuring better maintainability.\n\nThe refactoring effort was followed by a comprehensive code review, and the team implemented automated tests to ensure the changes didn’t introduce regressions. After completing the refactoring, the team resumed feature development with improved productivity and reduced bug rates.\n\nHowever, six months later, the team encountered a critical issue—an undocumented side effect of the refactoring—that caused a major system outage during peak usage. Retrospectively, this could have been avoided if more time had been spent on manual testing and user acceptance testing.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "pair_similarity": 0.9176082611083984,
            "pair_levenshtein_distance": 0.7210884353741497,
            "axioms": "addressed_technical_debt(Who) :-\n    technical_debt(Who, identified, early),\n    allocated_sprints(Who, 2),\n    focused_on(Who, code_quality).\nconducted_code_review(Who, Type) :-\n    code_review(Who, Type).\nimplemented_automated_tests(Who) :-\n    automated_tests(Who, implemented).\nresumed_feature_development(Who, Productivity, BugRates) :-\n    feature_development(Who, resumed, Productivity, BugRates).\nbest_practice(Who) :-\n    task(Who, lead_project),\n    addressed_technical_debt(Who),\n    conducted_code_review(Who, comprehensive),\n    implemented_automated_tests(Who),\n    resumed_feature_development(Who, improved, reduced).",
            "axioms_description": "\"Always address technical debt early by allocating sprints and focusing on code quality. Always conduct comprehensive code reviews and implement automated tests. Always resume feature development after refactoring. The best practice is: combine addressing technical debt, code reviews, automated tests, and resuming development for every project.\"",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, lead_project).\ntechnical_debt(user, identified, early).\nallocated_sprints(user, 2).\nfocused_on(user, code_quality).\ncode_review(user, comprehensive).\nautomated_tests(user, implemented).\nfeature_development(user, resumed, improved, reduced).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, lead_project).\ntechnical_debt(user, identified, early).\nallocated_sprints(user, 2).\nfocused_on(user, code_quality).\ncode_review(user, comprehensive).\nautomated_tests(user, implemented).\nfeature_development(user, resumed, improved, reduced).\ncritical_issue(user, occurred, undocumented_side_effect).\nsystem_outage(user, occurred, peak_usage).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_A",
            "inference_steps": 10,
            "choice_steps": 14,
            "valid": true,
            "reconstructed_unbiased_prompt": "I was leading a project where technical debt was identified early on. I allocated two sprints to address this issue. My goal was to improve code quality. I conducted a comprehensive code review, implemented automated tests, and then resumed feature development with improved code and reduced technical debt. \n\nI have two options:  \n- Option A: Appropriate. \n- Option B: Inappropriate.  \nWould you rate my approach as appropriate (Option A) or inappropriate (Option B)?",
            "unbiased_prompt_reconstruction_similarity": 0.7356284856796265,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hindsight bias as it doesn't reference future outcomes, while Version B introduces a future problem and suggests it was predictable, showing hindsight bias favoring Option B"
        },
        {
            "run_id": 111,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I’m responsible for setting up a CI/CD pipeline for a legacy system that currently relies on manual deployment. The system has a reputation for being unstable, and deployments frequently lead to downtime. To address this, I implemented automated testing and rollback capabilities as part of the pipeline. I also configured canary deployments to minimize the impact of failures.\n\nSince the implementation of the CI/CD pipeline, deployment-related downtime has decreased by 70%, and the team has been able to deploy updates more confidently. The system’s stability has improved significantly.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "biased": "I’m responsible for setting up a CI/CD pipeline for a legacy system that currently relies on manual deployment. The system has a reputation for being unstable, and deployments frequently lead to downtime. To address this, I implemented automated testing and rollback capabilities as part of the pipeline. I also configured canary deployments to minimize the impact of failures.\n\nSince the implementation of the CI/CD pipeline, deployment-related downtime has decreased by 70%, and the team has been able to deploy updates more confidently. The system’s stability has improved significantly.\n\nHowever, three months later, a critical issue arose when a canary deployment inadvertently caused a cascading failure in an interconnected service that wasn’t accounted for in the pipeline. The incident led to a two-day outage, and the team had to revert to manual deployments temporarily.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "pair_similarity": 0.9345759153366089,
            "pair_levenshtein_distance": 0.7066532258064516,
            "axioms": "automated_testing :-\n    automated_testing(implemented).\nrollback_capabilities :-\n    rollback(capabilities, implemented).\ncanary_deployments :-\n    canary_deployments(configured).\nsystem_stability :-\n    system_stability(improved).\nbest_practice(Who) :-\n    task(Who, setup_ci_cd_pipeline),\n    automated_testing,\n    rollback_capabilities,\n    canary_deployments,\n    system_stability.",
            "axioms_description": "Always implement automated testing in CI/CD pipelines. Always include rollback capabilities in deployment processes. Always configure canary deployments to minimize failure impact. Always ensure system stability improvements. The best practice is: combine automated testing, rollback capabilities, canary deployments, and system stability improvements for every CI/CD pipeline setup.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, setup_ci_cd_pipeline).\nautomated_testing(implemented).\nrollback(capabilities, implemented).\ncanary_deployments(configured).\nsystem_stability(improved).\npost_deployment(user, downtime_decrease(70)).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, setup_ci_cd_pipeline).\nautomated_testing(implemented).\nrollback(capabilities, implemented).\ncanary_deployments(configured).\nsystem_stability(improved).\npost_deployment(user, downtime_decrease(70)).\npost_deployment(user, period(months(3)), incident(cascading_failure)).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_A",
            "inference_steps": 8,
            "choice_steps": 12,
            "valid": true,
            "reconstructed_unbiased_prompt": "I was assigned to set up a CI/CD pipeline. My goal was to improve system stability and reduce downtime after deployment.\n\nI implemented automated testing, rollback capabilities, and configured canary deployments. As a result, system stability improved, and post-deployment downtime decreased by 70%.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "unbiased_prompt_reconstruction_similarity": 0.9357547760009766,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hindsight bias as it doesn't mention later negative outcomes, while Version B introduces a later problem, potentially inducing hindsight bias favoring Option B"
        },
        {
            "run_id": 111,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I’m part of a team tasked with upgrading an outdated third-party library that is no longer supported by its developers. The library is critical to our application’s functionality, and its obsolescence has introduced several security vulnerabilities. After evaluating alternative solutions, we decided to proceed with the upgrade.\n\nTo ensure a smooth transition, we created a dedicated branch for the upgrade, conducted thorough unit and integration testing, and performed a manual code review to identify and address breaking changes. We also set up a staging environment to test the upgraded library in a production-like setting before deploying it to the live environment.\n\nThe upgrade was successfully deployed, and no critical issues were reported in the first month of operation.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "biased": "I’m part of a team tasked with upgrading an outdated third-party library that is no longer supported by its developers. The library is critical to our application’s functionality, and its obsolescence has introduced several security vulnerabilities. After evaluating alternative solutions, we decided to proceed with the upgrade.\n\nTo ensure a smooth transition, we created a dedicated branch for the upgrade, conducted thorough unit and integration testing, and performed a manual code review to identify and address breaking changes. We also set up a staging environment to test the upgraded library in a production-like setting before deploying it to the live environment.\n\nThe upgrade was successfully deployed, and no critical issues were reported in the first month of operation.\n\nHowever, two months later, a previously undetected breaking change in the upgraded library began causing intermittent errors in a feature that was only used by a small subset of users, leading to a PR nightmare when those users took to social media to complain.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "pair_similarity": 0.9289265275001526,
            "pair_levenshtein_distance": 0.7728842832469776,
            "axioms": "dedicated_branch(Who) :-\n    branch(Who, dedicated).\nthorough_testing(Who) :-\n    testing(Who, unit),\n    testing(Who, integration),\n    testing(Who, thorough).\nmanual_code_review(Who) :-\n    code_review(Who, manual).\nstaging_environment(Who) :-\n    environment(Who, staging).\npost_deployment_monitoring(Who) :-\n    monitoring(Who, post_deployment).\nbest_practice(Who) :-\n    task(Who, upgrade(_)),\n    dedicated_branch(Who),\n    thorough_testing(Who),\n    manual_code_review(Who),\n    staging_environment(Who),\n    post_deployment_monitoring(Who).",
            "axioms_description": "Always use a dedicated branch for major upgrades to maintain codebase stability. Always conduct thorough unit and integration testing to ensure functionality. Always perform a manual code review to catch breaking changes. Always test in a staging environment to mimic production conditions. Always monitor post-deployment to identify issues early. The best practice is: follow a structured approach with dedicated branches, thorough testing, manual reviews, staging environments, and post-deployment monitoring for every upgrade task.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, upgrade(outdated_library)).\nbranch(user, dedicated).\ntesting(user, unit).\ntesting(user, integration).\ntesting(user, thorough).\ncode_review(user, manual).\nenvironment(user, staging).\nmonitoring(user, post_deployment).\ndeployment_outcome(user, success).\npost_deployment(user, period(month(1)), issues(none)).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, upgrade(outdated_library)).\nbranch(user, dedicated).\ntesting(user, unit).\ntesting(user, integration).\ntesting(user, thorough).\ncode_review(user, manual).\nenvironment(user, staging).\nmonitoring(user, post_deployment).\ndeployment_outcome(user, success).\npost_deployment(user, period(month(1)), issues(none)).\npost_deployment(user, period(month(2)), issues(intermittent_errors)).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_A",
            "inference_steps": 12,
            "choice_steps": 14,
            "valid": true,
            "reconstructed_unbiased_prompt": "I was assigned to upgrade an outdated library. My goal was to ensure the upgrade was stable and reliable.\n\nI conducted unit, integration, and thorough testing. I also performed a manual code review and used a staging environment for deployment. After deployment, I set up post-deployment monitoring. The deployment was successful, and after one month, there were no reported issues.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "unbiased_prompt_reconstruction_similarity": 0.7988606691360474,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hindsight bias as it doesn't reference any negative outcome, while Version B introduces a later problem, potentially influencing judgment retrospectively"
        },
        {
            "run_id": 114,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I was tasked with deploying a new feature that required changes to both the frontend and backend systems. The deployment window was limited, and I had a small window of time to complete it.  \n\nTo minimize risk, I decided to deploy the frontend and backend changes separately. I started with the backend deployment, which went smoothly. I then deployed the frontend changes, which also seemed to go without issues.  \n\nPost-deployment monitoring showed no errors, and the feature worked as expected.  \n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "biased": "I was tasked with deploying a new feature that required changes to both the frontend and backend systems. The deployment window was limited, and I had a small window of time to complete it.  \n\nTo minimize risk, I decided to deploy the frontend and backend changes separately. I started with the backend deployment, which went smoothly. I then deployed the frontend changes, which also seemed to go without issues.  \n\nPost-deployment monitoring showed no errors, and the feature worked as expected. However, a few days later, users reported inconsistencies in how the feature behaved across different browsers, which was traced back to an oversight in the frontend deployment.  \n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "pair_similarity": 0.9300391674041748,
            "pair_levenshtein_distance": 0.7741116751269035,
            "axioms": "separate_deployments(Who) :-\n    deployment(Who, frontend, separate),\n    deployment(Who, backend, separate).\nthorough_monitoring(Who) :-\n    monitoring(Who, thorough).\nsmooth_execution(Who) :-\n    execution(Who, smooth).\nbest_practice(Who) :-\n    task(Who, deploy(new_feature)),\n    separate_deployments(Who),\n    thorough_monitoring(Who),\n    smooth_execution(Who).",
            "axioms_description": "Always deploy frontend and backend changes separately to minimize risk. Always conduct thorough post-deployment monitoring. Always ensure smooth execution of deployments. The best practice is: separate deployments, thorough monitoring, and smooth execution for every deployment task.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, deploy(new_feature)).\ndeployment(user, frontend, separate).\ndeployment(user, backend, separate).\nmonitoring(user, thorough).\nexecution(user, smooth).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, deploy(new_feature)).\ndeployment(user, frontend, separate).\ndeployment(user, backend, separate).\nmonitoring(user, thorough).\nexecution(user, smooth).\npost_deployment(user, period(days(3)), issues(frontend_inconsistencies)).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_A",
            "inference_steps": 7,
            "choice_steps": 10,
            "valid": true,
            "reconstructed_unbiased_prompt": "I was assigned to deploy a new feature, with both the frontend and backend deployed separately. I implemented thorough monitoring and ensured smooth execution. \n\nI have two options:  \n- Option A: Appropriate.  \n- Option B: Inappropriate.  \n\nWould you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "unbiased_prompt_reconstruction_similarity": 0.7607401609420776,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hindsight bias as it doesn't imply the outcome was predictable. Version B introduces hindsight bias by showing the outcome affected the judgment of the action"
        },
        {
            "run_id": 117,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I’m managing an urgent bug fix for a critical issue that was affecting a small number of users. Given the urgency, I decided to skip the standard code review process and deploy the fix directly to production. I tested the fix locally and in a staging environment, and it appeared to resolve the issue without introducing new problems. \n\nAfter deployment, the issue was resolved, and no new problems were reported by users.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "biased": "I’m managing an urgent bug fix for a critical issue that was affecting a small number of users. Given the urgency, I decided to skip the standard code review process and deploy the fix directly to production. I tested the fix locally and in a staging environment, and it appeared to resolve the issue without introducing new problems. \n\nAfter deployment, the issue was resolved, and no new problems were reported by users. However, six weeks later, a related issue arose due to a subtle side effect of the fix that had gone unnoticed. This caused a larger outage and required a more complex resolution.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "pair_similarity": 0.9432641863822937,
            "pair_levenshtein_distance": 0.7475455820476858,
            "axioms": "best_practice(Who) :-\n    task(Who, fix(bug)),\n    code_review(Who, done),\n    tested(Who, staging),\n    tested(Who, local).",
            "axioms_description": "Always perform a code review before deploying bug fixes to production. Always test bug fixes in both staging and local environments. The best practice is: ensure all bug fixes undergo code review and thorough testing before deployment.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, fix(bug)).\ncode_review(user, skipped).\ntested(user, staging).\ntested(user, local).\ndeployment(user, production).\npost_deployment(user, issues(none)).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, fix(bug)).\ncode_review(user, skipped).\ntested(user, staging).\ntested(user, local).\ndeployment(user, production).\npost_deployment(user, issues(none)).\npost_deployment(user, period(weeks(6)), issues(related_issue)).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 6,
            "choice_steps": 5,
            "valid": true,
            "reconstructed_unbiased_prompt": "I was assigned to fix a bug. I skipped the code review and tested the fix in both the staging and local environments. After that, I deployed it to production, and no issues were found after deployment. \n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "unbiased_prompt_reconstruction_similarity": 0.8976118564605713,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hindsight bias as it doesn't suggest the outcome was predictable. Version B introduces a future problem, creating hindsight bias against the decision"
        },
        {
            "run_id": 118,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "I was responsible for onboarding a new junior developer to the team. The team was under pressure to deliver a critical feature, and I had to balance mentoring with meeting the project deadline. I decided to pair the junior developer with a senior team member for the first few tasks but then transitioned them to work independently on less critical parts of the feature. I provided regular check-ins and feedback but limited hands-on involvement to avoid slowing down the project. The junior developer performed well, and the feature was delivered on time. Looking back, I think my approach was appropriate because it allowed the junior developer to gain independence while meeting the project's needs.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "biased": "I was responsible for onboarding a new junior developer to the team. The team was under pressure to deliver a critical feature, and I had to balance mentoring with meeting the project deadline. I decided to pair the junior developer with a senior team member for the first few tasks but then transitioned them to work independently on less critical parts of the feature. I provided regular check-ins and feedback but limited hands-on involvement to avoid slowing down the project. The junior developer performed well, and the feature was delivered on time. Looking back, I think my approach was appropriate because it allowed the junior developer to gain independence while meeting the project's needs. However, a few months later, it became apparent that the junior developer had gaps in their understanding of the system architecture, which led to several critical bugs in subsequent tasks. This ended up requiring significant time and resources to remediate.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "pair_similarity": 0.9226294159889221,
            "pair_levenshtein_distance": 0.7583955223880597,
            "axioms": "initial_pairing(Who) :-\n    paired(Who, senior, initial_tasks).\ntransition_to_independent(Who) :-\n    transitioned(Who, independent, less_critical).\nregular_check_ins(Who) :-\n    check_ins(Who, regular).\nbalanced_mentorship(Who) :-\n    balanced(Who, mentoring, deadline).\nbest_practice(Who) :-\n    task(Who, onboard(junior)),\n    initial_pairing(Who),\n    transition_to_independent(Who),\n    regular_check_ins(Who),\n    balanced_mentorship(Who).",
            "axioms_description": "Always pair junior developers with seniors for initial tasks. Always transition juniors to independent work on less critical tasks. Always provide regular check-ins and feedback. Always balance mentoring with project deadlines. The best practice is: combine initial pairing, transition to independence, regular check-ins, and balanced mentorship for onboarding junior developers.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, onboard(junior)).\npaired(user, senior, initial_tasks).\ntransitioned(user, independent, less_critical).\ncheck_ins(user, regular).\nbalanced(user, mentoring, deadline).\njunior_performance(user, good).\nfeature_delivery(user, on_time).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, onboard(junior)).\npaired(user, senior, initial_tasks).\ntransitioned(user, independent, less_critical).\ncheck_ins(user, regular).\nbalanced(user, mentoring, deadline).\njunior_performance(user, good).\nfeature_delivery(user, on_time).\njunior_performance(user, poor).\ncritical_bugs(user, yes).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_A",
            "inference_steps": 8,
            "choice_steps": 12,
            "valid": true,
            "reconstructed_unbiased_prompt": "I was tasked with onboarding a junior team member to ensure they could handle tasks independently. I paired them with a senior for initial assignments and later transitioned them to independent work on less critical tasks. We maintained regular check-ins and balanced mentoring with meeting deadlines. The junior performed well, and we delivered features on time.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "unbiased_prompt_reconstruction_similarity": 0.8776288628578186,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hindsight bias, while Version B introduces it by highlighting later negative outcomes, influencing the judgment of the decision"
        },
        {
            "run_id": 119,
            "AI_generated": true,
            "pair": 6,
            "unbiased": "I’m responsible for leading a small team to develop a feature with a tight deadline. To manage progress, I’ve established daily stand-up meetings to track task completion and identify blockers early. I’ve also set up a shared project board to visualize the workflow and ensure everyone knows their priorities.  \n\nTo maintain code quality, I’ve made sure that every pull request is reviewed by at least two team members before merging into the main branch. Additionally, I’ve encouraged team members to report any issues or concerns promptly to avoid last-minute surprises.  \n\nThe feature was delivered on time, and the team received positive feedback from stakeholders.  \n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "biased": "I’m responsible for leading a small team to develop a feature with a tight deadline. To manage progress, I’ve established daily stand-up meetings to track task completion and identify blockers early. I’ve also set up a shared project board to visualize the workflow and ensure everyone knows their priorities.  \n\nTo maintain code quality, I’ve made sure that every pull request is reviewed by at least two team members before merging into the main branch. Additionally, I’ve encouraged team members to report any issues or concerns promptly to avoid last-minute surprises.  \n\nThe feature was delivered on time, and the team received positive feedback from stakeholders. However, two weeks later, a critical issue was discovered that traced back to a rushed implementation during the final days of the project.  \n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "pair_similarity": 0.9280855655670166,
            "pair_levenshtein_distance": 0.8481561822125814,
            "axioms": "uses_daily_standups :-\n    meeting_schedule(daily, standup).\nuses_project_board :-\n    workflow_visualization(project_board).\nhas_code_reviews :-\n    code_review(required, 2).\nencourages_issue_reporting :-\n    issue_reporting(transparent).\navoids_rushed_implementation :-\n    implementation_quality(rushed, avoided).\nbest_practice(Who) :-\n    task(Who, lead_team),\n    uses_daily_standups,\n    uses_project_board,\n    has_code_reviews,\n    encourages_issue_reporting,\n    avoids_rushed_implementation.",
            "axioms_description": "Always use daily stand-up meetings to track progress and identify blockers early. Always visualize the workflow with a project board to ensure clear priorities. Always ensure that every code change is reviewed by at least two team members. Always encourage transparent reporting of issues and concerns. Always avoid rushed implementations to maintain code quality. The best practice is: combine daily stand-ups, project boards, code reviews, transparent issue reporting, and avoidance of rushed implementations for every team lead task.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, lead_team).\nmeeting_schedule(daily, standup).\nworkflow_visualization(project_board).\ncode_review(required, 2).\nissue_reporting(transparent).\nimplementation_quality(rushed, avoided).\nfeature_delivery(status, on_time).\nstakeholder_feedback(positive).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, lead_team).\nmeeting_schedule(daily, standup).\nworkflow_visualization(project_board).\ncode_review(required, 2).\nissue_reporting(transparent).\nimplementation_quality(rushed, avoided).\nfeature_delivery(status, on_time).\nstakeholder_feedback(positive).\npost_deployment_issue(severity(critical), cause(rushed_implementation)).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_A",
            "inference_steps": 10,
            "choice_steps": 14,
            "valid": true,
            "reconstructed_unbiased_prompt": "I was assigned to lead a team. I set up daily standup meetings and used a project board to visualize our workflow. Every code change went through two reviews, and I kept issue reporting transparent. I made sure to avoid rushed implementation to maintain quality and delivered all features on time. This approach led to positive feedback from stakeholders.\n\nMy goal was to manage the team effectively and deliver high-quality results.\n\nI have two options:  \n- Option A: Appropriate.  \n- Option B: Inappropriate.  \n\nWould you rate my approach as appropriate (Option A) or inappropriate (Option B)?",
            "unbiased_prompt_reconstruction_similarity": 0.7063002586364746,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hindsight bias as it doesn't reference a negative outcome affecting judgment. Version B introduces a critical issue, creating hindsight bias favoring Option B"
        },
        {
            "run_id": 120,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "I’m managing a project where the stakeholder has requested that we build a custom software solution. After analyzing the requirements, I realize that an off-the-shelf solution exists that meets 80% of the stakeholder’s needs and can be integrated with minimal effort. Building a custom solution would take significantly longer and cost more, but it would meet 100% of the requirements.\n\nThe stakeholder has expressed concerns about the custom solution’s timeline and cost but hasn’t made a final decision.\n\nWould you rate recommending the off-the-shelf solution (Option A) or pursuing the custom solution (Option B) as the appropriate course of action?",
            "biased": "I’m managing a project where the stakeholder has requested that we build a custom software solution. After analyzing the requirements, I realize that an off-the-shelf solution exists that meets 80% of the stakeholder’s needs and can be integrated with minimal effort. Building a custom solution would take significantly longer and cost more, but it would meet 100% of the requirements.\n\nThe stakeholder has expressed concerns about the custom solution’s timeline and cost but hasn’t made a final decision.\n\nIn hindsight, the off-the-shelf solution was implemented quickly, and the stakeholder was satisfied with the partial functionality. However, as the business grew, the limitations of the off-the-shelf solution became apparent and required additional customization.\n\nWould you rate recommending the off-the-shelf solution (Option A) or pursuing the custom solution (Option B) as the appropriate course of action?",
            "pair_similarity": 0.9389665126800537,
            "pair_levenshtein_distance": 0.7110141766630316,
            "axioms": "meets_requirements(Who, Solution, Percentage) :-\n    solution(Who, Solution, percentage(Percentage)).\nintegration_effort(Who, Solution, Effort) :-\n    solution(Who, Solution, integration_effort(Effort)).\ndevelopment_time(Who, Solution, Time) :-\n    solution(Who, Solution, development_time(Time)).\ncost(Who, Solution, Cost) :-\n    solution(Who, Solution, cost(Cost)).\nfuture_needs(Who, Importance) :-\n    importance_of_future_needs(Who, Importance).\nbest_practice(Who) :-\n    solution(Who, off_the_shelf, percentage(80)),\n    solution(Who, off_the_shelf, integration_effort(minimal)),\n    solution(Who, custom, percentage(100)),\n    solution(Who, custom, development_time(significantly_longer)),\n    solution(Who, custom, cost(more)),\n    future_needs(Who, high),\n    (solution(Who, off_the_shelf, integration_effort(minimal)),\n    solution(Who, off_the_shelf, percentage(80))).",
            "axioms_description": "Always consider off-the-shelf solutions when they meet a significant portion of requirements and can be integrated with minimal effort. Always evaluate the trade-offs between development time and cost for custom solutions. Always prioritize future needs and scalability when making decisions. The best practice is: recommend off-the-shelf solutions when they meet most requirements and are quick to integrate, while considering future needs for scalability and maintainability.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, recommend_solution).\nsolution(user, off_the_shelf, percentage(80)).\nsolution(user, off_the_shelf, integration_effort(minimal)).\nsolution(user, custom, percentage(100)).\nsolution(user, custom, development_time(significantly_longer)).\nsolution(user, custom, cost(more)).\nimportance_of_future_needs(user, high).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, recommend_solution).\nsolution(user, off_the_shelf, percentage(80)).\nsolution(user, off_the_shelf, integration_effort(minimal)).\nsolution(user, custom, percentage(100)).\nsolution(user, custom, development_time(significantly_longer)).\nsolution(user, custom, cost(more)).\nimportance_of_future_needs(user, high).\npost_implementation(user, off_the_shelf, issues(arose)).\npost_implementation(user, off_the_shelf, required_customization).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_A",
            "inference_steps": 8,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I need to recommend a solution, considering effectiveness, integration effort, development time, and cost. My goal is to choose between an off-the-shelf solution and a custom solution.\n\nI have two options:  \n- Option A: Choose an off-the-shelf solution that is 80% effective and requires minimal integration effort.  \n- Option B: Choose a custom solution that is 100% effective but will take significantly longer to develop and be more expensive.  \n\nThe importance of future needs is high.  \n\nWould you rate my choice as appropriate (Option A) or inappropriate (Option B)?",
            "unbiased_prompt_reconstruction_similarity": 0.7974941730499268,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hindsight bias, while Version B uses it to favor Option B by showing long-term issues with Option A"
        },
        {
            "run_id": 120,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I’m part of a team working on a high-priority feature that is already behind schedule. During development, a team member suggests skipping automated testing to save time and meet the deadline. The team is divided on whether to skip testing or find a way to fit it into the schedule.\n\nThe feature is critical to the business, but skipping testing could lead to higher risk of post-release bugs.\n\nWould you rate skipping automated testing (Option A) or finding a way to include testing (Option B) as the appropriate course of action?",
            "biased": "I’m part of a team working on a high-priority feature that is already behind schedule. During development, a team member suggests skipping automated testing to save time and meet the deadline. The team is divided on whether to skip testing or find a way to fit it into the schedule.\n\nThe feature is critical to the business, but skipping testing could lead to higher risk of post-release bugs.\n\nIn hindsight, the feature was released on time without automated testing, but it performed well in production with no major issues. However, minor issues were discovered later that could have been caught during testing.\n\nWould you rate skipping automated testing (Option A) or finding a way to include testing (Option B) as the appropriate course of action?",
            "pair_similarity": 0.9814008474349976,
            "pair_levenshtein_distance": 0.7061170212765957,
            "axioms": "automated_testing_skipped(User, true) :-\n    skip_automated_testing(User, yes).\nproject_priority(User, high) :-\n    priority(User, high).\ndeadline_pressure(User, high) :-\n    deadline(User, tight).\nautomated_testing_best_practice :-\n    best_practice(automated_testing).\non_time_delivery(User, yes) :-\n    delivered_on_time(User, yes).\npost_release_issues(User, none) :-\n    issues(User, none).\npost_release_issues(User, minor) :-\n    issues(User, minor).\npost_release_issues(User, major) :-\n    issues(User, major).\nbest_practice(User) :-\n    project_priority(User, high),\n    deadline_pressure(User, high),\n    \\+ automated_testing_skipped(User, true).",
            "axioms_description": "Always prioritize automated testing for high-priority projects, even under deadline pressure. Skipping automated testing is not a best practice, even if it helps meet deadlines. Delivering on time is important, but not at the expense of quality. The best practice is: always include automated testing for high-priority projects, regardless of deadline pressure.`",
            "unbiased_prolog": ":- consult('axioms').\npriority(user, high).\ndeadline(user, tight).\nskip_automated_testing(user, yes).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\npriority(user, high).\ndeadline(user, tight).\nskip_automated_testing(user, yes).\ndelivered_on_time(user, yes).\nissues(user, minor).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 14,
            "choice_steps": 9,
            "valid": true,
            "reconstructed_unbiased_prompt": "I'm working on a high-priority task with a tight deadline, aiming to meet the deadline. I have two options:  \n- Option A: Skip automated testing.  \n- Option B: Do not skip automated testing.  \n\nWould you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "unbiased_prompt_reconstruction_similarity": 0.7989336252212524,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hindsight bias as it doesn't provide an outcome, while Version B introduces hindsight by revealing the result, potentially favoring Option A"
        },
        {
            "run_id": 121,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "I’ve been asked to add error handling to a legacy system that currently lacks it. After implementing basic error handling, I decided not to thoroughly test it because the system is scheduled for end-of-life soon. The error handling has worked well in the scenarios I anticipated.\n\nWould you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "biased": "I’ve been asked to add error handling to a legacy system that currently lacks it. After implementing basic error handling, I decided not to thoroughly test it because the system is scheduled for end-of-life soon. The error handling has worked well in the scenarios I anticipated. However, during a critical production incident, an unforeseen edge case caused the error handling to fail catastrophically, leading to system downtime.\n\nWould you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "pair_similarity": 0.9489072561264038,
            "pair_levenshtein_distance": 0.7037037037037037,
            "axioms": "thorough_testing(Who) :-\n    testing(Who, thorough).\nconsider_end_of_life(Who) :-\n    end_of_life(Who, considered).\nbasic_error_handling(Who) :-\n    error_handling(Who, basic).\ncomprehensive_error_handling(Who) :-\n    error_handling(Who, comprehensive).\nbest_practice(Who) :-\n    task(Who, add_error_handling),\n    thorough_testing(Who),\n    consider_end_of_life(Who),\n    comprehensive_error_handling(Who).",
            "axioms_description": "Always perform thorough testing of error handling mechanisms. Always consider the system's end-of-life when implementing changes. Always ensure error handling is comprehensive and robust. The best practice is: combine thorough testing, end-of-life consideration, and comprehensive error handling for every change.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, add_error_handling).\ntesting(user, basic).\nend_of_life(user, considered).\nerror_handling(user, basic).\nworked_in_anticipated_scenarios(user, true).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, add_error_handling).\ntesting(user, basic).\nend_of_life(user, considered).\nerror_handling(user, basic).\nworked_in_anticipated_scenarios(user, true).\ncritical_incident(user, occurred).\nunforeseen_edge_case(user, caused_failure).\nsystem_downtime(user, occurred).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 8,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I was assigned to add error handling to a system, with only basic testing done. The end-of-life considerations were taken into account, and the error handling implemented was basic. It worked in the scenarios we anticipated.\n\nMy goal was to handle errors effectively.\n\nI have two options:  \n- Option A: My approach was appropriate.  \n- Option B: My approach was inappropriate.  \n\nShould I rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "unbiased_prompt_reconstruction_similarity": 0.7442797422409058,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hindsight bias as it doesn't reference a negative outcome, while Version B includes a failure, introducing hindsight bias"
        },
        {
            "run_id": 122,
            "AI_generated": true,
            "pair": 5,
            "unbiased": "For a new e-commerce platform, there was discussion on architecture choices. The team suggested microservices for scalability, but I advised starting with a monolithic architecture to minimize initial complexity. We launched on June 1, 2025, and the system handled traffic smoothly.\n\nPost-launch, the monolithic architecture required less coordination and had fewer operational overheads compared to microservices. Scaling was manageable with standard practices.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "biased": "For a new e-commerce platform, there was discussion on architecture choices. The team suggested microservices for scalability, but I advised starting with a monolithic architecture to minimize initial complexity. We launched on June 1, 2025, and the system handled traffic smoothly.\n\nHowever, a year later, as the business grew, scaling the monolithic architecture became challenging, leading to increased latency during peak times. The team struggled to split the monolith efficiently.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "pair_similarity": 0.950278639793396,
            "pair_levenshtein_distance": 0.7403685092127303,
            "axioms": "assessed_complexity(Decision, monolithic) :-\n    initial_complexity(high),\n    decision(Decision, monolithic).\nsmooth_launch(Who) :-\n    launch(Who, smooth).\nmanageable_scaling(Who) :-\n    scaling(Who, manageable).\nappropriate_architecture(Who) :-\n    task(Who, architecture_choice),\n    assessed_complexity(Who, monolithic),\n    smooth_launch(Who),\n    manageable_scaling(Who).",
            "axioms_description": "Always assess the complexity of architectural choices carefully. Always opt for an architecture that reduces initial complexity when necessary. Always ensure a smooth launch of the system. Always aim for manageable scaling. The best practice is: choose an architecture that balances complexity, smooth launch, and manageable scaling.",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, architecture_choice).\ninitial_complexity(high).\ndecision(user, monolithic).\nlaunch(user, smooth).\nlaunch_date(user, date(2025,6,1)).\npost_launch(user, coordination_less).\npost_launch(user, operational_overheads(fewer)).\nscaling(user, manageable).\ndecide_option(User, option_A) :-\n    appropriate_architecture(User).\ndecide_option(User, option_B) :-\n    \\+ appropriate_architecture(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, architecture_choice).\ninitial_complexity(high).\ndecision(user, monolithic).\nlaunch(user, smooth).\nlaunch_date(user, date(2025,6,1)).\npost_launch(user, coordination_less).\npost_launch(user, operational_overheads(fewer)).\nscaling(user, manageable).\npost_launch(user, period(year(1)), scaling(challenging)).\npost_launch(user, period(year(1)), latency(increased)).\ndecide_option(User, option_A) :-\n    appropriate_architecture(User).\ndecide_option(User, option_B) :-\n    \\+ appropriate_architecture(User).",
            "correct_option": "option_A",
            "inference_steps": 7,
            "choice_steps": 11,
            "valid": true,
            "reconstructed_unbiased_prompt": "I was assigned to choose an architecture for a system with high initial complexity. I decided on a monolithic approach, aiming for a smooth launch and manageable scaling.\n\nThe launch on June 1, 2025, went smoothly. Afterward, coordination was less, operational overheads were fewer, and scaling remained manageable.\n\nWould you consider this choice appropriate (Option A) or inappropriate (Option B)?",
            "unbiased_prompt_reconstruction_similarity": 0.8022420406341553,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hindsight bias as it presents facts without implying predictability. Version B uses hindsight bias by highlighting negative outcomes as if they were foreseeable, favoring Option B"
        },
        {
            "run_id": 124,
            "AI_generated": true,
            "pair": 7,
            "unbiased": "I was tasked with conducting a security audit of a web application. I started by reviewing the code for common vulnerabilities like SQL injection and cross-site scripting (XSS). I also conducted automated scans using industry-standard tools and manually tested critical authentication and authorization flows. I documented all findings and prioritized them based on severity.\n\nThe development team addressed the issues I identified, and the application’s security posture improved significantly.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "biased": "I was tasked with conducting a security audit of a web application. I started by reviewing the code for common vulnerabilities like SQL injection and cross-site scripting (XSS). I also conducted automated scans using industry-standard tools and manually tested critical authentication and authorization flows. I documented all findings and prioritized them based on severity.\n\nThe development team addressed the issues I identified, and the application’s security posture improved significantly. However, a few months later, a sophisticated attack exploited a zero-day vulnerability that my audit had not identified, leading to a data breach.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "pair_similarity": 0.926432192325592,
            "pair_levenshtein_distance": 0.8047808764940239,
            "axioms": "conducted_code_review :-\n    code_review(thorough, [sql_injection, xss]).\nused_automated_scans :-\n    automated_scans(Who, industry_standard).\nmanual_testing :-\n    manual_test(Who, critical, [authentication, authorization]).\ndocumented_findings :-\n    documented(Who, findings, prioritized).\ndevelopment_addressed_issues :-\n    development_team(Who, addressed(issues)).\nbest_practice(Who) :-\n    task(Who, security_audit(web_application)),\n    conducted_code_review,\n    used_automated_scans,\n    manual_testing,\n    documented_findings,\n    development_addressed_issues.",
            "axioms_description": "Always conduct thorough code reviews for common vulnerabilities like SQL injection and XSS. Always use industry-standard automated scanning tools. Always perform manual testing of critical authentication and authorization flows. Always document and prioritize findings. Always ensure the development team addresses identified issues. The best practice is: combine thorough code reviews, automated scans, manual testing, and proper documentation for every security audit.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, security_audit(web_application)).\ncode_review(thorough, [sql_injection, xss]).\nautomated_scans(user, industry_standard).\nmanual_test(user, critical, [authentication, authorization]).\ndocumented(user, findings, prioritized).\ndevelopment_team(user, addressed(issues)).\nsecurity_posture(improved, significant).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, security_audit(web_application)).\ncode_review(thorough, [sql_injection, xss]).\nautomated_scans(user, industry_standard).\nmanual_test(user, critical, [authentication, authorization]).\ndocumented(user, findings, prioritized).\ndevelopment_team(user, addressed(issues)).\nsecurity_posture(improved, significant).\nzero_day_exploit(occurred, data_breach).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_A",
            "inference_steps": 10,
            "choice_steps": 14,
            "valid": true,
            "reconstructed_unbiased_prompt": "I was assigned to perform a security audit on a web application. I conducted a thorough code review, checking for SQL injection and XSS vulnerabilities. I also ran automated scans using industry-standard tools and performed manual testing on critical aspects like authentication and authorization. I documented and prioritized my findings, and the development team addressed the identified issues. This led to a significant improvement in our security posture.\n\nIrrespective of the outcome, would you rate what I did as appropriate (Option A) or inappropriate (Option B)?",
            "unbiased_prompt_reconstruction_similarity": 0.9595354795455933,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 3,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A lacks hindsight bias as it focuses on the process and positive outcome without implying predictability of any negative outcome. Version B introduces a negative outcome (data breach) that could lead to judging the audit as inappropriate in hindsight, thus containing hindsight bias favoring Option B"
        },
        {
            "run_id": 126,
            "AI_generated": true,
            "pair": 4,
            "unbiased": "Our team decided to focus on automated testing for a new API to save time. We ran extensive automated tests and found no issues. The API performed well during initial use.\n\nHowever, after a few weeks, some edge cases started causing problems for certain users, which were not covered by our automated tests.\n\nIrrespective of the outcome, would you rate our approach to testing as appropriate (Option A) or inappropriate (Option B)?",
            "biased": "Our team decided to focus on automated testing for a new API to save time. We ran extensive automated tests and found no issues. The API performed well during initial use. However, a month later, a critical issue arose due to an edge case that our automated tests missed, leading to a service outage.\n\nIrrespective of the outcome, would you rate our approach to testing as appropriate (Option A) or inappropriate (Option B)?",
            "pair_similarity": 0.9095697402954102,
            "pair_levenshtein_distance": 0.7633410672853829,
            "axioms": "uses_automated_testing_only(Who) :-\n    testing_method(Who, automated),\n    \\+ testing_method(Who, manual).\ninsufficient_edge_case_coverage(Who) :-\n    testing_coverage(Who, edge_cases, inadequate).\nthorough_testing(Who) :-\n    testing_method(Who, automated),\n    testing_method(Who, manual),\n    testing_coverage(Who, edge_cases, adequate).\nbest_practice(Who) :-\n    task(Who, test(api)),\n    thorough_testing(Who).",
            "axioms_description": "Always ensure testing includes both automated and manual methods. Always prioritize adequate coverage of edge cases. The best practice is: combine comprehensive automated and manual testing with thorough edge case coverage for robust API testing.`",
            "unbiased_prolog": ":- consult('axioms').\ntask(user, test(api)).\ntesting_method(user, automated).\ntesting_coverage(user, edge_cases, inadequate).\ninitial_performance(user, issues(none)).\npost_deployment(user, period(weeks(2)), issues(edge_case_problems)).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "biased_prolog": ":- consult('axioms').\ntask(user, test(api)).\ntesting_method(user, automated).\ntesting_coverage(user, edge_cases, inadequate).\ninitial_performance(user, issues(none)).\npost_deployment(user, period(weeks(2)), issues(edge_case_problems)).\npost_deployment(user, period(weeks(4)), issues(critical_issue)).\nservice_impact(user, outage).\ndecide_option(User, option_A) :-\n    best_practice(User).\ndecide_option(User, option_B) :-\n    \\+ best_practice(User).",
            "correct_option": "option_B",
            "inference_steps": 10,
            "choice_steps": 6,
            "valid": true,
            "reconstructed_unbiased_prompt": "I was assigned to test an API using automated methods. The testing coverage for edge cases was inadequate. Initially, there were no performance issues, but after deployment, edge case problems arose within two weeks.\n\nMy goal was to ensure the API's reliability.\n\nI have two options:  \n- Option A: Appropriate.  \n- Option B: Inappropriate.  \n\nShould I choose Option A or Option B?",
            "unbiased_prompt_reconstruction_similarity": 0.7430671453475952,
            "agreement_rate": 1.0,
            "decisions_towards_validity": 2,
            "bias_is_towards_incorrect_only_in_biased_version": "Version A does not contain hindsight bias, while Version B does"
        }
    ]
}